{"meta":{"title":"山西小魔头技术博客","subtitle":"没有压力的生命就会黯淡","description":"失落时悄悄徘徊，伤感时默默遐想","author":"WangQingLei","url":"https://qinglei1989.github.io","root":"/"},"pages":[{"title":"关于","date":"2021-05-16T13:08:59.000Z","updated":"2021-06-02T15:20:40.704Z","comments":true,"path":"about/index.html","permalink":"https://qinglei1989.github.io/about/index.html","excerpt":"","text":"个人简历 个人信息 中文名：王清雷 英文名：WangQL 昵称：山西小魔头 性别：男 类别：高级灵长类动物 职业：JAVA BUG开发工程师 学校：中北大学 爱好：活着 性格：善良、阳光、勤奋 专业技能 ​ 2021.06.02记录自己的不专业，努力学习，充实技能列表 自我评价 ​ 本人性格开朗，待人友善，真诚谦虚。工作积极进取，态度认真。"},{"title":"contact","date":"2021-05-16T13:19:43.000Z","updated":"2021-05-16T13:19:43.768Z","comments":true,"path":"contact/index.html","permalink":"https://qinglei1989.github.io/contact/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-05-16T13:16:04.000Z","updated":"2021-06-05T06:18:39.167Z","comments":true,"path":"categories/index.html","permalink":"https://qinglei1989.github.io/categories/index.html","excerpt":"","text":""},{"title":"friends","date":"2021-05-16T13:16:41.000Z","updated":"2021-05-16T13:16:41.265Z","comments":true,"path":"friends/index.html","permalink":"https://qinglei1989.github.io/friends/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-06-03T13:16:25.000Z","updated":"2021-06-03T16:19:16.232Z","comments":true,"path":"tags/index.html","permalink":"https://qinglei1989.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"docker-compose","slug":"docker-compose","date":"2023-04-06T15:04:16.000Z","updated":"2023-04-06T17:10:33.890Z","comments":true,"path":"2023/04/06/docker-compose/","link":"","permalink":"https://qinglei1989.github.io/2023/04/06/docker-compose/","excerpt":"Docker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用。","text":"Docker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用。 Docker Compose 简介 Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。 其代码目前在 https://github.com/docker/compose 上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 安装与卸载 Docker Desktop for Mac/Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 PS D:\\hexoBlog&gt; docker-compose --version Docker Compose version v2.15.1 PS D:\\hexoBlog&gt; 使用 术语 首先介绍几个术语。 服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元。 可见，一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。 场景最常见的项目是 web 网站，该项目应该包含 web 应用和缓存。 下面我们用 Python 来建立一个能够记录页面访问次数的 web 网站。 web 应用新建文件夹，在该目录中编写 app.py 文件 from flask import Flask from redis import Redis app &#x3D; Flask(__name__) redis &#x3D; Redis(host&#x3D;&#39;redis&#39;, port&#x3D;6379) @app.route(&#39;&#x2F;&#39;) def hello(): count &#x3D; redis.incr(&#39;hits&#39;) return &#39;Hello World! 该页面已被访问 &#123;&#125; 次。\\n&#39;.format(count) if __name__ &#x3D;&#x3D; &quot;__main__&quot;: app.run(host&#x3D;&quot;0.0.0.0&quot;, debug&#x3D;True) Dockerfile 编写 Dockerfile 文件，内容为 FROM python:3.6-alpine ADD . &#x2F;code WORKDIR &#x2F;code RUN pip install redis flask CMD [&quot;python&quot;, &quot;app.py&quot;] docker-compose.yml 编写 docker-compose.yml 文件，这个是 Compose 使用的主模板文件。 version: &#39;3&#39; services: web: build: . ports: - &quot;5000:5000&quot; redis: image: &quot;redis:alpine&quot; 运行 compose 项目 PS D:\\src&gt; cd code PS D:\\src\\code&gt; docker-compose up -d [+] Building 83.6s (9&#x2F;9) FINISHED &#x3D;&gt; [internal] load build definition from Dockerfile 0.0s &#x3D;&gt; &#x3D;&gt; transferring dockerfile: 142B 0.0s &#x3D;&gt; [internal] load .dockerignore 0.0s &#x3D;&gt; &#x3D;&gt; transferring context: 2B 0.0s &#x3D;&gt; [internal] load metadata for docker.io&#x2F;library&#x2F;python:3.6-alpine 0.8s &#x3D;&gt; [internal] load build context 0.0s &#x3D;&gt; &#x3D;&gt; transferring context: 664B 0.0s &#x3D;&gt; CACHED [1&#x2F;4] FROM docker.io&#x2F;library&#x2F;python:3.6-alpine@sha256:579978dec4602646fe1262f02b96371779bfb0294e92c913 0.0s &#x3D;&gt; [2&#x2F;4] ADD . &#x2F;code 0.0s &#x3D;&gt; [3&#x2F;4] WORKDIR &#x2F;code 0.0s &#x3D;&gt; [4&#x2F;4] RUN pip install redis flask 82.4s &#x3D;&gt; exporting to image 0.2s &#x3D;&gt; &#x3D;&gt; exporting layers 0.2s &#x3D;&gt; &#x3D;&gt; writing image sha256:01616d273ca94adc55f1d51a9a7167f3a9fa3a027125feea28e560277d193009 0.0s &#x3D;&gt; &#x3D;&gt; naming to docker.io&#x2F;library&#x2F;code-web 0.0s [+] Running 3&#x2F;3 - Network code_default Created 0.6s - Container code-web-1 Started 1.3s - Container code-redis-1 Started 1.0s PS D:\\src\\code&gt; 此时访问本地 5000 端口，每次刷新页面，计数就会加 1。 使用 命令对象与格式对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。 执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。 docker-compose 命令的基本的使用格式是 docker-compose [-f&#x3D;&lt;arg&gt;...] [options] [COMMAND] [ARGS...] 命令选项 -f, –file FILE指定使用的 Compose 模板文件，默认为docker-compose.yml`，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 命令使用说明build格式为 docker-compose build [options] [SERVICE...]。 构建（重新构建）项目中的服务容器。 服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。 可以随时在项目目录下运行 docker-compose build 来重新构建服务。 选项包括： --force-rm 删除构建过程中的临时容器。 --no-cache 构建镜像过程中不使用 cache（这将加长构建过程）。 --pull 始终尝试通过 pull 来获取更新版本的镜像。 config验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因。 down此命令将会停止 up 命令所启动的容器，并移除网络 exec进入指定的容器。 help获得一个命令的帮助。 images列出 Compose 文件中包含的镜像。 kill格式为 docker-compose kill [options] [SERVICE...]。 通过发送 SIGKILL 信号来强制停止服务容器。 支持通过 -s 参数来指定发送的信号，例如通过如下指令发送 SIGINT 信号。 docker-compose kill -s SIGINT logs格式为 docker-compose logs [options] [SERVICE...]。 查看服务容器的输出。默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 --no-color 来关闭颜色。 该命令在调试问题的时候十分有用。 pause格式为 docker-compose pause [SERVICE...]。 暂停一个服务容器。 port格式为 docker-compose port [options] SERVICE PRIVATE_PORT。 打印某个容器端口所映射的公共端口。 选项： --protocol=proto 指定端口协议，tcp（默认值）或者 udp。 --index=index 如果同一服务存在多个容器，指定命令对象容器的序号（默认为 1）。 ps格式为 docker-compose ps [options] [SERVICE...]。 列出项目中目前的所有容器。 选项： -q 只打印容器的 ID 信息。 pull格式为 docker-compose pull [options] [SERVICE...]。 拉取服务依赖的镜像。 选项： --ignore-pull-failures 忽略拉取镜像过程中的错误。 push推送服务依赖的镜像到 Docker 镜像仓库。 restart格式为 docker-compose restart [options] [SERVICE...]。 重启项目中的服务。 选项： -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm格式为 docker-compose rm [options] [SERVICE...]。 删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 选项： -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 run格式为 docker-compose run [options] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]。 在指定服务上执行一个命令。 例如： $ docker-compose run ubuntu ping docker.com 将会启动一个 ubuntu 服务容器，并执行 ping docker.com 命令。 默认情况下，如果存在关联，则所有关联的服务将会自动被启动，除非这些服务已经在运行中。 该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照配置自动创建。 两个不同点： 给定命令将会覆盖原有的自动运行命令； 不会自动创建端口，以避免冲突。 如果不希望自动启动关联的容器，可以使用 --no-deps 选项，例如 $ docker-compose run –no-deps web python manage.py shell 将不会启动 web 容器所关联的其它容器。 选项： -d 后台运行容器。 --name NAME 为容器指定一个名字。 --entrypoint CMD 覆盖默认的容器启动指令。 -e KEY=VAL 设置环境变量值，可多次使用选项来设置多个环境变量。 -u, --user=&quot;&quot; 指定运行容器的用户名或者 uid。 --no-deps 不自动启动关联的服务容器。 --rm 运行命令后自动删除容器，d 模式下将忽略。 -p, --publish=[] 映射容器端口到本地主机。 --service-ports 配置服务端口并映射到本地主机。 -T 不分配伪 tty，意味着依赖 tty 的指令将无法运行。 scale格式为 docker-compose scale [options] [SERVICE=NUM...]。 设置指定服务运行的容器个数。 通过 service=num 的参数来设置数量。例如： $ docker-compose scale web=3 db=2 将启动 3 个容器运行 web 服务，2 个容器运行 db 服务。 一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 start格式为 docker-compose start [SERVICE...]。 启动已经存在的服务容器。 stop格式为 docker-compose stop [options] [SERVICE...]。 停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top查看各个服务容器内运行的进程。 unpause格式为 docker-compose unpause [SERVICE...]。 恢复处于暂停状态中的服务。 up格式为 docker-compose up [options] [SERVICE...]。 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 链接的服务都将会被自动启动，除非已经处于运行状态。 可以说，大部分时候都可以直接通过该命令来启动一个项目。 默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。 当通过 Ctrl-C 停止命令时，所有容器将会停止。 如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。 默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 docker-compose up --no-recreate。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 docker-compose up --no-deps -d &lt;SERVICE_NAME&gt; 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。 选项： -d 在后台运行服务容器。 --no-color 不使用颜色来区分不同的服务的控制台输出。 --no-deps 不启动服务所链接的容器。 --force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。 --no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。 --no-build 不自动构建缺失的服务镜像。 -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 version格式为 docker-compose version。 打印版本信息。 Compose 模板文件 模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。 默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。 version: &quot;3&quot; services: webapp: image: examples&#x2F;web ports: - &quot;80:80&quot; volumes: - &quot;&#x2F;data&quot; build指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 version: &#39;3&#39; services: webapp: build: .&#x2F;dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。 version: &#39;3&#39; services: webapp: build: context: .&#x2F;dir dockerfile: Dockerfile-alternate args: buildno: 1 使用 cache_from 指定构建镜像的缓存 build: context: . cache_from: - alpine:latest - corp&#x2F;web_app:3.14 cap_add, cap_drop指定容器的内核能力（capacity）分配。 例如，让容器拥有所有能力可以指定为： cap_add: - ALL 去掉 NET_ADMIN 能力可以指定为： cap_drop: - NET_ADMIN command覆盖容器启动后默认执行的命令。 command: echo &quot;hello world&quot; configs仅用于 Swarm mode，详细内容请查看 Swarm mode 一节。 cgroup_parent指定父 cgroup 组，意味着将继承该组的资源限制。 例如，创建了一个 cgroup 组名称为 cgroups_1。 cgroup_parent: cgroups_1 container_name指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 deploy仅用于 Swarm mode，详细内容请查看 Swarm mode 一节 devices指定设备映射关系。 devices: - &quot;&#x2F;dev&#x2F;ttyUSB1:&#x2F;dev&#x2F;ttyUSB0&quot; depends_on解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web version: &#39;3&#39; services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。 dns自定义 DNS 服务器。可以是一个值，也可以是一个列表。 dns: 8.8.8.8 dns: - 8.8.8.8 - 114.114.114.114 dns_search配置 DNS 搜索域。可以是一个值，也可以是一个列表。 dns_search: example.com dns_search: - domain1.example.com - domain2.example.com tmpfs挂载一个 tmpfs 文件系统到容器。 tmpfs: &#x2F;run tmpfs: - &#x2F;run - &#x2F;tmp env_file从文件中获取环境变量，可以为单独的文件路径或列表。 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 env_file: .env env_file: - .&#x2F;common.env - .&#x2F;apps&#x2F;web.env - &#x2F;opt&#x2F;secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 \\# common.env: Set development environment PROG_ENV&#x3D;development environment设置环境变量。你可以使用数组或字典两种格式。 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。 environment: RACK_ENV: development SESSION_SECRET: environment: - RACK_ENV&#x3D;development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF expose暴露端口，但不映射到宿主机，只被连接的服务访问。 仅可以指定内部端口为参数 expose: - &quot;3000&quot; - &quot;8000&quot; external_links 注意：不建议使用该指令。 链接到 docker-compose.yml 外部的容器，甚至并非 Compose 管理的外部容器。 external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql extra_hosts类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息。 extra_hosts: - &quot;googledns:8.8.8.8&quot; - &quot;dockerhub:52.1.157.61&quot; 会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目。 8.8.8.8 googledns 52.1.157.61 dockerhub healthcheck通过命令检查容器是否健康运行。 healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http:&#x2F;&#x2F;localhost&quot;] interval: 1m30s timeout: 10s retries: 3 image指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 image: ubuntu image: orchardup&#x2F;postgresql image: a4bc65fd labels为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。 labels: com.startupteam.description: &quot;webapp for a startup team&quot; com.startupteam.department: &quot;devops department&quot; com.startupteam.release: &quot;rc3 for v1.0&quot; links 注意：不推荐使用该指令。 logging配置日志选项。 logging: driver: syslog options: syslog-address: &quot;tcp:&#x2F;&#x2F;192.168.0.42:123&quot; 目前支持三种日志驱动类型。 driver: &quot;json-file&quot; driver: &quot;syslog&quot; driver: &quot;none&quot; options 配置日志驱动的相关参数。 options: max-size: &quot;200k&quot; max-file: &quot;10&quot; network_mode设置网络模式。使用和 docker run 的 --network 参数一样的值。 network_mode: &quot;bridge&quot; network_mode: &quot;host&quot; network_mode: &quot;none&quot; network_mode: &quot;service:[service name]&quot; network_mode: &quot;container:[container name&#x2F;id]&quot; networks配置容器连接的网络。 version: &quot;3&quot; services: some-service: networks: - some-network - other-network networks: some-network: other-network: pid跟主机系统共享进程命名空间。打开该选项的容器之间，以及容器和宿主机系统之间可以通过进程 ID 来相互访问和操作。 pid: &quot;host&quot; ports暴露端口信息。 使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; 注意：当使用 *HOST:CONTAINER* 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 *YAML* 会自动解析 *xx:yy* 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 secrets存储敏感数据，例如 mysql 服务密码。 version: &quot;3.1&quot; services: mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: &#x2F;run&#x2F;secrets&#x2F;db_root_password secrets: - db_root_password - my_other_secret secrets: my_secret: file: .&#x2F;my_secret.txt my_other_secret: external: true security_opt指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如配置标签的用户名和角色名。 security_opt: - label:user:USER - label:role:ROLE stop_signal设置另一个信号来停止容器。在默认情况下使用的是 SIGTERM 停止容器。 stop_signal: SIGUSR1 sysctls配置容器内核参数。 sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0 sysctls: - net.core.somaxconn&#x3D;1024 - net.ipv4.tcp_syncookies&#x3D;0 ulimits指定容器的 ulimits 限制值。 例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes数据卷所挂载路径设置。可以设置为宿主机路径(HOST:CONTAINER)或者数据卷名称(VOLUME:CONTAINER)，并且可以设置访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 volumes: - &#x2F;var&#x2F;lib&#x2F;mysql - cache&#x2F;:&#x2F;tmp&#x2F;cache - ~&#x2F;configs:&#x2F;etc&#x2F;configs&#x2F;:ro 如果路径为数据卷名称，必须在文件中配置数据卷。 version: &quot;3&quot; services: my_src: image: mysql:8.0 volumes: - mysql_data:&#x2F;var&#x2F;lib&#x2F;mysql volumes: mysql_data: 其它指令此外，还有包括 domainname, entrypoint, hostname, ipc, mac_address, privileged, read_only, shm_size, restart, stdin_open, tty, user, working_dir 等指令，基本跟 docker run 中对应参数的功能一致。 指定服务容器启动后执行的入口文件。 entrypoint: &#x2F;code&#x2F;entrypoint.sh 指定容器中运行应用的用户名。 user: nginx 指定容器中工作目录。 working_dir: &#x2F;code 指定容器中搜索域名、主机名、mac 地址等。 domainname: your_website.com hostname: test mac_address: 08-00-27-00-0C-0A 允许容器中运行一些特权命令。 privileged: true 指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效，在生产环境中推荐配置为 always 或者 unless-stopped。 restart: always 以只读模式挂载容器的 root 文件系统，意味着不能对容器内容进行修改。 read_only: true 打开标准输入，可以接受外部输入。 stdin_open: true 模拟一个伪终端。 tty: true 读取变量Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量。 例如，下面的 Compose 文件将从运行它的环境中读取变量 $&#123;MONGO_VERSION&#125; 的值，并写入执行的指令中。 version: &quot;3&quot; services: db: image: &quot;mongo:$&#123;MONGO_VERSION&#125;&quot; 如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器；如果执行 MONGO_VERSION=2.8 docker-compose up 则会启动一个 mongo:2.8 镜像的容器。 若当前目录存在 .env 文件，执行 docker-compose 命令时将从该文件中读取变量。 在当前目录新建 .env 文件并写入以下内容。 \\# 支持 # 号注释 MONGO_VERSION&#x3D;3.6 执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器。","categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"}]},{"title":"docker-network","slug":"docker-network","date":"2023-04-04T14:09:29.000Z","updated":"2023-04-05T16:40:45.389Z","comments":true,"path":"2023/04/04/docker-network/","link":"","permalink":"https://qinglei1989.github.io/2023/04/04/docker-network/","excerpt":"Docker 允许通过外部访问容器或容器互联的方式来提供网络服务。","text":"Docker 允许通过外部访问容器或容器互联的方式来提供网络服务。 Docker 网络 外部访问容器 容器中可以运行一些网络应用，要让外部也可以访问这些应用，可以通过 -P 或 -p 参数来指定端口映射。 当使用 -P 标记时，Docker 会随机映射一个端口到内部容器开放的网络端口。 使用 docker container ls 可以看到，本地主机的 32768 被映射到了容器的 80 端口。此时访问本机的 32768 端口即可访问容器内 NGINX 默认页面。 PS D:\\hexoBlog&gt; docker run -d -P nginx:alpine 27aa47874b6995822708fe578f96997f37f5fcbe5b3b1d4d3fb0d625936c65b6 PS D:\\hexoBlog&gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 27aa47874b69 nginx:alpine &quot;&#x2F;docker-entrypoint.…&quot; 15 seconds ago Up 15 seconds 0.0.0.0:32772-&gt;80&#x2F;tcp friendly_thompson PS D:\\hexoBlog&gt; docker container ls -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 27aa47874b69 nginx:alpine &quot;&#x2F;docker-entrypoint.…&quot; 21 seconds ago Up 20 seconds 0.0.0.0:32772-&gt;80&#x2F;tcp friendly_thompson PS D:\\hexoBlog&gt; 同样的，可以通过 docker logs 命令来查看访问记录。 PS D:\\hexoBlog&gt; docker logs 27aa &#x2F;docker-entrypoint.sh: &#x2F;docker-entrypoint.d&#x2F; is not empty, will attempt to perform configuration &#x2F;docker-entrypoint.sh: Looking for shell scripts in &#x2F;docker-entrypoint.d&#x2F; &#x2F;docker-entrypoint.sh: Launching &#x2F;docker-entrypoint.d&#x2F;10-listen-on-ipv6-by-default.sh 10-listen-on-ipv6-by-default.sh: info: Getting the checksum of &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf 10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf &#x2F;docker-entrypoint.sh: Launching &#x2F;docker-entrypoint.d&#x2F;20-envsubst-on-templates.sh &#x2F;docker-entrypoint.sh: Launching &#x2F;docker-entrypoint.d&#x2F;30-tune-worker-processes.sh &#x2F;docker-entrypoint.sh: Configuration complete; ready for start up 2023&#x2F;04&#x2F;04 14:12:54 [notice] 1#1: using the &quot;epoll&quot; event method 2023&#x2F;04&#x2F;04 14:12:54 [notice] 1#1: nginx&#x2F;1.21.5 2023&#x2F;04&#x2F;04 14:12:54 [notice] 1#1: built by gcc 10.3.1 20211027 (Alpine 10.3.1_git20211027) 2023&#x2F;04&#x2F;04 14:12:54 [notice] 1#1: OS: Linux 5.10.16.3-microsoft-standard-WSL2 2023&#x2F;04&#x2F;04 14:12:54 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576 2023&#x2F;04&#x2F;04 14:12:54 [notice] 1#1: start worker processes 2023&#x2F;04&#x2F;04 14:12:54 [notice] 1#1: start worker process 32 2023&#x2F;04&#x2F;04 14:12:54 [notice] 1#1: start worker process 33 PS D:\\hexoBlog&gt; -p 则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort。 映射所有接口地址 使用 hostPort:containerPort 格式本地的 80 端口映射到容器的 80 端口，可以执行 PS D:\\hexoBlog&gt; docker run -d -p 80:80 nginx:alpine 9f272729128400aac8a098c63219094f1c5af8b98efb4ba99fc69a2fd9b4ad51 此时默认会绑定本地所有接口上的所有地址。 映射到指定地址的指定端口 可以使用 ip:hostPort:containerPort 格式指定映射使用一个特定地址，比如 localhost 地址 127.0.0.1 PS D:\\hexoBlog&gt; docker run -d -p 127.0.0.1:80:80 nginx:alpine da7caa7f8fb6604b338fe4e69140fb8a93fec7921a48dcb809b6be823e74ab13 PS D:\\hexoBlog&gt; 映射到指定地址的任意端口 使用 ip::containerPort 绑定 localhost 的任意端口到容器的 80 端口，本地主机会自动分配一个端口。 PS D:\\hexoBlog&gt; docker run -d -p 127.0.0.1::80 nginx:alpine 3c7709ac45f21083e0eebc3ac06ebde9277a17800b04cbc71b4ee39ea86dc425 PS D:\\hexoBlog&gt; docker container ls -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3c7709ac45f2 nginx:alpine &quot;&#x2F;docker-entrypoint.…&quot; 12 seconds ago Up 11 seconds 127.0.0.1:1347-&gt;80&#x2F;tcp modest_chatterjee PS D:\\hexoBlog&gt; 还可以使用 udp 标记来指定 udp 端口 docker run -d -p 127.0.0.1:80:80&#x2F;udp nginx:alpine 查看映射端口配置 使用 docker port 来查看当前映射的端口配置，也可以查看到绑定的地址 PS D:\\hexoBlog&gt; docker port 3c77 80 127.0.0.1:1347 PS D:\\hexoBlog&gt; 注意： 容器有自己的内部网络和 ip 地址（使用 docker inspect 查看，Docker 还可以有一个可变的网络配置。） -p 标记可以多次使用来绑定多个端口 docker run -d -p 80:80 -p 443:443 nginx:alpine 容器互联 如果你之前有 Docker 使用经验，你可能已经习惯了使用 --link 参数来使容器互联。 随着 Docker 网络的完善，强烈建议大家将容器加入自定义的 Docker 网络来连接多个容器，而不是使用 --link 参数。 新建网络 下面先创建一个新的 Docker 网络。 docker network create -d bridge my-net -d 参数指定 Docker 网络类型，有 bridge overlay。 连接容器 运行一个容器并连接到新建的 my-net 网络 PS C:\\Users\\wang&gt; docker run -it --rm --name busybox1 --network my-net busybox sh Unable to find image &#39;busybox:latest&#39; locally latest: Pulling from library&#x2F;busybox 5cc84ad355aa: Pull complete Digest: sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678 Status: Downloaded newer image for busybox:latest &#x2F; # 打开新的终端，再运行一个容器并加入到 my-net 网络 docker run -it --rm --name busybox2 --network my-net busybox sh 再打开一个新的终端查看容器信息 PS C:\\Users\\wang&gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5c9d543e62cb busybox &quot;sh&quot; 29 seconds ago Up 27 seconds busybox2 1e4adc902eaf busybox &quot;sh&quot; About a minute ago Up About a minute busybox1 PS C:\\Users\\wang&gt; 下面通过 ping 来证明 busybox1 容器和 busybox2 容器建立了互联关系。 在 busybox1 容器输入以下命令 &#x2F; # ping busybox2 PING busybox2 (172.18.0.3): 56 data bytes 64 bytes from 172.18.0.3: seq&#x3D;0 ttl&#x3D;64 time&#x3D;0.068 ms 64 bytes from 172.18.0.3: seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.166 ms 64 bytes from 172.18.0.3: seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.167 ms 64 bytes from 172.18.0.3: seq&#x3D;3 ttl&#x3D;64 time&#x3D;0.129 ms 64 bytes from 172.18.0.3: seq&#x3D;4 ttl&#x3D;64 time&#x3D;0.141 ms 64 bytes from 172.18.0.3: seq&#x3D;5 ttl&#x3D;64 time&#x3D;0.075 ms 64 bytes from 172.18.0.3: seq&#x3D;6 ttl&#x3D;64 time&#x3D;0.076 ms 64 bytes from 172.18.0.3: seq&#x3D;7 ttl&#x3D;64 time&#x3D;0.094 ms 64 bytes from 172.18.0.3: seq&#x3D;8 ttl&#x3D;64 time&#x3D;0.064 ms 64 bytes from 172.18.0.3: seq&#x3D;9 ttl&#x3D;64 time&#x3D;0.102 ms 用 ping 来测试连接 busybox2 容器，它会解析成 172.18.0.3。 同理在 busybox2 容器执行 ping busybox1，也会成功连接到。 PS C:\\Users\\wang&gt; docker run -it --rm --name busybox2 --network my-net busybox sh &#x2F; # ping busybox1 PING busybox1 (172.18.0.2): 56 data bytes 64 bytes from 172.18.0.2: seq&#x3D;0 ttl&#x3D;64 time&#x3D;0.074 ms 64 bytes from 172.18.0.2: seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.063 ms 64 bytes from 172.18.0.2: seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.227 ms 64 bytes from 172.18.0.2: seq&#x3D;3 ttl&#x3D;64 time&#x3D;0.259 ms 64 bytes from 172.18.0.2: seq&#x3D;4 ttl&#x3D;64 time&#x3D;0.162 ms 64 bytes from 172.18.0.2: seq&#x3D;5 ttl&#x3D;64 time&#x3D;0.107 ms 64 bytes from 172.18.0.2: seq&#x3D;6 ttl&#x3D;64 time&#x3D;0.093 ms 64 bytes from 172.18.0.2: seq&#x3D;7 ttl&#x3D;64 time&#x3D;0.256 ms 这样，busybox1 容器和 busybox2 容器建立了互联关系。 如果你有多个容器之间需要互相连接，推荐使用 Docker Compose。 配置 DNS 如何自定义配置容器的主机名和 DNS 呢？秘诀就是 Docker 利用虚拟文件来挂载容器的 3 个相关配置文件。 在容器中使用 mount 命令可以看到挂载信息： mount &#x2F;dev&#x2F;disk&#x2F;by-uuid&#x2F;1fec...ebdf on &#x2F;etc&#x2F;hostname type ext4 ... &#x2F;dev&#x2F;disk&#x2F;by-uuid&#x2F;1fec...ebdf on &#x2F;etc&#x2F;hosts type ext4 ... tmpfs on &#x2F;etc&#x2F;resolv.conf type tmpfs ... 这种机制可以让宿主主机 DNS 信息发生更新后，所有 Docker 容器的 DNS 配置通过 /etc/resolv.conf 文件立刻得到更新。 配置全部容器的 DNS ，也可以在 /etc/docker/daemon.json 文件中增加以下内容来设置。 在 Windows 上Docker 引擎的配置文件在“C:\\ProgramData\\Docker\\config\\daemon.json”。 配置全部容器的 DNS ，也可以在 /etc/docker/daemon.json 文件中增加以下内容来设置。 &#123; &quot;dns&quot; : [ &quot;114.114.114.114&quot;, &quot;8.8.8.8&quot; ] &#125; Windows环境修改步骤如下： 右键任务栏docker小图标，选择settings； 点击DockerEngineer选项，在弹出的设置中加入需要添加的设置（遵循json格式）； 添加完毕后点击客户端的Apply&amp;Restart即可； 这样每次启动的容器 DNS 自动配置为 114.114.114.114 和 8.8.8.8。使用以下命令来证明其已经生效。 PS C:\\Users\\wang&gt; docker run -it --rm ubuntu:18.04 cat etc&#x2F;resolv.conf nameserver 114.114.114.114 nameserver 8.8.8.8 手动指定容器的配置 如果用户想要手动指定容器的配置，可以在使用 docker run 命令启动容器时加入如下参数： -h HOSTNAME 或者 --hostname=HOSTNAME 设定容器的主机名，它会被写到容器内的 /etc/hostname 和 /etc/hosts。但它在容器外部看不到，既不会在 docker container ls 中显示，也不会在其他的容器的 /etc/hosts 看到。 --dns=IP_ADDRESS 添加 DNS 服务器到容器的 /etc/resolv.conf 中，让容器用这个服务器来解析所有不在 /etc/hosts 中的主机名。 --dns-search=DOMAIN 设定容器的搜索域，当设定搜索域为 .example.com 时，在搜索一个名为 host 的主机时，DNS 不仅搜索 host，还会搜索 host.example.com。 PS C:\\Users\\wang&gt; docker run -it --rm -h host_ubuntu --dns&#x3D;114.114.114.114 --dns-search&#x3D;test.com ubuntu Unable to find image &#39;ubuntu:latest&#39; locally latest: Pulling from library&#x2F;ubuntu 7b1a6ab2e44d: Pull complete Digest: sha256:626ffe58f6e7566e00254b638eb7e0f3b11d4da9675088f4781a50ae288f3322 Status: Downloaded newer image for ubuntu:latest root@host_ubuntu:&#x2F;# cat &#x2F;etc&#x2F;host host.conf hostname hosts root@host_ubuntu:&#x2F;# cat &#x2F;etc&#x2F;hostname host_ubuntu root@host_ubuntu:&#x2F;# cat &#x2F;etc&#x2F;hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 172.17.0.2 host_ubuntu root@host_ubuntu:&#x2F;# cat &#x2F;etc&#x2F;r rc0.d&#x2F; rc2.d&#x2F; rc4.d&#x2F; rc6.d&#x2F; resolv.conf rc1.d&#x2F; rc3.d&#x2F; rc5.d&#x2F; rcS.d&#x2F; rmt root@host_ubuntu:&#x2F;# cat &#x2F;etc&#x2F;resolv.conf search test.com nameserver 114.114.114.114 root@host_ubuntu:&#x2F;# 如果在容器启动时没有指定 –dns 和 –dns-search，Docker 会默认用宿主主机上的 /etc/resolv.conf 来配置容器的 DNS。","categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"}]},{"title":"docker-volumes","slug":"docker-volumes","date":"2023-04-03T15:14:06.000Z","updated":"2023-04-04T13:52:41.764Z","comments":true,"path":"2023/04/03/docker-volumes/","link":"","permalink":"https://qinglei1989.github.io/2023/04/03/docker-volumes/","excerpt":"如何在 Docker 内部以及容器之间管理数据，在容器中管理数据主要有两种方式：数据卷（Volumes）和 挂载主机目录 (Bind mounts)","text":"如何在 Docker 内部以及容器之间管理数据，在容器中管理数据主要有两种方式：数据卷（Volumes）和 挂载主机目录 (Bind mounts) Docker数据管理 数据卷（Volumes） 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性： 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。 创建一个数据卷 docker volume create my-vol 查看所有的 数据卷 docker volume ls PS C:\\Users\\wang&gt; docker volume ls DRIVER VOLUME NAME local my-vol PS C:\\Users\\wang&gt; 在主机里使用以下命令可以查看指定 数据卷 的信息 PS C:\\Users\\wang&gt; docker volume inspect my-vol [ &#123; &quot;CreatedAt&quot;: &quot;2023-04-03T15:33:00Z&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;my-vol&#x2F;_data&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125; ] 启动一个挂载数据卷的容器 在用 docker run 命令的时候，使用 --mount 标记来将 数据卷 挂载到容器里。在一次 docker run 中可以挂载多个 数据卷。 下面创建一个名为 web 的容器，并加载一个 数据卷 到容器的 /usr/share/nginx/html 目录。 docker run -d -P --name web --mount source&#x3D;my-vol,target&#x3D;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html nginx:alpine 查看数据卷的具体信息 在主机里使用以下命令可以查看 web 容器的信息 docker inspect web 数据卷 信息在 “Mounts” Key 下面 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Source&quot;: &quot;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;my-vol&#x2F;_data&quot;, &quot;Destination&quot;: &quot;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;z&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ], 删除数据卷 docker volume rm my-vol 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。 无主的数据卷可能会占据很多空间，要清理请使用以下命令 docker volume prune 挂载主机目录 挂载一个主机目录作为数据卷 使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。 docker run -d -P --name web --mount type&#x3D;bind,source&#x3D;d:&#x2F;src&#x2F;webapp,target&#x3D;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html nginx:alpine 上面的命令加载主机的 d:/src/webapp 目录到容器的 /usr/share/nginx/html目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径。 Docker 挂载主机目录的默认权限是 读写，用户也可以通过增加 readonly 指定为 只读。 docker run -d -P --name web --mount type&#x3D;bind,source&#x3D;d:&#x2F;src&#x2F;webapp,target&#x3D;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html,readonly nginx:alpine 加了 readonly 之后，就挂载为 只读 了。如果你在容器内 /usr/share/nginx/html 目录新建文件，会显示如下错误 PS C:\\Users\\wang&gt; docker run -d -P --name web2222 --mount type&#x3D;bind,source&#x3D;d:&#x2F;src&#x2F;webapp,target&#x3D;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html,readonly nginx:alpine 46393e69054492e61288b219c16f5abbea859ef14f56d32588f30c151b76a1fc PS C:\\Users\\wang&gt; docker exec -it 463 sh &#x2F; # cd &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F; &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html # ls test.html 新建 Microsoft Word 文档.docx &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html # touch sss.text touch: sss.text: Read-only file system &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html # 查看数据卷的具体信息 在主机里使用以下命令可以查看 web 容器的信息 docker inspect web2222 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;d:&#x2F;src&#x2F;webapp&quot;, &quot;Destination&quot;: &quot;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: false, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], 挂载一个本地主机文件作为数据卷 --mount 标记也可以从主机挂载单个文件到容器中 docker run --rm -it --mount type&#x3D;bind,source&#x3D;$HOME&#x2F;.bash_history,target&#x3D;&#x2F;root&#x2F;.bash_history ubuntu:18.04 bash PS C:\\Users\\wang&gt; docker run --rm -it --mount type&#x3D;bind,source&#x3D;$HOME&#x2F;.bash_history,target&#x3D;&#x2F;root&#x2F;.bash_history ubuntu:18.04 bash root@fef85f6abf1a:&#x2F;# history 1 git clone git@gitlab.xxxxx.com:business&#x2F;auth.git 2 git clone git@gitlab.xxxxx.com:business&#x2F;auth.git 这样就可以记录在容器输入过的命令了。","categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"}]},{"title":"docker-container","slug":"docker-container","date":"2023-04-02T15:29:00.000Z","updated":"2023-04-03T16:03:32.139Z","comments":true,"path":"2023/04/02/docker-container/","link":"","permalink":"https://qinglei1989.github.io/2023/04/02/docker-container/","excerpt":"容器是独立运行的一个或一组应用，以及它们的运行态环境。对应的，虚拟机可以理解为模拟运行的一整套操作系统（提供了运行态环境和其他系统环境）和跑在上面的应用。","text":"容器是独立运行的一个或一组应用，以及它们的运行态环境。对应的，虚拟机可以理解为模拟运行的一整套操作系统（提供了运行态环境和其他系统环境）和跑在上面的应用。 Docker容器 启动容器 启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止状态（exited）的容器重新启动。 因为 Docker 的容器实在太轻量级了，很多时候用户都是随时删除和新创建容器。 新建并启动 所需要的命令主要为 docker run。 PS D:\\hexoBlog&gt; docker run ubuntu:18.04 &#x2F;bin&#x2F;echo &#39;Hello world&#39; Unable to find image &#39;ubuntu:18.04&#39; locally 18.04: Pulling from library&#x2F;ubuntu 284055322776: Pull complete Digest: sha256:0fedbd5bd9fb72089c7bbca476949e10593cebed9b1fb9edf5b79dbbacddd7d6 Status: Downloaded newer image for ubuntu:18.04 Hello world PS D:\\hexoBlog&gt; 下面的命令则启动一个 bash 终端，允许用户进行交互。 PS D:\\hexoBlog&gt; docker run -t -i ubuntu:18.04 &#x2F;bin&#x2F;bash root@90c7e77fd36f:&#x2F;# -t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开。 在交互模式下，用户可以通过所创建的终端来输入命令，例如 PS D:\\hexoBlog&gt; docker run -t -i ubuntu:18.04 &#x2F;bin&#x2F;bash root@90c7e77fd36f:&#x2F;# pwd &#x2F; 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从 registry 下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 启动已终止容器 可以利用 docker start [OPTIONS] 容器 [容器2...] 命令，直接将一个已经终止（exited）的容器启动运行。 PS D:\\hexoBlog&gt; docker start 90c7e77fd36fe91b84dcf4b400ebc99b84875bcd7eb4df4646bf4b3e44e43b61 90c7e77fd36fe91b84dcf4b400ebc99b84875bcd7eb4df4646bf4b3e44e43b61 PS D:\\hexoBlog&gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 90c7e77fd36f ubuntu:18.04 &quot;&#x2F;bin&#x2F;bash&quot; 6 minutes ago Up 5 seconds awesome_dijkstra PS D:\\hexoBlog&gt; 守护态运行 更多的时候，需要让 Docker 在后台运行而不是直接把执行命令的结果输出在当前宿主机下。 此时，可以通过添加 -d 参数来实现。 如果不使用 -d 参数运行容器。 PS D:\\hexoBlog&gt; docker run ubuntu:18.04 &#x2F;bin&#x2F;bash -c &quot;while true; do echo hello world; sleep 1; done&quot; hello world hello world hello world 容器会把输出的结果 (STDOUT) 打印到宿主机上面 如果使用了 -d 参数运行容器。 PS D:\\hexoBlog&gt; docker run -d ubuntu:18.04 &#x2F;bin&#x2F;bash -c &quot;while true; do echo hello world; sleep 1; done&quot; 088422d392d10c33c0607f0b324d22ed77ee50e6f84b59e980d31bb8be08a146 PS D:\\hexoBlog&gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 088422d392d1 ubuntu:18.04 &quot;&#x2F;bin&#x2F;bash -c &#39;while…&quot; 28 seconds ago Up 27 seconds awesome_shirley PS D:\\hexoBlog&gt; docker container logs 088 hello world hello world hello world hello world hello world hello world hello world hello world hello world 此时容器会在后台运行并不会把输出的结果 (STDOUT) 打印到宿主机上面(输出结果可以用 docker logs 查看)。 使用 -d 参数启动后会返回一个唯一的 id，也可以通过 docker container ls 命令来查看容器信息。 要获取容器的输出信息，可以通过 docker container logs 命令。 终止 可以使用 docker container stop 来终止一个运行中的容器。 PS D:\\hexoBlog&gt; docker container stop 088 088 PS D:\\hexoBlog&gt; 例如对于上一章节中只启动了一个终端的容器，用户通过 exit 命令或 Ctrl+d 来退出终端时，所创建的容器立刻终止。 终止状态的容器可以用 docker container ls -a 命令看到。例如 PS D:\\hexoBlog&gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES PS D:\\hexoBlog&gt; docker container ls -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 088422d392d1 ubuntu:18.04 &quot;&#x2F;bin&#x2F;bash -c &#39;while…&quot; 8 minutes ago Exited (137) 50 seconds ago awesome_shirley PS D:\\hexoBlog&gt; 处于终止状态的容器，可以通过 docker container start 命令来重新启动。 此外，docker container restart 命令会将一个运行态的容器终止，然后再重新启动它。 PS D:\\hexoBlog&gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 088422d392d1 ubuntu:18.04 &quot;&#x2F;bin&#x2F;bash -c &#39;while…&quot; 6 minutes ago Up 6 minutes awesome_shirley PS D:\\hexoBlog&gt; docker container restart 088 088 进入容器 exec 命令-i -t 参数docker exec 后边可以跟多个参数，这里主要说明 -i -t 参数。 只用 -i 参数时，由于没有分配伪终端，界面没有我们熟悉的 Linux 命令提示符，但命令执行结果仍然可以返回。 当 -i -t 参数一起使用时，则可以看到我们熟悉的 Linux 命令提示符。 PS D:\\hexoBlog&gt; docker exec -it 088 &#x2F;bin&#x2F;bash root@088422d392d1:&#x2F;# exit exit docker exec 无法进入容器问题解决 docker run -d -P --name web --mount source&#x3D;my-vol,target&#x3D;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html nginx:alpine PS C:\\Users\\wang&gt; docker exec -it f9f &#x2F;bin&#x2F;bash OCI runtime exec failed: exec failed: unable to start container process: exec: &quot;&#x2F;bin&#x2F;bash&quot;: stat &#x2F;bin&#x2F;bash: no such file or directory: unknown 经过各种求教，得到的答案，nginx:alpine精简版，在做镜像的时候，只装了sh，没有装bash，所以用不了bash。shell类型有很多种，但是sh类型的shell是最基础的，所以大部分镜像都支持。这就不难理解为什么docker exec -it 可以使用 /bin/sh进入镜像内部了。 docker exec使用小技巧：后面的/bin/或者/usr/bin/可以省略掉，直接写sh 或者 bash。 导入和导出 导出容器 PS C:\\Users\\wang&gt; docker export 088 &gt; dead.tar PS C:\\Users\\wang&gt; docker import dead.tar test20210608ubuntu:v3 Error response from daemon: Error processing tar file(exit status 1): archive&#x2F;tar: invalid tar header windows下会导出到当前D:\\hexoBlog路径下 &gt;“符号仅在linux下使用 windows中只能用-o导出 导入容器快照 PS C:\\Users\\wang&gt; docker export 088 -o dead.tar PS C:\\Users\\wang&gt; docker import dead.tar test20210ntu:v3 sha256:1888c816f59ea7288cfd82be6922e493f67f05e5fbbc754a4046efb541c83197 PS C:\\Users\\wang&gt; 删除 可以使用 docker container rm 来删除一个处于终止状态的容器。 如果要删除一个运行中的容器，可以添加 -f 参数。Docker 会发送 SIGKILL 信号给容器。 PS C:\\Users\\wang&gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 088422d392d1 ubuntu:18.04 &quot;&#x2F;bin&#x2F;bash -c &#39;while…&quot; 47 minutes ago Up 6 minutes awesome_shirley PS C:\\Users\\wang&gt; docker container rm -f 088 088 PS C:\\Users\\wang&gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES PS C:\\Users\\wang&gt; docker container ls -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES PS C:\\Users\\wang&gt; 清理所有处于终止状态的容器 用 docker container ls -a 命令可以查看所有已经创建的包括终止状态的容器，如果数量太多要一个个删除可能会很麻烦，用下面的命令可以清理掉所有处于终止状态的容器。 docker container prune","categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"}]},{"title":"docker-image","slug":"docker-image","date":"2023-03-30T16:06:45.000Z","updated":"2023-03-30T16:39:10.293Z","comments":true,"path":"2023/03/31/docker-image/","link":"","permalink":"https://qinglei1989.github.io/2023/03/31/docker-image/","excerpt":"Docker 运行容器前需要本地存在对应的镜像，如果本地不存在该镜像，Docker 会从镜像仓库下载该镜像。","text":"Docker 运行容器前需要本地存在对应的镜像，如果本地不存在该镜像，Docker 会从镜像仓库下载该镜像。 Docker镜像 获取镜像 从 Docker 镜像仓库获取镜像的命令是 docker pull。其命令格式为： $ docker pull [选项] [Docker Registry 地址[:端口号]&#x2F;]仓库名[:标签] 具体的选项可以通过 docker pull --help 命令看到，这里我们说一下镜像名称的格式 Docker 镜像仓库地址：地址的格式一般是 &lt;域名/IP&gt;[:端口号]。默认地址是 Docker Hub(docker.io)。 仓库名：如之前所说，这里的仓库名是两段式名称，即 &lt;用户名&gt;/&lt;软件名&gt;。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。 PS D:\\&gt; docker pull ubuntu:18.04 18.04: Pulling from library&#x2F;ubuntu Digest: sha256:0fedbd5bd9fb72089c7bbca476949e10593cebed9b1fb9edf5b79dbbacddd7d6 Status: Image is up to date for ubuntu:18.04 docker.io&#x2F;library&#x2F;ubuntu:18.04 列出镜像 要想列出已经下载下来的镜像，可以使用 docker image ls 命令。 PS D:\\&gt; docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE test20210608ubuntu v1 78ba2af0dfd4 24 hours ago 63.1MB ubuntu 18.04 5a214d77f5d7 18 months ago 63.1MB hello-world latest feb5d9fea6a5 18 months ago 13.3kB PS D:\\&gt; 删除本地镜像 如果要删除本地的镜像，可以使用 docker image rm 命令，其格式为： $ docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 用 ID、镜像名、摘要删除镜像 PS D:\\&gt; docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE test20210608ubuntu v1 78ba2af0dfd4 24 hours ago 63.1MB ubuntu 18.04 5a214d77f5d7 18 months ago 63.1MB hello-world latest feb5d9fea6a5 18 months ago 13.3kB PS D:\\&gt; docker image rm 78b Untagged: test20210608ubuntu:v1 Deleted: sha256:78ba2af0dfd4352c1b621bc3e9769556c12dec4b918c175e35c0fb16f8afa29e Deleted: sha256:932a6bae4790489982e95401e5e5ab1c02719af61d5ca8facd5a49159f5b2999 我们也可以用镜像名，也就是 &lt;仓库名&gt;:&lt;标签&gt;，来删除镜像。 PS D:\\&gt; docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 18.04 5a214d77f5d7 18 months ago 63.1MB hello-world latest feb5d9fea6a5 18 months ago 13.3kB PS D:\\&gt; docker image rm ubuntu:18.04 Untagged: ubuntu:18.04 Untagged: ubuntu@sha256:0fedbd5bd9fb72089c7bbca476949e10593cebed9b1fb9edf5b79dbbacddd7d6 Deleted: sha256:5a214d77f5d747e6ed81632310baa6190301feeb875cf6bf9da560108fa09972 Deleted: sha256:824bf068fd3dc3ad967022f187d85250eb052f61fe158486b2df4e002f6f984e PS D:\\&gt; docker image rm hello-world Untagged: hello-world:latest Untagged: hello-world@sha256:2498fce14358aa50ead0cc6c19990fc6ff866ce72aeb5546e1d59caac3d0d60f Deleted: sha256:feb5d9fea6a5e9606aa995e879d862b825965ba48de054caab5ef356dc6b3412 Deleted: sha256:e07ee1baac5fae6a26f30cabfe54a36d3402f96afda318fe0a96cec4ca393359 PS D:\\&gt; 当然，更精确的是使用 镜像摘要 删除镜像。 PS D:\\&gt; docker image ls --digests REPOSITORY TAG DIGEST IMAGE ID CREATED SIZE ubuntu latest sha256:626ffe58f6e7566e00254b638eb7e0f3b11d4da9675088f4781a50ae288f3322 ba6acccedd29 17 months ago 72.8MB PS D:\\&gt;","categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"}]},{"title":"docker基础概念","slug":"docker-introduction","date":"2023-03-30T15:37:56.000Z","updated":"2023-03-30T15:52:27.194Z","comments":true,"path":"2023/03/30/docker-introduction/","link":"","permalink":"https://qinglei1989.github.io/2023/03/30/docker-introduction/","excerpt":"Docker基础概念","text":"Docker基础概念 Docker基础概念 什么是 Docker runc 是一个 Linux 命令行工具，用于根据 OCI容器运行时规范 创建和运行容器。 containerd 是一个守护程序，它管理容器生命周期，提供了在一个节点上执行容器和管理镜像的最小功能集。 Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。 下面的图片比较了 Docker 和传统虚拟化方式的不同之处。传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 为什么要用 Docker 作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源 由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间 传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境 开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署 对开发和运维（DevOps）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合 持续集成(Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment) 系统进行自动部署。 而且使用 Dockerfile 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。 更轻松的迁移 由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展 Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的 官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 Docker 三个基本概念 镜像（Image） 我们都知道，操作系统分为 内核 和 用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:18.04 就包含了完整的一套 Ubuntu 18.04 最小系统的 root 文件系统。 Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 不包含任何动态数据，其内容在构建之后也不会被改变。 容器（Container） 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间,因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。 仓库（Repository） 镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry就是这样的服务。 一个 Docker Registry 中可以包含多个 仓库（Repository）；每个仓库可以包含多个 标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，16.04, 18.04。我们可以通过 ubuntu:16.04，或者 ubuntu:18.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。 仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。","categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"}]},{"title":"Mybatis-json","slug":"Mybatis-json","date":"2023-03-19T09:43:01.000Z","updated":"2023-03-19T15:27:40.777Z","comments":true,"path":"2023/03/19/Mybatis-json/","link":"","permalink":"https://qinglei1989.github.io/2023/03/19/Mybatis-json/","excerpt":"最近工作中使用了Mysql的JSON字段，对相关知识点做一个简单的记录。","text":"最近工作中使用了Mysql的JSON字段，对相关知识点做一个简单的记录。 MyBatis-JSON字段 Mysql中的JSON字段 MySQL在2015年中期发布了MySQL 5.7.8，为我们提供了JSON数据类型。从那时起，它一直被用作逃避严格的列定义并存储所有形状和大小的JSON文档的一种方式：审核日志，配置设置，第三方有效负载，用户定义的字段等。 -- auto-generated definition create table sys_json ( id int auto_increment primary key, json json not null, del_flag char default &#39;1&#39; not null comment &#39;删除标记：0已删除 1未删除&#39; ); INSERT INTO sys_json (id, json, del_flag) VALUES (1, &#39;&#123;&quot;after&quot;: &quot;外呼策略:测试;优先级:7;&quot;, &quot;before&quot;: &quot;外呼策略:test030801;优先级:5;&quot;&#125;&#39;, &#39;1&#39;); INSERT INTO sys_json (id, json, del_flag) VALUES (2, &#39;&#123;&quot;id&quot;: 142, &quot;name&quot;: &quot;wql&quot;, &quot;label&quot;: &quot;李四的家人&quot;&#125;&#39;, &#39;1&#39;); INSERT INTO sys_json (id, json, del_flag) VALUES (3, &#39;&#123;&quot;id&quot;: 3000, &quot;name&quot;: &quot;wql&quot;, &quot;birthday&quot;: &quot;2023-08-08&quot;&#125;&#39;, &#39;1&#39;); 编制索引 若json字符串非数组时，可以通过$.字段名来表示查询对应的value SELECT json-&gt;&gt;&quot;$.id&quot; FROM sys_json; SELECT JSON_UNQUOTE(JSON_EXTRACT(json, &quot;$.id&quot;)) FROM sys_json; 编制列 ALTER TABLE sys_json ADD COLUMN json_id VARCHAR(255) GENERATED ALWAYS as (json-&gt;&gt;&quot;$.id&quot;); 查询 SELECT json_id FROM sys_json; 现在我们已经准备好了生成的列，我们可以像添加任何其他列一样向其添加索引。 ALTER TABLE sys_json ADD INDEX json_id (json_id) USING BTREE; 我们在 json_id上定义了一个索引，它是一个基于表达式json-&gt;&gt;&quot;$.id&quot; 生成的列。我们已经证明，当我们对 json_id列进行查询时，会使用索引。更有趣的是，优化程序足够聪明，如果我们忘记对命名 email 列进行查询，它依然可以帮助我们！ 功能索引 引用 在 MySQL 中对 JSON 编制索引 MySQL 5.7新增对JSON支持 MySql中json类型数据的查询以及在MyBatis-Plus中的使用 MybatisPlus如何处理Mysql的json类型","categories":[{"name":"持久层","slug":"持久层","permalink":"https://qinglei1989.github.io/categories/%E6%8C%81%E4%B9%85%E5%B1%82/"}],"tags":[{"name":"MyBatis-Plus","slug":"MyBatis-Plus","permalink":"https://qinglei1989.github.io/tags/MyBatis-Plus/"}]},{"title":"elasticsearch-cat","slug":"elasticsearch-cat","date":"2023-03-06T12:39:48.000Z","updated":"2023-03-06T12:39:48.937Z","comments":true,"path":"2023/03/06/elasticsearch-cat/","link":"","permalink":"https://qinglei1989.github.io/2023/03/06/elasticsearch-cat/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"elasticsearch-基础操作","slug":"elasticsearch-basic-operation","date":"2023-03-05T16:18:35.000Z","updated":"2023-03-06T17:17:17.018Z","comments":true,"path":"2023/03/06/elasticsearch-basic-operation/","link":"","permalink":"https://qinglei1989.github.io/2023/03/06/elasticsearch-basic-operation/","excerpt":"j记录索引、映射、文档的相关操作。","text":"j记录索引、映射、文档的相关操作。 Elasticsearch基础操作 索引操作 创建索引 PUT &#x2F;$&#123;index_name&#125; &#123; &quot;settings&quot;:&#123; ... &#125;, &quot;mappings&quot;:&#123; ... &#125; &#125; 示例： PUT &#x2F;wql &#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125; &#125; 删除索引 DELETE &#x2F;wql 关闭索引 POST &#x2F;wql&#x2F;_close &#123; &quot;acknowledged&quot; : true, &quot;shards_acknowledged&quot; : true, &quot;indices&quot; : &#123; &quot;wql&quot; : &#123; &quot;closed&quot; : true &#125; &#125; &#125; 打开索引 POST &#x2F;wql&#x2F;_open &#123; &quot;acknowledged&quot; : true, &quot;shards_acknowledged&quot; : true &#125; 索引别名 POST &#x2F;_aliases &#123; &quot;actions&quot;: [&#123; &quot;add&quot;: &#123; &quot;index&quot;: &quot;reindex_old&quot;, &quot;alias&quot;: &quot;index-alias&quot; &#125; &#125;, &#123; &quot;remove&quot;: &#123; &quot;index&quot;: &quot;reindex_new&quot;, &quot;alias&quot;: &quot;index-alias&quot; &#125; &#125; ] &#125; 映射操作 查看映射 GET &#x2F;bank&#x2F;_mapping &#123; &quot;bank&quot; : &#123; &quot;mappings&quot; : &#123; &quot;properties&quot; : &#123; &quot;account_number&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125;, &quot;address&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125;, &quot;age&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125;, &quot;balance&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125;, &quot;city&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125;, &quot;email&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125;, &quot;employer&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125;, &quot;firstname&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125;, &quot;gender&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125;, &quot;lastname&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125;, &quot;state&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot;, &quot;ignore_above&quot; : 256 &#125; &#125; &#125; &#125; &#125; &#125; &#125; 扩展映射 POST &#x2F;wql&#x2F;_mapping &#123; &quot;properties&quot;: &#123; &quot;address&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125; 基本数据类型 text和keyword的区别 复杂数据类型 数组类型 # 增加标签字段 POST &#x2F;hotel&#x2F;_mapping &#123; &quot;properties&quot;:&#123; &quot;tags&quot;: &#123; &quot;type&quot;:&quot;keyword&quot; &#125; &#125; &#125; # 插入数据 POST &#x2F;hotel&#x2F;_doc&#x2F;1 &#123; &quot;title&quot;: &quot;文雅酒店&quot;, &quot;price&quot;: 300, &quot;full_room&quot;: true, &quot;create_time&quot;:&quot;20211103&quot;, &quot;tags&quot;:[&quot;有车位&quot;, &quot;免费&quot;] &#125; POST &#x2F;hotel&#x2F;_doc&#x2F;2 &#123; &quot;title&quot;: &quot;文雅酒店&quot;, &quot;price&quot;: 300, &quot;full_room&quot;: true, &quot;create_time&quot;:&quot;20211103&quot;, &quot;tags&quot;:[&quot;有车位&quot;, &quot;免费WIFI&quot;] &#125; #查询数据 GET &#x2F;hotel&#x2F;_search &#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;term&quot;: &#123; &quot;tags&quot;: &#123; &quot;value&quot;: &quot;有车位&quot; &#125; &#125;&#125;, &#123;&quot;term&quot;: &#123; &quot;tags&quot;: &#123; &quot;value&quot;: &quot;免费WIFI&quot; &#125; &#125;&#125; ] &#125; &#125; &#125; # 结果 &#123; &quot;took&quot; : 5, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : &#123; &quot;value&quot; : 1, &quot;relation&quot; : &quot;eq&quot; &#125;, &quot;max_score&quot; : 0.7587298, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;hotel&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 0.7587298, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;文雅酒店&quot;, &quot;price&quot; : 300, &quot;full_room&quot; : true, &quot;create_time&quot; : &quot;20211103&quot;, &quot;tags&quot; : [ &quot;有车位&quot;, &quot;免费WIFI&quot; ] &#125; &#125; ] &#125; &#125; 动态映射 生产禁用，因为映射生成的类型可能与用户实际的预期有差异 多字段 PUT &#x2F;users &#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;user_name&quot;:&#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;user_name_keyword&quot;:&#123; &quot;type&quot;:&quot;keyword&quot; &#125; &#125; &#125; &#125; &#125; &#125; GET &#x2F;users&#x2F;_mapping &#123; &quot;users&quot; : &#123; &quot;mappings&quot; : &#123; &quot;properties&quot; : &#123; &quot;user_name&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;fields&quot; : &#123; &quot;user_name_keyword&quot; : &#123; &quot;type&quot; : &quot;keyword&quot; &#125; &#125; &#125; &#125; &#125; &#125; &#125; # 这样我们就可以实现既可以按姓名进行搜索，又可以按姓名排序了 GET &#x2F;users&#x2F;_search &#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;user_name&quot;: &quot;张三&quot; &#125; &#125;, &quot;sort&quot;: [ &#123; &quot;user_name.user_name_keyword&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125; ] &#125; 文档操作 单条写入 POST &#x2F;hotel&#x2F;_doc&#x2F;1 &#123; &quot;title&quot;: &quot;文雅酒店&quot;, &quot;price&quot;: 300, &quot;full_room&quot;: true, &quot;create_time&quot;:&quot;20211103&quot;, &quot;tags&quot;:[&quot;有车位&quot;, &quot;免费&quot;] &#125; 批量写入 POST &#x2F;_bulk &#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;hotel&quot;, &quot;_id&quot;:&quot;2&quot;&#125;&#125; &#123;&quot;title&quot;: &quot;文雅酒店&quot;,&quot;price&quot;: 300,&quot;full_room&quot;: true,&quot;create_time&quot;:&quot;20211103&quot;,&quot;tags&quot;:[&quot;有车位&quot;, &quot;免费&quot;],&quot;comment_info&quot;:&#123;&quot;favourable_commment&quot;:199,&quot;negative_comment&quot;:68&#125;&#125; &#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;users&quot;, &quot;_id&quot;:&quot;2&quot;&#125;&#125; &#123;&quot;user_name&quot;: &quot;user_name&quot;&#125; # 响应结果 &#123; &quot;took&quot; : 42, &quot;errors&quot; : false, &quot;items&quot; : [ &#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;hotel&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_version&quot; : 10, &quot;result&quot; : &quot;updated&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 17, &quot;_primary_term&quot; : 1, &quot;status&quot; : 200 &#125; &#125;, &#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;users&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 1, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 &#125; &#125; ] &#125; 单条更新 POST &#x2F;hotel&#x2F;_update&#x2F;1 &#123; &quot;doc&quot;: &#123; &quot;title&quot;: &quot;文雅酒店dag&quot; &#125; &#125; #更新结果 &#123; &quot;_index&quot; : &quot;hotel&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 12, &quot;result&quot; : &quot;updated&quot;, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;_seq_no&quot; : 21, &quot;_primary_term&quot; : 1 &#125; 批量更新 POST &#x2F;_bulk &#123;&quot;update&quot;:&#123;&quot;_index&quot;:&quot;users&quot;, &quot;_id&quot;:&quot;2&quot;&#125;&#125; &#123;&quot;doc&quot;:&#123;&quot;user_name&quot;: &quot;user_name&quot;&#125;&#125; 根据条件更新 POST &#x2F;users&#x2F;_update_by_query &#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;user_name&quot;: &#123; &quot;value&quot;: &quot;user_name&quot; &#125; &#125; &#125;, &quot;script&quot;: &#123; &quot;source&quot;: &quot;ctx._source[&#39;user_name&#39;] &#x3D; &#39;wql&#39;&quot;, &quot;lang&quot;: &quot;painless&quot; &#125; &#125; 单条删除 DELETE &#x2F;hotel&#x2F;_doc&#x2F;1 批量删除 POST &#x2F;_bulk &#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;users&quot;, &quot;_id&quot;:&quot;2&quot;&#125;&#125; &#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;hotel&quot;, &quot;_id&quot;:&quot;2&quot;&#125;&#125; 根据条件删除 POST &#x2F;users&#x2F;_delete_by_query &#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;user_name&quot;: &#123; &quot;value&quot;: &quot;wql&quot; &#125; &#125; &#125; &#125;","categories":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://qinglei1989.github.io/tags/Elasticsearch/"}]},{"title":"elasticsearch-optimize","slug":"elasticsearch-optimize","date":"2023-02-27T16:25:35.000Z","updated":"2023-02-27T17:16:44.506Z","comments":true,"path":"2023/02/28/elasticsearch-optimize/","link":"","permalink":"https://qinglei1989.github.io/2023/02/28/elasticsearch-optimize/","excerpt":"ElasticSearch调优手册","text":"ElasticSearch调优手册 ElasticSearch调优手册 写给Java应用开发看的ElasticSearch调优手册 https://blog.csdn.net/weixin_43824520/article/details/126860414 https://blog.csdn.net/weixin_42277397/article/details/124689975 https://www.cnblogs.com/jluo/p/16821479.html","categories":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://qinglei1989.github.io/tags/Elasticsearch/"}]},{"title":"工作总结-服务启动预热","slug":"work-summary-preheat","date":"2023-02-25T15:21:11.000Z","updated":"2023-02-25T16:47:26.908Z","comments":true,"path":"2023/02/25/work-summary-preheat/","link":"","permalink":"https://qinglei1989.github.io/2023/02/25/work-summary-preheat/","excerpt":"K8s容器服务启动预热优化思路与总结。","text":"K8s容器服务启动预热优化思路与总结。 工作总结-服务启动预热 1、背景介绍 authority-api在2023年2月9日下午16点40分进行了线上发布。发布的时候有业务反馈调用auth接口出现超时的情况。下图为authority项目当时的499超时请求。 经过查看发现超时的请求全部为新启动的POD。而且过一会之后服务恢复稳定，接口响应也恢复正常。 authority-api-v1-7bdbf7d9c-j6hrp authority-api-v1-7bdbf7d9c-d97tk 以authority-api-v1-7bdbf7d9c-d97tk为例做分析： [082d24b4e4644e8d8706e2ba5b2e4d9b] 2023-02-09 16:46:18 - [INFO] [SlowLogAspect:67 logController] 请求开始 controller HealthController.healthCheck [] [082d24b4e4644e8d8706e2ba5b2e4d9b] 2023-02-09 16:46:18 - [INFO] [SlowLogAspect:73 logController] 请求结束，controller response &#123;&quot;errMsg&quot;:&quot;ok&quot;,&quot;errorMsg&quot;:&quot;ok&quot;,&quot;status&quot;:0,&quot;ts&quot;:1675932378516,&quot;version&quot;:0&#125;, elapse[16ms] 2023-02-09 16:46:18健康检查通过 nginx日志： work@authority-api-v1-7bdbf7d9c-d97tk:~$ less &#x2F;mnt&#x2F;logs&#x2F;nginx&#x2F;access-2023-02-09.log remote_addr&#x3D;[172.17.3.120] http_x_forward&#x3D;[172.20.240.117, 172.20.240.117, 10.170.20.168,10.178.25.154] time&#x3D;[2023-02-09T16:46:19+08:00] request&#x3D;[POST &#x2F;users&#x2F;search?with&#x3D;roles.permissions&amp;_octo&#x3D;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiI5OGE2YmI3MmJlYmM0YjY0YjIyNWViYjJlYzI0YjAxOSIsImlhdCI6MTY3NTkzMTE5NywiZXhwIjoxNjc1OTM0Nzk3fQ.ZoBDoNVPVZYmvhZWEnc551LP4RCHFQlgCtMpeUZlBtE HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[179] elapsed&#x3D;[0.103] refer&#x3D;[-] body&#x3D;[search&#x3D;] ua&#x3D;[Java&#x2F;1.8.0_74] cookie&#x3D;[-] gzip&#x3D;[-] log_id&#x3D;[authority-api-v1-7bdbf7d9c-d97tk71675932379.6971457172.20.240.117, 172.20.240.117, 10.170.20.168,10.178.25.15447] msec&#x3D;[1675932379.697] http_host&#x3D;[authority-api.production.svc.renrenaiche.cn] http_accept&#x3D;[application&#x2F;json|-|-] upstream_response_time&#x3D;[0.102] sent_http_set_cookie&#x3D;[-] session_id&#x3D;[-] rrc_tg&#x3D;[-] x-request-id&#x3D;[f4f9de521b231417c8480aa32ee905b3] remote_addr&#x3D;[172.17.10.26] http_x_forward&#x3D;[-] time&#x3D;[2023-02-09T16:46:22+08:00] request&#x3D;[POST &#x2F;api&#x2F;v1&#x2F;user&#x2F;list HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[437] elapsed&#x3D;[3.517] refer&#x3D;[-] body&#x3D;[[59089]] ua&#x3D;[okhttp&#x2F;3.8.1] cookie&#x3D;[-] gzip&#x3D;[-] log_id&#x3D;[authority-api-v1-7bdbf7d9c-d97tk71675932382.935650-35] msec&#x3D;[1675932382.935] http_host&#x3D;[authority-api.production.svc.renrenaiche.cn] http_accept&#x3D;[*&#x2F;*|gzip|-] upstream_response_time&#x3D;[3.518] sent_http_set_cookie&#x3D;[-] session_id&#x3D;[-] rrc_tg&#x3D;[-] x-request-id&#x3D;[71804753-1dd8-9336-a4b0-f558e2661c79] remote_addr&#x3D;[172.17.3.120] http_x_forward&#x3D;[172.20.240.117, 172.20.240.117, 10.170.20.172,10.178.25.136] time&#x3D;[2023-02-09T16:46:22+08:00] request&#x3D;[POST &#x2F;users&#x2F;search?with&#x3D;roles.permissions&amp;_octo&#x3D;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiI5OGE2YmI3MmJlYmM0YjY0YjIyNWViYjJlYzI0YjAxOSIsImlhdCI6MTY3NTkzMTE5NywiZXhwIjoxNjc1OTM0Nzk3fQ.ZoBDoNVPVZYmvhZWEnc551LP4RCHFQlgCtMpeUZlBtE HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[179] elapsed&#x3D;[0.015] refer&#x3D;[-] body&#x3D;[search&#x3D;] ua&#x3D;[Java&#x2F;1.8.0_74] cookie&#x3D;[-] gzip&#x3D;[-] log_id&#x3D;[authority-api-v1-7bdbf7d9c-d97tk71675932382.9831457172.20.240.117, 172.20.240.117, 10.170.20.172,10.178.25.136302] msec&#x3D;[1675932382.983] http_host&#x3D;[authority-api.production.svc.renrenaiche.cn] http_accept&#x3D;[application&#x2F;json|-|-] upstream_response_time&#x3D;[0.016] sent_http_set_cookie&#x3D;[-] session_id&#x3D;[-] rrc_tg&#x3D;[-] x-request-id&#x3D;[6128250dc00d2af915fec4682005a4ca] remote_addr&#x3D;[172.17.7.254] http_x_forward&#x3D;[10.178.33.82, 10.178.25.161,10.178.25.154] time&#x3D;[2023-02-09T16:46:23+08:00] request&#x3D;[POST &#x2F;users&#x2F;search?search&#x3D;id%3A57801&amp;filter&#x3D;id%3Bname%3Busername%3Buser_id%3Bmobile HTTP&#x2F;1.1] status&#x3D;[499] byte&#x3D;[0] elapsed&#x3D;[5.033] refer&#x3D;[-] body&#x3D;[-] ua&#x3D;[okhttp&#x2F;3.3.1] cookie&#x3D;[-] gzip&#x3D;[-] log_id&#x3D;[authority-api-v1-7bdbf7d9c-d97tk71675932383.940178910.178.33.82, 10.178.25.161,10.178.25.15411] msec&#x3D;[1675932383.940] http_host&#x3D;[authority-api.production.svc.renrenaiche.cn] http_accept&#x3D;[*&#x2F;*|gzip|-] upstream_response_time&#x3D;[5.034] sent_http_set_cookie&#x3D;[-] session_id&#x3D;[-] rrc_tg&#x3D;[-] x-request-id&#x3D;[17859928592f6c1374e2cfdfd081ffb4] remote_addr&#x3D;[172.17.7.254] http_x_forward&#x3D;[10.178.42.106, 10.178.25.136,10.178.25.154] time&#x3D;[2023-02-09T16:46:25+08:00] request&#x3D;[POST &#x2F;users&#x2F;search?with&#x3D;roles%3Bhr&amp;trashed&#x3D;true&amp;search&#x3D;id%3A67730%3Bid%3A50654%3Bid%3A74590 HTTP&#x2F;1.1] status&#x3D;[499] byte&#x3D;[0] elapsed&#x3D;[4.999] refer&#x3D;[-] body&#x3D;[-] ua&#x3D;[okhttp&#x2F;3.3.1] cookie&#x3D;[-] gzip&#x3D;[-] log_id&#x3D;[authority-api-v1-7bdbf7d9c-d97tk71675932385.076193210.178.42.106, 10.178.25.136,10.178.25.154100] msec&#x3D;[1675932385.076] http_host&#x3D;[authority-api.production.svc.renrenaiche.cn] http_accept&#x3D;[*&#x2F;*|gzip|-] upstream_response_time&#x3D;[4.998] sent_http_set_cookie&#x3D;[-] session_id&#x3D;[-] rrc_tg&#x3D;[-] x-request-id&#x3D;[fc9b822972501e8eb0832b262002f52e] remote_addr&#x3D;[172.17.3.120] http_x_forward&#x3D;[10.178.18.204, 10.178.25.154,10.178.25.136] time&#x3D;[2023-02-09T16:46:25+08:00] request&#x3D;[POST &#x2F;api&#x2F;v1&#x2F;partner&#x2F;area&#x2F;subordinate&#x2F;batch HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[361] elapsed&#x3D;[3.204] refer&#x3D;[-] body&#x3D;[[56900]] ua&#x3D;[Java&#x2F;1.8.0_222] cookie&#x3D;[-] gzip&#x3D;[-] log_id&#x3D;[authority-api-v1-7bdbf7d9c-d97tk71675932385.586181110.178.18.204, 10.178.25.154,10.178.25.136274] msec&#x3D;[1675932385.586] http_host&#x3D;[authority-api.production.svc.renrenaiche.cn] http_accept&#x3D;[*&#x2F;*|-|-] upstream_response_time&#x3D;[3.204] sent_http_set_cookie&#x3D;[-] session_id&#x3D;[-] rrc_tg&#x3D;[-] x-request-id&#x3D;[2f1e322ec3abd614c6c9467a84b6b0d9] remote_addr&#x3D;[172.17.3.120] http_x_forward&#x3D;[10.178.18.204, 10.178.25.154,10.178.25.136] time&#x3D;[2023-02-09T16:46:25+08:00] request&#x3D;[POST &#x2F;api&#x2F;v1&#x2F;partner&#x2F;area&#x2F;subordinate&#x2F;batch HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[355] elapsed&#x3D;[2.851] refer&#x3D;[-] body&#x3D;[[77462]] ua&#x3D;[Java&#x2F;1.8.0_222] cookie&#x3D;[-] gzip&#x3D;[-] log_id&#x3D;[authority-api-v1-7bdbf7d9c-d97tk71675932385.683181110.178.18.204, 10.178.25.154,10.178.25.136294] msec&#x3D;[1675932385.683] http_host&#x3D;[authority-api.production.svc.renrenaiche.cn] http_accept&#x3D;[*&#x2F;*|-|-] upstream_response_time&#x3D;[2.851] sent_http_set_cookie&#x3D;[-] session_id&#x3D;[-] rrc_tg&#x3D;[-] x-request-id&#x3D;[804f6723d61767b573981699a20ad5ef] remote_addr&#x3D;[172.17.3.120] http_x_forward&#x3D;[10.178.18.109, 10.178.25.154,10.178.25.161] time&#x3D;[2023-02-09T16:46:25+08:00] request&#x3D;[GET &#x2F;api&#x2F;v1&#x2F;partner&#x2F;area&#x2F;subordinate?user_id&#x3D;81304 HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[341] elapsed&#x3D;[4.555] refer&#x3D;[-] body&#x3D;[-] ua&#x3D;[Java&#x2F;1.8.0_222] cookie&#x3D;[-] gzip&#x3D;[-] log_id&#x3D;[authority-api-v1-7bdbf7d9c-d97tk71675932385.685140610.178.18.109, 10.178.25.154,10.178.25.161182] msec&#x3D;[1675932385.685] http_host&#x3D;[authority-api.production.svc.renrenaiche.cn] http_accept&#x3D;[*&#x2F;*|-|-] upstream_response_time&#x3D;[4.555] sent_http_set_cookie&#x3D;[-] session_id&#x3D;[-] rrc_tg&#x3D;[-] x-request-id&#x3D;[72c90611a47c393063a7fbff76a0d371] remote_addr&#x3D;[172.17.7.254] http_x_forward&#x3D;[10.178.33.82, 10.178.25.136,10.178.25.161] time&#x3D;[2023-02-09T16:46:25+08:00] request&#x3D;[POST &#x2F;users&#x2F;search?search&#x3D;id%3A42605&amp;filter&#x3D;id%3Bname%3Busername%3Buser_id%3Bmobile HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[308] elapsed&#x3D;[4.586] refer&#x3D;[-] body&#x3D;[-] ua&#x3D;[okhttp&#x2F;3.3.1] cookie&#x3D;[-] gzip&#x3D;[-] log_id&#x3D;[authority-api-v1-7bdbf7d9c-d97tk71675932385.780178910.178.33.82, 10.178.25.136,10.178.25.161186] msec&#x3D;[1675932385.780] http_host&#x3D;[authority-api.production.svc.renrenaiche.cn] http_accept&#x3D;[*&#x2F;*|gzip|-] upstream_response_time&#x3D;[4.586] sent_http_set_cookie&#x3D;[-] session_id&#x3D;[-] rrc_tg&#x3D;[-] x-request-id&#x3D;[549791788fc3279b1e05f22bdff1fc11] remote_addr&#x3D;[172.17.7.254] http_x_forward&#x3D;[10.178.33.82, 10.178.25.154,10.178.25.136] time&#x3D;[2023-02-09T16:46:26+08:00] request&#x3D;[POST &#x2F;users&#x2F;search?sear: 从NGINX中可以看到接口响应慢甚至超时。 而服务中大多数接口数据保存在缓存中，响应不应该过慢。 所以初步判断是Authority-api的QPS比较高，服务启动之后大量的请求打入，服务缺少必要的预热，导致响应时间长，而QPS比较高，短时间大量创建数据库链接等，加剧服务响应慢。 2、服务压测 2.1、压测环境准备生产环境启动新版本POD 按每秒50并发进行压测 2.2、users/search接口压测初始版本： 压测结束之后再次按同样线程组再次进行并发压测 2.3 多线程接口预热此时我们增加必要的预热操作之后再重复进行上边的压测操作 第一次压测之后再次进行请求 2.4 主线程单次接口预热 再次请求 2.5 多线程接口预热+连接池参数调整 再次请求 3、压测结论根据压测报告，目前多线程预热的预期结果优于主线程单次预热的情况，所以预热采取多线程预热的方式，就绪探针中配置预热接口。 增加服务启动预热效果如下： 启动异常 增加服务预热 常规情况 前200个请求平均响应时长 6.65s 0.322s 0.003s 前500个请求平均响应时长 4.74s 0.143s 0.003s 499请求499请求 5条 0条 0条 4、优化点4.1、Tomcat优化目前公司使用的是SpringBoot1.4.1 在org.springframework.boot.autoconfigure.web.ServerProperties中查看Tomcat配置 打印断点测试初始值都为0 高版本Tomcat min-spare-threads：最小备用线程数，tomcat启动时的初始化的线程数。默认10 max-threads：Tomcat可创建的最大的线程数，每一个线程处理一个请求，超过这个请求数后，客户端请求只能排队，等有线程释放才能处理。（建议这个配置数可以在服务器CUP核心数的200~250倍之间）默认200 引用：https://www.cnblogs.com/lys_013/p/13185940.html?ivk_sa=1024320u 4.2、dispatcherServlet 是懒加载的SpringBoot在启动后，首次调用接口的时候是比较慢的，造成这种结果的原因是 DispatcherServlet 没有预热的原因，在SpringBoot启动的时候 DispatcherServlet 并没有进行初始化，而在第一次接口请求的时候，才会进行初始化操作。 https://blog.csdn.net/qq_39595769/article/details/120887883 dispatcherServlet会在就绪探针的时候会被调用到，所以此处不是导致项目启动超时的根本原因，优化之后可能会加快项目启动时间，预计优化效果有限 4.3、数据库链接是懒加载的只能在项目启动之后自己查一次库做预热 https://blog.csdn.net/yb2020/article/details/128099065 5、针对auth-api的优化城市缓存应该放到项目启动之后调用，防止并发问题","categories":[{"name":"工作总结","slug":"工作总结","permalink":"https://qinglei1989.github.io/categories/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"工作总结","slug":"工作总结","permalink":"https://qinglei1989.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"}]},{"title":"elasticsearch-query-dsl","slug":"elasticsearch-query-dsl","date":"2023-02-12T17:05:39.000Z","updated":"2023-02-12T17:53:07.688Z","comments":true,"path":"2023/02/13/elasticsearch-query-dsl/","link":"","permalink":"https://qinglei1989.github.io/2023/02/13/elasticsearch-query-dsl/","excerpt":"ElasticSearch-Query DSL","text":"ElasticSearch-Query DSL ElasticSearch-Query DSL ES中的检索方式 在ElasticSearch中支持两种检索方式 REST request URL URL+检索参数 GET /rrc/_search # 检索rrc下的所有信息 GET &#x2F;rrc&#x2F;_search &#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;car_model&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;id&quot;: 1, &quot;source_model_id&quot;: 2, &quot;source&quot;: 2, &quot;series_id&quot;: 1, &quot;param&quot;: &quot;33 44&quot;, &quot;user&quot;: 1, &quot;create_time&quot;: &quot;2023-03-09&quot;, &quot;update_time&quot;: &quot;2023-03-09&quot;, &quot;version_type&quot;: &quot;33&quot;, &quot;model_year&quot;: 2023, &quot;displacement_and_engine&quot;: &quot;445566&quot;, &quot;switch_status&quot;: &quot;1&quot;, &quot;model_type&quot;: &quot;333&quot;, &quot;remark&quot;: &quot;333&quot; &#125; &#125; ] &#125; &#125; GET bank/_search?q=*&amp;sort=account_number:asc REST request body uri+请求体 https://mp.weixin.qq.com/s?__biz=MzI2NDY1MTA3OQ==&amp;mid=2247484073&amp;idx=1&amp;sn=bca9f04059d62709d2a3d5a18c270585&amp;chksm=eaa82a81dddfa397199a279a8665f9537ce7f6e49c9b3b09ff6a70d03303144d06f0399b778e&amp;scene=21#wechat_redirect https://zhuanlan.zhihu.com/p/467897115","categories":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://qinglei1989.github.io/tags/Elasticsearch/"}]},{"title":"elasticsearch-reindex","slug":"elasticsearch-reindex","date":"2023-02-05T16:19:41.000Z","updated":"2023-02-05T17:25:49.220Z","comments":true,"path":"2023/02/06/elasticsearch-reindex/","link":"","permalink":"https://qinglei1989.github.io/2023/02/06/elasticsearch-reindex/","excerpt":"ES数据库重建索引——Reindex(数据迁移)","text":"ES数据库重建索引——Reindex(数据迁移) Elasticsearch-Reindex 应用背景 1、当你的数据量过大，而你的索引最初创建的分片数量不足，导致数据入库较慢的情况，此时需要扩大分片的数量，此时可以尝试使用Reindex。 2、当数据的mapping需要修改，但是大量的数据已经导入到索引中了，重新导入数据到新的索引太耗时；但是在ES中，一个字段的mapping在定义并且导入数据之后是不能再修改的， 所以这种情况下也可以考虑尝试使用Reindex。 需要重建的索引，线上使用的一定是索引的别名。因为改索引重建完成之后会被删除。 Reindex ES提供了_reindex这个API。相对于我们重新导入数据肯定会快不少，实测速度大概是bulk导入数据的5-10倍。 数据迁移步骤： 源索引 &#123; &quot;reindex_old&quot;: &#123; &quot;mappings&quot;: &#123; &quot;reindex_type&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125; &#125; &#125; &#125; &#125; &#125; 当后期向索引中加入string类型的title值的时候，就会报错 PUT &#x2F;reindex_old&#x2F;reindex_type&#x2F;2 &#123; &quot;title&quot;: &quot;name&quot; &#125; &#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;mapper_parsing_exception&quot;, &quot;reason&quot;: &quot;failed to parse [title]&quot; &#125; ], &quot;type&quot;: &quot;mapper_parsing_exception&quot;, &quot;reason&quot;: &quot;failed to parse [title]&quot;, &quot;caused_by&quot;: &#123; &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;Invalid format: \\&quot;name\\&quot;&quot; &#125; &#125;, &quot;status&quot;: 400 &#125; 依靠dynamic mapping，插入数据，但是不小心有些数据是2019-09-10这种日期格式的，所以title这种field被自动映射为了date类型，实际上它应该是string类型的。 但是在ES中，一个字段的mapping在定义并且导入数据之后是不能再修改的，所以这种情况下也可以考虑尝试使Reindex 创建索引别名 旧索引reindex_old，新索引的名字是reindex_new，终端java应用已经在使用reindex_old在操作了，难道还要去停止java应用，修改使用的index为reindex_new，才重新启动java应用吗？这个过程中，就会导致java应用停机，可用性降低。 所以说，给java应用一个别名，这个别名是指向旧索引的，java应用先用着，java应用先用reindex_alias来操作，此时实际指向的是旧的my_index POST &#x2F;_aliases &#123; &quot;actions&quot;: [ &#123; &quot;add&quot;: &#123; &quot;index&quot;: &quot;reindex_old&quot;, &quot;alias&quot;: &quot;reindex_alias&quot; &#125; &#125; ] &#125; 创建新的索引 注意：在创建索引的时候要把表结构也要创建好(也就是mapping) PUT &#x2F;reindex_new&#x2F;reindex_type&#x2F;_mapping &#123; &quot;reindex_type&quot;:&#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125; # 查看新建立的mapping &#123; &quot;reindex_new&quot;: &#123; &quot;mappings&quot;: &#123; &quot;reindex_type&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125; &#125; &#125; 同步数据到新的mapping POST &#x2F;_reindex &#123; &quot;source&quot;: &#123; &quot;index&quot;: &quot;reindex_old&quot; &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;reindex_new&quot; &#125; &#125; # 结果 &#123; &quot;took&quot;: 44, &quot;timed_out&quot;: false, &quot;total&quot;: 1, &quot;updated&quot;: 0, &quot;created&quot;: 1, &quot;deleted&quot;: 0, &quot;batches&quot;: 1, &quot;version_conflicts&quot;: 0, &quot;noops&quot;: 0, &quot;retries&quot;: &#123; &quot;bulk&quot;: 0, &quot;search&quot;: 0 &#125;, &quot;throttled_millis&quot;: 0, &quot;requests_per_second&quot;: -1, &quot;throttled_until_millis&quot;: 0, &quot;failures&quot;: [] &#125; 查看进度 GET _tasks?detailed&#x3D;true&amp;actions&#x3D;*reindex&amp;human 新的索引添加别名，旧的索引去除别名 POST &#x2F;_aliases &#123; &quot;actions&quot;: [&#123; &quot;add&quot;: &#123; &quot;index&quot;: &quot;reindex_old&quot;, &quot;alias&quot;: &quot;index-alias&quot; &#125; &#125;, &#123; &quot;remove&quot;: &#123; &quot;index&quot;: &quot;reindex_new&quot;, &quot;alias&quot;: &quot;index-alias&quot; &#125; &#125; ] &#125; 删除旧索引 DELETE &#x2F;reindex_old 数据迁移效率 常规的如果我们只是进行少量的数据迁移利用普通的reindex就可以很好的达到要求，但是当我们发现我们需要迁移的数据量过大时，我们会发现reindex的速度会变得很慢 数据量几十个G的场景下，elasticsearch reindex速度太慢，从旧索引导数据到新索引，当前最佳方案是什么？ 原因分析： reindex的核心做跨索引、跨集群的数据迁移。 慢的原因及优化思路无非包括： 1）批量大小值可能太小。需要结合堆内存、线程池调整大小； 2）reindex的底层是scroll实现，借助scroll并行优化方式，提升效率； 3）跨索引、跨集群的核心是写入数据，考虑写入优化角度提升效率。 可行方案： 1）提升批量写入大小值 默认情况下，_reindex使用1000进行批量操作，您可以在source中调整batch_size。 POST _reindex &#123; &quot;source&quot;: &#123; &quot;index&quot;: &quot;source&quot;, &quot;size&quot;: 5000 &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;dest&quot; &#125; &#125; 批量大小设置的依据： 1、使用批量索引请求以获得最佳性能。 批量大小取决于数据、分析和集群配置，但一个好的起点是每批处理5-15MB。 注意，这是物理大小。文档数量不是度量批量大小的好指标。例如，如果每批索引1000个文档: 1）每个1kb的1000个文档是1mb。 2）每个100kb的1000个文档是100MB。 这些是完全不同的体积大小。 2、逐步递增文档容量大小的方式调优。 1）从大约5-15MB的大容量开始，慢慢增加，直到你看不到性能的提升。然后开始增加批量写入的并发性(多线程等等)。 2）使用kibana、cerebro或iostat、top和ps等工具监视节点，以查看资源何时开始出现瓶颈。如果您开始接收EsRejectedExecutionException，您的集群就不能再跟上了:至少有一个资源达到了容量。 要么减少并发性，或者提供更多有限的资源(例如从机械硬盘切换到ssd固态硬盘)，要么添加更多节点。 2）借助scroll的sliced提升写入效率 Reindex支持SlicedScroll以并行化重建索引过程。这种并行化可以提高效率，并提供一种方便的方法将请求分解为更小的部分。 sliced原理（frommedcl） 1）用过Scroll接口吧，很慢？如果你数据量很大，用Scroll遍历数据那确实是接受不了，现在Scroll接口可以并发来进行数据遍历了。 2）每个Scroll请求，可以分成多个Slice请求，可以理解为切片，各Slice独立并行，利用Scroll重建或者遍历要快很多倍。 slicing使用举例 slicing的设定分为两种方式：手动设置分片、自动设置分片。 手动设置分片参见官网。 自动设置分片如下： POST _reindex?slices&#x3D;5&amp;refresh &#123; &quot;source&quot;: &#123; &quot;index&quot;: &quot;twitter&quot; &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;new_twitter&quot; &#125; &#125; slices大小设置注意事项： 1）slices大小的设置可以手动指定，或者设置slices设置为auto，auto的含义是：针对单索引，slices大小=分片数；针对多索引，slices=分片的最小值。 2）当slices的数量等于索引中的分片数量时，查询性能最高效。slices大小大于分片数，非但不会提升效率，反而会增加开销。 3）如果这个slices数字很大(例如500)，建议选择一个较低的数字，因为过大的slices会影响性能。 效果 实践证明，比默认设置reindex速度能提升10倍+。 引用 ES数据库重建索引——Reindex(数据迁移)","categories":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://qinglei1989.github.io/tags/Elasticsearch/"}]},{"title":"Sublime Text使用教程总结","slug":"tools-sublime","date":"2023-01-28T16:03:44.000Z","updated":"2023-01-29T15:22:02.700Z","comments":true,"path":"2023/01/29/tools-sublime/","link":"","permalink":"https://qinglei1989.github.io/2023/01/29/tools-sublime/","excerpt":"Sublime Text使用总结","text":"Sublime Text使用总结 Sublime Text安装教程 插件安装：https://juejin.cn/post/6952706277583798309 Sublime Text使用总结 块编辑模式 鼠标光标移动到第一行开头，先按住键盘 shift 键 再点鼠标 右键并向下拖动 进入块编辑模式。 记住：鼠标右键拖动选好后，要先松开 鼠标右键，然后再松开 键盘的 shift 键，否则会弹出右键弹窗 操作不规则的行首 行尾方法 保持光标为如上图所示的块编辑状态，按键盘上的 end 键（Ctrl + 右箭头） 保持光标为如上图所示的块编辑状态，按键盘上的 Home键（Ctrl + 左箭头） 去除空行 https://blog.csdn.net/qq_41908521/article/details/107360927 查找提取 打开需要处理的文件，找到要提取行的数据按【ctrl + F】，把数据复制到查找面板里，然后选择【find all】，在文件中你会看到我们想选的内容被选中了，然后选择TAB栏中的【selection】的下拉列表中的【Expand Selection to line】，你会看到我们要查找的数据所在的行被选中，然后按【ctrl + C】赋值数据行，最后新建文件粘贴数据就好了，这样我们所需要的数据就被提取出来了。","categories":[{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"Sublime Text","slug":"Sublime-Text","permalink":"https://qinglei1989.github.io/tags/Sublime-Text/"}]},{"title":"Elasticsearch Head插件","slug":"elasticsearch-head","date":"2023-01-05T15:33:04.000Z","updated":"2023-01-06T14:08:17.035Z","comments":true,"path":"2023/01/05/elasticsearch-head/","link":"","permalink":"https://qinglei1989.github.io/2023/01/05/elasticsearch-head/","excerpt":"ElasticSearch head就是一款能连接ElasticSearch搜索引擎，并提供可视化的操作页面对ElasticSearch搜索引擎进行各种设置和数据检索功能的管理插件，如在head插件页面编写RESTful接口风格的请求，就可以对ElasticSearch中的数据进行增删改查、创建或者删除索引等操作。类似于使用navicat工具连接MySQL这种关系型数据库，对数据库做操作。","text":"ElasticSearch head就是一款能连接ElasticSearch搜索引擎，并提供可视化的操作页面对ElasticSearch搜索引擎进行各种设置和数据检索功能的管理插件，如在head插件页面编写RESTful接口风格的请求，就可以对ElasticSearch中的数据进行增删改查、创建或者删除索引等操作。类似于使用navicat工具连接MySQL这种关系型数据库，对数据库做操作。 Elasticsearch Head插件 插件安装 安装链接：https://chrome.google.com/webstore/detail/multi-elasticsearch-head/cpmmilfkofbeimbmgiclohpodggeheim?hl=zh-CNgit地址：https://github.com/mobz/elasticsearch-head 打开head后效果 集群健康值。Elasticsearch 中其实有专门的衡量索引健康状况的标志，分为三个等级： green，绿色。这代表所有的主分片和副本分片都已分配。你的集群是 100% 可用的。 yellow，黄色。所有的主分片已经分片了，但至少还有一个副本是缺失的。 red，红色。至少一个主分片以及它的全部副本都在缺失中。 基本查询 检索关键字 must子句文档必须匹配must所有子句查询 should子句文档应该匹配should子句查询的至少一个 must_not子句文档不能匹配该查询条件，相当于“！=” 3.2 检索条件 match：分词匹配 term：表示精确匹配 wildcard：通配符匹配 prefix：前缀匹配 range：区间查询 query_string：允许在单个查询字符串中指定AND text：文本 missing： 无值（类似于sql中IS NULL） 复合查询 ES以RESTful接口风格的请求，使用json进行复杂的查询。请求格式：http://ip:port/索引/类型/文档Id 查询数据（GET） {index}/{type}/{id} 查询官方文档：https://www.elastic.co/guide/cn/elasticsearch/guide/current/query-dsl-intro.html 插入数据（PUT、POST） PUT方法需要指明id POST方法自动生成id 更新数据（PUT） 删除数据（DELETE） 给索引添加字段 创建索引 创建mapping &#123; &quot;wechat_data&quot;: &#123; &quot;dynamic&quot;: &quot;false&quot;, &quot;properties&quot;: &#123; &quot;wechat_id&quot;: &#123; &quot;store&quot;: true, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;creator&quot;: &#123; &quot;store&quot;: true, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;groupId&quot;: &#123; &quot;store&quot;: true, &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;description&quot;: &#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;type&quot;: &quot;text&quot; &#125;, &quot;insert_time&quot;: &#123; &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;store&quot;: true, &quot;type&quot;: &quot;date&quot; &#125;, &quot;reading&quot;: &#123; &quot;store&quot;: true, &quot;type&quot;: &quot;integer&quot; &#125;, &quot;auto_id&quot;: &#123; &quot;store&quot;: true, &quot;type&quot;: &quot;long&quot; &#125;, &quot;createDate&quot;: &#123; &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;store&quot;: true, &quot;type&quot;: &quot;date&quot; &#125; &#125; &#125; &#125; 总结 Elasticsearch Head插件直接在chrome浏览器安装后就可以使用，非常方便，对于初学者大有益处，使用head插件可以快速实现ES索引数据的增删改查、创建或者删除索引等操作。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://qinglei1989.github.io/tags/Elasticsearch/"}]},{"title":"Mybatis-Cache","slug":"Mybatis-Cache","date":"2022-12-11T16:40:28.000Z","updated":"2022-12-19T17:19:28.779Z","comments":true,"path":"2022/12/12/Mybatis-Cache/","link":"","permalink":"https://qinglei1989.github.io/2022/12/12/Mybatis-Cache/","excerpt":"Mybatis一级缓存与二级缓存学习","text":"Mybatis一级缓存与二级缓存学习 MyBatis Cache 一级缓存 Mybatis默认的情况下，它只开启了一级缓存。 所以在参数和 SQL 完全一样的情况下，我们使用同一个 SqlSession 对象调用同一个Mapper 的方法，往往只执行一次 SQL，因为使用 SqlSession 第一次查询后，MyBatis 会将其放在缓存中，以后再查询的时候，如果没有声明需要刷新，并且缓存没超时的情况下.SqlSession 都只会取出当前缓存的数据，而不会再次发送Sql到数据库。但是如果你使用的是不同的 SqlSesion 对象，因为不同的 SqlSession 都是相互隔离的，所以用相同的 Mapper、参数和方法，它还是会再次发送 SOL 到数据库去执行，返回结果。 SqlSessionFactoryUtil工具类 package com.wql.utils; import com.wql.mapper.SysUserMyBatisMapper; import org.apache.ibatis.datasource.pooled.PooledDataSource; import org.apache.ibatis.mapping.Environment; import org.apache.ibatis.session.Configuration; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import org.apache.ibatis.transaction.TransactionFactory; import org.apache.ibatis.transaction.jdbc.JdbcTransactionFactory; import java.util.Objects; public class SqlSessionFactoryUtil &#123; &#x2F;&#x2F; SqlSessionFactory对象 private static SqlSessionFactory sqlSessionFactory &#x3D; null; &#x2F;&#x2F; 类线程锁 private static final Class CLASS_LOCK &#x3D; SqlSessionFactoryUtil.class; &#x2F;** * 私有构造函数 *&#x2F; private SqlSessionFactoryUtil() &#123; &#125; public static SqlSessionFactory initSqlSessionFactory() &#123; synchronized(CLASS_LOCK) &#123; if (Objects.nonNull(sqlSessionFactory)) &#123; return sqlSessionFactory; &#125; &#x2F;&#x2F; 构建数据库连接池 PooledDataSource dataSource &#x3D; new PooledDataSource(); dataSource.setDriver(&quot;com.mysql.cj.jdbc.Driver&quot;); dataSource.setUrl(&quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;tudou?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf8&amp;serverTimezone&#x3D;UTC&amp;useSSL&#x3D;false&amp;allowPublicKeyRetrieval&#x3D;true&quot;); dataSource.setUsername(&quot;root&quot;); dataSource.setPassword(&quot;&quot;); &#x2F;&#x2F; 构建数据库事务方式 TransactionFactory transactionalFactory &#x3D; new JdbcTransactionFactory(); &#x2F;&#x2F; 创建数据库运行环境 Environment environment &#x3D; new Environment(&quot;development&quot;, transactionalFactory, dataSource); &#x2F;&#x2F;构建config对象 Configuration config &#x3D; new Configuration(environment); &#x2F;&#x2F; 加入映射器 config.addMapper(SysUserMyBatisMapper.class); sqlSessionFactory &#x3D; new SqlSessionFactoryBuilder().build(config); return sqlSessionFactory; &#125; &#125; &#x2F;** * 打开SqlSession *&#x2F; public static SqlSession openSqlSession() &#123; if (sqlSessionFactory &#x3D;&#x3D; null) &#123; initSqlSessionFactory(); &#125; return sqlSessionFactory.openSession(); &#125; &#125; SysUserMyBatisMapper类 public interface SysUserMyBatisMapper &#123; SysUser queryById(Long id); &#125; SysUserMyBatisMapper XML &lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-&#x2F;&#x2F;mybatis.org&#x2F;&#x2F;DTD Mapper 3.0&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;mybatis.org&#x2F;dtd&#x2F;mybatis-3-mapper.dtd&quot;&gt; &lt;mapper namespace&#x3D;&quot;com.wql.mapper.SysUserMyBatisMapper&quot;&gt; &lt;sql id&#x3D;&quot;BaseColumn&quot;&gt; id, job_number,user_name, pass_word, phone &lt;&#x2F;sql&gt; &lt;resultMap id&#x3D;&quot;CityAreaResultMap&quot; type&#x3D;&quot;com.wql.domain.SysUser&quot;&gt; &lt;id column&#x3D;&quot;id&quot; property&#x3D;&quot;id&quot;&#x2F;&gt; &lt;id column&#x3D;&quot;job_number&quot; property&#x3D;&quot;jobNumber&quot;&#x2F;&gt; &lt;id column&#x3D;&quot;user_name&quot; property&#x3D;&quot;userName&quot;&#x2F;&gt; &lt;id column&#x3D;&quot;pass_word&quot; property&#x3D;&quot;passWord&quot;&#x2F;&gt; &lt;&#x2F;resultMap&gt; &lt;select id&#x3D;&quot;queryById&quot; resultMap&#x3D;&quot;CityAreaResultMap&quot;&gt; SELECT &lt;include refid&#x3D;&quot;BaseColumn&quot;&#x2F;&gt; FROM sys_user WHERE id &#x3D; #&#123;id&#125; &lt;&#x2F;select&gt; &lt;&#x2F;mapper&gt; 单元测试类 @Slf4j @SpringBootTest(webEnvironment &#x3D; SpringBootTest.WebEnvironment.DEFINED_PORT) class SysUserServiceImplTest &#123; @Test public void testCache() &#123; SqlSession sqlSession &#x3D; SqlSessionFactoryUtil.openSqlSession(); SysUserMyBatisMapper sysUserMyBatisMapper &#x3D; sqlSession.getMapper(SysUserMyBatisMapper.class); SysUser sysUser &#x3D; sysUserMyBatisMapper.queryById(1L); System.out.println(sysUser); sysUser &#x3D; sysUserMyBatisMapper.queryById(1L); System.out.println(sysUser); &#125; &#125; 日志打印： Opening JDBC Connection Created connection 309167705. Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@126d8659] &#x3D;&#x3D;&gt; Preparing: SELECT id, job_number,user_name, pass_word, phone FROM sys_user WHERE id &#x3D; ? &#x3D;&#x3D;&gt; Parameters: 1(Long) &lt;&#x3D;&#x3D; Columns: id, job_number, user_name, pass_word, phone &lt;&#x3D;&#x3D; Row: 1, , 33, 33, 33 &lt;&#x3D;&#x3D; Total: 1 SysUser(id&#x3D;1, jobNumber&#x3D;, idCard&#x3D;null, userName&#x3D;33, passWord&#x3D;33, phone&#x3D;33, userStatus&#x3D;null) SysUser(id&#x3D;1, jobNumber&#x3D;, idCard&#x3D;null, userName&#x3D;33, passWord&#x3D;33, phone&#x3D;33, userStatus&#x3D;null) 只打印了一次SQL，说明使用到了Mybatis的一级缓存。 一级缓存配置开发者只需在MyBatis的配置文件中，添加如下语句，就可以使用一级缓存。共有两个选项，SESSION或者STATEMENT，默认是SESSION级别，即在一个MyBatis会话中执行的所有语句，都会共享这一个缓存。一种是STATEMENT级别不使用一级缓存，此级别下每次执行完一个Mapper中的语句后都会将一级缓存清除。 protected LocalCacheScope localCacheScope &#x3D; LocalCacheScope.SESSION; &#x2F;&#x2F;默认配置 &#x2F;&#x2F; 在SqlSessionFactoryUtil中加入配置 config.setLocalCacheScope(LocalCacheScope.STATEMENT); 再次执行单元测试 Opening JDBC Connection Created connection 1351814143. Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@50930bff] &#x3D;&#x3D;&gt; Preparing: SELECT id, job_number,user_name, pass_word, phone FROM sys_user WHERE id &#x3D; ? &#x3D;&#x3D;&gt; Parameters: 1(Long) &lt;&#x3D;&#x3D; Columns: id, job_number, user_name, pass_word, phone &lt;&#x3D;&#x3D; Row: 1, , 33, 33, 33 &lt;&#x3D;&#x3D; Total: 1 SysUser(id&#x3D;1, jobNumber&#x3D;, idCard&#x3D;null, userName&#x3D;33, passWord&#x3D;33, phone&#x3D;33, userStatus&#x3D;null) &#x3D;&#x3D;&gt; Preparing: SELECT id, job_number,user_name, pass_word, phone FROM sys_user WHERE id &#x3D; ? &#x3D;&#x3D;&gt; Parameters: 1(Long) &lt;&#x3D;&#x3D; Columns: id, job_number, user_name, pass_word, phone &lt;&#x3D;&#x3D; Row: 1, , 33, 33, 33 &lt;&#x3D;&#x3D; Total: 1 SysUser(id&#x3D;1, jobNumber&#x3D;, idCard&#x3D;null, userName&#x3D;33, passWord&#x3D;33, phone&#x3D;33, userStatus&#x3D;null) 对于SESSION级别缓存消失的情况有： select会被缓存 insert ，update，delete语句会刷新缓存 sqlSession.clearCache();手动清理缓存 在两次查询中间加入sqlSession.clearCache(); SysUser sysUser &#x3D; sysUserMyBatisMapper.queryById(1L); System.out.println(sysUser); sqlSession.clearCache(); sysUser &#x3D; sysUserMyBatisMapper.queryById(1L); System.out.println(sysUser); 日志打印： Opening JDBC Connection Created connection 525119867. Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@1f4cb17b] &#x3D;&#x3D;&gt; Preparing: SELECT id, job_number,user_name, pass_word, phone FROM sys_user WHERE id &#x3D; ? &#x3D;&#x3D;&gt; Parameters: 1(Long) &lt;&#x3D;&#x3D; Columns: id, job_number, user_name, pass_word, phone &lt;&#x3D;&#x3D; Row: 1, , 33, 33, 33 &lt;&#x3D;&#x3D; Total: 1 SysUser(id&#x3D;1, jobNumber&#x3D;, idCard&#x3D;null, userName&#x3D;33, passWord&#x3D;33, phone&#x3D;33, userStatus&#x3D;null) &#x3D;&#x3D;&gt; Preparing: SELECT id, job_number,user_name, pass_word, phone FROM sys_user WHERE id &#x3D; ? &#x3D;&#x3D;&gt; Parameters: 1(Long) &lt;&#x3D;&#x3D; Columns: id, job_number, user_name, pass_word, phone &lt;&#x3D;&#x3D; Row: 1, , 33, 33, 33 &lt;&#x3D;&#x3D; Total: 1 SysUser(id&#x3D;1, jobNumber&#x3D;, idCard&#x3D;null, userName&#x3D;33, passWord&#x3D;33, phone&#x3D;33, userStatus&#x3D;null) 打印了两次SQL Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@2e9dcdd3] was not registered for synchronization because synchronization is not active [TRACEID:] 2022-12-12 00:57:37.168 [main-994] INFO c.alibaba.druid.pool.DruidDataSource 994 init - &#123;dataSource-1&#125; inited JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@760c777d] will not be managed by Spring &#x3D;&#x3D;&gt; Preparing: SELECT id,job_number,user_name,pass_word,phone,user_status,create_date,create_user,update_date,update_user,extra_info,del_flag FROM sys_user WHERE id&#x3D;? AND del_flag&#x3D;1 &#x3D;&#x3D;&gt; Parameters: 1(Integer) &lt;&#x3D;&#x3D; Columns: id, job_number, user_name, pass_word, phone, user_status, create_date, create_user, update_date, update_user, extra_info, del_flag &lt;&#x3D;&#x3D; Row: 1, , 33, 33, 33, 1, 2021-12-02 23:36:44, 33, 2021-12-12 22:25:13, 33, 33, 1 &lt;&#x3D;&#x3D; Total: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@2e9dcdd3] Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@70bc9070] was not registered for synchronization because synchronization is not active JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@760c777d] will not be managed by Spring &#x3D;&#x3D;&gt; Preparing: SELECT id,job_number,user_name,pass_word,phone,user_status,create_date,create_user,update_date,update_user,extra_info,del_flag FROM sys_user WHERE id&#x3D;? AND del_flag&#x3D;1 &#x3D;&#x3D;&gt; Parameters: 1(Integer) &lt;&#x3D;&#x3D; Columns: id, job_number, user_name, pass_word, phone, user_status, create_date, create_user, update_date, update_user, extra_info, del_flag &lt;&#x3D;&#x3D; Row: 1, , 33, 33, 33, 1, 2021-12-02 23:36:44, 33, 2021-12-12 22:25:13, 33, 33, 1 &lt;&#x3D;&#x3D; Total: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@70bc9070] 一级缓存工作流程和源码分析 每个SqlSession中持有了Executor，每个Executor中有一个LocalCache。当用户发起查询时，MyBatis根据当前执行的语句生成MappedStatement，在Local Cache进行查询，如果缓存命中的话，直接返回结果给用户，如果缓存没有命中的话，查询数据库，结果写入Local Cache，最后返回结果给用户。 源码解析： SqlSession： 对外提供了用户和数据库之间交互需要的所有方法，隐藏了底层的细节。默认实现类是DefaultSqlSession。 Executor： SqlSession向用户提供操作数据库的方法，但和数据库操作有关的职责都会委托给Executor。 接口继承关系 Executor 有3个子类，父类中的抽象方法doQuery就是让三个子类去重写，实现各自的功能。 简单执行器 -SimpleExecutor简单执行器是默认的执行器。一个Statement只执行一次，执行完毕后则进行销毁。 protected ExecutorType defaultExecutorType &#x3D; ExecutorType.SIMPLE; @Override public SqlSession openSession() &#123; return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false); &#125; @Override public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt &#x3D; null; try &#123; Configuration configuration &#x3D; ms.getConfiguration(); StatementHandler handler &#x3D; configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt &#x3D; prepareStatement(handler, ms.getStatementLog()); return handler.query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125; &#125; private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; Connection connection &#x3D; getConnection(statementLog); stmt &#x3D; handler.prepare(connection, transaction.getTimeout()); handler.parameterize(stmt); return stmt; &#125; 参数解读 MappedStatement ： 映射SQL Object parameter ： SQL中的动态参数 RowBounds：分页用的，默认不分页 RowBounds.DEFAULT ， 可参考 org.apache.ibatis.session.RowBounds ResultHandler： 自定义处理返回结果 ，不使用写 Executor.NO_RESULT_HANDLER BoundSql ： 绑定的SQL 获取大管家 Configuration 每次都要newStatementHandler ，这个StatementHandler 后面我们重点将，是专门处理JDBC的 prepareStatement –&gt; BaseStatementHandler #prepare 方法 调用SimpleStatementHandler#query 相同的SQL每次调用都会预编译 ，我们期望的结果是相同的SQL只要编译一次即可，那SimpleExecutor不支持 ReuseExecutor-重用执行器@Override public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Configuration configuration &#x3D; ms.getConfiguration(); StatementHandler handler &#x3D; configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); Statement stmt &#x3D; prepareStatement(handler, ms.getStatementLog()); return handler.query(stmt, resultHandler); &#125; &#x2F;&#x2F; 先判断本地缓存statementMap是否有数据，有的话从statementMap获取，没有的话建立Statement，并存入本地缓存statementMap &#x2F;&#x2F; 注意这个缓存的声明周期 是仅限于本次会话。 会话结束后，这些缓存都会被销毁掉。 &#x2F;&#x2F; 区别于SimpleExecutor的实现，多了个本地缓存。 推荐使用ReuseExecutor 。 private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; BoundSql boundSql &#x3D; handler.getBoundSql(); String sql &#x3D; boundSql.getSql(); if (hasStatementFor(sql)) &#123; stmt &#x3D; getStatement(sql); applyTransactionTimeout(stmt); &#125; else &#123; Connection connection &#x3D; getConnection(statementLog); stmt &#x3D; handler.prepare(connection, transaction.getTimeout()); putStatement(sql, stmt); &#125; handler.parameterize(stmt); return stmt; &#125; &#x2F;&#x2F; 相同的SQL语句会缓存对应的PrepareStatement , 缓存的生命周期： 会话有效期 private boolean hasStatementFor(String sql) &#123; try &#123; return statementMap.keySet().contains(sql) &amp;&amp; !statementMap.get(sql).getConnection().isClosed(); &#125; catch (SQLException e) &#123; return false; &#125; &#125; ReuseExecutor虽然相同的SQL只要编译一次，但是我们日常编程中使用的是Spring-Mybatis，不使用事务的情况下，每条语句都会重新生成SqlSession，所以ReuseExecutor的一次编译失效。 BatchExecutor-批处理执行器优点：可以向数据库发送多条不同的ＳＱＬ语句。缺点：没有预编译，存在sql注入风险，且当sql只有参数不同时，也需要重复多次，冗余。 一级缓存源码public abstract class BaseExecutor implements Executor &#123; protected PerpetualCache localOutputParameterCache; &#x2F;&#x2F; BaseExecutor成员变量之一的PerpetualCache，是对Cache接口最基本的实现，其实现非常简单，内部持有HashMap，对一级缓存的操作实则是对HashMap的操作。 public class PerpetualCache implements Cache &#123; private final String id; private final Map&lt;Object, Object&gt; cache &#x3D; new HashMap&lt;&gt;(); 在源码分析的最后，我们确认一下，如果是insert/delete/update方法，缓存就会刷新的原因。 SqlSession的insert方法和delete方法，都会统一走update的流程。 总结 MyBatis一级缓存的生命周期和SqlSession一致。 MyBatis一级缓存内部设计简单，只是一个没有容量限定的HashMap，在缓存的功能性上有所欠缺。 MyBatis的一级缓存最大范围是SqlSession内部，有多个SqlSession或者分布式的环境下，数据库写操作会引起脏数据，建议设定缓存级别为Statement。 mybatis-spring 在MyBatis中，使用sqlsessionFactory创建一个sqlsession。但是在mybatis-spring中，我们不再需要直接使用sqlsessionFactory。而是使用SqlSessionTemplate，它实现了sqlsession，作为代码中任何现有使用sqlsession的替代品。sqlsessionTemplate是线程安全的，可以由多个DAO或Mapper共享。 官网文档：mybatis-spring官方文档 private class SqlSessionInterceptor implements InvocationHandler &#123; private SqlSessionInterceptor() &#123; &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; &#x2F;&#x2F; 1.创建一个SqlSession SqlSession sqlSession &#x3D; SqlSessionUtils.getSqlSession(SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); Object unwrapped; try &#123; &#x2F;&#x2F; 2.调用原始函数 Object result &#x3D; method.invoke(sqlSession, args); &#x2F;&#x2F; 如果不是事务，关闭当前的SqlSession if (!SqlSessionUtils.isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) &#123; sqlSession.commit(true); &#125; unwrapped &#x3D; result; &#125; catch (Throwable var11) &#123; unwrapped &#x3D; ExceptionUtil.unwrapThrowable(var11); if (SqlSessionTemplate.this.exceptionTranslator !&#x3D; null &amp;&amp; unwrapped instanceof PersistenceException) &#123; SqlSessionUtils.closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); sqlSession &#x3D; null; Throwable translated &#x3D; SqlSessionTemplate.this.exceptionTranslator.translateExceptionIfPossible((PersistenceException)unwrapped); if (translated !&#x3D; null) &#123; unwrapped &#x3D; translated; &#125; &#125; throw (Throwable)unwrapped; &#125; finally &#123; if (sqlSession !&#x3D; null) &#123; SqlSessionUtils.closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); &#125; &#125; return unwrapped; &#125; &#125; 如果没有添加Transactional注解的话，每次都会创建一个新的SqlSession并且在执行完毕之后，还会将事务提交、关闭SqlSession。因此多次请求之间无法通过SqlSession来共享缓存。 二级缓存 二级缓存默认是不开启的，需要手动开启二级缓存，实现二级缓存的时候，MyBatis要求返回的POJO必须是可序列化的。 &lt;settings&gt; &lt;setting name &#x3D; &quot;cacheEnabled&quot; value &#x3D; &quot;true&quot; &#x2F;&gt; &lt;&#x2F;settings&gt; 来开启二级缓存，还需要在 Mapper 的xml 配置文件中加入 &lt;cache&gt; 标签 &lt;!-- 表示表查询结果保存到二级缓存(共享缓存) --&gt; &lt;cache&#x2F;&gt; 设置 cache 标签的属性 cache 标签有多个属性，一起来看一些这些属性分别代表什么意义 eviction: 缓存回收策略，有这几种回收策略 LRU - 最近最少回收，移除最长时间不被使用的对象 FIFO - 先进先出，按照缓存进入的顺序来移除它们 SOFT - 软引用，移除基于垃圾回收器状态和软引用规则的对象 WEAK - 弱引用，更积极的移除基于垃圾收集器和弱引用规则的对象 默认是 LRU 最近最少回收策略 flushinterval 缓存刷新间隔，缓存多长时间刷新一次，默认不清空，设置一个毫秒值 readOnly: 是否只读；true 只读，MyBatis 认为所有从缓存中获取数据的操作都是只读操作，不会修改数据。MyBatis 为了加快获取数据，直接就会将数据在缓存中的引用交给用户。不安全，速度快。读写(默认)：MyBatis 觉得数据可能会被修改 size : 缓存存放多少个元素 type: 指定自定义缓存的全类名(实现Cache 接口即可) blocking： 若缓存中找不到对应的key，是否会一直blocking，直到有对应的数据进入缓存。 二级缓存失效的条件 第一次SqlSession 未提交 ​ SqlSession 在未提交的时候，SQL 语句产生的查询结果还没有放入二级缓存中，这个时候 SqlSession2 在查询的时候是感受不到二级缓存的存在的 更新对二级缓存影响 ​ 同一个命名空间下的更新操作会使二级缓存失效 多表操作对二级缓存的影响 多表查询更新跨命名空间极大可能会出现脏数据。使用 &lt;cache-ref&gt;来把一个命名空间指向另外一个命名空间，从而消除上述的影响 总结： MyBatis的二级缓存相对于一级缓存来说，实现了SqlSession之间缓存数据的共享，同时粒度更加的细，能够到namespace级别，通过Cache接口实现类不同的组合，对Cache的可控性也更强。 MyBatis在多表查询时，极大可能会出现脏数据，有设计上的缺陷，安全使用二级缓存的条件比较苛刻。 在分布式环境下，由于默认的MyBatis Cache实现都是基于本地的，分布式环境下必然会出现读取到脏数据，需要使用集中式缓存将MyBatis的Cache接口实现，有一定的开发成本，直接使用Redis、Memcached等分布式缓存可能成本更低，安全性也更高。 引用 解决spring结合mybatis时一级缓存失效的问题 框架-myBatis 聊聊MyBatis缓存机制 MyBatis源码解析（一） Executor执行器","categories":[{"name":"持久层","slug":"持久层","permalink":"https://qinglei1989.github.io/categories/%E6%8C%81%E4%B9%85%E5%B1%82/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://qinglei1989.github.io/tags/MyBatis/"}]},{"title":"elasticsearch-consistency","slug":"elasticsearch-consistency","date":"2022-12-05T17:05:08.000Z","updated":"2022-12-05T17:25:02.134Z","comments":true,"path":"2022/12/06/elasticsearch-consistency/","link":"","permalink":"https://qinglei1989.github.io/2022/12/06/elasticsearch-consistency/","excerpt":"ES中primary shard写完，会同步到replica shard上，两者最终可能会出现不一致的情况。那es是如何确定主副分片的写一致性的呢？","text":"ES中primary shard写完，会同步到replica shard上，两者最终可能会出现不一致的情况。那es是如何确定主副分片的写一致性的呢？ Elasticsearch写一致性 ES5.0之前 写入前检查存活shard的方式 consistency 我们在发送任何一个增删改请求的时候，比如说put /product/book/id，都可以带上一个consistency参数，指明我们想要的写一致性类型 put &#x2F;product&#x2F;book&#x2F;1?consistency&#x3D;quorum consistency有三个可选值： one：只要有1个primary shard是可用的，就可以进行写操作 all：必须所有的primary shard和replica shard都是可用的，才可以进行写操作 quorum：默认值。要求所有的shard中，必须大部分shard都是可用的，才可以进行写操作 quorum机制 写之前必须确保大多数shard都是可用的，具体公式如下： Available shard &gt;&#x3D; (primary shard数量 + replica shard份数) &#x2F; 2 + 1 例子： 有3个primary shard，replica shard份数为1时，按公式计算 (3 + 3 * 1) &#x2F; 2 + 1 &#x3D; 3 所以，要求6个shard中至少有3个shard是可用的，才可以执行这个写操作 有种特殊情况，比如es只有1个节点，index有1个primary shard和1个replica shard，这种情况replica shard实际上是无法分配到节点上的，存活shard只有1个，而quorum=(1+1)/2+1=2,按公式算的话最终会无法写入，不过es对这种情况做了例外处理是可以正常写入的。 有3个primary shard，replica shard份数为1，总共有3+3*1=6个shard quorum=(3+1)/2+1=3 所以，要求6个shard中至少有3个shard是可用的，才可以执行这个写操作 有种特殊情况，比如es只有1个节点，index有1个primary shard和1个replica shard，这种情况replica shard实际上是无法分配到节点上的，存活shard只有1个，而quorum=(1+1)/2+1=2,按公式算的话最终会无法写入，不过es对这种情况做了例外处理是可以正常写入的。 quorum不齐全时不会直接拒绝写入 当quorum不齐全时，会默认等待1分钟，看等待期间可用的shard有没有增加到quorum的数量，等待时间结束若还不满足，则拒绝写入。比如我在写入时手动指定30秒等待(超时)时间，语法为 put &#x2F;product&#x2F;book&#x2F;1?timeout&#x3D;30 ES5.0之后 consistency检查是在put之前做的。然而虽然检查的时候，可用shard数量满足quorum数量，但是真正从primary shard写到replica shard之前，仍然会出现shard挂掉的可能，但update api会返回succeed。因此，这个检查并不能保证replica shard成功写入，甚至这个primary shard是否能成功写入也未必能保证。 因此es5.0后修改了语法，用wait_for_active_shards代替原来的consistency #写入完1个primary shard就返回客户端 PUT &#x2F;product&#x2F;book&#x2F;1?wait_for_active_shards&#x3D;1 也可以在建索引的时候指定write.wait_for_active_shards PUT &#x2F;product &#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;text&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;store&quot; : true &#125;, &quot;fullname&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125;, &quot;settings&quot; : &#123; &quot;index&quot; : &#123; &quot;number_of_shards&quot; : 1, &quot;number_of_replicas&quot; : 2, &quot;write.wait_for_active_shards&quot;:3 &#125; &#125; &#125; 引用 跟我学Elasticsearch(15) 主副分片写一致性原理以及quorum机制 Elasticsearch分布式一致性","categories":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://qinglei1989.github.io/tags/Elasticsearch/"}]},{"title":"elasticsearch-search","slug":"elasticsearch-search","date":"2022-12-05T17:02:23.000Z","updated":"2023-01-03T16:47:14.802Z","comments":true,"path":"2022/12/06/elasticsearch-search/","link":"","permalink":"https://qinglei1989.github.io/2022/12/06/elasticsearch-search/","excerpt":"Elasticsearch-search知识点。","text":"Elasticsearch-search知识点。 Elasticsearch-search知识点 search结果分析 GET _search &#123; &quot;took&quot;: 4, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 21, &quot;successful&quot;: 21, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;.kibana&quot;, &quot;_type&quot;: &quot;config&quot;, &quot;_id&quot;: &quot;5.2.0&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;buildNum&quot;: 14695 &#125; &#125; ] &#125; &#125; took：整个搜索请求花费了1毫秒 hits.total：本次搜索，返回了1条结果（es官方默认限制索引查询最多只能查询10000条数据） hits.max_score：本次搜索的所有结果中，最大的相关度分数是多少 hits.hits：默认查询前10条数据，完整数据，按_score降序排序 shards：这次查询路由到的primary shard和replica shard timeout：默认无timeout，可以手动指定timeout，走timeout查询执行机制 search的timeout机制 有些搜索应用对时间是很敏感的，比如说我们的电商网站，你不能说让用户等10分钟，才能等到一次搜索请求的结果，如果那样的话人家早走了，不来买东西了。 而timeout机制，就是指定每个shard只能在timeout时间范围内将搜索到的部分数据(也可能全都搜索到了)直接返回给client，而不是等所有的数据全部搜索出来以后再返回。 比如，有2个shard，每个shard要搜索出来1000条数据需要1分钟，此时我们指定timeout=10ms，每个shard运行到10ms的时候可能就搜索出10条，那么这个请求本来应该在1分钟后总共拿到2000条数据，但是指定timeout后，就会在10ms拿到20条数据返回给客户端。 这样就可以确保一次搜索请求可以在指定的timeout时长内完成。为一些时间敏感的搜索应用提供良好的支持。 timeout的语法： GET &#x2F;_search?timeout&#x3D;10m timeout的单位：ms(毫秒),s(秒),m(分钟) multi-index&amp;multi-type搜索模式 (1) /_search：所有索引，所有type下的所有数据都搜索出来(2) /index1/_search：指定一个index，搜索其下所有type的数据(3) /index1,index2/_search：同时搜索两个index下的数据(4) /*1,*2/_search：按照通配符去匹配多个索引(5) /index1/type1/_search：搜索一个index下指定的type的数据(6) /index1/type1,type2/_search：可以搜索一个index下多个type的数据(7) /index1,index2/type1,type2/_search：搜索多个index下的多个type的数据(8) /_all/type1,type2/_search：_all，可以代表搜索所有index下的指定type的数据 备注：中间不要带空格 GET &#x2F;rrc,rrs&#x2F;index1,user&#x2F;_search &#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;index_not_found_exception&quot;, &quot;reason&quot;: &quot;no such index&quot;, &quot;resource.type&quot;: &quot;index_or_alias&quot;, &quot;resource.id&quot;: &quot;rrs&quot;, &quot;index_uuid&quot;: &quot;_na_&quot;, &quot;index&quot;: &quot;rrs&quot; &#125; ], &quot;type&quot;: &quot;index_not_found_exception&quot;, &quot;reason&quot;: &quot;no such index&quot;, &quot;resource.type&quot;: &quot;index_or_alias&quot;, &quot;resource.id&quot;: &quot;rrs&quot;, &quot;index_uuid&quot;: &quot;_na_&quot;, &quot;index&quot;: &quot;rrs&quot; &#125;, &quot;status&quot;: 404 &#125; # ?怎么和老师讲的有点出入，百度中：https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;45461096&#x2F;elasticsearch-returns-404-while-multi-index-multi-type-search GET &#x2F;rrc,index2&#x2F;user,type2&#x2F;_search?ignore_unavailable &#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;9&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;tiedan&quot;, &quot;price&quot;: 1764 &#125; &#125; ] &#125; &#125; ES分页 GET _search &quot;hits&quot;: &#123; &quot;total&quot;: 17, &quot;max_score&quot;: 1 &#125; # 作分页查询 GET _search?from&#x3D;0&amp;size&#x3D;1 &#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 21, &quot;successful&quot;: 21, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 17, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;.kibana&quot;, &quot;_type&quot;: &quot;config&quot;, &quot;_id&quot;: &quot;5.2.0&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;buildNum&quot;: 14695 &#125; &#125; ] &#125; &#125; 关注深度分页问题，是一个归并排序的过程。 query string基础语法 q=field:search content的语法，还有一个是掌握+和-的含义 GET &#x2F;test_index&#x2F;test_type&#x2F;_search?q&#x3D;test_field:test12 &#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 0.2876821, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;12&quot;, &quot;_score&quot;: 0.2876821, &quot;_source&quot;: &#123; &quot;test_field&quot;: &quot;test12&quot; &#125; &#125; ] &#125; &#125; GET &#x2F;test_index&#x2F;test_type&#x2F;_search?q&#x3D;+test_field:test12 &#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 0.2876821, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;12&quot;, &quot;_score&quot;: 0.2876821, &quot;_source&quot;: &#123; &quot;test_field&quot;: &quot;test12&quot; &#125; &#125; ] &#125; &#125; GET &#x2F;test_index&#x2F;test_type&#x2F;_search?q&#x3D;-test_field:test12 &#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;test_field&quot;: &quot;replaced test2&quot; &#125; &#125; ] &#125; &#125; _all metadata的原理和作用 GET /test_index/test_type/_search?q=test 直接可以搜索所有的field，任意一个field包含指定的关键字就可以搜索出来。我们在进行中搜索的时候，难道是对document中的每一个field都进行一次搜索吗？不是的 es中的_all元数据，在建立索引的时候，我们插入一条document，它里面包含了多个field，此时，es会自动将多个field的值，全部用字符串的方式串联起来，变成一个长的字符串，作为_all field的值，同时建立索引 后面如果在搜索的时候，没有对某个field指定搜索，就默认搜索_all field，其中是包含了所有field的值的 举个例子 &#123; &quot;name&quot;: &quot;jack&quot;, &quot;age&quot;: 26, &quot;email&quot;: &quot;jack@sina.com&quot;, &quot;address&quot;: &quot;guamgzhou&quot; &#125; &quot;jack 26 jack@sina.com guangzhou&quot;，作为这一条document的_all field的值，同时进行分词后建立对应的倒排索引 生产环境不使用 mapping 准备数据： PUT &#x2F;website&#x2F;article&#x2F;1 &#123; &quot;post_date&quot;: &quot;2017-01-01&quot;, &quot;title&quot;: &quot;my first article&quot;, &quot;content&quot;: &quot;this is my first article in this website&quot;, &quot;author_id&quot;: 11400 &#125; PUT &#x2F;website&#x2F;article&#x2F;2 &#123; &quot;post_date&quot;: &quot;2017-01-02&quot;, &quot;title&quot;: &quot;my second article&quot;, &quot;content&quot;: &quot;this is my second article in this website&quot;, &quot;author_id&quot;: 11400 &#125; PUT &#x2F;website&#x2F;article&#x2F;3 &#123; &quot;post_date&quot;: &quot;2017-01-03&quot;, &quot;title&quot;: &quot;my third article&quot;, &quot;content&quot;: &quot;this is my third article in this website&quot;, &quot;author_id&quot;: 11400 &#125; 尝试各种搜索 GET /website/article/_search?q=2017 3条结果GET /website/article/_search?q=2017-01-01 3条结果GET /website/article/_search?q=post_date:2017-01-01 1条结果GET /website/article/_search?q=post_date:2017 1条结果 在上面的准备数据过程中，ES使用dynamic mapping，自动为我们建立index，创建type，以及type对应的mapping，mapping中包含了每个field对应的数据类型，以及如何分词等设置我们当然，后面会讲解，也可以手动在创建数据之前，先创建index和type，以及type对应的mapping GET &#x2F;website&#x2F;_mapping&#x2F;article &#123; &quot;website&quot;: &#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;author_id&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125;, &quot;post_date&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; 搜索结果为什么不一致，因为es自动建立mapping的时候，设置了不同的field不同的data type。不同的data type的分词、搜索等行为是不一样的。所以出现了_all field和post_date field的搜索表现完全不一样。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://qinglei1989.github.io/tags/Elasticsearch/"}]},{"title":"Mybatis-Interceptor","slug":"Mybatis-Interceptor","date":"2022-12-03T17:22:07.000Z","updated":"2022-12-07T17:03:09.467Z","comments":true,"path":"2022/12/04/Mybatis-Interceptor/","link":"","permalink":"https://qinglei1989.github.io/2022/12/04/Mybatis-Interceptor/","excerpt":"插件（plugins）","text":"插件（plugins） MyBatis plugins 插件（plugins） MyBatis 允许你在映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) 拦截执行器的方法 ParameterHandler (getParameterObject, setParameters) 拦截参数的处理 ResultSetHandler (handleResultSets, handleOutputParameters) 拦截结果集的处理 StatementHandler (prepare, parameterize, batch, update, query) 拦截Sql语法构建的处理 官方文档地址 提示 覆盖配置类 除了用插件来修改 MyBatis 核心行为以外，还可以通过完全覆盖配置类来达到目的。只需继承配置类后覆盖其中的某个方法，再把它传递到 SqlSessionFactoryBuilder.build(myConfig) 方法即可。再次重申，这可能会极大影响 MyBatis 的行为，务请慎之又慎。 拦截执行器的方法 拦截参数的处理 拦截结果集的处理 拦截Sql语法构建的处理 拦截器使用 工作中遇到一个需求，为服务的数据表增加逻辑删除功能，服务本身技术栈为（SpringBoot+Mybatis）当时自己考虑到了两个方法： 将项目的Mybatis升级到Mybatis-Plus，然后增加逻辑删除字段 编写Mybatis插件，将所有的查询语句增加状态值判断，将Delete语句转换为逻辑删除Update。 Mybatis-Plus官方说明中很重要的一点是逻辑删除”只对自动注入的 sql 起效”，也就是说XML中自定义的SQL不会自动拼接逻辑删除条件也不会将物理删除更改为逻辑删除。如果依然修改XML升级就没有意义。 于是考虑第二种方案，拦截SQL将delete语句修改为逻辑删除，在Select语句中添加逻辑删除判断。但是后来证明自己有明显的考虑不足之处。因为复杂嵌套SQL拼接where条件十分难搞。 package com.rrc.authority.base.interceptor; import com.rrc.authority.base.utils.JsqlparserUtil; import lombok.extern.slf4j.Slf4j; import org.apache.commons.collections.CollectionUtils; import org.apache.ibatis.executor.statement.StatementHandler; import org.apache.ibatis.mapping.BoundSql; import org.apache.ibatis.mapping.MappedStatement; import org.apache.ibatis.mapping.SqlCommandType; import org.apache.ibatis.plugin.*; import org.apache.ibatis.reflection.DefaultReflectorFactory; import org.apache.ibatis.reflection.MetaObject; import org.apache.ibatis.reflection.SystemMetaObject; import java.lang.reflect.Field; import java.sql.Connection; import java.util.Arrays; import java.util.List; import java.util.Properties; import java.util.stream.Collectors; @Slf4j @Intercepts(&#123;@Signature(type &#x3D; StatementHandler.class, method &#x3D; &quot;prepare&quot;, args &#x3D; &#123;Connection.class, Integer.class&#125;)&#125;) public class LogicDeleteInterceptor implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; StatementHandler statementHandler &#x3D; (StatementHandler) invocation.getTarget(); &#x2F;&#x2F; 通过MetaObject优雅访问对象的属性，这里是访问statementHandler的属性;：MetaObject是Mybatis提供的一个用于方便、 &#x2F;&#x2F; 优雅访问对象属性的对象，通过它可以简化代码、不需要try&#x2F;catch各种reflect异常，同时它支持对JavaBean、Collection、Map三种类型对象的操作。 MetaObject metaObject &#x3D; MetaObject.forObject(statementHandler, SystemMetaObject.DEFAULT_OBJECT_FACTORY, SystemMetaObject.DEFAULT_OBJECT_WRAPPER_FACTORY, new DefaultReflectorFactory()); &#x2F;&#x2F; 先拦截到RoutingStatementHandler，里面有个StatementHandler类型的delegate变量，其实现类是 BaseStatementHandler，然后就到BaseStatementHandler的成员变量mappedStatement MappedStatement mappedStatement &#x3D; (MappedStatement) metaObject.getValue(&quot;delegate.mappedStatement&quot;); &#x2F;&#x2F; id为执行的mapper方法的全路径名，如com.cq.UserMapper.insertUser， 便于后续使用反射 String id &#x3D; mappedStatement.getId(); &#x2F;&#x2F; sql语句类型 select、delete、insert、update String sqlCommandType &#x3D; mappedStatement.getSqlCommandType().toString(); &#x2F;&#x2F; 数据库连接信息 Configuration configuration &#x3D; mappedStatement.getConfiguration(); DataSource dataSource &#x3D; configuration.getEnvironment().getDataSource(); BoundSql boundSql &#x3D; statementHandler.getBoundSql(); &#x2F;&#x2F; 获取到原始sql语句 String sql &#x3D; boundSql.getSql().toLowerCase(); log.info(&quot;请求SQL语句 &#123;&#125;&quot;, sql); &#x2F;&#x2F; 具体处理逻辑 &#x2F;&#x2F;通过反射修改sql语句 Field field &#x3D; boundSql.getClass().getDeclaredField(&quot;sql&quot;); field.setAccessible(true); field.set(boundSql, sql); return invocation.proceed(); &#125; @Override public Object plugin(Object target) &#123; if (target instanceof StatementHandler) &#123; return Plugin.wrap(target, this); &#125; else &#123; return target; &#125; &#125; @Override public void setProperties(Properties properties) &#123; &#x2F;&#x2F; 空方法 &#125; &#125; Jsqlparser解析SQL 从SQL中提取表名 String sql &#x3D; &quot;SELECT * FROM TABLE1&quot;; Statement statement &#x3D; CCJSqlParserUtil.parse(sql); TablesNamesFinder tablesNamesFinder &#x3D; new TablesNamesFinder(); List&lt;String&gt; tableList &#x3D; tablesNamesFinder.getTableList(statement); 提取SQL中的表别名 &#x2F;** * 获取SQL中的全部表别名 * * @param sql sql语句 * @return String *&#x2F; public static Map&lt;String,String&gt; getMainJoinTableAlias(String sql) throws JSQLParserException &#123; Map&lt;String,String&gt; map &#x3D; new HashMap&lt;&gt;(); PlainSelect plainSelect &#x3D; (PlainSelect)((Select) CCJSqlParserUtil.parse(sql)).getSelectBody(); Table table &#x3D; (Table)plainSelect.getFromItem(); if(Objects.nonNull(table.getAlias()))&#123; map.put(table.getName(), table.getAlias().getName()); &#125; if (Objects.nonNull(plainSelect.getJoins())) &#123; for (Join join: plainSelect.getJoins()) &#123; table &#x3D; (Table)join.getRightItem(); if(Objects.nonNull(table.getAlias()))&#123; map.put(table.getName(), table.getAlias().getName()); &#125; &#125; &#125; return map; &#125; 引用 细粒度权限，用户只能看到自己相关的数据 mybatis-插件拦截器动态替换表名 关于JSqlparser使用攻略(高效的SQL解析工具) mybatis mybatis-spring-boot https://www.cnblogs.com/yougewe/p/10072740.html 下次学习这个","categories":[{"name":"持久层","slug":"持久层","permalink":"https://qinglei1989.github.io/categories/%E6%8C%81%E4%B9%85%E5%B1%82/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://qinglei1989.github.io/tags/MyBatis/"}]},{"title":"elasticsearch文档知识点","slug":"elasticsearch-document","date":"2022-11-26T05:21:03.000Z","updated":"2022-11-28T17:59:06.039Z","comments":true,"path":"2022/11/26/elasticsearch-document/","link":"","permalink":"https://qinglei1989.github.io/2022/11/26/elasticsearch-document/","excerpt":"Elasticsearch document知识点。","text":"Elasticsearch document知识点。 Elasticsearch文档 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;num&quot;: 1, &quot;tags&quot;: [] &#125; &#125; _index索引元数据 代表一个document存放在哪个索引中 索引名称必须是小写的，不能用下划线开头，不能包含逗号。 _type元类型数据 代表document属于index中的哪个类别type名称可以是大写或者小写，但是同时不能用下划线开头，不能包含逗号 _id元数据 代表document的唯一标识，与index和type一起，可以唯一标识和定位一个document我们可以手动指定document的id（put /index/type/id），也可以不指定，由es自动为我们创建一个id id生成策略 手动指定document id 根据应用情况来说，是否满足手动指定document id的前提： 一般来说从某些其他的系统中导入一些数据到es，会采取这种方式，就是使用系统中已有数据的唯一标识，作为es中document的id。 PUT &#x2F;rrc&#x2F;user&#x2F;11 &#123; &quot;name&quot;:&quot;wang&quot;, &quot;price&quot;:30 &#125; &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;11&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true &#125; 自动生成document id POST &#x2F;rrc&#x2F;user &#123; &quot;name&quot;:&quot;wangql&quot;, &quot;price&quot;:30 &#125; &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;AYSyqRvxLAoa11ADX7JR&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true &#125; 自动生成的id，长度为20个字符，URL安全，base64编码，GUID算法，分布式系统并行生成时不可能会发生冲突 _source元数据 在创建一个document的时候，使用的那个放在request body中的json串，默认情况下，在get的时候，会原封不动的给我们返回回来。 get &#x2F;rrc&#x2F;user&#x2F;11 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;11&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;wang&quot;, &quot;price&quot;: 30 &#125; &#125; 定制返回结果 get &#x2F;rrc&#x2F;user&#x2F;11?_source&#x3D;name &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;11&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;wangql&quot; &#125; &#125; 乐观锁并发控制方案 Elasticsearch内部如何基于_version进行乐观锁并发控制 第一次创建一个document的时候，它的version内部版本号就是1；以后，每次对这个document执行修改或者删除操作，都会对这个_version版本号自动加1；哪怕是删除，也会对这条数据的版本号加1 PUT &#x2F;rrc&#x2F;user&#x2F;4 &#123; &quot;name&quot;:&quot;tie&#39;dan&quot;, &quot;price&quot;:30 &#125; # 首次插入version为1 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true &#125; DELETE &#x2F;rrc&#x2F;user&#x2F;4 # 执行删除操作 version为2 &#123; &quot;found&quot;: true, &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_version&quot;: 2, &quot;result&quot;: &quot;deleted&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125; &#125; &#x2F;&#x2F; 我们会发现，在删除一个document之后，可以从一个侧面证明，它不是立即物理删除掉的，因为它的一些版本号等信息还是保留着的。先删除一条document，再重新创建这条document，其实会在delete version基础之上，再把version号加1。 # 重新创建document PUT &#x2F;rrc&#x2F;user&#x2F;4 &#123; &quot;name&quot;:&quot;tie&#39;dan&quot;, &quot;price&quot;:30 &#125; # 版本号增加到3 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;4&quot;, &quot;_version&quot;: 3, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true &#125; 基于_version进行乐观锁并发控制 # 构建数据 PUT &#x2F;rrc&#x2F;user&#x2F;9 &#123; &quot;name&quot;:&quot;tie&#39;dan&quot;, &quot;price&quot;:30 &#125; &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;9&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true &#125; 基于version字段进行更新 post &#x2F;rrc&#x2F;user&#x2F;9&#x2F;_update?version&#x3D;1 &#123; &quot;doc&quot;:&#123; &quot;name&quot;:&quot;goudan&quot; &#125; &#125; # 查询数据 版本号变更2 GET &#x2F;rrc&#x2F;user&#x2F;9 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;9&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;goudan&quot;, &quot;price&quot;: 30 &#125; &#125; # 如果此时依然有其他的客户端基于version&#x3D;1进行修改操作 post &#x2F;rrc&#x2F;user&#x2F;9&#x2F;_update?version&#x3D;1 &#123; &quot;doc&quot;:&#123; &quot;name&quot;:&quot;goudan&quot; &#125; &#125; # 会有相应的提示信息 当前的版本号为2 更新不成功 &#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[user][9]: version conflict, current version [2] is different than the one provided [1]&quot;, &quot;index_uuid&quot;: &quot;uUbcg5zwTxmrq6qWNjMRUw&quot;, &quot;shard&quot;: &quot;1&quot;, &quot;index&quot;: &quot;rrc&quot; &#125; ], &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[user][9]: version conflict, current version [2] is different than the one provided [1]&quot;, &quot;index_uuid&quot;: &quot;uUbcg5zwTxmrq6qWNjMRUw&quot;, &quot;shard&quot;: &quot;1&quot;, &quot;index&quot;: &quot;rrc&quot; &#125;, &quot;status&quot;: 409 &#125; 基于external version进行乐观锁并发控制 ES内部版本控制version=1自定义版本控制?version=1&amp;version_type=external ES提供了一个feature，就是说，你可以不用它提供的内部version版本号来进行并发控制，可以基于你自己维护的一个版本号来进行并发控制。 version_type=external，唯一的区别在于，version，只有当你提供的version与es中的version一模一样的时候，才可以进行修改，只要不一样，就报错；当version_type=external的时候，只有当你提供的version比es中的_version大的时候，才能完成修改 # 获取数据 此时版本号为2 GET &#x2F;rrc&#x2F;user&#x2F;9 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;9&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;goudan&quot;, &quot;price&quot;: 30 &#125; &#125; # 我们基于external version进行局部更新 post &#x2F;rrc&#x2F;user&#x2F;9&#x2F;_update?version&#x3D;10&amp;version_type&#x3D;external &#123; &quot;doc&quot;:&#123; &quot;name&quot;:&quot;goudan&quot; &#125; &#125; # 根据报错可以发现external version不支持ES局部更新 &#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;action_request_validation_exception&quot;, &quot;reason&quot;: &quot;Validation Failed: 1: version type [EXTERNAL] is not supported by the update API;&quot; &#125; ], &quot;type&quot;: &quot;action_request_validation_exception&quot;, &quot;reason&quot;: &quot;Validation Failed: 1: version type [EXTERNAL] is not supported by the update API;&quot; &#125;, &quot;status&quot;: 400 &#125; # 我们基于external version进行更新操作 PUT &#x2F;rrc&#x2F;user&#x2F;9?version&#x3D;10&amp;version_type&#x3D;external &#123; &quot;name&quot;:&quot;tiedan&quot;, &quot;price&quot;:99 &#125; # 此时数据修改成功 版本号变成了10 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;9&quot;, &quot;_version&quot;: 10, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: false &#125; # 如果此时依然有其他的客户端基于version&#x3D;9进行修改操作 PUT &#x2F;rrc&#x2F;user&#x2F;9?version&#x3D;9&amp;version_type&#x3D;external &#123; &quot;name&quot;:&quot;tiedan&quot;, &quot;price&quot;:99 &#125; # 此时报版本冲突 当前版本号为10 &#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[user][9]: version conflict, current version [10] is higher or equal to the one provided [9]&quot;, &quot;index_uuid&quot;: &quot;uUbcg5zwTxmrq6qWNjMRUw&quot;, &quot;shard&quot;: &quot;1&quot;, &quot;index&quot;: &quot;rrc&quot; &#125; ], &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[user][9]: version conflict, current version [10] is higher or equal to the one provided [9]&quot;, &quot;index_uuid&quot;: &quot;uUbcg5zwTxmrq6qWNjMRUw&quot;, &quot;shard&quot;: &quot;1&quot;, &quot;index&quot;: &quot;rrc&quot; &#125;, &quot;status&quot;: 409 &#125; 部分更新partial update # 部分更新 POST &#x2F;rrc&#x2F;user&#x2F;9&#x2F;_update &#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;test2&quot; &#125; &#125; 部分更新内置乐观锁并发控制 可以通过添加retry_on_conflict参数来控制重试次数。 基于groovy脚本进行partial update es，其实是有个内置的脚本支持的，可以基于groovy脚本实现各种各样的复杂操作 基于groovy脚本执行partial update 内置脚本更新 GET &#x2F;rrc&#x2F;user&#x2F;9 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;9&quot;, &quot;_version&quot;: 10, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;tiedan&quot;, &quot;price&quot;: 99 &#125; &#125; # 内置脚本更新 POST &#x2F;rrc&#x2F;user&#x2F;9&#x2F;_update &#123; &quot;script&quot;: &quot;ctx._source.price +&#x3D; 1&quot; &#125; # 查询document GET &#x2F;rrc&#x2F;user&#x2F;9 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;9&quot;, &quot;_version&quot;: 11, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;tiedan&quot;, &quot;price&quot;: 100 &#125; &#125; 外部脚本更新 外部脚本位置： elasticsearch安装路径&#x2F;config&#x2F;scripts 脚本命名：test-add-tags.groovy，内容如下： ctx._source.price+&#x3D;new_price 脚本调用 POST &#x2F;rrc&#x2F;user&#x2F;9&#x2F;_update &#123; &quot;script&quot;: &#123; &quot;lang&quot;: &quot;groovy&quot;, &quot;file&quot;: &quot;test-add-tags&quot;, &quot;params&quot;: &#123; &quot;new_price&quot;: 99 &#125; &#125; &#125; # 调用结果 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;9&quot;, &quot;_version&quot;: 28, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125; &#125; 用脚本删除 ctx.op &#x3D; ctx._source.num &#x3D;&#x3D; count ? &#39;delete&#39; : &#39;none&#39; POST &#x2F;rrc&#x2F;user&#x2F;9&#x2F;_update &#123; &quot;script&quot;: &#123; &quot;lang&quot;: &quot;groovy&quot;, &quot;file&quot;: &quot;test-delete-document&quot;, &quot;params&quot;: &#123; &quot;count&quot;: 1 &#125; &#125; &#125; upsert操作 如果指定的document不存在，就执行upsert中的初始化操作；如果指定的document存在，就执行doc或者script指定的partial update操作 # document不存在 POST &#x2F;rrc&#x2F;user&#x2F;999&#x2F;_update &#123; &quot;script&quot; : &quot;ctx._source.num+&#x3D;1&quot;, &quot;upsert&quot;: &#123; &quot;num&quot;: 0, &quot;tags&quot;: [] &#125; &#125; # document不存在 执行初始化操作 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;999&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125; &#125; # 再次执行 此时document已经存在 POST &#x2F;rrc&#x2F;user&#x2F;999&#x2F;_update &#123; &quot;script&quot; : &quot;ctx._source.num+&#x3D;1&quot;, &quot;upsert&quot;: &#123; &quot;num&quot;: 0, &quot;tags&quot;: [] &#125; &#125; # 此时执行的是update操作 &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;999&quot;, &quot;_version&quot;: 2, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125; &#125; 批量查询mget 相对于一条一条的数据查询，如果我们要查询100条数据，那么就要发送100次网络请求。但是如果我们使用批量查询，查询100条数据，就只需要发送1次网络请求，网络请求的性能开销缩减100倍。 # 查询不同index下的数据 GET &#x2F;_mget &#123; &quot;docs&quot; : [ &#123; &quot;_index&quot; : &quot;rrc&quot;, &quot;_type&quot; : &quot;user&quot;, &quot;_id&quot; : 1 &#125;, &#123; &quot;_index&quot; : &quot;rrc&quot;, &quot;_type&quot; : &quot;user&quot;, &quot;_id&quot; : 999 &#125; ] &#125; &#123; &quot;docs&quot;: [ &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;num&quot;: 1, &quot;tags&quot;: [] &#125; &#125;, &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;999&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;num&quot;: 1, &quot;tags&quot;: [] &#125; &#125; ] &#125; # 查询同一个index下的数据 GET &#x2F;rrc&#x2F;_mget &#123; &quot;docs&quot; : [ &#123; &quot;_type&quot; : &quot;user&quot;, &quot;_id&quot; : 1 &#125;, &#123; &quot;_type&quot; : &quot;user&quot;, &quot;_id&quot; : 999 &#125; ] &#125; &#123; &quot;docs&quot;: [ &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;num&quot;: 1, &quot;tags&quot;: [] &#125; &#125;, &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;999&quot;, &quot;_version&quot;: 2, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;num&quot;: 1, &quot;tags&quot;: [] &#125; &#125; ] &#125; # 查询同一个type下的数据 GET &#x2F;rrc&#x2F;user&#x2F;_mget &#123; &quot;docs&quot; : [ &#123; &quot;_id&quot; : 1 &#125;, &#123; &quot;_id&quot; : 999 &#125; ] &#125; # 简写 GET &#x2F;rrc&#x2F;user&#x2F;_mget &#123; &quot;ids&quot;: [1, 2] &#125; 一般来说，在进行查询的时候，如果一次性要查询多条数据的话，那么一定要用batch批量操作的api，尽可能减少网络开销次数，提升系统性能。 批量操作bulk bulk是es提供的一种批量增删改的操作 bulk对JSON串的有着严格的要求。每个JSON串不能换行，只能放在同一行，同时，相邻的JSON串之间必须要有换行（Linux下是\\n；Window下是\\r\\n）。bulk的每个操作必须要一对JSON串（delete语法除外）。 语法： POST &#x2F;_bulk &#123; action: &#123; metadata &#125;&#125; &#123; request body &#125; &#123; action: &#123; metadata &#125;&#125; &#123; request body &#125; bulk的操作类型 create 如果文档不存在就创建，但如果文档存在就返回错误 index 如果文档不存在就创建，如果文档存在就更新 update 更新一个文档，如果文档不存在就返回错误 delete 删除一个文档，如果要删除的文档id不存在，就返回错误 POST &#x2F;_bulk &#123; &quot;index&quot;: &#123;&quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;:&quot;user&quot;, &quot;_id&quot;:&quot;1&quot;&#125;&#125; &#123;&quot;name&quot;: &quot;test1&quot;, &quot;price&quot;: 50&#125; &#123; &quot;took&quot;: 47, &quot;errors&quot;: false, &quot;items&quot;: [ &#123; &quot;index&quot;: &#123; &quot;_index&quot;: &quot;rrc&quot;, &quot;_type&quot;: &quot;user&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 7, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: false, &quot;status&quot;: 200 &#125; &#125; ] &#125; 批量操作： POST &#x2F;_bulk &#123; &quot;delete&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;3&quot; &#125;&#125; &#123; &quot;create&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;12&quot; &#125;&#125; &#123; &quot;test_field&quot;: &quot;test12&quot; &#125; &#123; &quot;index&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;2&quot; &#125;&#125; &#123; &quot;test_field&quot;: &quot;replaced test2&quot; &#125; &#123; &quot;update&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_retry_on_conflict&quot; : 3&#125; &#125; &#123; &quot;doc&quot; : &#123;&quot;test_field2&quot; : &quot;bulk test1&quot;&#125; &#125; &#123; &quot;took&quot;: 33, &quot;errors&quot;: true, &quot;items&quot;: [ &#123; &quot;delete&quot;: &#123; &quot;found&quot;: false, &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;not_found&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;status&quot;: 404 &#125; &#125;, &#123; &quot;create&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;12&quot;, &quot;status&quot;: 409, &quot;error&quot;: &#123; &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[test_type][12]: version conflict, document already exists (current version [1])&quot;, &quot;index_uuid&quot;: &quot;OrzYgLkZTnCiHq6FBDSOoQ&quot;, &quot;shard&quot;: &quot;1&quot;, &quot;index&quot;: &quot;test_index&quot; &#125; &#125; &#125;, &#123; &quot;index&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_version&quot;: 17, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: false, &quot;status&quot;: 200 &#125; &#125;, &#123; &quot;update&quot;: &#123; &quot;_index&quot;: &quot;test_index&quot;, &quot;_type&quot;: &quot;test_type&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;status&quot;: 404, &quot;error&quot;: &#123; &quot;type&quot;: &quot;document_missing_exception&quot;, &quot;reason&quot;: &quot;[test_type][1]: document missing&quot;, &quot;index_uuid&quot;: &quot;OrzYgLkZTnCiHq6FBDSOoQ&quot;, &quot;shard&quot;: &quot;3&quot;, &quot;index&quot;: &quot;test_index&quot; &#125; &#125; &#125; ] &#125; bulk操作中，任意一个操作失败，是不会影响其他的操作的，但是在返回结果里，会告诉你异常日志 document数据路由原理 1个index的数据会被分配到多个shard中，1个document只会被放到其中1个primary shard中 也就是说，当我们创建document的时候，es就要决定这个document是放在这个index的哪个shard上，这个过程就称为document routing(数据路由)。 路由算法 公式：shard=hash(routing)%number_of_primary_shards 每次增删改查一个document的时候，都会带过来一个routing，默认就是这个document的id，也就说会默认会根据id来路由 举个例子，1个index有3个primary shard(P1,P2,P3)，_id是1 hash(1)假如等于22，hash值对primary shard数量求余22%3=1，那这个document由es决定放在P1上。 使用默认routing或手动指定routing 默认的routing就是_id 也可以在写入document的时候指定routing，语法为 put &#x2F;index&#x2F;type&#x2F;id?routing&#x3D;user_id 通过协调节点进行增删改的内部原理 前面讲了数据路由原理，这里要讲的是document是在哪里进行路由，那么就要引出一个概念：协调节点。简单地说所有的shard都是协调节点。java客户端可以往任何一个shard发送请求，因为任何一个shard都知道每个document在哪个shard上。下面讲一下增删改的流程/内部原理： (1) 请求会从协调节点被转发到最终的primary shard上去处理。 (2) 然后primary shard将document同步到replica shard上。 (3) 协调节点发现路由到的所有primary shard和对应的replica shard都处理完请求后，就返回响应结果给客户端。 通过协调节点进行查询的内部原理 与增删改不同的是，协调节点会把查询请求路由到涉及到的document的其中一个primary shard或replica shard上，具体会使用round-robin随机轮询算法，使读请求负载均衡。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://qinglei1989.github.io/tags/Elasticsearch/"}]},{"title":"RabbitMQ延迟队列","slug":"middleware-rabbitmq-delayed-message","date":"2022-11-21T16:09:41.000Z","updated":"2023-01-18T14:21:07.625Z","comments":true,"path":"2022/11/22/middleware-rabbitmq-delayed-message/","link":"","permalink":"https://qinglei1989.github.io/2022/11/22/middleware-rabbitmq-delayed-message/","excerpt":"RabbitMQ延迟队列","text":"RabbitMQ延迟队列 【MQ中间件】RabbitMQ延迟队列 什么是延时队列 延时队列，首先，它是一种队列，队列意味着内部的元素是有序的，元素出队和入队是有方向性的，元素从一端进入，从另一端取出。 其次，延时队列最重要的特性就体现在它的延时属性上，跟普通的队列不一样的是，普通队列中的元素总是等着希望被早点取出处理，而延时队列中的元素则是希望被在指定时间得到取出和处理，所以延时队列中的元素是都是带时间属性的。 简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。 延时队列使用场景 那么什么时候需要用延时队列呢？考虑一下以下场景： 订单在十分钟之内未支付则自动取消。 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。 账单在一周内未支付，则自动结算。 用户注册成功后，如果三天内没有登陆则进行短信提醒。 用户发起退款，如果三天内没有得到处理则通知相关运营人员。 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议。 对于少量数据，我们可以使用定时任务来完成相应的需求。 但对于数据量比较大，并且时效性较强的场景，如：“订单十分钟内未支付则关闭“，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能单位时间内无法完成所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下。 这时候，延时队列就可以闪亮登场了，以上场景，正是延时队列的用武之地。 RabbitMQ中的TTL TTL是RabbitMQ中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。 换句话说，如果一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没有被消费，则会成为“死信”（至于什么是死信，请翻看上一篇）。如果同时配置了队列的TTL和消息的TTL，那么较小的那个值将会被使用。 那么，如何设置这个TTL值呢？有两种方式，第一种是在创建队列的时候设置队列的“x-message-ttl”属性，如下： Map&lt;String, Object&gt; args &#x3D; new HashMap&lt;String, Object&gt;(); args.put(&quot;x-message-ttl&quot;, 6000); channel.queueDeclare(queueName, durable, exclusive, autoDelete, args); 这样所有被投递到该队列的消息都最多不会存活超过6s。 另一种方式便是针对每条消息设置TTL，代码如下： AMQP.BasicProperties.Builder builder &#x3D; new AMQP.BasicProperties.Builder(); builder.expiration(&quot;6000&quot;); AMQP.BasicProperties properties &#x3D; builder.build(); channel.basicPublish(exchangeName, routingKey, mandatory, properties, &quot;msg body&quot;.getBytes()); 这样这条消息的过期时间也被设置成了6s。 但这两种方式是有区别的，如果设置了队列的TTL属性，那么一旦消息过期，就会被队列丢弃，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间。 另外，还需要注意的一点是，如果不设置TTL，表示消息永远不会过期，如果将TTL设置为0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。 如何利用RabbitMQ实现延时队列 RabbitMQ 本身是不支持的，可以通过它提供的两个特性 Time-To-Live and Expiration、Dead Letter Exchanges 来实现，通过以下泳道图可以看到一个消息从发布到消费的整个过程。 延时队列，不就是想要消息延迟多久被处理吗，TTL则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就万事大吉了，因为里面的消息都是希望被立即处理的消息。 生产者生产一条延时消息，根据需要延时时间的不同，利用不同的routingkey将消息路由到不同的延时队列，每个队列都设置了不同的TTL属性，并绑定在同一个死信交换机中，消息过期后，根据routingkey的不同，又会被路由到不同的死信队列中，消费者只需要监听对应的死信队列进行处理即可。 相关代码： 先声明交换机、队列以及他们的绑定关系： @Configuration public class RabbitMQConfig &#123; public static final String DELAY_EXCHANGE_NAME &#x3D; &quot;delay.queue.demo.business.exchange&quot;; public static final String DELAY_QUEUEA_NAME &#x3D; &quot;delay.queue.demo.business.queuea&quot;; public static final String DELAY_QUEUEB_NAME &#x3D; &quot;delay.queue.demo.business.queueb&quot;; public static final String DELAY_QUEUEA_ROUTING_KEY &#x3D; &quot;delay.queue.demo.business.queuea.routingkey&quot;; public static final String DELAY_QUEUEB_ROUTING_KEY &#x3D; &quot;delay.queue.demo.business.queueb.routingkey&quot;; public static final String DEAD_LETTER_EXCHANGE &#x3D; &quot;delay.queue.demo.deadletter.exchange&quot;; public static final String DEAD_LETTER_QUEUEA_ROUTING_KEY &#x3D; &quot;delay.queue.demo.deadletter.delay_10s.routingkey&quot;; public static final String DEAD_LETTER_QUEUEB_ROUTING_KEY &#x3D; &quot;delay.queue.demo.deadletter.delay_60s.routingkey&quot;; public static final String DEAD_LETTER_QUEUEA_NAME &#x3D; &quot;delay.queue.demo.deadletter.queuea&quot;; public static final String DEAD_LETTER_QUEUEB_NAME &#x3D; &quot;delay.queue.demo.deadletter.queueb&quot;; &#x2F;&#x2F; 声明延时Exchange @Bean(&quot;delayExchange&quot;) public DirectExchange delayExchange()&#123; return new DirectExchange(DELAY_EXCHANGE_NAME); &#125; &#x2F;&#x2F; 声明死信Exchange @Bean(&quot;deadLetterExchange&quot;) public DirectExchange deadLetterExchange()&#123; return new DirectExchange(DEAD_LETTER_EXCHANGE); &#125; &#x2F;&#x2F; 声明延时队列A 延时10s &#x2F;&#x2F; 并绑定到对应的死信交换机 @Bean(&quot;delayQueueA&quot;) public Queue delayQueueA()&#123; Map&lt;String, Object&gt; args &#x3D; new HashMap&lt;&gt;(2); &#x2F;&#x2F; x-dead-letter-exchange 这里声明当前队列绑定的死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, DEAD_LETTER_EXCHANGE); &#x2F;&#x2F; x-dead-letter-routing-key 这里声明当前队列的死信路由key args.put(&quot;x-dead-letter-routing-key&quot;, DEAD_LETTER_QUEUEA_ROUTING_KEY); &#x2F;&#x2F; x-message-ttl 声明队列的TTL args.put(&quot;x-message-ttl&quot;, 6000); return QueueBuilder.durable(DELAY_QUEUEA_NAME).withArguments(args).build(); &#125; &#x2F;&#x2F; 声明延时队列B 延时 60s &#x2F;&#x2F; 并绑定到对应的死信交换机 @Bean(&quot;delayQueueB&quot;) public Queue delayQueueB()&#123; Map&lt;String, Object&gt; args &#x3D; new HashMap&lt;&gt;(2); &#x2F;&#x2F; x-dead-letter-exchange 这里声明当前队列绑定的死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, DEAD_LETTER_EXCHANGE); &#x2F;&#x2F; x-dead-letter-routing-key 这里声明当前队列的死信路由key args.put(&quot;x-dead-letter-routing-key&quot;, DEAD_LETTER_QUEUEB_ROUTING_KEY); &#x2F;&#x2F; x-message-ttl 声明队列的TTL args.put(&quot;x-message-ttl&quot;, 60000); return QueueBuilder.durable(DELAY_QUEUEB_NAME).withArguments(args).build(); &#125; &#x2F;&#x2F; 声明死信队列A 用于接收延时10s处理的消息 @Bean(&quot;deadLetterQueueA&quot;) public Queue deadLetterQueueA()&#123; return new Queue(DEAD_LETTER_QUEUEA_NAME); &#125; &#x2F;&#x2F; 声明死信队列B 用于接收延时60s处理的消息 @Bean(&quot;deadLetterQueueB&quot;) public Queue deadLetterQueueB()&#123; return new Queue(DEAD_LETTER_QUEUEB_NAME); &#125; &#x2F;&#x2F; 声明延时队列A绑定关系 @Bean public Binding delayBindingA(@Qualifier(&quot;delayQueueA&quot;) Queue queue, @Qualifier(&quot;delayExchange&quot;) DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DELAY_QUEUEA_ROUTING_KEY); &#125; &#x2F;&#x2F; 声明业务队列B绑定关系 @Bean public Binding delayBindingB(@Qualifier(&quot;delayQueueB&quot;) Queue queue, @Qualifier(&quot;delayExchange&quot;) DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DELAY_QUEUEB_ROUTING_KEY); &#125; &#x2F;&#x2F; 声明死信队列A绑定关系 @Bean public Binding deadLetterBindingA(@Qualifier(&quot;deadLetterQueueA&quot;) Queue queue, @Qualifier(&quot;deadLetterExchange&quot;) DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DEAD_LETTER_QUEUEA_ROUTING_KEY); &#125; &#x2F;&#x2F; 声明死信队列B绑定关系 @Bean public Binding deadLetterBindingB(@Qualifier(&quot;deadLetterQueueB&quot;) Queue queue, @Qualifier(&quot;deadLetterExchange&quot;) DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DEAD_LETTER_QUEUEB_ROUTING_KEY); &#125; &#125; 接下来，创建两个消费者，分别对两个死信队列的消息进行消费： @Slf4j @Component public class DeadLetterQueueConsumer &#123; @RabbitListener(queues &#x3D; DEAD_LETTER_QUEUEA_NAME) public void receiveA(Message message, Channel channel) throws IOException &#123; String msg &#x3D; new String(message.getBody()); log.info(&quot;当前时间：&#123;&#125;,死信队列A收到消息：&#123;&#125;&quot;, new Date().toString(), msg); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; @RabbitListener(queues &#x3D; DEAD_LETTER_QUEUEB_NAME) public void receiveB(Message message, Channel channel) throws IOException &#123; String msg &#x3D; new String(message.getBody()); log.info(&quot;当前时间：&#123;&#125;,死信队列B收到消息：&#123;&#125;&quot;, new Date().toString(), msg); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; &#125; 发送消息 @Override public void sendDelayMessage(String msg, String type) &#123; if (&quot;delay10&quot;.equals(type)) &#123; rabbitTemplate.convertAndSend(DELAY_EXCHANGE_NAME, DELAY_QUEUEA_ROUTING_KEY, msg); return; &#125; rabbitTemplate.convertAndSend(DELAY_EXCHANGE_NAME, DELAY_QUEUEB_ROUTING_KEY, msg); &#125; 发送测试消息 http:&#x2F;&#x2F;localhost:8080&#x2F;rabbitmq&#x2F;sendmsg?msg&#x3D;testMsg1&amp;type&#x3D;delay10 http:&#x2F;&#x2F;localhost:8080&#x2F;rabbitmq&#x2F;sendmsg?msg&#x3D;testMsg2&amp;type&#x3D;delay60 第一条消息在6s后变成了死信消息，然后被消费者消费掉，第二条消息在60s之后变成了死信消息，然后被消费掉，这样，一个还算ok的延时队列就打造完成了。 不过，等等，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有6s和60s两个时间选项，如果需要一个小时后处理，那么就需要增加TTL为一个小时的队列，如果是预定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？？ DLX + TTL 方式存在的时序问题 对于延迟队列不管是 AMQP 协议或者 RabbitMQ 本身是不支持的，使用 RabbitMQ 死信队列（DLX） + TTL 的方式来模拟实现延迟队列是通常的一种做法。 左侧队列 queue1 分别两条消息 msg1、msg2 过期时间都为 1s，输出顺序为 msg1、msg2 是没问题的 右侧队列 queue2 分别两条消息 msg1、msg2 注意问题来了，msg2 的消息过期时间为 1S 而 msg1 的消息过期为 2S，因为这是在同一个队列，必须前一个消费，第二个才能消费，所以就出现了时序问题。 如果你的消息过期时间是有规律的，例如，有的 1S、有的 2S，那么我们可以以时间为维度设计为两个队列。如果此时消息的过期时间不确定或者消息过期时间维度过多，在消费端我们就要去监听多个消息队列且对于消息过期时间不确定的也是很难去设计的。 RabbitMQ延时队列优化 利用RabbitMQ插件实现延迟队列 插件安装 rabbitmq和延时插件的版本必须匹配 &#x2F;&#x2F; 查看rabbitmq版本号 root@myrabbit:&#x2F;opt&#x2F;rabbitmq&#x2F;plugins# rabbitmqctl version 3.9.11 &#x2F;&#x2F; 进入插件目录 root@myrabbit:&#x2F;opt&#x2F;rabbitmq&#x2F;plugins# cd &#x2F;opt&#x2F;rabbitmq&#x2F;plugins &#x2F;&#x2F; 下载插件 wget https:&#x2F;&#x2F;github.com&#x2F;rabbitmq&#x2F;rabbitmq-delayed-message-exchange&#x2F;releases&#x2F;download&#x2F;3.9.0&#x2F;rabbitmq_delayed_message_exchange-3.9.0.ez &#x2F;&#x2F; 安装 root@myrabbit:&#x2F;opt&#x2F;rabbitmq&#x2F;plugins# rabbitmq-plugins enable rabbitmq_delayed_message_exchange Enabling plugins on node rabbit@myrabbit: rabbitmq_delayed_message_exchange The following plugins have been configured: rabbitmq_delayed_message_exchange rabbitmq_management rabbitmq_management_agent rabbitmq_mqtt rabbitmq_prometheus rabbitmq_web_dispatch Applying plugin configuration to rabbit@myrabbit... The following plugins have been enabled: rabbitmq_delayed_message_exchange started 1 plugins. root@myrabbit:&#x2F;opt&#x2F;rabbitmq&#x2F;plugins# &#x2F;&#x2F; 查看插件 root@myrabbit:&#x2F;opt&#x2F;rabbitmq&#x2F;plugins# rabbitmq-plugins list Listing plugins with pattern &quot;.*&quot; ... Configured: E &#x3D; explicitly enabled; e &#x3D; implicitly enabled | Status: * &#x3D; running on rabbit@myrabbit |&#x2F; [ ] rabbitmq_amqp1_0 3.9.11 [ ] rabbitmq_auth_backend_cache 3.9.11 [ ] rabbitmq_auth_backend_http 3.9.11 [ ] rabbitmq_auth_backend_ldap 3.9.11 [ ] rabbitmq_auth_backend_oauth2 3.9.11 [ ] rabbitmq_auth_mechanism_ssl 3.9.11 [ ] rabbitmq_consistent_hash_exchange 3.9.11 [E*] rabbitmq_delayed_message_exchange 3.9.0 重启容器 实现原理 消息在发布之后不会立即进入队列，先将消息保存至 Mnesia。这个插件将会尝试确认消息是否过期，首先要确保消息的延迟范围是 Delay &gt; 0, Delay =&lt; ERL_MAX_T（在 Erlang 中可以被设置的范围为 (2^32)-1 毫秒），如果消息过期通过 x-delayed-type 类型标记的交换机投递至目标队列，整个消息的投递过程也就完成了。 实例 如果不能实现在消息粒度上添加TTL，并使其在设置的TTL时间及时死亡，就无法设计成一个通用的延时队列。 @Configuration public class DelayedRabbitMQConfig &#123; public static final String DELAYED_QUEUE_NAME &#x3D; &quot;delay.queue.demo.delay.queue&quot;; public static final String DELAYED_EXCHANGE_NAME &#x3D; &quot;delay.queue.demo.delay.exchange&quot;; public static final String DELAYED_ROUTING_KEY &#x3D; &quot;delay.queue.demo.delay.routingkey&quot;; @Bean public Queue immediateQueue() &#123; return new Queue(DELAYED_QUEUE_NAME); &#125; @Bean public CustomExchange customExchange() &#123; Map&lt;String, Object&gt; args &#x3D; new HashMap&lt;&gt;(); args.put(&quot;x-delayed-type&quot;, &quot;direct&quot;); return new CustomExchange(DELAYED_EXCHANGE_NAME, &quot;x-delayed-message&quot;, true, false, args); &#125; @Bean public Binding bindingNotify(@Qualifier(&quot;immediateQueue&quot;) Queue queue, @Qualifier(&quot;customExchange&quot;) CustomExchange customExchange) &#123; return BindingBuilder.bind(queue).to(customExchange).with(DELAYED_ROUTING_KEY).noargs(); &#125; &#125; controller层再添加一个入口： @GetMapping(&quot;&#x2F;sendDelayLetterMessage&quot;) public String sendDelayLetterMessage(String msg, Integer delayTime) &#123; rabbitMQService.sendDelayLetterMessage(msg, delayTime); return &quot;ok&quot;; &#125; 消息发送者ServiceImpl实现类： @Override public void sendDelayLetterMessage(String msg, Integer delayTime) &#123; rabbitTemplate.convertAndSend(DELAYED_EXCHANGE_NAME, DELAYED_ROUTING_KEY, msg, a -&gt;&#123; a.getMessageProperties().setDelay(delayTime); return a; &#125;); &#125; 消息接收者 @Slf4j @Component public class DelayMessageReceiver &#123; @RabbitListener(queues &#x3D; DELAYED_QUEUE_NAME) public void receiveD(Message message, Channel channel) throws IOException &#123; String msg &#x3D; new String(message.getBody()); log.info(&quot;当前时间：&#123;&#125;,延时队列收到消息：&#123;&#125;&quot;, new Date().toString(), msg); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; &#125; 请求连接： http:&#x2F;&#x2F;localhost:8080&#x2F;&#x2F;system&#x2F;rabbitmq&#x2F;&#x2F;sendDelayLetterMessage?msg&#x3D;delay20000&amp;delayTime&#x3D;20000 http:&#x2F;&#x2F;localhost:8080&#x2F;&#x2F;system&#x2F;rabbitmq&#x2F;&#x2F;sendDelayLetterMessage?msg&#x3D;delay2000&amp;delayTime&#x3D;2000 相关日志打印： [TRACEID:0ef19c49ad984cc5b5730df0a55c7523] 2022-11-27 00:58:16.403 [http-nio-8080-exec-11-67] INFO com.wql.aspect.WebLogAspect 67 doAfterReturning - WebLogAspect.doAfterReturning() [TRACEID:] 2022-11-27 00:58:18.410 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#4-1-26] INFO c.wql.consumer.DelayMessageReceiver 26 receiveD - 当前时间：Sun Nov 27 00:58:18 CST 2022,延时队列收到消息：delay2000 [TRACEID:] 2022-11-27 00:58:35.005 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#4-1-26] INFO c.wql.consumer.DelayMessageReceiver 26 receiveD - 当前时间：Sun Nov 27 00:58:35 CST 2022,延时队列收到消息：delay20000 第二个消息被先消费掉了，符合预期。 局限性 Delayed Message 插件实现 RabbitMQ 延迟队列这种方式也不完全是一个银弹，它将延迟消息存在于 Mnesia 表中，并且在当前节点上具有单个磁盘副本，它们将在节点重启之后幸存(也就是说不支持集群部署)。 目前该插件的当前设计并不真正适合包含大量延迟消息（例如数十万或数百万）的场景，详情参见 #/issues/72 另外该插件的一个可变性来源是依赖于 Erlang 计时器，在系统中使用了一定数量的长时间计时器之后，它们开始争用调度程序资源，并且时间漂移不断累积。 插件的禁用要慎重，以下方式可以实现将插件禁用，但是注意如果此时还有延迟消息未消费，那么禁掉此插件后所有的未消费的延迟消息将丢失。 rabbitmq-plugins disable rabbitmq_delayed_message_exchange 如果你采用了 Delayed Message 插件这种方式来实现，对于消息可用性要求较高的，在发消息之前可以先落入 DB 打标记，消费之后将消息标记为已消费，中间可以加入定时任务做检测，这可以进一步保证你的消息的可靠性。 引用 Docker安装RabbitMQ并安装延时队列插件 MQ高级 一文带你搞定RabbitMQ延迟队列 Delayed Message 插件实现 RabbitMQ 延迟队列 延迟队列报错（NO_ROUTE）","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://qinglei1989.github.io/categories/rabbitmq/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"RabbitMQ死信队列","slug":"middleware-rabbitmq-deadletter","date":"2022-11-19T16:03:02.000Z","updated":"2022-11-21T17:35:47.102Z","comments":true,"path":"2022/11/20/middleware-rabbitmq-deadletter/","link":"","permalink":"https://qinglei1989.github.io/2022/11/20/middleware-rabbitmq-deadletter/","excerpt":"RabbitMQ死信队列","text":"RabbitMQ死信队列 【MQ中间件】RabbitMQ死信队列 死信队列 “死信”是RabbitMQ中的一种消息机制，当你在消费消息时，如果队列里的消息出现以下情况： 消息被否定确认，使用 channel.basicNack 或 channel.basicReject ，并且此时requeue 属性被设置为false。 消息在队列的存活时间超过设置的TTL时间。 消息队列的消息数量已经超过最大队列长度。 那么该消息将成为“死信”。 “死信”消息会被RabbitMQ进行特殊处理，如果配置了死信队列信息，那么该消息将会被丢进死信队列中，如果没有配置，则该消息将会被丢弃。 如何配置死信队列 通过在channel.queueDeclare 方法中设置x-dead-letter-exchange 参数来为队列添加DLX args.put (”x-dead-letter-exchange ”,” dlx exchange ”); 也可以为这个DLX 指定路由键，如果没有特殊指定，则使用原队列的路由键： args.put (”x-dead-letter-routing-key”,”dlx-routing-key”); 配置死信队列呢？其实很简单，大概可以分为以下步骤： 配置业务队列，绑定到业务交换机上 为业务队列配置死信交换机和路由key 为死信交换机配置死信队列 注意，并不是直接声明一个公共的死信队列，然后所以死信消息就自己跑到死信队列里去了。而是为每个需要使用死信的业务队列配置一个死信交换机，这里同一个项目的死信交换机可以共用一个，然后为每个业务队列分配一个单独的路由key。 代码 package com.wql.config; import org.springframework.amqp.core.*; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.util.HashMap; import java.util.Map; &#x2F;** * @author: wangql * @Title: CustomConfigurer * @ProjectName: tudou * @Description: * @date: 2022&#x2F;1&#x2F;30 16:32 *&#x2F; @Configuration public class DeadLetterRabbitConfig &#123; public static final String BUSINESS_EXCHANGE_NAME &#x3D; &quot;dead.letter.demo.simple.business.exchange&quot;; public static final String BUSINESS_QUEUEA_NAME &#x3D; &quot;dead.letter.demo.simple.business.queuea&quot;; public static final String BUSINESS_QUEUEB_NAME &#x3D; &quot;dead.letter.demo.simple.business.queueb&quot;; public static final String DEAD_LETTER_EXCHANGE &#x3D; &quot;dead.letter.demo.simple.deadletter.exchange&quot;; public static final String DEAD_LETTER_QUEUEA_ROUTING_KEY &#x3D; &quot;dead.letter.demo.simple.deadletter.queuea.routingkey&quot;; public static final String DEAD_LETTER_QUEUEB_ROUTING_KEY &#x3D; &quot;dead.letter.demo.simple.deadletter.queueb.routingkey&quot;; public static final String DEAD_LETTER_QUEUEA_NAME &#x3D; &quot;dead.letter.demo.simple.deadletter.queuea&quot;; public static final String DEAD_LETTER_QUEUEB_NAME &#x3D; &quot;dead.letter.demo.simple.deadletter.queueb&quot;; &#x2F;&#x2F; 声明业务Exchange @Bean(&quot;businessExchange&quot;) public FanoutExchange businessExchange()&#123; return new FanoutExchange(BUSINESS_EXCHANGE_NAME); &#125; &#x2F;&#x2F; 声明死信Exchange @Bean(&quot;deadLetterExchange&quot;) public DirectExchange deadLetterExchange()&#123; return new DirectExchange(DEAD_LETTER_EXCHANGE); &#125; &#x2F;&#x2F; 声明业务队列A @Bean(&quot;businessQueueA&quot;) public Queue businessQueueA()&#123; Map&lt;String, Object&gt; args &#x3D; new HashMap&lt;&gt;(2); &#x2F;&#x2F; x-dead-letter-exchange 这里声明当前队列绑定的死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, DEAD_LETTER_EXCHANGE); &#x2F;&#x2F; x-dead-letter-routing-key 这里声明当前队列的死信路由key args.put(&quot;x-dead-letter-routing-key&quot;, DEAD_LETTER_QUEUEA_ROUTING_KEY); return QueueBuilder.durable(BUSINESS_QUEUEA_NAME).withArguments(args).build(); &#125; &#x2F;&#x2F; 声明业务队列B @Bean(&quot;businessQueueB&quot;) public Queue businessQueueB()&#123; Map&lt;String, Object&gt; args &#x3D; new HashMap&lt;&gt;(2); &#x2F;&#x2F; x-dead-letter-exchange 这里声明当前队列绑定的死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, DEAD_LETTER_EXCHANGE); &#x2F;&#x2F; x-dead-letter-routing-key 这里声明当前队列的死信路由key args.put(&quot;x-dead-letter-routing-key&quot;, DEAD_LETTER_QUEUEB_ROUTING_KEY); return QueueBuilder.durable(BUSINESS_QUEUEB_NAME).withArguments(args).build(); &#125; &#x2F;&#x2F; 声明死信队列A @Bean(&quot;deadLetterQueueA&quot;) public Queue deadLetterQueueA()&#123; return new Queue(DEAD_LETTER_QUEUEA_NAME); &#125; &#x2F;&#x2F; 声明死信队列B @Bean(&quot;deadLetterQueueB&quot;) public Queue deadLetterQueueB()&#123; return new Queue(DEAD_LETTER_QUEUEB_NAME); &#125; &#x2F;&#x2F; 声明业务队列A绑定关系 @Bean public Binding businessBindingA(@Qualifier(&quot;businessQueueA&quot;) Queue queue, @Qualifier(&quot;businessExchange&quot;) FanoutExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange); &#125; &#x2F;&#x2F; 声明业务队列B绑定关系 @Bean public Binding businessBindingB(@Qualifier(&quot;businessQueueB&quot;) Queue queue, @Qualifier(&quot;businessExchange&quot;) FanoutExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange); &#125; &#x2F;&#x2F; 声明死信队列A绑定关系 @Bean public Binding deadLetterBindingA(@Qualifier(&quot;deadLetterQueueA&quot;) Queue queue, @Qualifier(&quot;deadLetterExchange&quot;) DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DEAD_LETTER_QUEUEA_ROUTING_KEY); &#125; &#x2F;&#x2F; 声明死信队列B绑定关系 @Bean public Binding deadLetterBindingB(@Qualifier(&quot;deadLetterQueueB&quot;) Queue queue, @Qualifier(&quot;deadLetterExchange&quot;) DirectExchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(DEAD_LETTER_QUEUEB_ROUTING_KEY); &#125; &#125; 这里声明了两个Exchange，一个是业务Exchange，另一个是死信Exchange，业务Exchange下绑定了两个业务队列，业务队列都配置了同一个死信Exchange，并分别配置了路由key，在死信Exchange下绑定了两个死信队列，设置的路由key分别为业务队列里配置的路由key。 application.yml default-requeue-rejected属性设置为false。 业务队列消费类： package com.wql.consumer; import com.rabbitmq.client.Channel; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.core.Message; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; import java.io.IOException; import static com.wql.config.DeadLetterRabbitConfig.BUSINESS_QUEUEA_NAME; import static com.wql.config.DeadLetterRabbitConfig.BUSINESS_QUEUEB_NAME; @Slf4j @Component public class BusinessMessageReceiver &#123; @RabbitListener(queues &#x3D; BUSINESS_QUEUEA_NAME) public void receiveA(Message message, Channel channel) throws IOException &#123; String msg &#x3D; new String(message.getBody()); log.info(&quot;收到业务消息A：&#123;&#125;&quot;, msg); boolean ack &#x3D; true; Exception exception &#x3D; null; try &#123; if (msg.contains(&quot;deadletter&quot;))&#123; throw new RuntimeException(&quot;dead letter exception&quot;); &#125; &#125; catch (Exception e)&#123; ack &#x3D; false; exception &#x3D; e; &#125; if (!ack)&#123; log.error(&quot;消息消费发生异常，error msg:&#123;&#125;&quot;, exception.getMessage(), exception); channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, false); &#125; else &#123; channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; &#125; @RabbitListener(queues &#x3D; BUSINESS_QUEUEB_NAME) public void receiveB(Message message, Channel channel) throws IOException &#123; String msg &#x3D; new String(message.getBody()); log.info(&quot;收到业务消息A：&#123;&#125;&quot;, msg); boolean ack &#x3D; true; Exception exception &#x3D; null; try &#123; if (msg.contains(&quot;deadletter&quot;))&#123; throw new RuntimeException(&quot;dead letter exception&quot;); &#125; &#125; catch (Exception e)&#123; ack &#x3D; false; exception &#x3D; e; &#125; if (!ack)&#123; log.error(&quot;消息消费发生异常，error msg:&#123;&#125;&quot;, exception.getMessage(), exception); channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, false); &#125; else &#123; channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; &#125; &#125; 死信队列消费类： package com.wql.consumer; import com.rabbitmq.client.Channel; import org.springframework.amqp.core.Message; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.stereotype.Component; import java.io.IOException; import static com.wql.config.DeadLetterRabbitConfig.DEAD_LETTER_QUEUEA_NAME; import static com.wql.config.DeadLetterRabbitConfig.DEAD_LETTER_QUEUEB_NAME; @Component public class DeadLetterMessageReceiver &#123; @RabbitListener(queues &#x3D; DEAD_LETTER_QUEUEA_NAME) public void receiveA(Message message, Channel channel) throws IOException &#123; System.out.println(&quot;收到死信消息A：&quot; + new String(message.getBody())); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; @RabbitListener(queues &#x3D; DEAD_LETTER_QUEUEB_NAME) public void receiveB(Message message, Channel channel) throws IOException &#123; System.out.println(&quot;收到死信消息B：&quot; + new String(message.getBody())); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; &#125; 发送死信消息： @Override public String sendDeadLetterMessage(String msg) &#123; String messageId &#x3D; String.valueOf(UUID.randomUUID()); String createTime &#x3D; LocalDateTime.now().format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;)); Map&lt;String, Object&gt; map &#x3D; new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, messageId); map.put(&quot;messageData&quot;, msg); map.put(&quot;createTime&quot;, createTime); rabbitTemplate.convertAndSend(BUSINESS_EXCHANGE_NAME, null, map); return &quot;ok&quot;; &#125; 引用 RabbitMQ 如何进行消息可靠投递 Rabbitmq——备份交换机 RabbitMQ重试机制","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://qinglei1989.github.io/categories/rabbitmq/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"工作总结-年轻代GC频繁","slug":"work-summary-jvm","date":"2022-11-16T12:07:01.000Z","updated":"2023-02-25T15:25:24.990Z","comments":true,"path":"2022/11/16/work-summary-jvm/","link":"","permalink":"https://qinglei1989.github.io/2022/11/16/work-summary-jvm/","excerpt":"服务器从阿里云ECS迁移到58容器，为了保证迁移的顺利，在58容器做了一个简单的压测，发现了年轻代GC频繁的问题，在此做一下记录。","text":"服务器从阿里云ECS迁移到58容器，为了保证迁移的顺利，在58容器做了一个简单的压测，发现了年轻代GC频繁的问题，在此做一下记录。 工作总结-年轻代GC频繁 环境配置及相关监控 阿里云ECS配置 阿里云ECS监控 58容器 压测 基于日常的NGINX日志重放做简单压测，58容器启动了两个POD，单台QPS在100/s左右。压测1小时之后的argus监控显示如下： 现像 5分钟之内的GC次数最高达到了63次，平均GC次数达到了41.2次。而GC时长最长高达812ms，平均GC时长519ms。为什么会频繁的发生GC呢。 分析gc日志：GC分析官网，发现了一个惊讶的地方，如下： 新生代的内存竟然只有166M。 查看项目的jvm参数配置： work 45 14 24 00:28 ? 00:00:30 &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;bin&#x2F;java -Dsun.misc.URLClassPath.disableJarChecking&#x3D;true -DLOG_PATH&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-api-jmeter -server -XX:MaxRAMPercentage&#x3D;30.0 -XX:InitialRAMPercentage&#x3D;30.0 -XX:MinRAMPercentage&#x3D;30.0 -verbose:gc -XX:+UseParNewGC -XX:+PrintHeapAtGC -XX:+PrintGCDetails -XX:ConcGCThreads&#x3D;2 -XX:GCLogFileSize&#x3D;50M -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseConcMarkSweepGC -XX:ParallelGCThreads&#x3D;2 -XX:NumberOfGCLogFiles&#x3D;1 -XX:+UseGCLogFileRotation -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+CMSParallelRemarkEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintGCApplicationStoppedTime -Dsun.net.httpserver.maxReqTime&#x3D;30 -Dsun.net.httpserver.maxRspTime&#x3D;30 -XX:CMSInitiatingOccupancyFraction&#x3D;70 -Xloggc:&#x2F;mnt&#x2F;logs&#x2F;authority-api-jmeter&#x2F;jvm&#x2F;gc.log -XX:HeapDumpPath&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-api-jmeter&#x2F;jvm -javaagent:&#x2F;usr&#x2F;local&#x2F;jmx-exporter&#x2F;jmx_prometheus_javaagent-0.14.0.jar&#x3D;9990:&#x2F;usr&#x2F;local&#x2F;jmx-exporter&#x2F;prometheus-jmx-config.yaml -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -jar &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api-jmeter&#x2F;lib&#x2F;authority-api.jar --server.address&#x3D;0.0.0.0 --spring.config.location&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api-jmeter&#x2F;conf&#x2F; --spring.profiles.active&#x3D;production --logging.config&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api-jmeter&#x2F;conf&#x2F;log4j2.yml 容器模式下，我们可以给每个JVM实例所属的POD分配任意大小的内存上限。比如，给每个账户服务分配4G，给每个支付服务分配8G。如此一来，启动脚本就不好写成通用的了，指定3G也不是，指定6G也不是。 但是有了这三个新增参数MaxRAMPercentage、InitialRAMPercentage、MinRAMPercentage，我们就可以在通用的启动脚本中指定堆的内存量百分比（-XX:MaxRAMPercentage=30 -XX:InitialRAMPercentage=30 -XX:MinRAMPercentage=30）。 对于我们的8G内存，按照30%分配的话，我们就相当于设置了堆内存-Xmx2.4G -Xms2.4G，按照新生代与老年代的默认比例1：2来说。新生代的大小应该为0.8G，老年代1.6G。 通过jmap -heap显示Java堆的如下信息： work@authority-api-jmeter-v1-65c64db6c7-74z8p:~$ jmap -heap 45 Attaching to process ID 45, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.222-b10 using parallel threads in the new generation. using thread-local object allocation. Concurrent Mark-Sweep GC Heap Configuration: MinHeapFreeRatio &#x3D; 40 MaxHeapFreeRatio &#x3D; 70 MaxHeapSize &#x3D; 2577399808 (2458.0MB) NewSize &#x3D; 174456832 (166.375MB) MaxNewSize &#x3D; 174456832 (166.375MB) OldSize &#x3D; 2402942976 (2291.625MB) NewRatio &#x3D; 2 SurvivorRatio &#x3D; 8 MetaspaceSize &#x3D; 21807104 (20.796875MB) CompressedClassSpaceSize &#x3D; 1073741824 (1024.0MB) MaxMetaspaceSize &#x3D; 17592186044415 MB G1HeapRegionSize &#x3D; 0 (0.0MB) Heap Usage: New Generation (Eden + 1 Survivor Space): capacity &#x3D; 157024256 (149.75MB) used &#x3D; 64436528 (61.45146179199219MB) free &#x3D; 92587728 (88.29853820800781MB) 41.03603458563752% used Eden Space: capacity &#x3D; 139591680 (133.125MB) used &#x3D; 49245504 (46.96417236328125MB) free &#x3D; 90346176 (86.16082763671875MB) 35.27825154049296% used From Space: capacity &#x3D; 17432576 (16.625MB) used &#x3D; 15191024 (14.487289428710938MB) free &#x3D; 2241552 (2.1377105712890625MB) 87.14159054863721% used To Space: capacity &#x3D; 17432576 (16.625MB) used &#x3D; 0 (0.0MB) free &#x3D; 17432576 (16.625MB) 0.0% used concurrent mark-sweep generation: capacity &#x3D; 2402942976 (2291.625MB) used &#x3D; 52197864 (49.779762268066406MB) free &#x3D; 2350745112 (2241.8452377319336MB) 2.1722473034665972% used 30750 interned Strings occupying 3569720 bytes. 可以看到实际新生代的大小与日志分析结果相同为166.4 mb（Eden133.125MB + 2 Survivor Space16.625MB） 经过查找资料发现：新生代的大小为： max_heap/(NewRatio+1) 和 ScaleForWordSize(young_gen_per_worker * parallel_gc_threads) 中较小的那个 max_heap/(NewRatio+1) 这个我们都了解，就是按照 默认NewRatio 为2来计算，新生代的大小应该为0.8G。 而ScaleForWordSize最终的计算公式是 机器硬件决定(x86位64M) * 并行线程数(-XX:ParallelGCThreads指定的值) * 13 &#x2F; 10 由于我们指定了-XX:ParallelGCThreads=2,按照这个公式64M * 2 * 13 / 10=166.4M。 所以二者之间取小值，我们最终的新生代的大小为166.4M。验证了现像。 总结：所以我们在使用CMS收集器模式时，一定要指定新生代的大小，完整参数如下： -XX:+UseConcMarkSweepGC -XX:NewRatio&#x3D;2 -XX:ParallelGCThreads&#x3D;2 -XX:CICompilerCount&#x3D;2 调整 发现生产环境很多服务都存在此问题 打印heap参数： work@authority-api-v1-dc978c6b5-kb8f9:~$ jmap -heap 47 Attaching to process ID 47, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.222-b10 using parallel threads in the new generation. using thread-local object allocation. Concurrent Mark-Sweep GC Heap Configuration: MinHeapFreeRatio &#x3D; 40 MaxHeapFreeRatio &#x3D; 70 MaxHeapSize &#x3D; 2577399808 (2458.0MB) NewSize &#x3D; 859111424 (819.3125MB) MaxNewSize &#x3D; 859111424 (819.3125MB) OldSize &#x3D; 1718288384 (1638.6875MB) NewRatio &#x3D; 2 SurvivorRatio &#x3D; 8 MetaspaceSize &#x3D; 21807104 (20.796875MB) CompressedClassSpaceSize &#x3D; 1073741824 (1024.0MB) MaxMetaspaceSize &#x3D; 17592186044415 MB G1HeapRegionSize &#x3D; 0 (0.0MB) Heap Usage: New Generation (Eden + 1 Survivor Space): capacity &#x3D; 773259264 (737.4375MB) used &#x3D; 594538992 (566.9965667724609MB) free &#x3D; 178720272 (170.44093322753906MB) 76.88740629171434% used Eden Space: capacity &#x3D; 687407104 (655.5625MB) used &#x3D; 593315240 (565.8295059204102MB) free &#x3D; 94091864 (89.73299407958984MB) 86.31206115670285% used From Space: capacity &#x3D; 85852160 (81.875MB) used &#x3D; 1223752 (1.1670608520507812MB) free &#x3D; 84628408 (80.70793914794922MB) 1.4254178345658397% used To Space: capacity &#x3D; 85852160 (81.875MB) used &#x3D; 0 (0.0MB) free &#x3D; 85852160 (81.875MB) 0.0% used concurrent mark-sweep generation: capacity &#x3D; 1718288384 (1638.6875MB) used &#x3D; 104572760 (99.72835540771484MB) free &#x3D; 1613715624 (1538.9591445922852MB) 6.085867830670268% used 52552 interned Strings occupying 5734440 bytes. work@authority-api-v1-dc978c6b5-kb8f9:~$ 确认堆新生代已经调整为819.3125MB。 后续 今天又收到了其他部门反馈接口偶发超时问题，下午将容器服务引入了Wtrace，等后续出现接口超时问题时来查看耗时原因，同时依然查看JVM参数，做响应的优化。查看内存分配情况 [~]$ jmap -heap 24433 Attaching to process ID 24433, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.74-b02 using parallel threads in the new generation. using thread-local object allocation. Concurrent Mark-Sweep GC Heap Configuration: MinHeapFreeRatio &#x3D; 40 MaxHeapFreeRatio &#x3D; 70 MaxHeapSize &#x3D; 2147483648 (2048.0MB) NewSize &#x3D; 357892096 (341.3125MB) MaxNewSize &#x3D; 715784192 (682.625MB) OldSize &#x3D; 715849728 (682.6875MB) NewRatio &#x3D; 2 SurvivorRatio &#x3D; 8 MetaspaceSize &#x3D; 21807104 (20.796875MB) CompressedClassSpaceSize &#x3D; 1073741824 (1024.0MB) MaxMetaspaceSize &#x3D; 268435456 (256.0MB) G1HeapRegionSize &#x3D; 0 (0.0MB) Heap Usage: New Generation (Eden + 1 Survivor Space): capacity &#x3D; 322109440 (307.1875MB) used &#x3D; 226564424 (216.06867218017578MB) free &#x3D; 95545016 (91.11882781982422MB) 70.33771627431969% used Eden Space: capacity &#x3D; 286326784 (273.0625MB) used &#x3D; 221015664 (210.77696228027344MB) free &#x3D; 65311120 (62.28553771972656MB) 77.19000678609235% used From Space: capacity &#x3D; 35782656 (34.125MB) used &#x3D; 5548760 (5.291709899902344MB) free &#x3D; 30233896 (28.833290100097656MB) 15.506842197516026% used To Space: capacity &#x3D; 35782656 (34.125MB) used &#x3D; 0 (0.0MB) free &#x3D; 35782656 (34.125MB) 0.0% used concurrent mark-sweep generation: capacity &#x3D; 715849728 (682.6875MB) used &#x3D; 69264248 (66.05553436279297MB) free &#x3D; 646585480 (616.631965637207MB) 9.675808384186464% used 41925 interned Strings occupying 4788072 bytes. [work@线上-业务运营-车源-c1_UserCenter_API-01 ~]$ 因为为发现Eden Space的空间依旧不足，而且自己已经设置了-XX:NewRatio=2，查看JVM参数有-Xms1024m -Xmx2048m，也就是初始阶段新生代的内存分配为：1024M / 3 = 341M (Eden 273.0625 + Survivor 34.125 * 2)。于是JVM参数-Xms调整为2048M。 [work@线上-业务运营-车源-c1_UserCenter_API-00 ~]$ jmap -heap 23078 Attaching to process ID 23078, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.74-b02 using parallel threads in the new generation. using thread-local object allocation. Concurrent Mark-Sweep GC Heap Configuration: MinHeapFreeRatio &#x3D; 40 MaxHeapFreeRatio &#x3D; 70 MaxHeapSize &#x3D; 2147483648 (2048.0MB) NewSize &#x3D; 715784192 (682.625MB) MaxNewSize &#x3D; 715784192 (682.625MB) OldSize &#x3D; 1431699456 (1365.375MB) NewRatio &#x3D; 2 SurvivorRatio &#x3D; 8 MetaspaceSize &#x3D; 21807104 (20.796875MB) CompressedClassSpaceSize &#x3D; 1073741824 (1024.0MB) MaxMetaspaceSize &#x3D; 268435456 (256.0MB) G1HeapRegionSize &#x3D; 0 (0.0MB) Heap Usage: New Generation (Eden + 1 Survivor Space): capacity &#x3D; 644218880 (614.375MB) used &#x3D; 453082096 (432.09275817871094MB) free &#x3D; 191136784 (182.28224182128906MB) 70.33045911352364% used Eden Space: capacity &#x3D; 572653568 (546.125MB) used &#x3D; 415579960 (396.3279342651367MB) free &#x3D; 157073608 (149.79706573486328MB) 72.57091952669018% used From Space: capacity &#x3D; 71565312 (68.25MB) used &#x3D; 37502136 (35.76482391357422MB) free &#x3D; 34063176 (32.48517608642578MB) 52.40267240084135% used To Space: capacity &#x3D; 71565312 (68.25MB) used &#x3D; 0 (0.0MB) free &#x3D; 71565312 (68.25MB) 0.0% used concurrent mark-sweep generation: capacity &#x3D; 1431699456 (1365.375MB) used &#x3D; 45248776 (43.15259552001953MB) free &#x3D; 1386450680 (1322.2224044799805MB) 3.1604940415651033% used 40553 interned Strings occupying 4633272 bytes. [work@线上-业务运营-车源-c1_UserCenter_API-00 ~]$ 生产环境Xms和Xmx配置为相等，因为生产环境意味着一台机器或者一个容器只有一个服务，独占机器意味着没有必要调整jvm大小，直接分配Xmx就行了。否则每一次调整都可能会有开销。初始堆大小-Xms与最大堆大小-Xmx是不等的，那么JVM就会根据堆内存的使用情况，动态的向操作系统申请内存，扩大或者是缩小，以-Xmx和-Xms的值为上下界，这里的每一次调整都会产生一定的系统开销， 引用 CMS GC 默认新生代是多大 JVM新生代、老年代的默认比值真的是1:2吗？ jvm gc调优-新生代的默认值 JVM的Xms和Xmx参数设置为相同值有什么好处？","categories":[{"name":"工作总结","slug":"工作总结","permalink":"https://qinglei1989.github.io/categories/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"工作总结","slug":"工作总结","permalink":"https://qinglei1989.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"}]},{"title":"Elasticsearch核心概念","slug":"elasticsearch-introduction","date":"2022-11-15T16:14:35.000Z","updated":"2023-01-06T15:06:38.967Z","comments":true,"path":"2022/11/16/elasticsearch-introduction/","link":"","permalink":"https://qinglei1989.github.io/2022/11/16/elasticsearch-introduction/","excerpt":"Elasticsearch核心概念。","text":"Elasticsearch核心概念。 Elasticsearch核心概念 lucene和elasticsearch lucene是一个 Java库 ，最先进、功能最强大的搜索库，直接基于lucene开发，非常复杂，api复杂（实现一些简单的功能，写大量的java代码），需要深入理解原理（各种索引结构）。 Elasticsearch基于lucene，是一个基于 JSON ， 分布式 ， 网络服务器。提供简单易用的restful api接口 所以总结一下： Elasticsearch 基于Lucene构建，并提供基于 JSON的REST API来引用Lucene功能。 Elasticsearch在Lucene之上 提供了一个 分布式系统 。Lucene并没有意识到分布式系统的存在。Elasticsearch提供了这种分布式结构的抽象。 Elasticsearch提供了其他支持功能，例如线程池，队列，节点/集群监视API，数据监视API，集群管理等。 elasticsearch的核心概念 NRT Near Realtime（NRT）：近实时，两个意思，从写入数据到数据可以被搜索到有一个小延迟（大概1秒）；基于es执行搜索和分析可以达到秒级 集群（Cluster） 集群，包含多个节点，每个节点属于哪个集群是通过一个配置（集群名称，默认是elasticsearch）来决定的。 节点（Node） 节点，集群中的一个节点，节点也有一个名称（默认是随机分配的），节点名称很重要（在执行运维管理操作的时候），默认节点会去加入一个名称为“elasticsearch”的集群，如果直接启动一堆节点，那么它们会自动组成一个elasticsearch集群，当然一个节点也可以组成一个elasticsearch集群 文档（Document）&amp;field 文档，es中的最小数据单元，一个document可以是一条客户数据，一条商品分类数据，一条订单数据，通常用JSON数据结构表示，每个index下的type中，都可以去存储多个document。一个document里面有多个field，每个field就是一个数据字段。 相当于数据库中的行和字段 索引（Index） 索引，包含一堆有相似结构的文档数据，比如可以有一个客户索引，商品分类索引，订单索引，索引有一个名称。一个index包含很多document，一个index就代表了一类类似的或者相同的document。比如说建立一个product index，商品索引，里面可能就存放了所有的商品数据，所有的商品document。 相当于数据库 类型（Type） 类型，每个索引里都可以有一个或多个type，type是index中的一个逻辑数据分类，一个type下的document，都有相同的field，比如博客系统，有一个索引，可以定义用户数据type，博客数据type，评论数据type。 相当于数据库中的表 分片（shard） 单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储。有了shard就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个shard都是一个lucene index。 副本（replica） 任何一个服务器随时可能故障或宕机，此时shard可能就会丢失，因此可以为每个shard创建多个replica副本。replica可以在shard故障时提供备用服务，保证数据不丢失，多个replica还可以提升搜索操作的吞吐量和性能 简单集群管理 检查ES是否启动成功：http://localhost:9200/?pretty Kibana Dev Tools界面：http://localhost:5601/ ElasticSearch默认的TCP服务端口是9300，Kibana的服务端口是5601,当我们启动了Kibana之后，它会默认帮我们连接上9300，所以我们可以从http://localhost:5601中进入Kibana的管理界面来管理ElasticSearch。如果你是第一次使用，那么ElasticSearch会自动创建一个名为elasticsearch的集群，Kibana会在这个节点中初始化一个index 集群健康检查 _cat/health?v epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent 1668700299 23:51:39 elasticsearch yellow 1 1 1 1 0 0 1 0 - 50.0% 此命令常见的用途一般有两个:1、验证节点之间的健康状况是否一致，2、跟踪大型集群随时间的故障恢复情况 如何快速了解集群的健康状况？ green：每个索引的primary shard和replica shard都是active状态的yellow：每个索引的primary shard都是active状态的，但是部分replica shard不是active状态，处于不可用的状态red：不是所有索引的primary shard都是active状态的，部分索引有数据丢失了 快速查看集群中有哪些索引 GET &#x2F;_cat&#x2F;indices?v health status index uuid pri rep docs.count docs.deleted store.size pri.store.size yellow open .kibana OMzTLQtiTNiST9J_cxGhVg 1 1 1 0 3.1kb 3.1kb 简单的索引操作 创建索引：PUT /test_index?pretty PUT &#x2F;test_index?pretty &#123; &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true &#125; 删除索引：DELETE /test_index?pretty DELETE &#x2F;test_index?pretty &#123; &quot;acknowledged&quot;: true &#125; 文档的增删改查 es会自动建立index和type，不需要提前创建，而且es默认会对document每个field都建立倒排索引，让其可以被搜索 新增： PUT &#x2F;ecommerce&#x2F;product&#x2F;1 &#123; &quot;name&quot; : &quot;gaolujie yagao&quot;, &quot;desc&quot; : &quot;gaoxiao meibai&quot;, &quot;price&quot; : 30, &quot;producer&quot; : &quot;gaolujie producer&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot; ] &#125; &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true &#125; 查询： GET &#x2F;ecommerce&#x2F;product&#x2F;1 &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;gaolujie yagao&quot;, &quot;desc&quot;: &quot;gaoxiao meibai&quot;, &quot;price&quot;: 30, &quot;producer&quot;: &quot;gaolujie producer&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot; ] &#125; &#125; 修改 PUT &#x2F;ecommerce&#x2F;product&#x2F;1 &#123; &quot;name&quot; : &quot;jiaqiangban1 gaolujie yagao&quot;, &quot;desc&quot; : &quot;gaoxiao meibai&quot;, &quot;price&quot; : 30, &quot;producer&quot; : &quot;gaolujie producer&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot; ] &#125; &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 3, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: false &#125; 替换方式有一个不好，即使必须带上所有的field，才能去进行信息的修改。 POST &#x2F;ecommerce&#x2F;product&#x2F;1&#x2F;_update &#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;rrc gaolujie yagao&quot; &#125; &#125; &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 4, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125; &#125; 删除 DELETE &#x2F;ecommerce&#x2F;product&#x2F;1 &#123; &quot;found&quot;: true, &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 5, &quot;result&quot;: &quot;deleted&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125; &#125; 多种搜索方式 query string search 搜索全部商品 GET &#x2F;ecommerce&#x2F;product&#x2F;_search &#123; &quot;took&quot;: 2, &#x2F;&#x2F;耗费了几毫秒 &quot;timed_out&quot;: false, &#x2F;&#x2F;是否超时，这里是没有 &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &#x2F;&#x2F;数据拆成了5个分片，所以对于搜索请求，会打到所有的primary shard（或者是它的某个replica shard也可以） &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &#x2F;&#x2F; 查询结果的数量，3个document &quot;max_score&quot;: 1, &#x2F;&#x2F;score的含义，就是document对于一个search的相关度的匹配分数，越相关，就越匹配，分数也高 &quot;hits&quot;: [ &#x2F;&#x2F;包含了匹配搜索的document的详细数据 &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;jiajieshi yagao&quot;, &quot;desc&quot;: &quot;youxiao fangzhu&quot;, &quot;price&quot;: 25, &quot;producer&quot;: &quot;jiajieshi producer&quot;, &quot;tags&quot;: [ &quot;fangzhu&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;gaolujie yagao&quot;, &quot;desc&quot;: &quot;gaoxiao meibai&quot;, &quot;price&quot;: 30, &quot;producer&quot;: &quot;gaolujie producer&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;zhonghua yagao&quot;, &quot;desc&quot;: &quot;caoben zhiwu&quot;, &quot;price&quot;: 40, &quot;producer&quot;: &quot;zhonghua producer&quot;, &quot;tags&quot;: [ &quot;qingxin&quot; ] &#125; &#125; ] &#125; &#125; query string search的由来，因为search参数都是以http请求的query string来附带的 搜索商品名称中包含yagao的商品，而且按照售价降序排序：GET /ecommerce/product/_search?q=name:yagao&amp;sort=price:desc 适用于临时的在命令行使用一些工具，比如curl，快速的发出请求，来检索想要的信息；但是如果查询请求很复杂，是很难去构建的在生产环境中，几乎很少使用query string search query DSL 查询所有的商品 GET &#x2F;ecommerce&#x2F;product&#x2F;_search &#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125; &#125; &#123; &quot;took&quot;: 2, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;jiajieshi yagao&quot;, &quot;desc&quot;: &quot;youxiao fangzhu&quot;, &quot;price&quot;: 25, &quot;producer&quot;: &quot;jiajieshi producer&quot;, &quot;tags&quot;: [ &quot;fangzhu&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;gaolujie yagao&quot;, &quot;desc&quot;: &quot;gaoxiao meibai&quot;, &quot;price&quot;: 30, &quot;producer&quot;: &quot;gaolujie producer&quot;, &quot;tags&quot;: [ &quot;meibai&quot;, &quot;fangzhu&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;zhonghua yagao&quot;, &quot;desc&quot;: &quot;caoben zhiwu&quot;, &quot;price&quot;: 40, &quot;producer&quot;: &quot;zhonghua producer&quot;, &quot;tags&quot;: [ &quot;qingxin&quot; ] &#125; &#125; ] &#125; &#125; 查询名称包含yagao的商品，同时按照价格降序排序 GET &#x2F;ecommerce&#x2F;product&#x2F;_search &#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;name&quot; : &quot;yagao&quot; &#125; &#125;, &quot;sort&quot;: [ &#123; &quot;price&quot;: &quot;desc&quot; &#125; ] &#125; 分页查询商品，总共3条商品，假设每页就显示1条商品，现在显示第2页，所以就查出来第2个商品 GET &#x2F;ecommerce&#x2F;product&#x2F;_search &#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;from&quot;: 1, &quot;size&quot;: 1 &#125; 指定要查询出来商品的名称和价格就可以 GET &#x2F;ecommerce&#x2F;product&#x2F;_search &#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;, &quot;_source&quot;: [&quot;name&quot;, &quot;price&quot;] &#125; 更加适合生产环境的使用，可以构建复杂的查询 query filter 搜索商品名称包含yagao，而且售价大于25元的商品 GET &#x2F;ecommerce&#x2F;product&#x2F;_search &#123; &quot;query&quot; : &#123; &quot;bool&quot; : &#123; &quot;must&quot; : &#123; &quot;match&quot; : &#123; &quot;name&quot; : &quot;yagao&quot; &#125; &#125;, &quot;filter&quot; : &#123; &quot;range&quot; : &#123; &quot;price&quot; : &#123; &quot;gt&quot; : 25 &#125; &#125; &#125; &#125; &#125; &#125; full-text search（全文检索） 全文检索会将输入的搜索串拆解开来，去倒排索引里面去一一匹配，只要能匹配上任意一个拆解后的单词，就可以作为结果返回 GET &#x2F;ecommerce&#x2F;product&#x2F;_search &#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;producer&quot; : &quot;yagao producer&quot; &#125; &#125; &#125; phrase search（短语搜索） phrase search，要求输入的搜索串，必须在指定的字段文本中，完全包含一模一样的，才可以算匹配，才能作为结果返回 GET &#x2F;ecommerce&#x2F;product&#x2F;_search &#123; &quot;query&quot; : &#123; &quot;match_phrase&quot; : &#123; &quot;producer&quot; : &quot;yagao producer&quot; &#125; &#125; &#125; GET &#x2F;ecommerce&#x2F;product&#x2F;_search &#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;producer&quot;: &quot;jiajieshi producer&quot; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123; &quot;producer&quot;:&#123;&#125; &#125; &#125; &#125; &#123; &quot;took&quot;: 56, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;failed&quot;: 0 &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 1, &quot;max_score&quot;: 0.51623213, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;ecommerce&quot;, &quot;_type&quot;: &quot;product&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 0.51623213, &quot;_source&quot;: &#123; &quot;name&quot;: &quot;jiajieshi yagao&quot;, &quot;desc&quot;: &quot;youxiao fangzhu&quot;, &quot;price&quot;: 25, &quot;producer&quot;: &quot;jiajieshi producer&quot;, &quot;tags&quot;: [ &quot;fangzhu&quot; ] &#125;, &quot;highlight&quot;: &#123; &quot;producer&quot;: [ &quot;&lt;em&gt;jiajieshi&lt;&#x2F;em&gt; &lt;em&gt;producer&lt;&#x2F;em&gt;&quot; ] &#125; &#125; ] &#125; &#125; highlight search（高亮搜索结果） GET &#x2F;ecommerce&#x2F;product&#x2F;_search &#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;producer&quot; : &quot;producer&quot; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot; : &#123; &quot;producer&quot; : &#123;&#125; &#125; &#125; &#125; 引用 ElasticSearch的介绍","categories":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://qinglei1989.github.io/tags/Elasticsearch/"}]},{"title":"SpringBoot整合RabbitMQ","slug":"middleware-rabbitmq-springboot","date":"2022-11-12T16:03:02.000Z","updated":"2022-11-13T15:16:40.680Z","comments":true,"path":"2022/11/13/middleware-rabbitmq-springboot/","link":"","permalink":"https://qinglei1989.github.io/2022/11/13/middleware-rabbitmq-springboot/","excerpt":"SpringBoot整合RabbitMQ","text":"SpringBoot整合RabbitMQ 【MQ中间件】RabbitMQ – SpringBoot整合RabbitMQ 基于SpringBoot配置类构建消息队列 POM依赖 &lt;!--rabbitmq starter依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; application.yml #配置rabbitMq 服务器 rabbitmq: host: 127.0.0.1 port: 5672 username: admin password: admin #虚拟host 可以不设置,使用server默认host virtual-host: rrcVhost 生产者配置类 配置类生成交换机与队列 配置类DirectTypeRabbitConfig &#x2F;&#x2F;注意：XxxType表示是交换机类型：可以是Fanout&#x2F;Direct&#x2F;Topic&#x2F;Headers @Configuration public class DirectTypeRabbitConfig &#123; &#x2F;&#x2F;使用注入方式声明对应的Queue @Bean public Queue emailQueue() &#123; &#x2F;&#x2F; durable:是否持久化,默认是false,持久化队列：会被存储在磁盘上，当消息代理重启时仍然存在，暂存队列：当前连接有效 &#x2F;&#x2F; exclusive:默认也是false，只能被当前创建的连接使用，而且当连接关闭后队列即被删除。此参考优先级高于durable &#x2F;&#x2F; autoDelete:是否自动删除，当没有生产者或者消费者使用此队列，该队列会自动删除。 &#x2F;&#x2F;一般设置一下队列的持久化就好,其余两个就是默认false return new Queue(&quot;email.DirectType.queue&quot;, true); &#125; &#x2F;&#x2F;声明交换机，不同的交换机类型不同：DirectExchange&#x2F;FanoutExchange&#x2F;TopicExchange&#x2F;HeadersExchange @Bean public DirectTypeExchange DirectTypeOrderExchange() &#123; &#x2F;&#x2F; durable:是否持久化,默认是true,持久化队列：会被存储在磁盘上，当消息代理重启时仍然存在，暂存队列：当前连接有效 &#x2F;&#x2F; autoDelete:是否自动删除，当没有生产者或者消费者使用此队列，该队列会自动删除。默认false return new DirectTypeExchange(&quot;DirectType_order_exchange&quot;, true, false); &#125; &#x2F;&#x2F;绑定关系：将队列和交换机绑定, 并设置用于匹配键：routingKey @Bean public Binding bindingXxxType1() &#123; return BindingBuilder .bind(emailQueue()) &#x2F;&#x2F;绑定哪个Queue .to(xxxTypeOrderExchange()) .with(&quot;routingKey&quot;);&#x2F;&#x2F;fanout这里绑定Queues的时候不要设置routing key，是采用广播订阅发送的方式&#96; &#125; &#125; 消息发送类，主要给创建的队列填充消息，这里主要用到RabbitTemplate类调用convertAndSend方法进行对应交换机消息队列的发送： rabbitTemplate.convertAndSend(String exchange, String routingKey, Object object) 消费者配置类 Direct模式消息消费者 &#x2F;&#x2F;通过@RabbitListener绑定队列接收消息 @RabbitListener(queues &#x3D; &#123;&quot;weixin.direct.queue&quot;&#125;) @Component public class DirectDuanxinConsumer &#123; &#x2F;&#x2F;队列中的消息会通过@RabbitHandler注解注入到方法参数中，就可以获取到队列中的消息 @RabbitHandler public void reviceMessage(String message)&#123; System.out.println(&quot;duanxin direct queue----接收到了订单信息是：-&gt;&quot; + message); &#125; &#125; Topic模式消息消费者 &#x2F;&#x2F;通过@RabbitListener绑定队列接收消息 &#x2F;&#x2F; bindings其实就是用来确定队列和交换机绑定关系 @RabbitListener(bindings &#x3D; @QueueBinding( &#x2F;&#x2F;队列名字，绑定对应的队列接收消息 value &#x3D; @Queue(value &#x3D; &quot;weixin.topic.queue&quot;, autoDelete &#x3D; &quot;false&quot;), &#x2F;&#x2F;交换机名字，必须和生产者中交换机名相同；指定绑定的交换机类型 exchange &#x3D; @Exchange(value &#x3D; &quot;topic_order_exchange&quot;, type &#x3D; ExchangeTypes.TOPIC), key &#x3D; &quot;com.#&quot; )) @Component public class TopicDuanxinConsumer &#123; &#x2F;&#x2F;队列中的消息会通过@RabbitHandler注解注入到方法参数中，就可以获取到队列中的消息 @RabbitHandler public void reviceMessage(String message)&#123; System.out.println(&quot;duanxin topic----接收到了订单信息是：-&gt;&quot; + message); &#125; &#125; 生产者确认 #配置rabbitMq 服务器 rabbitmq: host: 127.0.0.1 port: 5672 username: admin password: admin #虚拟host 可以不设置,使用server默认host virtual-host: rrcVhost #确认消息已发送到交换机(Exchange) publisher-confirm-type: correlated #确认消息已发送到队列(Queue) publisher-returns: true 配置相关的消息确认回调函数，RabbitConfig.java @Configuration public class RabbitConfig &#123; @Bean public RabbitTemplate createRabbitTemplate(ConnectionFactory connectionFactory)&#123; RabbitTemplate rabbitTemplate &#x3D; new RabbitTemplate(); rabbitTemplate.setConnectionFactory(connectionFactory); &#x2F;&#x2F;设置开启Mandatory,才能触发回调函数,无论消息推送结果怎么样都强制调用回调函数 rabbitTemplate.setMandatory(true); rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; System.out.println(&quot;ConfirmCallback: &quot;+&quot;相关数据：&quot;+correlationData); System.out.println(&quot;ConfirmCallback: &quot;+&quot;确认情况：&quot;+ack); System.out.println(&quot;ConfirmCallback: &quot;+&quot;原因：&quot;+cause); &#125; &#125;); rabbitTemplate.setReturnsCallback(new RabbitTemplate.ReturnsCallback() &#123; @Override public void returnedMessage(ReturnedMessage returnedMessage) &#123; System.out.println(&quot;ReturnCallback: &quot;+&quot;消息：&quot;+returnedMessage.getMessage()); System.out.println(&quot;ReturnCallback: &quot;+&quot;回应码：&quot;+returnedMessage.getReplyCode()); System.out.println(&quot;ReturnCallback: &quot;+&quot;回应信息：&quot;+ returnedMessage.getReplyText()); System.out.println(&quot;ReturnCallback: &quot;+&quot;交换机：&quot;+ returnedMessage.getExchange()); System.out.println(&quot;ReturnCallback: &quot;+&quot;路由键：&quot;+ returnedMessage.getRoutingKey()); &#125; &#125;); return rabbitTemplate; &#125; &#125; 可以看到上面写了两个回调函数，一个叫 ConfirmCallback ，一个叫 RetrunCallback；那么以上这两种回调函数都是在什么情况会触发呢？ 先从总体的情况分析，推送消息存在四种情况： 消息推送到server，但是在server里找不到交换机 消息推送到server，找到交换机了，但是没找到队列 消息推送到sever，交换机和队列啥都没找到 消息推送成功 情形1：ConfirmCallback: 相关数据：null ConfirmCallback: 确认情况：false ConfirmCallback: 原因：channel error; protocol method: #method&lt;channel.close&gt;(reply-code&#x3D;404, reply-text&#x3D;NOT_FOUND - no exchange &#39;TestDirectDurableExchange1111&#39; in vhost &#39;rrcVhost&#39;, class-id&#x3D;60, method-id&#x3D;40) 触发的是 ConfirmCallback 回调函数 情形2：CASE 1：新增一个交换机lonelyDirectExchange，但是不给这个交换机绑定队列。 ReturnCallback: 消息：(Body:&#39;&#123;createTime&#x3D;2022-11-13 13:42:55, messageId&#x3D;i&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;0, messageData&#x3D;test message, hello!&#125;&#39; MessageProperties [headers&#x3D;&#123;&#125;, contentType&#x3D;application&#x2F;x-java-serialized-object, contentLength&#x3D;0, receivedDeliveryMode&#x3D;PERSISTENT, priority&#x3D;0, deliveryTag&#x3D;0]) ReturnCallback: 回应码：312 ReturnCallback: 回应信息：NO_ROUTE ReturnCallback: 交换机：lonelyDirectExchange ReturnCallback: 路由键：TestDirectDurableRouting ConfirmCallback: 相关数据：null ConfirmCallback: 确认情况：true ConfirmCallback: 原因：null CASE 2：使用错误的routingKey。 ReturnCallback: 消息：(Body:&#39;&#123;createTime&#x3D;2022-11-13 13:46:32, messageId&#x3D;i&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;0, messageData&#x3D;test message, hello!&#125;&#39; MessageProperties [headers&#x3D;&#123;&#125;, contentType&#x3D;application&#x2F;x-java-serialized-object, contentLength&#x3D;0, receivedDeliveryMode&#x3D;PERSISTENT, priority&#x3D;0, deliveryTag&#x3D;0]) ReturnCallback: 回应码：312 ReturnCallback: 回应信息：NO_ROUTE ReturnCallback: 交换机：TestDirectDurableExchange ReturnCallback: 路由键：TestDirectDurableRouting9999 ConfirmCallback: 相关数据：null ConfirmCallback: 确认情况：true ConfirmCallback: 原因：null 可以看到两个函数都被调用了；这种情况下，消息是推送成功到服务器了的，所以ConfirmCallback对消息确认情况是true；而在RetrunCallback回调函数的打印参数里面可以看到，消息是推送到了交换机成功了，但是在路由分发给队列的时候，找不到队列，所以报了错误 NO_ROUTE 。 结论：这种情况触发的是 ConfirmCallback和RetrunCallback两个回调函数。 情形3：消息推送到sever，交换机和队列啥都没找到。这种情况其实一看就觉得跟①很像，没错 ，③和①情况回调是一致的，所以不做结果说明了。 结论： 这种情况触发的是 ConfirmCallback 回调函数。 情形4：ConfirmCallback: 相关数据：null ConfirmCallback: 确认情况：true ConfirmCallback: 原因：null 正常成功的消息推送触发ConfirmCallback 回调函数。 以上是生产者推送消息的消息确认 回调函数的使用介绍（可以在回调函数根据需求做对应的扩展或者业务数据处理）。 消息确认机制 和生产者的消息确认机制不同，因为消息接收本来就是在监听消息，符合条件的消息就会消费下来。所以，消息接收的确认机制主要存在三种模式： 自动确认默认的消息确认情况。 AcknowledgeMode.NONERabbitMQ成功将消息发出（即将消息成功写入TCP Socket）中立即认为本次投递已经被正确处理，不管消费者端是否成功处理本次投递。所以这种情况如果消费端消费逻辑抛出异常，也就是消费端没有处理成功这条消息，那么就相当于丢失了消息。一般这种情况我们都是使用try catch捕捉异常后，打印日志用于追踪数据，这样找出对应数据再做后续处理。 根据情况确认这个不做介绍 手动确认我们配置接收消息确认机制时，多数选择的模式。消费者收到消息后，手动调用basic.ack/basic.nack/basic.reject后，RabbitMQ收到这些消息后，才认为本次投递成功。basic.ack用于肯定确认basic.nack用于否定确认（注意：这是AMQP 0-9-1的RabbitMQ扩展）basic.reject用于否定确认，但与basic.nack相比有一个限制:一次只能拒绝单条消息 消费者端以上的3个方法都表示消息已经被正确投递，但是basic.ack表示消息已经被正确处理。而basic.nack,basic.reject表示没有被正确处理： 着重讲下reject，因为有时候一些场景是需要重新入列的。 channel.basicReject(deliveryTag, true); 拒绝消费当前消息，如果第二参数传入true，就是将数据重新丢回队列里，那么下次还会消费这消息。设置false，就是告诉服务器，我已经知道这条消息数据了，因为一些原因拒绝它，而且服务器也把这个消息丢掉就行。 下次不想再消费这条消息了。 使用拒绝后重新入列这个确认模式要谨慎，因为一般都是出现异常的时候，catch异常再拒绝入列，选择是否重入列。 但是如果使用不当会导致一些每次都被你重入列的消息一直消费-入列-消费-入列这样循环，会导致消息积压。 顺便也简单讲讲 nack，这个也是相当于设置不消费某条消息。 channel.basicNack(deliveryTag, false, true);第一个参数依然是当前消息到的数据的唯一id;第二个参数是指是否针对多条消息；如果是true，也就是说一次性针对当前通道的消息的tagID小于当前这条消息的，都拒绝确认。第三个参数是指是否重新入列，也就是指不确认的消息是否重新丢回到队列里面去。 同样使用不确认后重新入列这个确认模式要谨慎，因为这里也可能因为考虑不周出现消息一直被重新丢回去的情况，导致积压。 mandatory与备份交换机(Alternate Exchange)备份交换机：为一个普通交换机添加一个”备胎“，当交换机接收到一条无法路由的消息时，就会把消息转发给备份交换机，有备份交换机来转发和处理，该交换机类型一般为”fanout“型，这样就可以把所有消息发送到与其绑定队列中去。 案例：一个生产者发送一条路由不通的消息，看看备份交换机如何处理，如下图： 当mandatory参数设为true时，交换器无法根据自身的类型和路由键找到一个符合条件的队列，那么 RabbitMQ会调用Basic.Return命令将消息返回给生产者。当mandatory参数设置为false时，出现上述情形，则消息直接被丢弃。 生产者在发送消息的时候如果不设置mandatory参数，那么消息在未被路由的情况下将会丢失;如果设置了mandatory参数，那么需要添加ReturnListener的编程逻辑，生产者的代码将变得复杂。如果既不想复杂化生产者的编程逻辑，又不想消息丢失，那么可以使用备份交换器，这样可以将未被路由的消息存储在RabbitMQ中，再在需要的时候去处理这些消息。这样可以将未被路由的消息存储在RabbitMQ中，再在需要的时候去处理这些消息。 对于备份交换器，总结了以下几种特殊情况:如果设置的备份交换器不存在，客户端和RabbitMQ服务端都不会有异常出现，此时消息会丢失。 如果备份交换器没有绑定任何队列，客户端和RabbitMQ服务端都不会有异常出现，此时消息会丢失。 如果备份交换器没有任何匹配的队列，客户端和RabbitMQ服务端都不会有异常出现,此时消息会丢失。 如果备份交换器和mandatory参数一起使用，那么mandatory参数无效。 重试机制 消费端在处理消息过程中可能会报错，此时该如何重新处理消息呢？解决方案有以下两种 在redis或者数据库中记录重试次数，达到最大重试次数以后消息进入死信队列或者其他队列，再单独针对这些消息进行处理； 使用spring-rabbit中自带的retry功能； 相关配置： #配置rabbitMq 服务器 rabbitmq: host: 127.0.0.1 port: 5672 username: admin password: admin #虚拟host 可以不设置,使用server默认host virtual-host: rrcVhost #确认消息已发送到交换机(Exchange) publisher-confirm-type: correlated #确认消息已发送到队列(Queue) publisher-returns: true #开启自动确认 none 手动确认 manual listener: simple: #消费端限流机制必须开启手动确认 acknowledge-mode: manual #消费端最多拉取的消息条数，签收后不满该条数才会继续拉取 prefetch: 1 retry: enabled: true max-attempts: 5 max-interval: 10000 # 重试最大间隔时间 initial-interval: 2000 # 重试初始间隔时间 multiplier: 2 # 间隔时间乘子，间隔时间*乘子&#x3D;下一次的间隔时间，最大不能超过设置的最大间隔时间 日志打印： [TRACEID:] 2022-11-13 18:08:13.391 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1-21] INFO com.wql.consumer.DirectReceiver 21 listenMessage - 成功接收到消息：(Body:&#39;&#123;createTime&#x3D;2022-11-13 18:08:13, messageId&#x3D;i&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;0, messageData&#x3D;test message, hello!&#125;&#39; MessageProperties [headers&#x3D;&#123;&#125;, contentType&#x3D;application&#x2F;x-java-serialized-object, contentLength&#x3D;0, receivedDeliveryMode&#x3D;PERSISTENT, priority&#x3D;0, redelivered&#x3D;false, receivedExchange&#x3D;TestDirectDurableExchange, receivedRoutingKey&#x3D;TestDirectDurableRouting, deliveryTag&#x3D;1, consumerTag&#x3D;amq.ctag-1pjqPhATqOrYTl1qTTmlEg, consumerQueue&#x3D;TestDirectDurableQueue]) [TRACEID:] 2022-11-13 18:08:15.406 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1-21] INFO com.wql.consumer.DirectReceiver 21 listenMessage - 成功接收到消息：(Body:&#39;&#123;createTime&#x3D;2022-11-13 18:08:13, messageId&#x3D;i&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;0, messageData&#x3D;test message, hello!&#125;&#39; MessageProperties [headers&#x3D;&#123;&#125;, contentType&#x3D;application&#x2F;x-java-serialized-object, contentLength&#x3D;0, receivedDeliveryMode&#x3D;PERSISTENT, priority&#x3D;0, redelivered&#x3D;false, receivedExchange&#x3D;TestDirectDurableExchange, receivedRoutingKey&#x3D;TestDirectDurableRouting, deliveryTag&#x3D;1, consumerTag&#x3D;amq.ctag-1pjqPhATqOrYTl1qTTmlEg, consumerQueue&#x3D;TestDirectDurableQueue]) [TRACEID:] 2022-11-13 18:08:15.423 [AMQP Connection 127.0.0.1:5672-748] ERROR o.s.a.r.c.CachingConnectionFactory 748 log - Shutdown Signal: channel error; protocol method: #method&lt;channel.close&gt;(reply-code&#x3D;406, reply-text&#x3D;PRECONDITION_FAILED - unknown delivery tag 1, class-id&#x3D;60, method-id&#x3D;80) [TRACEID:] 2022-11-13 18:08:19.418 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1-21] INFO com.wql.consumer.DirectReceiver 21 listenMessage - 成功接收到消息：(Body:&#39;&#123;createTime&#x3D;2022-11-13 18:08:13, messageId&#x3D;i&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;0, messageData&#x3D;test message, hello!&#125;&#39; MessageProperties [headers&#x3D;&#123;&#125;, contentType&#x3D;application&#x2F;x-java-serialized-object, contentLength&#x3D;0, receivedDeliveryMode&#x3D;PERSISTENT, priority&#x3D;0, redelivered&#x3D;false, receivedExchange&#x3D;TestDirectDurableExchange, receivedRoutingKey&#x3D;TestDirectDurableRouting, deliveryTag&#x3D;1, consumerTag&#x3D;amq.ctag-1pjqPhATqOrYTl1qTTmlEg, consumerQueue&#x3D;TestDirectDurableQueue]) [TRACEID:] 2022-11-13 18:08:27.453 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1-21] INFO com.wql.consumer.DirectReceiver 21 listenMessage - 成功接收到消息：(Body:&#39;&#123;createTime&#x3D;2022-11-13 18:08:13, messageId&#x3D;i&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;0, messageData&#x3D;test message, hello!&#125;&#39; MessageProperties [headers&#x3D;&#123;&#125;, contentType&#x3D;application&#x2F;x-java-serialized-object, contentLength&#x3D;0, receivedDeliveryMode&#x3D;PERSISTENT, priority&#x3D;0, redelivered&#x3D;false, receivedExchange&#x3D;TestDirectDurableExchange, receivedRoutingKey&#x3D;TestDirectDurableRouting, deliveryTag&#x3D;1, consumerTag&#x3D;amq.ctag-1pjqPhATqOrYTl1qTTmlEg, consumerQueue&#x3D;TestDirectDurableQueue]) [TRACEID:] 2022-11-13 18:08:27.455 [AMQP Connection 127.0.0.1:5672-748] ERROR o.s.a.r.c.CachingConnectionFactory 748 log - Shutdown Signal: channel error; protocol method: #method&lt;channel.close&gt;(reply-code&#x3D;406, reply-text&#x3D;PRECONDITION_FAILED - unknown delivery tag 1, class-id&#x3D;60, method-id&#x3D;80) [TRACEID:] 2022-11-13 18:08:37.464 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1-21] INFO com.wql.consumer.DirectReceiver 21 listenMessage - 成功接收到消息：(Body:&#39;&#123;createTime&#x3D;2022-11-13 18:08:13, messageId&#x3D;i&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;0, messageData&#x3D;test message, hello!&#125;&#39; MessageProperties [headers&#x3D;&#123;&#125;, contentType&#x3D;application&#x2F;x-java-serialized-object, contentLength&#x3D;0, receivedDeliveryMode&#x3D;PERSISTENT, priority&#x3D;0, redelivered&#x3D;false, receivedExchange&#x3D;TestDirectDurableExchange, receivedRoutingKey&#x3D;TestDirectDurableRouting, deliveryTag&#x3D;1, consumerTag&#x3D;amq.ctag-1pjqPhATqOrYTl1qTTmlEg, consumerQueue&#x3D;TestDirectDurableQueue]) [TRACEID:] 2022-11-13 18:08:37.474 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1-74] WARN o.s.a.r.r.RejectAndDontRequeueRecoverer 74 recover - Retries exhausted for message (Body:&#39;&#123;createTime&#x3D;2022-11-13 18:08:13, messageId&#x3D;i&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;0, messageData&#x3D;test message, hello!&#125;&#39; MessageProperties [headers&#x3D;&#123;&#125;, contentType&#x3D;application&#x2F;x-java-serialized-object, contentLength&#x3D;0, receivedDeliveryMode&#x3D;PERSISTENT, priority&#x3D;0, redelivered&#x3D;false, receivedExchange&#x3D;TestDirectDurableExchange, receivedRoutingKey&#x3D;TestDirectDurableRouting, deliveryTag&#x3D;1, consumerTag&#x3D;amq.ctag-1pjqPhATqOrYTl1qTTmlEg, consumerQueue&#x3D;TestDirectDurableQueue])org.springframework.amqp.rabbit.support.ListenerExecutionFailedException: Listener method &#39;public void com.wql.consumer.DirectReceiver.listenMessage(org.springframework.amqp.core.Message,com.rabbitmq.client.Channel) throws java.io.IOException,java.lang.InterruptedException&#39; threw exception at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:230) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandlerAndProcessResult(MessagingMessageListenerAdapter.java:150) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:135) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1650) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1569) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:93) at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329) at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:225) at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:116) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215) at org.springframework.amqp.rabbit.listener.$Proxy143.invokeListener(Unknown Source) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1557) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:1548) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:1492) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:968) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:914) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1600(SimpleMessageListenerContainer.java:83) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.mainLoop(SimpleMessageListenerContainer.java:1289) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1195) at java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.amqp.AmqpException: PublisherCallbackChannel is closed at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:1139) at com.sun.proxy.$Proxy144.basicAck(Unknown Source) at com.wql.consumer.DirectReceiver.listenMessage(DirectReceiver.java:29) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) at org.springframework.amqp.rabbit.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:68) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:222) ... 27 common frames omitted [TRACEID:] 2022-11-13 18:08:37.476 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1-169] WARN o.s.a.r.l.ConditionalRejectingErrorHandler 169 log - Execution of Rabbit message listener failed.org.springframework.amqp.rabbit.support.ListenerExecutionFailedException: Retry Policy Exhausted at org.springframework.amqp.rabbit.retry.RejectAndDontRequeueRecoverer.recover(RejectAndDontRequeueRecoverer.java:76) at org.springframework.amqp.rabbit.config.StatelessRetryOperationsInterceptorFactoryBean.lambda$createRecoverer$0(StatelessRetryOperationsInterceptorFactoryBean.java:74) at org.springframework.retry.interceptor.RetryOperationsInterceptor$ItemRecovererCallback.recover(RetryOperationsInterceptor.java:142) at org.springframework.retry.support.RetryTemplate.handleRetryExhausted(RetryTemplate.java:539) at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:387) at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:225) at org.springframework.retry.interceptor.RetryOperationsInterceptor.invoke(RetryOperationsInterceptor.java:116) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215) at org.springframework.amqp.rabbit.listener.$Proxy143.invokeListener(Unknown Source) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1557) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:1548) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:1492) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:968) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:914) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1600(SimpleMessageListenerContainer.java:83) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.mainLoop(SimpleMessageListenerContainer.java:1289) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1195) at java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.amqp.AmqpRejectAndDontRequeueException: null ... 19 common frames omitted Caused by: org.springframework.amqp.rabbit.support.ListenerExecutionFailedException: Listener method &#39;public void com.wql.consumer.DirectReceiver.listenMessage(org.springframework.amqp.core.Message,com.rabbitmq.client.Channel) throws java.io.IOException,java.lang.InterruptedException&#39; threw exception at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:230) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandlerAndProcessResult(MessagingMessageListenerAdapter.java:150) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.onMessage(MessagingMessageListenerAdapter.java:135) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1650) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1569) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.retry.interceptor.RetryOperationsInterceptor$1.doWithRetry(RetryOperationsInterceptor.java:93) at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329) ... 14 common frames omitted Caused by: org.springframework.amqp.AmqpException: PublisherCallbackChannel is closed at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:1139) at com.sun.proxy.$Proxy144.basicAck(Unknown Source) at com.wql.consumer.DirectReceiver.listenMessage(DirectReceiver.java:29) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171) at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120) at org.springframework.amqp.rabbit.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:68) at org.springframework.amqp.rabbit.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:222) ... 27 common frames omitted [TRACEID:] 2022-11-13 18:08:37.483 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1-1429] INFO o.s.a.r.l.SimpleMessageListenerContainer 1429 killOrRestart - Restarting Consumer@208185c0: tags&#x3D;[[amq.ctag-1pjqPhATqOrYTl1qTTmlEg]], channel&#x3D;Cached Rabbit Channel: PublisherCallbackChannelImpl: AMQChannel(amqp:&#x2F;&#x2F;admin@127.0.0.1:5672&#x2F;rrcVhost,9), conn: Proxy@4229b92c Shared Rabbit Connection: SimpleConnection@1fe7fa16 [delegate&#x3D;amqp:&#x2F;&#x2F;admin@127.0.0.1:5672&#x2F;rrcVhost, localPort&#x3D; 27950], acknowledgeMode&#x3D;MANUAL local queue size&#x3D;0 可以看到重试次数是5次（包含自身消费的一次），重试时间依次是2s，4s，8s，10s（上一次间隔时间*间隔时间乘子），最后一次重试时间理论上是16s，但是由于设置了最大间隔时间是10s，因此最后一次间隔时间只能是10s，和配置相符合。 注意： 重试并不是RabbitMQ重新发送了消息，仅仅是消费者内部进行的重试，换句话说就是重试跟mq没有任何关系； 因此上述消费者代码不能添加try{}catch(){}，一旦捕获了异常，在自动ack模式下，就相当于消息正确处理了，消息直接被确认掉了，不会触发重试的； retry使用场景上面说了什么是重试，以及如何解决重试造成的数据丢失，那么怎么来选择重试的使用场景呢？ 是否是消费者只要发生异常就要去重试呢？其实不然，假设下面的两个场景： http下载视频或者图片或者调用第三方接口空指针异常或者类型转换异常（其他的受检查的运行时异常）很显然，第一种情况有重试的意义，第二种没有。 对于第一种情况，由于网络波动等原因造成请求失败，重试是有意义的； 对于第二种情况，需要修改代码才能解决的问题，重试也没有意义，需要的是记录日志以及人工处理或者轮询任务的方式去处理。 retry最佳实践对于消费端异常的消息，如果在有限次重试过程中消费成功是最好的，如果有限次重试之后仍然失败的消息，不管是采用RejectAndDontRequeueRecoverer还是使用死信队列都是可以的，同时也可以采用折中的方法，先将消息从业务队列中ack掉，再将消息发送到另外的一个队列中，后续再单独处理异常数据的队列。 另外，看到有人说retry只能在自动ack模式下使用，经过测试在手动ack模式下retry也是生效的，只不过不能使用catch捕获异常，即使在自动ack模式下使用catch捕获异常也是会导致不触发重试的。当然，在手动ackm模式下要记得确认消息，不管是确认消费成功还是确认消费失败，不然消息会一直处于unack状态，直到消费者进程重启或者停止。 如果一定要在手动ack模式下使用retry功能，最好还是确认在有限次重试过程中可以重试成功，否则超过重试次数，又没办法执行nack，就会出现消息一直处于unack的问题，我想这也就是所说的retry只能在自动ack模式下使用的原因，测试代码如下： 引用 RabbitMQ 如何进行消息可靠投递 Rabbitmq——备份交换机 RabbitMQ重试机制","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://qinglei1989.github.io/categories/rabbitmq/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"RabbitMQ消息持久化与内存管控","slug":"middleware-rabbitmq-monitor","date":"2022-11-11T16:03:02.000Z","updated":"2022-11-11T16:51:02.535Z","comments":true,"path":"2022/11/12/middleware-rabbitmq-monitor/","link":"","permalink":"https://qinglei1989.github.io/2022/11/12/middleware-rabbitmq-monitor/","excerpt":"RabbitMQ消息持久化与内存管控。","text":"RabbitMQ消息持久化与内存管控。 【MQ中间件】RabbitMQ消息持久化与内存管控 RibbitMQ持久化 持久化就把信息写入到磁盘的过程。 消息什么时候需要持久化： 消息本身在publish的时候就要求消息写入磁盘； 内存紧张，需要将部分内存中的消息转移到磁盘； 持久化是为提高rabbitmq消息的可靠性，防止在异常情况(重启，关闭，宕机)下数据的丢失。 rabbitmq持久化分为三个部分: 交换器的持久化、队列的持久化和消息的持久化。 交换器的持久化交换器的持久化是通过声明队列时，将durable参数设置为true实现的。如果交换器不设置持久化，那么rabbitmq服务重启之后，exchange将不复存在，不过消息不会丢失，那么既而发送方rabbitmq producer就无法正常发送消息。建议将交换器设置为持久化。 队列的持久化队列的持久化是通过声明队列时，将durable参数设置为true实现的。如果队列不设置持久化，那么rabbitmq服务重启之后，相关的队列元数据将会丢失，而消息是存储在队列中的，所以队列中的消息也会被丢失。 消息的持久化队列的持久化只能保证其队列本身的元数据不会被丢失，但是不能保证消息不会被丢失。所以消息本身也需要被持久化，可以在投递消息前设置AMQP.BasicProperties的属性deliveryMode为2即可，spring boot和rabbitmq整合以后，默认消息是会被持久化的。 消息都设置为持久化，但是这样会影响RabbitMQ的性能。因为我们将消息写入到内存的同时还需要将消息写入到磁盘。对于可靠性要求不是那么高的消息可以不采用持久化处理，以提高整体系统的吞吐量。 总结将交换器、队列和消息都设置持久化之后就能保证数据不会被丢失吗？当然不是，多个方面 消费者端: 消费者订阅队列将autoAck设置为true,虽然消费者接收到了消息，但是没有来得及处理就宕机了，那数据也会丢失，解决方案就是以为手动确认接收消息，待处理完消息之后，手动删除消息 在rabbitmq服务端，如果消息正确被发送，但是rabbitmq未来得及持久化，没有将数据写入磁盘，服务异常而导致数据丢失，解决方案，可以通过rabbitmq集群的方式实现消息中间件的高可用性 内存限制 内存告警当内存使用超过配置的阈值或者磁盘剩余空间低于配置的阈值时会暂时阻塞客户端的连接，并停止接收从客户端发来的消息，以避免服务崩溃，客户端与服务端的心跳检测也会失败。当出现内存告警时，可以通过管理命令临时调整内存大小。 rabbitmqctl set_vm_memory_high_watermark &lt;fraction&gt; fraction为内存阈值，RabbitMQ默认是0.4，表示当RabbitMQ使用的内存超过总内存的40%时，就会产生告警并阻塞所有生产连接。 通过此命令修改的阈值在RabbitMQ重启之后将会失效，通过修改配置文件的方式设置的阈值才会永久有效，但需要重启服务才会生效。 配置文件：RabbitMQ.conf #相对值，也就是前面的fraction，建议设置在0.4~0.66之间，不要超过0.7 vm_memory_high_watermark.relative&#x3D;0.4 #绝对值，单位为KB,MB,GB,对应的临时命令是：RabbitMQctl set_vm_memory_high_watermark absolute &lt;value&gt; #vm_memory_high_watermark.absolute&#x3D;1GB 当出现blocking或blocked话说明到达了阈值和以及高负荷运行了。 内存换页在某个broker节点触及内存并阻塞生产者之前，他会尝试将队列内存中的消息换页存储到磁盘以释放内存空间。持久化和非持久化的消息都会被转储到磁盘中，其中持久化的消息本身就在磁盘中有一个备份，所以这里会将持久化的消息从内存中清除掉。默认情况下，在内存达到内存阈值的50%时会进行换页操作。也就是说，在默认的内存阈值40%的情况下，当内存超过0.4*0.5=0.2时会经行换页动作。内存换页可以通过在配置文件中设置来进行调整。 vm_memory_high_watermark_paging_ratio&#x3D;0.75 磁盘限制当磁盘剩余空间低于设置的阈值时，RabbitMQ同样会阻塞生产者，这样可以避免因非持久化的消息持续换页而耗尽磁盘空间导致服务崩溃。默认情况下，磁盘的阈值是5OM，表示当磁盘剩余空间低于5OM时，会阻塞生产者并停止内存中消息的换页动作。这个阈值的设置可以减小，但不能完全消除因磁盘耗尽而导致崩溃的可能性。比如在两次磁盘空间检测期间内，磁盘空间从大于50M被耗尽到OM。备注:一个相对谨慎的做法是将磁盘阈值设置为与操作系统所显示的内存大小一致。通过以下命令可以临时调整磁盘阈值 #设置具体大小，单位为KB&#x2F;MB&#x2F;GB rabbitmqctl set_disk_free_limit &lt;disk_limit&gt; #设置相对值，建议取值为1.0~2.0(相对于内存的倍数，如内存大小是8c,若为1.0，则表示磁盘剩余8G时阻塞) rabbitmqctl set_disk_free_limit mem_relative &lt;fraction&gt; 对应的配置文件配置如下: disk_free_limit.relative&#x3D;2.0 #disk_free_limit_absolute&#x3D;50MB 运行时查看生效的配置文件信息rabbitmq-diagnostics environment 引用 RabbitMQ持久化机制 RabbitMQ – RabbitMQ死信队列及内存监控 RabbitMQ持久化机制","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://qinglei1989.github.io/categories/rabbitmq/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"RabbitMQ -- RabbitMQ消息模式","slug":"middleware-rabbitmq-message","date":"2022-11-03T16:03:02.000Z","updated":"2022-11-13T16:01:37.637Z","comments":true,"path":"2022/11/04/middleware-rabbitmq-message/","link":"","permalink":"https://qinglei1989.github.io/2022/11/04/middleware-rabbitmq-message/","excerpt":"RabbitMQ – RabbitMQ消息模式","text":"RabbitMQ – RabbitMQ消息模式 【MQ中间件】RabbitMQ – RabbitMQ消息模式 RabbitMQ入门 默认情况下，rabbitmq是没有安装web端的客户端插件，需要安装才可以生效： rabbitmq-plugins enable rabbitmq_management 说明：rabbitmq有一个默认账号和密码是：**guest** 默认情况只能在localhost本机下访问，所以需要添加一个远程登录的用户。 安装完毕以后，重启服务即可 systemctl restart rabbitmq-server 一定要记住，在对应服务器(阿里云，腾讯云等)的安全组中开放15672的端口。 RabbitMQ架构 从架构图中可以看出：RabbitMQ架构包含了Provider（生产者）、Exchanges（交换机）、Queues（队列）、Consumer（消费者）。 RabbitMQ支持的消息模式 简单模式 Simple 在简单模式的消息发送中，不需要特别创建交换机（指定交换机的类型），通过默认的交换机Binding Default exchange，通过指定Routing key为queue name即可向queue name指向的Queue队列发送消息（1对1分发）。 注意： rabbitmq发送消息一定有一个交换机，如果没有创建交换机，默认使用Default_exchange进行绑定。 工作队列模式 WorkQueues 工作队列模式也是指定的默认的default默认交换机对多个Queue消费者进行消息的发送， 主要有两种模式：1、轮询模式分发：一个消费者一条，按均分配，平均分，不会因为哪个消费者内部处理速率较快而减少消息的发送； ​ 轮询模式设置为自动应答 ​ 不设置限流 2、公平分发：根据消费者的消费能力进行公平分发，处理快的处理的多，处理慢的处理的少；按劳分配； ​ 设置为手动应答 ​ 开启限流 发布订阅模式 Publish/Subscribe 发布订阅模式使用fanout类型交换机绑定每一个消费者Queue队列，相当于广播的形式，订阅了该交换机（频道）的Queue都会收到通过交换机发送的来自生产者的消息。 路由模式Routing 路由模式的交换机类型是：direct类型 路由模式与发布订阅模式非常相似，也非常容易理解。它只是在发布订阅模式上新增了路由key，通过对应的路由key与对应的Queue进行绑定，这个Queue就被key唯一标识了。 然后当交换机再去发送消息的时候，会在绑定了交换机的Queue中指定对应的路由key进行发送，只有对应路由key为发送key一一对应的才能收到消息。 主题Topic模式 主题模式topics相较于路由模式是非常相似的，只不过在路由的基础之上增加了支持模糊匹配的Routing key的形式。 主题模式的交换机类型选择必须是topic类型。 匹配规则： #：表示0个或者多个，取值范围为[0,+无穷大） *：表示1个，取值为1，即必须要有一个。 参数模式 引用 RabbitMQ – RabbitMQ消息模式](https://www.cnblogs.com/yif0118/p/14665274.html) rabbitmq文档","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://qinglei1989.github.io/categories/rabbitmq/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"spring-boot-shardingjdbc","slug":"spring-boot-shardingjdbc","date":"2022-10-27T17:47:15.000Z","updated":"2022-11-03T15:56:50.146Z","comments":true,"path":"2022/10/28/spring-boot-shardingjdbc/","link":"","permalink":"https://qinglei1989.github.io/2022/10/28/spring-boot-shardingjdbc/","excerpt":"Mysql数据库架构演进从单机到主从到分库分表在数据量及访问压力不是特别大的情况，首先考虑缓存、读写分离、索引技术等方案 如果数据量极大，且业务持续增长快，再考虑分库分表方案","text":"Mysql数据库架构演进从单机到主从到分库分表在数据量及访问压力不是特别大的情况，首先考虑缓存、读写分离、索引技术等方案 如果数据量极大，且业务持续增长快，再考虑分库分表方案 Sharding-JDBC学习 Mysql数据库架构演变历史 单机 请求量大查询慢 单机故障导致业务不可用 主从 数据库主从同步，从库可以水平扩展，满足更大读需求 但单服务器TPS，内存，IO都是有限的 分库分表 解决数据库本身瓶颈，包括连接数过多等。分库可以解决单台数据库的并发访问压力问题。分表可以解决单表海量数据的查询性能问题 解决系统本身IO、CPU瓶颈 分库分表 垂直分表“大表拆小表”，基于列字段进行的。 拆分原则一般是表中的字段较多，将不常用的或者数据较大，长度较长的拆分到“扩展表 如text类型字段 访问频次低、字段大的商品描述信息单独存放在一张表中，访问频次较高的商品基本信息单独放在一张表中 垂直分库 垂直分库能够突破IO、连接数及单机硬件资源的瓶颈。垂直分库可以更好解决业务层面的耦合，业务清晰，且方便管理和维护 一般从单体项目根据不同业务进行拆分改造为微服务项目，就是垂直分库 垂直分库分表可以提高并发，但是依然没有解决单表数据量过大的问题 水平分表 把一张大表拆分成N个小表，表结构一样，但数据不一样，每张表只有部分数据，全部表的数据合起来就是全部数据 但是这些表还是在同一个库中，所以单数据库操作还是有IO瓶颈，主要是解决单表数据量过大的问题 水平分库 把同个表的数据按照一定规则分到不同的数据库中，数据库在不同的服务器上 每个库的结构都一样,但每个库的数据都不一样，没有交集，所有库的并集就是全量数据 水平分库的粒度，比水平分表更大 常规开发里面单表建议1千万内，推荐是百万级别单表存储，常规sql和索引优化先行，然后结合缓存+异步+nosql+mq 水平分库分表常见策略讲解 range方案一：自增id，根据ID范围进行分表（左闭右开） 优点是id是自增长，可以无限增长。扩容不用迁移数据，容易理解和维护 缺点是大部分读和写都访会问新的数据，有IO瓶颈，整体资源利用率低。数据倾斜严重，热点数据过于集中，部分节点有瓶颈 range延伸时间：年、月、日范围，比如按照月份生成 库或表 pay_log_2022_01、pay_log_2022_02 空间：地理位置：省份、区域（华东、华北、华南）比如按照 省份 生成 库或表 Hash取模Hash分库分表是最普遍的方案。保证数据较均匀的分散落在不同的库、表中，可以有效的避免热点数据集中问题。缺点是扩容不是很方便，需要数据迁移 分库分表常见中间件介绍 Mycat 地址 http://www.mycat.org.cn/ Java语言编写的MySQL数据库网络协议的开源中间件，前身 Cobar 遵守Mysql原生协议，跨语言，跨平台，跨数据库的通用中间件代理 是基于 Proxy，它复写了 MySQL 协议，将 Mycat Server 伪装成一个 MySQL 数据库 和ShardingShere下的Sharding-Proxy作用类似，需要单独部署 ShardingSphere 下的Sharding-JDBC 地址：https://shardingsphere.apache.org/ Apache ShardingSphere 是一套开源的分布式数据库中间件解决方案组成的生态圈 它由 Sharding-JDBC、Sharding-Proxy 和 Sharding-Sidecar 3个独立产品组合 Sharding-JDBC 基于jdbc驱动，不用额外的proxy，支持任意实现 JDBC 规范的数据库 它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖 可理解为加强版的 JDBC 驱动，兼容 JDBC 和各类 ORM 框架 二者之间的区别： 两者设计理念相同，主流程都是SQL解析–&gt;SQL路由–&gt;SQL改写–&gt;结果归并 sharding-jdbc 基于jdbc驱动，不用额外的proxy，在本地应用层重写Jdbc原生的方法，实现数据库分片形式 是基于 JDBC 接口的扩展，是以 jar 包的形式提供轻量级服务的，性能高 代码有侵入性 Mycat 是基于 Proxy，它复写了 MySQL 协议，将 Mycat Server 伪装成一个 MySQL 数据库 客户端所有的jdbc请求都必须要先交给MyCat，再有MyCat转发到具体的真实服务器 缺点是效率偏低，中间包装了一层 代码无侵入性 分库分表基础概念 数据节点Node 数据分片的最小单元，由数据源名称和数据表组成ds_0.product_order_0 真实表 在分片的数据库中真实存在的物理表,比如订单表 product_order_0、product_order_1、product_order_2 逻辑表 水平拆分的数据库（表）的相同逻辑和数据结构表的总称,比如订单表 product_order_{0..1}逻辑表就是product_order 绑定表 指分片规则一致的主表和子表 比如product_order表和product_order_item表，均按照order_id分片，则此两张表互为绑定表关系 绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升 广播表 指所有的分片数据源中都存在的表，表结构和表中的数据在每个数据库中均完全一致 适用于数据量不大且需要与海量数据的表进行关联查询的场景 例如：字典表、配置表 分库分表和Sharding-Jdbc常见分片算法讲解 数据库表分片（水平库、表）,包含分片键和分片策略 分片键 (PartitionKey) 用于分片的数据库字段，是将数据库(表)水平拆分的关键字段, ShardingSphere也支持根据多个字段进行分片 分片策略 行表达式分片策略 InlineShardingStrategy（必备） 只支持【单分片键】使用Groovy的表达式，提供对SQL语句中的 =和IN 的分片操作支持,可以通过简单的配置使用，无需自定义分片算法，从而避免繁琐的Java代码开发 标准分片策略StandardShardingStrategy 只支持【单分片键】，提供PreciseShardingAlgorithm和RangeShardingAlgorithm两个分片算法 PreciseShardingAlgorithm 精准分片 是必选的，用于处理=和IN的分片 RangeShardingAlgorithm 范围分配 是可选的，用于处理BETWEEN AND分片 如果不配置RangeShardingAlgorithm，如果SQL中用了BETWEEN AND语法，则将按照全库路由处理，性能下降 复合分片策略ComplexShardingStrategy（需了解） 支持【多分片键】，多分片键之间的关系复杂，由开发者自己实现，提供最大的灵活度 提供对SQL语句中的=, IN和BETWEEN AND的分片操作支持 Hint分片策略HintShardingStrategy（需了解） 这种分片策略无需配置分片健，分片健值也不再从 SQL中解析，外部手动指定分片健或分片库，让 SQL在指定的分库、分表中执行 用于处理使用Hint行分片的场景，通过Hint而非SQL解析的方式分片的策略 Hint策略会绕过SQL解析的，对于这些比较复杂的需要分片的查询，Hint分片策略性能可能会更好 不分片策略 NoneShardingStrategy 不分片的策略。 springboot整合shardingjdbc 框架版本说明 &lt;properties&gt; &lt;maven.compiler.source&gt;8&lt;&#x2F;maven.compiler.source&gt; &lt;maven.compiler.target&gt;8&lt;&#x2F;maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;&#x2F;project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;&#x2F;project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;&#x2F;java.version&gt; &lt;mybatis-plus.version&gt;3.4.0&lt;&#x2F;mybatis-plus.version&gt; &lt;spring-boot.version&gt;2.5.0&lt;&#x2F;spring-boot.version&gt; &lt;lombok.version&gt;1.18.16&lt;&#x2F;lombok.version&gt; &lt;mysql.version&gt;8.0.25&lt;&#x2F;mysql.version&gt; &lt;sharding-jdbc.version&gt;4.1.1&lt;&#x2F;sharding-jdbc.version&gt; &lt;&#x2F;properties&gt; maven pom文件配置 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;&#x2F;version&gt; &lt;scope&gt;test&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;!--mybatis plus和springboot整合--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;mybatis-plus.version&#125;&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;&#x2F;groupId&gt; &lt;artifactId&gt;lombok&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;&#x2F;version&gt; &lt;!--&lt;scope&gt;provided&lt;&#x2F;scope&gt;--&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;&#x2F;groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;sharding-jdbc.version&#125;&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;&#x2F;groupId&gt; &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt; &lt;version&gt;4.13&lt;&#x2F;version&gt; &lt;scope&gt;test&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;&#x2F;dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;&#x2F;version&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;&#x2F;fork&gt; &lt;addResources&gt;true&lt;&#x2F;addResources&gt; &lt;&#x2F;configuration&gt; &lt;&#x2F;plugin&gt; &lt;&#x2F;plugins&gt; &lt;&#x2F;build&gt; SQL脚本 create table product_order_0 ( id bigint auto_increment primary key, out_trade_no varchar(64) null comment &#39;订单唯一标识&#39;, state varchar(11) null comment &#39;NEW 未支付订单,PAY已经支付订单,CANCEL超时取消订单&#39;, create_time datetime null comment &#39;订单生成时间&#39;, pay_amount decimal(16, 2) null comment &#39;订单实际支付价格&#39;, nickname varchar(64) null comment &#39;昵称&#39;, user_id bigint null comment &#39;用户id&#39; ) collate &#x3D; utf8mb4_bin; 配置文件： #水平分表配置 spring: shardingsphere: datasource: # 数据源名称，多数据源以逗号分隔(ds0,ds1) names: ds0,ds1 # names定义的数据源名称作为key（key不能包含下划线，否则无法识别配置） ds0: type: com.zaxxer.hikari.HikariDataSource driver: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;shop_order_0?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;allowPublicKeyRetrieval&#x3D;true username: root password: ds1: type: com.zaxxer.hikari.HikariDataSource driver: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;shop_order_1?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;allowPublicKeyRetrieval&#x3D;true username: root password: 水平分表-单分片键 #水平分表配置 spring: shardingsphere: datasource: # 数据源名称，多数据源以逗号分隔(ds0,ds1) names: ds0,ds1 # names定义的数据源名称作为key（key不能包含下划线，否则无法识别配置） ds0: type: com.zaxxer.hikari.HikariDataSource driver: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;shop_order_0?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;allowPublicKeyRetrieval&#x3D;true username: root password: ds1: type: com.zaxxer.hikari.HikariDataSource driver: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;shop_order_1?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;allowPublicKeyRetrieval&#x3D;true username: root password: sharding: # binding‐tables[0]: product_order,product_order_item tables: product_order: key-generator: column: id #主键生成策略 可选内置的 SNOWFLAKE(雪花算法)&#x2F;UUID 也可以自定义 type: SNOWFLAKE # 分库策略 database-strategy: inline: sharding-column: user_id algorithm-expression: ds$-&gt;&#123;user_id % 2&#125; # 由数据源名 + 表名组成，以小数点分隔。多个表以逗号分隔，支持inline表达式 actual-data-nodes: ds$-&gt;&#123;0..1&#125;.product_order_$-&gt;&#123;0..1&#125; #分表策略：单分片键 table-strategy: inline: #分片键 sharding-column: id #数据分片规则（ID是偶数把数据添加入product_order_0，奇数入product_order_1） algorithm-expression: product_order_$-&gt;&#123;id % 2&#125; product_order_item: key-generator: column: id type: SNOWFLAKE # 分库策略 database-strategy: inline: sharding-column: user_id algorithm-expression: ds$-&gt;&#123;user_id % 2&#125; actual-data-nodes: ds$-&gt;&#123;0..1&#125;.product_order_item_$-&gt;&#123;0..1&#125; table-strategy: inline: sharding-column: product_order_id algorithm-expression: product_order_item_$-&gt;&#123;product_order_id % 2&#125; ad_config: key-generator: column: id type: SNOWFLAKE # 广播表 broadcast-tables: ad_config props: sql: show: true 测试-分表-查询 @Test public void customRange1() &#123; &#x2F;&#x2F;分区字段查询数据：精准匹配分片表，不会去别的表中扫描数据 ProductOrder productOrder &#x3D; productOrderMapper.selectById(Long.valueOf(&quot;791057093019828224&quot;)); log.info(&quot;数据为&#123;&#125;&quot;, productOrder.toString()); &#x2F;&#x2F;非分区字段查询：全表匹配，汇总结果 List&lt;ProductOrder&gt; productOrderList &#x3D; productOrderMapper.selectList(new QueryWrapper&lt;ProductOrder&gt;().between(&quot;create_time&quot;,&quot;2022-10-23 21:38:28&quot;,&quot;2022-10-25 21:38:28&quot;)); log.info(&quot;数据量&#123;&#125;&quot;,productOrderList.size()); &#125; 日志打印如下： 2022-10-31 00:50:12.624 INFO 15368 --- [ main] ShardingSphere-SQL : Logic SQL: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order WHERE id&#x3D;? 2022-10-31 00:50:12.624 INFO 15368 --- [ main] ShardingSphere-SQL : SQLStatement: SelectStatementContext(super&#x3D;CommonSQLStatementContext(sqlStatement&#x3D;org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@2bc16fe2, tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@d66502), tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@d66502, projectionsContext&#x3D;ProjectionsContext(startIndex&#x3D;7, stopIndex&#x3D;67, distinctRow&#x3D;false, projections&#x3D;[ColumnProjection(owner&#x3D;null, name&#x3D;id, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;out_trade_no, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;state, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;create_time, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;pay_amount, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;nickname, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;user_id, alias&#x3D;Optional.empty)]), groupByContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@78545d40, orderByContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@34549979, paginationContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@144a5e6e, containsSubquery&#x3D;false) 2022-10-31 00:50:12.625 INFO 15368 --- [ main] ShardingSphere-SQL : Actual SQL: ds0 ::: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order_0 WHERE id&#x3D;? ::: [791057093019828224] 2022-10-31 00:50:12.625 INFO 15368 --- [ main] ShardingSphere-SQL : Actual SQL: ds1 ::: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order_0 WHERE id&#x3D;? ::: [791057093019828224] 2022-10-31 00:50:12.665 INFO 15368 --- [ main] CustomShardingjdbcTest : 数据为ProductOrder(id&#x3D;791057093019828224, outTradeNo&#x3D;333333, state&#x3D;代发货, createTime&#x3D;Sun Oct 23 21:38:28 CST 2022, payAmount&#x3D;0.04, nickname&#x3D;狗蛋4, userId&#x3D;14) 2022-10-31 00:50:12.730 INFO 15368 --- [ main] ShardingSphere-SQL : Logic SQL: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order WHERE (create_time BETWEEN ? AND ?) 2022-10-31 00:50:12.730 INFO 15368 --- [ main] ShardingSphere-SQL : SQLStatement: SelectStatementContext(super&#x3D;CommonSQLStatementContext(sqlStatement&#x3D;org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@52433946, tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@5403431a), tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@5403431a, projectionsContext&#x3D;ProjectionsContext(startIndex&#x3D;8, stopIndex&#x3D;68, distinctRow&#x3D;false, projections&#x3D;[ColumnProjection(owner&#x3D;null, name&#x3D;id, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;out_trade_no, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;state, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;create_time, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;pay_amount, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;nickname, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;user_id, alias&#x3D;Optional.empty)]), groupByContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@ab327c, orderByContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@3d798e76, paginationContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@763b0996, containsSubquery&#x3D;false) 2022-10-31 00:50:12.730 INFO 15368 --- [ main] ShardingSphere-SQL : Actual SQL: ds0 ::: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order_0 WHERE (create_time BETWEEN ? AND ?) ::: [2022-10-23 21:38:28, 2022-10-25 21:38:28] 2022-10-31 00:50:12.730 INFO 15368 --- [ main] ShardingSphere-SQL : Actual SQL: ds0 ::: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order_1 WHERE (create_time BETWEEN ? AND ?) ::: [2022-10-23 21:38:28, 2022-10-25 21:38:28] 2022-10-31 00:50:12.730 INFO 15368 --- [ main] ShardingSphere-SQL : Actual SQL: ds1 ::: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order_0 WHERE (create_time BETWEEN ? AND ?) ::: [2022-10-23 21:38:28, 2022-10-25 21:38:28] 2022-10-31 00:50:12.730 INFO 15368 --- [ main] ShardingSphere-SQL : Actual SQL: ds1 ::: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order_1 WHERE (create_time BETWEEN ? AND ?) ::: [2022-10-23 21:38:28, 2022-10-25 21:38:28] 2022-10-31 00:50:12.745 INFO 15368 --- [ main] CustomShardingjdbcTest : 数据量70 由上可以看出分片字段作为查询条件时，能准定位分片数据所在分片表（上边没有使用分库键，所以只能定位到分片表）。非分片字段查询时，全表匹配，汇总结果。 水平分表-单分片键（标准分片算法） # 打印执行的数据库以及语句 spring: shardingsphere: datasource: names: ds0,ds1 ds0: type: com.zaxxer.hikari.HikariDataSource driver: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;shop_order_0?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;allowPublicKeyRetrieval&#x3D;true username: root password: 900926 ds1: type: com.zaxxer.hikari.HikariDataSource driver: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;shop_order_1?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;allowPublicKeyRetrieval&#x3D;true username: root password: 900926 sharding: # binding‐tables[0]: product_order,product_order_item tables: product_order: key-generator: column: id type: SNOWFLAKE actual-data-nodes: ds$-&gt;&#123;0..1&#125;.product_order_$-&gt;&#123;0..1&#125; table-strategy: standard: sharding-column: id #精确分片算法类名称，用于 &#x3D; 和 IN。该类需实现PreciseShardingAlgorithm 接口并提供无参数的构造器 precise-algorithm-class-name: com.rrc.strategy.CustomTablePreciseShardingAlgorithm # 范围分片算法类名称，用于 BETWEEN，可选。该类需实现RangeShardingAlgorithm 接口并提供无参数的构造器 range-algorithm-class-name: com.rrc.strategy.CustomRangeShardingAlgorithm database-strategy: standard: sharding-column: user_id precise-algorithm-class-name: com.rrc.strategy.CustomDBPreciseShardingAlgorithm props: sql: show: true 精准分片算法实现 public class CustomTablePreciseShardingAlgorithm implements PreciseShardingAlgorithm&lt;Long&gt; &#123; &#x2F;** * * @param dataSourceNames 数据源集合 * 在分库时值为所有分片库的集合 databaseNames * 分表时为对应分片库中所有分片表的集合 tablesNames * * @param shardingValue 分片属性，包括 * logicTableName 为逻辑表， * columnName 分片健（字段）， * value 为从 SQL 中解析出的分片健的值 * @return *&#x2F; @Override public String doSharding(Collection&lt;String&gt; dataSourceNames, PreciseShardingValue&lt;Long&gt; shardingValue) &#123; for (String databaseName : dataSourceNames) &#123; String value &#x3D; shardingValue.getValue() % dataSourceNames.size() + &quot;&quot;; &#x2F;&#x2F;value是0，则进入0库表，1则进入1库表 if (databaseName.endsWith(value)) &#123; return databaseName; &#125; &#125; throw new IllegalArgumentException(); &#125; &#125; 范围分片算法实现 public class CustomRangeShardingAlgorithm implements RangeShardingAlgorithm&lt;Long&gt; &#123; &#x2F;** * * @param dataSourceNames 数据源集合 * 在分库时值为所有分片库的集合 databaseNames * 分表时为对应分片库中所有分片表的集合 tablesNames * * @param shardingValue 分片属性，包括 * logicTableName 为逻辑表， * columnName 分片健（字段）， * value 为从 SQL 中解析出的分片健的值 * @return *&#x2F; @Override public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; dataSourceNames, RangeShardingValue&lt;Long&gt; shardingValue) &#123; Set&lt;String&gt; result &#x3D; new LinkedHashSet&lt;&gt;(); &#x2F;&#x2F;between 开始值 Long lower &#x3D; shardingValue.getValueRange().lowerEndpoint(); &#x2F;&#x2F;between 结束值 Long upper &#x3D; shardingValue.getValueRange().upperEndpoint(); for(long i&#x3D;lower;i&lt;&#x3D;upper;i++)&#123; for(String datasource : dataSourceNames)&#123; String value &#x3D; i % dataSourceNames.size() +&quot;&quot;; if(datasource.endsWith(value))&#123; result.add(datasource); &#125; &#125; &#125; return result; &#125; &#125; 测试标准分片 @Test public void customRange() &#123; productOrderMapper.selectList(new QueryWrapper&lt;ProductOrder&gt;().between(&quot;id&quot;,793987167104794624L,793987167104794624L)); productOrderMapper.selectList(new QueryWrapper&lt;ProductOrder&gt;().in(&quot;id&quot;,793987167104794624L,793987167373230080L)); &#125; 日志打印如下： 2022-10-31 23:54:19.468 INFO 19472 --- [ main] ShardingSphere-SQL : Logic SQL: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order WHERE (id BETWEEN ? AND ?) 2022-10-31 23:54:19.468 INFO 19472 --- [ main] ShardingSphere-SQL : SQLStatement: SelectStatementContext(super&#x3D;CommonSQLStatementContext(sqlStatement&#x3D;org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@6c5ae8fd, tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@17354708), tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@17354708, projectionsContext&#x3D;ProjectionsContext(startIndex&#x3D;8, stopIndex&#x3D;68, distinctRow&#x3D;false, projections&#x3D;[ColumnProjection(owner&#x3D;null, name&#x3D;id, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;out_trade_no, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;state, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;create_time, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;pay_amount, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;nickname, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;user_id, alias&#x3D;Optional.empty)]), groupByContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@1aed6f0b, orderByContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@3b3546a3, paginationContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@134c38, containsSubquery&#x3D;false) 2022-10-31 23:54:19.469 INFO 19472 --- [ main] ShardingSphere-SQL : Actual SQL: ds0 ::: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order_0 WHERE (id BETWEEN ? AND ?) ::: [793987167104794624, 793987167104794624] 2022-10-31 23:54:19.469 INFO 19472 --- [ main] ShardingSphere-SQL : Actual SQL: ds1 ::: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order_0 WHERE (id BETWEEN ? AND ?) ::: [793987167104794624, 793987167104794624] 2022-10-31 23:54:19.554 INFO 19472 --- [ main] ShardingSphere-SQL : Logic SQL: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order WHERE (id IN (?,?)) 2022-10-31 23:54:19.554 INFO 19472 --- [ main] ShardingSphere-SQL : SQLStatement: SelectStatementContext(super&#x3D;CommonSQLStatementContext(sqlStatement&#x3D;org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@214fba74, tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@252c6cdb), tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@252c6cdb, projectionsContext&#x3D;ProjectionsContext(startIndex&#x3D;8, stopIndex&#x3D;68, distinctRow&#x3D;false, projections&#x3D;[ColumnProjection(owner&#x3D;null, name&#x3D;id, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;out_trade_no, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;state, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;create_time, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;pay_amount, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;nickname, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;user_id, alias&#x3D;Optional.empty)]), groupByContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@61c87f1b, orderByContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@1857fe6c, paginationContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@44976b08, containsSubquery&#x3D;false) 2022-10-31 23:54:19.554 INFO 19472 --- [ main] ShardingSphere-SQL : Actual SQL: ds0 ::: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order_0 WHERE (id IN (?,?)) ::: [793987167104794624, 793987167373230080] 2022-10-31 23:54:19.554 INFO 19472 --- [ main] ShardingSphere-SQL : Actual SQL: ds1 ::: SELECT id,out_trade_no,state,create_time,pay_amount,nickname,user_id FROM product_order_0 WHERE (id IN (?,?)) ::: [793987167104794624, 793987167373230080] 由上可以看出between(&quot;id&quot;,793987167104794624L,793987167104794624L)可以确定分片定位到product_order_0，而没有分库键所以执行了ds0和ds1的全库查询。 更换连接池 spring boot和shardingjdbc默认使用的数据库连接池是 HikariCP。如果要在shardingsphere中使用druid,需要在项目中整合后才能生效 说明： 为shardingsphere使用druid数据源时，不要使用druid-spring-boot-starter这个包，因为它在会启动时自动从配置文件生成datasource,所以在这里使用druid这个包 因为druid使用了log4j2,我们对spring-boot-starter-logging做了exclusion yml配置： # 打印执行的数据库以及语句 spring: shardingsphere: datasource: names: ds0,ds1 ds0: type: com.alibaba.druid.pool.DruidDataSource driverClassName: com.mysql.cj.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;shop_order_0?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;allowPublicKeyRetrieval&#x3D;true username: root password: 900926 ds1: type: com.alibaba.druid.pool.DruidDataSource driverClassName: com.mysql.cj.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;shop_order_1?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;allowPublicKeyRetrieval&#x3D;true username: root password: 900926 使用druid数据源时，原有的shardingsphere配置中,jdbc-url要修改为url. DruidConfig.java @Configuration public class DruidConfig &#123; &#x2F;** * Druid监控 *&#x2F; @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean &#x3D; new ServletRegistrationBean(new StatViewServlet(), &quot;&#x2F;druid&#x2F;*&quot;); Map&lt;String,String&gt; initParams &#x3D; new HashMap&lt;&gt;();&#x2F;&#x2F;这是配置的druid监控的登录密码 initParams.put(&quot;loginUsername&quot;,&quot;root&quot;); initParams.put(&quot;loginPassword&quot;,&quot;root&quot;); &#x2F;&#x2F;默认就是允许所有访问 initParams.put(&quot;allow&quot;,&quot;127.0.0.1,192.168.3.4&quot;); &#x2F;&#x2F;黑名单IP initParams.put(&quot;deny&quot;,&quot;192.168.15.21&quot;); bean.setInitParameters(initParams); return bean; &#125; &#x2F;** * web监控的filter *&#x2F; @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean &#x3D; new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; initParams &#x3D; new HashMap&lt;&gt;(); initParams.put(&quot;exclusions&quot;,&quot;&#x2F;static&#x2F;*,*.js,*.gif,*.jpg,*.png,*.css,*.ico,&#x2F;druid&#x2F;*&quot;);&#x2F;&#x2F;过滤掉需要监控的文件 bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList(&quot;&#x2F;*&quot;)); return bean; &#125; &#125; 自定义分布式ID算法 实现ShardingKeyGenerator接口，自定义分布式主键生成算法 @Slf4j public class SimpleShardingKeyGenerator implements ShardingKeyGenerator &#123; private AtomicLong atomic &#x3D; new AtomicLong(1000); @Getter @Setter private Properties properties &#x3D; new Properties(); &#x2F;** * 分布式主键实现算法。 *&#x2F; @Override public Comparable&lt;?&gt; generateKey() &#123; return atomic.incrementAndGet(); &#125; @Override public String getType() &#123; &#x2F;&#x2F;声明类型，需要在配置文件中配置此key return &quot;SIMPLE&quot;; &#125; @Override public Properties getProperties() &#123; return null; &#125; @Override public void setProperties(Properties properties) &#123; &#125; &#125; resources下配置META-INF/services/org.apache.shardingsphere.spi.keygen.ShardingKeyGenerator com.rrc.generator.SimpleShardingKeyGenerator 配置主键生成策略为自定义key 按上面配置的ShardingJDBC表主键生成策略并没有生效，主键依然是雪花算法生成的ID。 问题原因： MybatisPLus在不显式指定主键且有名为“id”的字段，会将id视为主键，当分片键也是该字段时，会与MP冲突，导致Sharding-JDBC的分片键生成策略失效。那么解决方案就很简单了：第一种：分片键不叫“id”就行了第二种：如果分片键是主键，又想叫id，可在分片键上标记主键@TableId，并指定主键类型type = IdType.AUTO即可 广播表 指所有的分片数据源中都存在的表，表结构和表中的数据在每个数据库中均完全一致。适用于数据量不大且需要与海量数据的表进行关联查询的场景，例如：字典表。 简单此处不做说明 绑定表 指分片规则一致的主表和子表。例如：course表和 course_detail表，均按照 course_id分片，则此两张表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。 简单此处不做说明 读写分离 配置文件： # 打印执行的数据库以及语句 spring: shardingsphere: datasource: names: ds0,ds1 ds0: type: com.zaxxer.hikari.HikariDataSource driver: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;shop_order_0?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;allowPublicKeyRetrieval&#x3D;true username: root password: 900926 ds1: type: com.zaxxer.hikari.HikariDataSource driver: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;shop_order_1?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&amp;allowPublicKeyRetrieval&#x3D;true username: root password: 900926 sharding: default-data-source-name: ds0 masterslave: #配置主从名称 name: ms #置主库master,负责数据的写入 master-data-source-name: ds0 #配置从库slave节点 slave-data-source-names: ds1 #配置slave节点的负载均衡均衡策略,采用轮询机制 load-balance-algorithm-type: round_robin props: sql: show: true 表结构： -- auto-generated definition create table ad_config ( id bigint unsigned not null comment &#39;主键id&#39; primary key, config_key varchar(1024) null comment &#39;配置key&#39;, config_value varchar(1024) null comment &#39;配置value&#39;, type varchar(128) null comment &#39;类型&#39; ) collate &#x3D; utf8mb4_bin; 测试类： @ActiveProfiles(&quot;rw&quot;) @RunWith(SpringRunner.class) @SpringBootTest(classes &#x3D; ShardingjdbcApplication.class) @Slf4j public class ShardingjdbcMasterSlave &#123; @Autowired private AdConfigMapper adConfigMapper; @Test public void insert() &#123; AdConfig adConfig &#x3D; new AdConfig(); adConfig.setId(100002L); adConfig.setConfigValue(&quot;1111&quot;); adConfig.setConfigKey(&quot;333333&quot;); adConfig.setType(&quot;44444&quot;); adConfigMapper.insert(adConfig); adConfig &#x3D; adConfigMapper.selectById(100001L); System.out.println(adConfig); &#125; &#125; 日志打印： 2022-11-02 00:41:07.324 INFO 19268 --- [ main] ShardingSphere-SQL : Logic SQL: INSERT INTO ad_config ( id, config_key, config_value, type ) VALUES ( ?, ?, ?, ? ) 2022-11-02 00:41:07.324 INFO 19268 --- [ main] ShardingSphere-SQL : SQLStatement: CommonSQLStatementContext(sqlStatement&#x3D;org.apache.shardingsphere.sql.parser.sql.statement.dml.InsertStatement@54567b05, tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@3a5e2525) 2022-11-02 00:41:07.324 INFO 19268 --- [ main] ShardingSphere-SQL : Actual SQL: ds0 ::: INSERT INTO ad_config ( id, config_key, config_value, type ) VALUES ( ?, ?, ?, ? ) 2022-11-02 00:41:07.515 INFO 19268 --- [ main] ShardingSphere-SQL : Logic SQL: SELECT id,config_key,config_value,type FROM ad_config WHERE id&#x3D;? 2022-11-02 00:41:07.515 INFO 19268 --- [ main] ShardingSphere-SQL : SQLStatement: SelectStatementContext(super&#x3D;CommonSQLStatementContext(sqlStatement&#x3D;org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@2086d469, tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@b1d19ff), tablesContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@b1d19ff, projectionsContext&#x3D;ProjectionsContext(startIndex&#x3D;7, stopIndex&#x3D;37, distinctRow&#x3D;false, projections&#x3D;[ColumnProjection(owner&#x3D;null, name&#x3D;id, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;config_key, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;config_value, alias&#x3D;Optional.empty), ColumnProjection(owner&#x3D;null, name&#x3D;type, alias&#x3D;Optional.empty)]), groupByContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@17c53dfb, orderByContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@184de357, paginationContext&#x3D;org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@efe49ab, containsSubquery&#x3D;false) 2022-11-02 00:41:07.515 INFO 19268 --- [ main] ShardingSphere-SQL : Actual SQL: ds1 ::: SELECT id,config_key,config_value,type FROM ad_config WHERE id&#x3D;? null 从日志可以发现写请求进入ds0，读请求进入ds1。 经验教训 雪花算法最后12位为存储序列号。同一毫秒时间戳时，通过这个递增的序列号来区分。即对于同一台机器而言，同一毫秒时间戳下，可以生成 2^12=4096 个不重复 id。 但是如果项目并发低，大概率同一毫秒内并发很少，12位序列号大概率都为0，生成的雪花算法都是偶数，所以分片HASH值应该为奇数，防止偶数/偶数导致数据分片不均匀。 引用 spring boot:配置shardingsphere springboot整合shardingjdbc实现分库分表最简单demo 10分钟入门分库分表中间件 Sharding-JDBC Sharding-JDBC整合Mybatisplus分片键生成策略冲突问题及分析解决 ShardingJDBC最新完整教程IDEA版通俗易懂 终于有人把ShardingSphere一口气全讲清楚了，透彻讲解原理，源码到实战一步到位！","categories":[{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://qinglei1989.github.io/tags/spring-boot/"}]},{"title":"docker-rabbitmq","slug":"docker-rabbitmq","date":"2022-10-24T17:27:54.000Z","updated":"2022-10-24T17:35:52.731Z","comments":true,"path":"2022/10/25/docker-rabbitmq/","link":"","permalink":"https://qinglei1989.github.io/2022/10/25/docker-rabbitmq/","excerpt":"","text":"https://www.jb51.net/article/233585.htm","categories":[],"tags":[]},{"title":"spring-boot-mybatis-plus","slug":"spring-boot-mybatis-plus","date":"2022-10-03T17:57:52.000Z","updated":"2022-10-04T22:31:37.674Z","comments":true,"path":"2022/10/04/spring-boot-mybatis-plus/","link":"","permalink":"https://qinglei1989.github.io/2022/10/04/spring-boot-mybatis-plus/","excerpt":"记录Springboot整合mybatis-plus中遇到的问题。","text":"记录Springboot整合mybatis-plus中遇到的问题。 Springboot整合mybatis-plus 引入Maven依赖 POM文件 &lt;!--添加父工程依赖--> &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.5.0&lt;/version> &lt;relativePath/> &lt;/parent> &lt;!--添加mybatis-plus相关依赖--> &lt;dependency> &lt;groupId>com.baomidou&lt;/groupId> &lt;artifactId>mybatis-plus-boot-starter&lt;/artifactId> &lt;version>3.3.2&lt;/version> &lt;/dependency> application.yml mybatis-plus: mapper-locations: classpath:&#x2F;mapper&#x2F;*.xml # 支持统配符 * 或者 ; 分割 typeEnumsPackage: com.wql.enums configuration: # 是否将sql打印到控制面板(该配置会将sql语句和查询的结果都打印到控制台) log-impl: org.apache.ibatis.logging.stdout.StdOutImpl global-config: db-config: logic-delete-field: delFlag # 全局逻辑删除的实体字段名(since 3.3.0,配置后可以忽略不配置步骤2) logic-delete-value: 0 # 逻辑已删除值(默认为 1) logic-not-delete-value: 1 # 逻辑未删除值(默认为 0) id-type: auto 属性说明： map-underscore-to-camel-case为true来开启驼峰功能，在mybatis-plus默认为开启状态 package com.baomidou.mybatisplus.core; &#x2F;** * replace default Configuration class * &lt;p&gt;Caratacus 2016&#x2F;9&#x2F;25 replace mapperRegistry&lt;&#x2F;p&gt; * * @author hubin * @since 2016-01-23 *&#x2F; public class MybatisConfiguration extends Configuration &#123; &#x2F;** * 初始化调用 *&#x2F; public MybatisConfiguration() &#123; super(); this.mapUnderscoreToCamelCase &#x3D; true; languageRegistry.setDefaultDriverClass(MybatisXMLLanguageDriver.class); &#125; db-column-underline为true来开启驼峰功能。只要设置db-column-underline与map-underscore-to-camel-case任意一个参数为true，实体类的字段都会自动转下划线的格式。 map-underscore-to-camel-case &gt; db-column-underline 为了歧义新版去掉 db-column-underline 动态数据源","categories":[{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://qinglei1989.github.io/tags/spring-boot/"}]},{"title":"spring-boot-tomcat","slug":"spring-boot-tomcat","date":"2022-10-03T16:08:43.000Z","updated":"2022-10-03T15:50:24.744Z","comments":true,"path":"2022/10/04/spring-boot-tomcat/","link":"","permalink":"https://qinglei1989.github.io/2022/10/04/spring-boot-tomcat/","excerpt":"最近在工作中做一个实时推送的需求（消息不需要持久化，允许少量丢失），便使用了Redis的发布订阅模式来开发。顺带温习了一下Redis的相关操作。","text":"最近在工作中做一个实时推送的需求（消息不需要持久化，允许少量丢失），便使用了Redis的发布订阅模式来开发。顺带温习了一下Redis的相关操作。 Springboot内置Tomcat配置参数调优 默认配置SpringBoot中如果使用内嵌Tomcat，那么内嵌Tomcat的默认配置在ServerProperties中。本文档以SpringBoot 2.5.0为例说明 包名 org.springframework.boot:spring-boot-autoconfigure:2.5.0 类 org.springframework.boot.autoconfigure.web.ServerProperties &#x2F;** * 最大的工作线程数，默认为200，只能最多有200个耗时（比如查数据库）操作同时进行，一般小型应用中，达不到200个并发耗时操作.（4核 * 8g内存，线程数800，一般是核数*200。操作系统做线程之间的切换调度是有系统开销的，所以不是越多越好。） *&#x2F; private int max &#x3D; 200; &#x2F;** * 最小工作线程数，默认为10，即初始化时会创建10个线程用于处理请求。 *&#x2F; private int minSpare &#x3D; 10; &#x2F;** * Tomcat在给定时间（同一时间）能接受的最大连接数。 *&#x2F; private int maxConnections &#x3D; 8192; &#x2F;** * 当前连接数超过maxConnections时，还能接受的连接的数量（排队的数量） *&#x2F; private int acceptCount &#x3D; 100; 内嵌Tomcat使用的默认协议为NIO，配置在TomcatServletWebServerFactory类中，如下： public class TomcatServletWebServerFactory extends AbstractServletWebServerFactory implements ConfigurableTomcatWebServerFactory, ResourceLoaderAware &#123; private static final Charset DEFAULT_CHARSET &#x3D; StandardCharsets.UTF_8; private static final Set&lt;Class&lt;?&gt;&gt; NO_CLASSES &#x3D; Collections.emptySet(); &#x2F;** * The class name of default protocol used.协议的默认配置 *&#x2F; public static final String DEFAULT_PROTOCOL &#x3D; &quot;org.apache.coyote.http11.Http11NioProtocol&quot;; private File baseDirectory; ........ &#125; 优化配置如下： server: tomcat: uri-encoding: UTF-8 #最大链接数 max-connections: 8192 #最大等待队列长度 accept-count: 500 threads: #最大线程数 max: 800 #最小线程数 min-spare: 100 connection-timeout: 30000 port: 8080 引用 https://www.jb51.net/article/214183.htm","categories":[{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://qinglei1989.github.io/tags/spring-boot/"}]},{"title":"spring-boot-webscoket","slug":"spring-boot-webscoket","date":"2022-08-16T16:37:17.000Z","updated":"2022-09-04T16:23:24.759Z","comments":true,"path":"2022/08/17/spring-boot-webscoket/","link":"","permalink":"https://qinglei1989.github.io/2022/08/17/spring-boot-webscoket/","excerpt":"SpringBoot读取properties（yml）文件中配置信息","text":"SpringBoot读取properties（yml）文件中配置信息 Springboot读取YML配置文件 @Value 该注解作用的作用是将我们配置文件的属性读出来，有@Value(“${}”)和@Value(“#{}”)两种方式 ① ${ property : default_value }② #{ obj.property? :default_value } 引用 https://mp.weixin.qq.com/s?__biz=MzU3MDAzNDg1MA==&amp;mid=2247494312&amp;idx=2&amp;sn=b3abfdb6b969b4630117087bc283c5d4&amp;chksm=fcf73565cb80bc732fd91eddaa48026fe04f54a0c69e6aadd64438026ba36928813a8012160a&amp;scene=178&amp;cur_album_id=1532834475389288449#rd https://docs.spring.io/spring-framework/docs/5.3.22/reference/html/web.html#websocket springboot整合websocket后运行测试类报错：javax.websocket.server.ServerContainer not availablespringboot项目添加websocket依赖后运行测试类报如下错误： https://www.cnblogs.com/yourblog/p/10369713.html","categories":[{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://qinglei1989.github.io/tags/spring-boot/"}]},{"title":"spring-cloud-openFeign","slug":"spring-cloud-openFeign","date":"2022-06-26T14:16:52.000Z","updated":"2023-01-15T16:00:22.749Z","comments":true,"path":"2022/06/26/spring-cloud-openFeign/","link":"","permalink":"https://qinglei1989.github.io/2022/06/26/spring-cloud-openFeign/","excerpt":"","text":"服务调用的组件OpenFeign介绍 服务调用历史 实现服务进程之间的调用方法有很多，在Feign之前常用如下： HttpClient提供高效的、最新的、功能丰富的支持 HTTP 协议的客户端编程工具包。 RestTemplate设计是为了Spring更好的请求并解析Restful风格的接口返回值而设计的，对HttpClient进行了封装以提高其易用性。 请求示例： 提供者接口： @Slf4j @RestController @RequestMapping(&quot;&#x2F;openfeign&#x2F;provider&quot;) public class OpenFeignProviderController &#123; @PostMapping(&quot;&#x2F;test&#x2F;&#123;id&#125;&quot;) public Order test(@PathVariable(&quot;id&quot;)Long id, @RequestParam(&quot;name&quot;) String name, @RequestParam(&quot;num&quot;) String num)&#123; return Order.builder() .id(id) .name(name) .num(num) .build(); &#125; &#125; HttpClient请求： @Slf4j @RestController @RequestMapping(&quot;&#x2F;http&#x2F;provider&quot;) public class HttpPostController &#123; @PostMapping(&quot;&#x2F;test&#x2F;&#123;id&#125;&quot;) public Order test(@PathVariable(&quot;id&quot;)Integer id) throws IOException &#123; &#x2F;&#x2F;发送远程的http请求的地址 String url &#x3D; &quot;http:&#x2F;&#x2F;localhost:9055&#x2F;openfeign&#x2F;provider&#x2F;test&#x2F;&quot; + id; &#x2F;&#x2F;创建HttpClient对象 CloseableHttpClient client &#x3D; HttpClients.createDefault(); &#x2F;&#x2F;创建HttpPost对象, 发送post请求 HttpPost method &#x3D; new HttpPost(url); &#x2F;&#x2F;封装发送到服务提供者的参数 NameValuePair name &#x3D; new BasicNameValuePair(&quot;name&quot;, &quot;蜂蜜&quot;); NameValuePair num &#x3D; new BasicNameValuePair(&quot;num&quot;, &quot;20&quot;); List&lt;NameValuePair&gt; params &#x3D; new ArrayList&lt;&gt;(); params.add(name); params.add(num); &#x2F;&#x2F;封装请求体数据 method.setEntity(new UrlEncodedFormEntity(params, &quot;UTF-8&quot;)); &#x2F;&#x2F;发送具体的http请求 HttpResponse response &#x3D; client.execute(method); &#x2F;&#x2F;获得服务提供者响应的具体数据 HttpEntity entity &#x3D; response.getEntity(); &#x2F;&#x2F;获得http的响应体 InputStream is &#x3D; entity.getContent(); int len &#x3D; 0; char[] buf &#x3D; new char[1024]; &#x2F;&#x2F;使用字符流读 InputStreamReader reader &#x3D; new InputStreamReader(is); StringBuffer sb &#x3D; new StringBuffer(); while((len &#x3D; reader.read(buf)) !&#x3D; -1)&#123; sb.append(String.valueOf(buf, 0, len)); &#125; &#x2F;&#x2F;转成对象 ObjectMapper mapper &#x3D; new ObjectMapper(); Order order &#x3D; mapper.readValue(sb.toString(), Order.class); System.out.println(order); return order; &#125; &#125; RestTemplate请求： @Slf4j @RestController @RequestMapping(&quot;&#x2F;rest_template&#x2F;consumer&quot;) public class RestTemplateController &#123; @Resource private RestTemplate restTemplate; @PostMapping(&quot;&#x2F;test&#x2F;&#123;id&#125;&quot;) public Order test(@PathVariable(&quot;id&quot;)Integer id) throws IOException &#123; &#x2F;&#x2F;发送远程http请求的url String url &#x3D; &quot;http:&#x2F;&#x2F;localhost:9055&#x2F;openfeign&#x2F;provider&#x2F;test&#x2F;&quot; + id; &#x2F;&#x2F;发送到远程服务的参数 MultiValueMap&lt;String, Object&gt; params &#x3D; new LinkedMultiValueMap&lt;&gt;(); params.add(&quot;name&quot;, &quot;蜂蜜&quot;); params.add(&quot;num&quot;, &quot;20&quot;); &#x2F;&#x2F;通过RestTemplate对象发送post请求 Order order &#x3D; restTemplate.postForObject(url, params, Order.class); return order; &#125; &#125; RestTemplate提供的delete()和put()方法都没有返回值。 RestTemplate的 delete 方法并不支持传入请求体（Request Body） 实际如果需要返回值的话需要使用exchange()方法来实现。 使用exchange()来获取返回值示例代理 @Test public void queryById() &#123; StringBuffer url &#x3D; new StringBuffer(baseUrl).append(&quot;api&#x2F;v1&#x2F;user&#x2F;role&quot;); JSONObject jsonObject &#x3D; new JSONObject(); HttpEntity httpEntity &#x3D; new HttpEntity(jsonObject, null); ResponseEntity&lt;String&gt; response &#x3D; restTemplate.exchange(url.toString(), HttpMethod.PUT, httpEntity, String.class); String result &#x3D; response.getBody(); log.info(&quot;result &#123;&#125;&quot;, result); &#125; RestTemplate的底层实现仍然是HttpClient或HttpUrlConnection或OkHttp（三者可选），只是对它进行了封装，从而降低编码复杂度。 但是不论是HttpClient还是RestTemplate也存在一定的缺点： 请求的URL分散，不好维护 所有的数据调用和转换(响应信息需要重新反序列化)都是由用户来完成的，我们可不想直接访问REST接口 所以有没有更好的方案，让我们可以像调用service那样来直接调用其他服务，直接把响应结果封装到一个对象里边呢？下面就引出了我们今天的主题Feign。 openFeign是什么 实际上在OpenFeign出现之前，有一个阶段，开发者经常使用的是Netflix Feign。二者在使用方式、版本集成方面还是有一些差异性。本篇只做一个简单的说明。 Feign旨在使得Java Http客户端变得更容易。Feign集成了Ribbon、RestTemplate实现了负载均衡的执行Http调用，只不过对原有的方式（Ribbon+RestTemplate）进行了封装，开发者不必手动使用RestTemplate调服务，而是定义一个接口，在这个接口中标注一个注解即可完成服务调用，这样更加符合面向接口编程的宗旨，简化了开发。 Maven坐标差异 &lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;&#x2F;groupId&gt; &lt;artifactId&gt;feign-core&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;&#x2F;groupId&gt; &lt;artifactId&gt;feign-core&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; Netflix Feign还是Open Feign &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; 简单来说： spring-cloud-starter-openfeign是为Spring Cloud2.x准备的，只不过维持了一段时间的对1.x的兼容。 而spring-cloud-starter-feign是专为Spring Cloud1.x服务。 下图中注释掉的部分是Feign的注解书写方式，没有注释掉的注解是Spring MVC的注解方式。 官方地址：https://docs.spring.io/spring-cloud-openfeign/docs/2.2.10.BUILD-SNAPSHOT/reference/html 官方地址：https://github.com/OpenFeign/feign 我们为什么要使用Feign Feign 解决了什么问题？ Feign 封装 HTTP 调用流程，面向接口编程。 Feign 本身很简单，但做了大量的适配工作，这也是这个框架存在的意义 openFeign调用演示 添加maven依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; 添加注解@EnableFeignClients开启openFeign功能 @SpringBootApplication @EnableDiscoveryClient @EnableFeignClients(defaultConfiguration &#x3D; FeignClientConfig.class, basePackages &#x3D; &quot;com.rrc.authority.core.feign&quot;) public class OpenFeignConsumer9006Application &#123; public static void main(String[] args) &#123; SpringApplication.run(OpenFeignConsumer9006Application.class, args); &#125; &#125; 新建一个openFeign接口，使用@FeignClient注解标注，如下 @FeignClient(value &#x3D; &quot;openFeign-provider&quot;) public interface OpenFeignService &#123; @GetMapping(&quot;&#x2F;openfeign&#x2F;provider&#x2F;test&#x2F;&#123;id&#125;&quot;) String get(@PathVariable(&quot;id&quot;)Integer id); &#125; 人人车FeignClient接口 @Component @FeignClient(name &#x3D; &quot;auth-service&quot;, url &#x3D; &quot;$&#123;auth-service.url&#125;&quot; ) public interface AuthServiceFeignClient &#123; &#x2F;** * 查询审批待办列表 * @param userId * @return *&#x2F; @RequestLine(&quot;GET &#x2F;users&#x2F;&#123;user_id&#125;?filter&#x3D;user_id;name;username&quot;) @Headers(&quot;Content-Type: application&#x2F;json&quot;) AuthUserDto queryAuthUserById(@Param(&quot;user_id&quot;) Integer userId); &#125; OpenFeign的核心设计原理 基于面向接口的动态代理方式生成实现类 根据Contract协议规则，解析接口类的注解信息，解析成内部表现 基于 RequestBean，动态生成Request 使用Encoder 将Bean转换成 Http报文正文（消息解析和转码逻辑） 拦截器负责对请求和返回进行装饰处理 日志记录 发送HTTP请求 Feign的大体机制 通过在启动类上标记 @EnableFeignClients 注解来开启feign的功能，服务启动后会扫描 @FeignClient 注解标记的接口，然后根据扫描的注解信息为每个接口类生成feign客户端请求，同时解析接口方法中的Spring MVC的相关注解，通过专门的注解解析器识别这些注解信息，以便后面可以正确的组装请求参数，使用 Ribbon 和 Eureka 获取到请求服务的真实地址等信息，最后使用 http 相关组件进行执行调用。其大致流程图如下： 代码入口@EnableFeignClients注解 在EnableFeignClients 注解类中有一个 @Import(FeignClientsRegistrar.class)的配置 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented @Import(FeignClientsRegistrar.class) public @interface EnableFeignClients &#123; String[] value() default &#123;&#125;; String[] basePackages() default &#123;&#125;; Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;; Class&lt;?&gt;[] defaultConfiguration() default &#123;&#125;; Class&lt;?&gt;[] clients() default &#123;&#125;; &#125; 日常代码写法： @EnableFeignClients(defaultConfiguration &#x3D; FeignClientConfig.class, basePackages &#x3D; &quot;com.rrc.authority.core.feign&quot;) 核心类FeignClientsRegistrar 追踪代码进入到FeignClientsRegistrar类中，会发现FeignClientsRegistrar 类实现了ImportBeanDefinitionRegistrar接口，因此项目启动时会调用registerBeanDefinitions方法，该方法中会扫描 EnableFeignClients 和 FeignClient 注解信息并设置相关信息。 &#x2F;** * spring boot 启动时会自动调用 ImportBeanDefinitionRegistrar 入口方法 *&#x2F; @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; &#x2F;&#x2F; 读取 @EnableFeignClients 注解中信息 5个属性的值 注册了一个FeignClientSpecification类 registerDefaultConfiguration(metadata, registry); &#x2F;&#x2F; 扫描所有@FeignClient注解的类 解析属性，最后注册到IoC容器中 registerFeignClients(metadata, registry); &#125; registerDefaultConfiguration方法 在registerDefaultConfiguration()方法中会读取@EnableFeignClients注解信息，然后将这些信息注册到一个 BeanDefinitionRegistry 里面去；之后feign的一些默认配置将通过这里注册的信息中取获取。 registerFeignClients方法 registerFeignClients()方法会扫描相关包路径（如果EnableFeignClients的basePackages没有配置，默认会直接使用启动类所在的包路径）下所有的@FeiginClient注解的类 然后根据@FeiginClient注解信息向BeanDefinitionRegistry里面注册bean，注意这里设置的bean名称生成规则是使用服务名+FeignClientSpecification.class.getSimpleName()，因此如果对一个服务写多个接口类会发生bean名称重复导致注册失败。所以需要增加一个 allow-bean-definition-overriding: true 的配置。 最后会调用 registerFeignClient() 方法注册feign客户端，这里的bean名称的为当前接口类的类路径。 registerFeignClient()方法中在构建bean的时候，实际构建的是FeignClientFactoryBean。 FeignClientFactoryBean 注入到容器的是一个FactoryBean， 则真正生成Bean 是FactoryBean的getObject 方法，而且是FactoryBean的创建是在IoC容器过程中创建的。SpringIoC创建完对象会先反射创建对象，然后属性注入，属性注入过程中会根据BeanDefinition对象的propertyValues 给反射的对象进行属性注入。 FactoryBean.getObject方法生成对象会在第一次使用bean时创建, 而不是在容器启动过程中就创建(也就是如果只声明不使用FactoryBean生成的对象不会进行创建)。 我们需要的target对象是一个接口，所以是需要用到JDK的动态代理来生成代理对象然后服务于业务。 class FeignClientFactoryBean implements FactoryBean&lt;Object&gt;, InitializingBean, ApplicationContextAware &#123; @Override public Object getObject() throws Exception &#123; return getTarget(); &#125; &#x2F;** * @param &lt;T&gt; the target type of the Feign client * @return a &#123;@link Feign&#125; client created with the specified data and the context * information *&#x2F; &lt;T&gt; T getTarget() &#123; FeignContext context &#x3D; this.applicationContext.getBean(FeignContext.class); Feign.Builder builder &#x3D; feign(context); if (!StringUtils.hasText(this.url)) &#123; if (!this.name.startsWith(&quot;http&quot;)) &#123; this.url &#x3D; &quot;http:&#x2F;&#x2F;&quot; + this.name; &#125; else &#123; this.url &#x3D; this.name; &#125; this.url +&#x3D; cleanPath(); return (T) loadBalance(builder, context, new HardCodedTarget&lt;&gt;(this.type, this.name, this.url)); &#125; if (StringUtils.hasText(this.url) &amp;&amp; !this.url.startsWith(&quot;http&quot;)) &#123; this.url &#x3D; &quot;http:&#x2F;&#x2F;&quot; + this.url; &#125; String url &#x3D; this.url + cleanPath(); Client client &#x3D; getOptional(context, Client.class); if (client !&#x3D; null) &#123; if (client instanceof LoadBalancerFeignClient) &#123; &#x2F;&#x2F; not load balancing because we have a url, &#x2F;&#x2F; but ribbon is on the classpath, so unwrap client &#x3D; ((LoadBalancerFeignClient) client).getDelegate(); &#125; if (client instanceof FeignBlockingLoadBalancerClient) &#123; &#x2F;&#x2F; not load balancing because we have a url, &#x2F;&#x2F; but Spring Cloud LoadBalancer is on the classpath, so unwrap client &#x3D; ((FeignBlockingLoadBalancerClient) client).getDelegate(); &#125; builder.client(client); &#125; Targeter targeter &#x3D; get(context, Targeter.class); return (T) targeter.target(this, builder, context, new HardCodedTarget&lt;&gt;(this.type, this.name, url)); &#125; ReflectiveFeign public &lt;T&gt; T newInstance(Target&lt;T&gt; target) &#123; &#x2F;&#x2F;根据接口类和Contract协议解析方式，解析接口类上的方法和注解，转换成内部的MethodHandler处理方式 Map&lt;String, MethodHandler&gt; nameToHandler &#x3D; targetToHandlersByName.apply(target); Map&lt;Method, MethodHandler&gt; methodToHandler &#x3D; new LinkedHashMap&lt;Method, MethodHandler&gt;(); List&lt;DefaultMethodHandler&gt; defaultMethodHandlers &#x3D; new LinkedList&lt;DefaultMethodHandler&gt;(); for (Method method : target.type().getMethods()) &#123; if (method.getDeclaringClass() &#x3D;&#x3D; Object.class) &#123; continue; &#125; else if (Util.isDefault(method)) &#123; DefaultMethodHandler handler &#x3D; new DefaultMethodHandler(method); defaultMethodHandlers.add(handler); methodToHandler.put(method, handler); &#125; else &#123; methodToHandler.put(method, nameToHandler.get(Feign.configKey(target.type(), method))); &#125; &#125; &#x2F;&#x2F; 基于Proxy.newProxyInstance 为接口类创建动态实现，将所有的请求转换给InvocationHandler 处理。 InvocationHandler handler &#x3D; factory.create(target, methodToHandler); T proxy &#x3D; (T) Proxy.newProxyInstance(target.type().getClassLoader(), new Class&lt;?&gt;[] &#123;target.type()&#125;, handler); for (DefaultMethodHandler defaultMethodHandler : defaultMethodHandlers) &#123; defaultMethodHandler.bindTo(proxy); &#125; return proxy; &#125; 对应的FeignClient源码为： @FeignClient(value &#x3D; &quot;openFeign-provider&quot;, configuration &#x3D; OpenFeignConfig.class) public interface OpenFeignService &#123; @GetMapping(&quot;&#x2F;openfeign&#x2F;provider&#x2F;test&#x2F;&#123;id&#125;&quot;) String get(@PathVariable(&quot;id&quot;)Integer id); &#x2F;** * 参数默认是@RequestBody标注的，如果通过POJO表单传参的，使用@SpringQueryMap标注 *&#x2F; @PostMapping(&quot;&#x2F;openfeign&#x2F;provider&#x2F;order1&quot;) Order createOrder1(@SpringQueryMap Order order); &#x2F;** * 参数默认是@RequestBody标注的，这里的@RequestBody可以不填 * 方法名称任意 *&#x2F; @PostMapping(&quot;&#x2F;openfeign&#x2F;provider&#x2F;order2&quot;) Order createOrder2(@RequestBody Order order); &#x2F;** * 必须要@RequestParam注解标注，且value属性必须填上参数名 * 方法参数名可以任意，但是@RequestParam注解中的value属性必须和provider中的参数名相同 *&#x2F; @PostMapping(&quot;&#x2F;openfeign&#x2F;provider&#x2F;test2&quot;) String test(@RequestParam(&quot;id&quot;) String arg1, @RequestParam(&quot;name&quot;) String arg2); @PostMapping(&quot;&#x2F;openfeign&#x2F;provider&#x2F;order3&quot;) String batchOrder(List&lt;Order&gt; orders); @PostMapping(&quot;&#x2F;openfeign&#x2F;provider&#x2F;header&quot;) String header(); &#125; SynchronousMethodHandler（同步方法调用处理器） final class SynchronousMethodHandler implements MethodHandler &#123; private static final long MAX_RESPONSE_BUFFER_SIZE &#x3D; 8192L; &#x2F;&#x2F; 方法元信息 private final MethodMetadata metadata; &#x2F;&#x2F; 目标 也就是最终真正构建Http请求Request的实例 一般为HardCodedTarget private final Target&lt;?&gt; target; &#x2F;&#x2F; 负责最终请求的发送 -&gt; 默认传进来的是基于JDK源生的，效率很低，不建议直接使用 private final Client client; &#x2F;&#x2F; 负责重试 --&gt;默认传进来的是Default，是有重试机制的哦，生产上使用请务必注意 private final Retryer retryer; &#x2F;&#x2F; 请求拦截器，它会在target.apply(template); 也就是模版 -&gt; 请求的转换之前完成拦截 &#x2F;&#x2F; 说明：并不是发送请求之前那一刻哦，请务必注意啦 &#x2F;&#x2F; 它的作用只能是对请求模版做定制，而不能再对Request做定制了 &#x2F;&#x2F; 内置仅有一个实现：BasicAuthRequestInterceptor 用于鉴权 private final List&lt;RequestInterceptor&gt; requestInterceptors; private final Logger logger; &#x2F;&#x2F; 若你想在控制台看到feign的请求日志，改变此日志级别为info吧（因为一般只有info才会输出到日志文件） private final Level logLevel; private final feign.RequestTemplate.Factory buildTemplateFromArgs; &#x2F;&#x2F; 请求参数：比如链接超时时间、请求超时时间等 private final Options options; private final Decoder decoder; &#x2F;&#x2F; 发生错误&#x2F;异常时的解码器 private final ErrorDecoder errorDecoder; &#x2F;&#x2F; 是否解码404状态码？默认是不解码的 private final boolean decode404; public Object invoke(Object[] argv) throws Throwable &#123; &#x2F;&#x2F; 根据方法入参，结合工厂构建出一个请求模版 RequestTemplate template &#x3D; this.buildTemplateFromArgs.create(argv); Retryer retryer &#x3D; this.retryer.clone(); while(true) &#123; try &#123; return this.executeAndDecode(template); &#125; catch (RetryableException var5) &#123; &#x2F;&#x2F; 该逻辑是：判断是否需要重试如果不重试了，该异常会继续抛出 retryer.continueOrPropagate(var5); if (this.logLevel !&#x3D; Level.NONE) &#123; this.logger.logRetry(this.metadata.configKey(), this.logLevel); &#125; &#125; &#125; &#125; Feign在默认情况下使用的是JDK原生的URLConnection发送HTTP请求，没有连接池，但是对每个地址会保持一个长连接，即利用HTTP的persistence connection。 在生产环境中，通常不使用默认的http client，通常有如下两种选择： 使用ApacheHttpClient 使用OkHttp 在openFeign接口服务的pom文件添加如下依赖： &lt;!--使用Apache HttpClient替换Feign原生httpclient--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;&#x2F;groupId&gt; &lt;artifactId&gt;httpclient&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;&#x2F;groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; @ConditionalOnClass(ApacheHttpClient.class)，必须要有ApacheHttpClient这个类才会生效，并且feign.httpclient.enabled这个配置要设置为true。 RequestInterceptor 令牌在openFeign调用过程中是不能自动中继的，因此必须手动的将令牌信息传递下去。 @Component public class FeignRequestInterceptor implements RequestInterceptor &#123; @Override public void apply(RequestTemplate template) &#123; &#x2F;&#x2F;从RequestContextHolder中获取HttpServletRequest HttpServletRequest httpServletRequest &#x3D; RequestContextUtils.getRequest(); &#x2F;&#x2F;获取RequestContextHolder中的信息 Map&lt;String, String&gt; headers &#x3D; getHeaders(httpServletRequest); &#x2F;&#x2F;放入feign的RequestTemplate中 for (Map.Entry&lt;String, String&gt; entry : headers.entrySet()) &#123; template.header(entry.getKey(), entry.getValue()); &#125; &#125; &#x2F;** * 获取原请求头 *&#x2F; private Map&lt;String, String&gt; getHeaders(HttpServletRequest request) &#123; Map&lt;String, String&gt; map &#x3D; new LinkedHashMap&lt;&gt;(); Enumeration&lt;String&gt; enumeration &#x3D; request.getHeaderNames(); if (enumeration !&#x3D; null) &#123; while (enumeration.hasMoreElements()) &#123; String key &#x3D; enumeration.nextElement(); String value &#x3D; request.getHeader(key); map.put(key, value); &#125; &#125; return map; &#125; &#125; 引用 Spring Cloud Feign原理详解 Spring Cloud 进阶","categories":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/categories/spring-cloud/"}],"tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/tags/spring-cloud/"}]},{"title":"spring-cloud-alibaba-nocas","slug":"spring-cloud-alibaba-nocas","date":"2022-06-12T15:35:16.000Z","updated":"2022-06-14T17:22:25.934Z","comments":true,"path":"2022/06/12/spring-cloud-alibaba-nocas/","link":"","permalink":"https://qinglei1989.github.io/2022/06/12/spring-cloud-alibaba-nocas/","excerpt":"","text":"Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 Nacos 前言 从上图不难看出阿里巴巴的野心，一个Nacos干掉了Spring Cloud的三大组件，分别是注册中心Eureka、服务配置Config，服务总线Bus。 启动Nocas Nocas下载地址：https://github.com/alibaba/nacos/tags 下载完成之后直接解压即可，从它的目录结构和文件名称一看这就是一个Spring Boot 项目。 进入/bin目录，有两个脚本，如下： startup.cmd：windows平台的启动脚本 startup.sh：Linux平台的启动脚本 startup.cmd中配置的启动参数 # standalone代表单机模式运行 if %MODE% &#x3D;&#x3D; &quot;standalone&quot; ( set &quot;JAVA_OPT&#x3D;%JAVA_OPT% -Xms512m -Xmx512m -Xmn256m&quot; set &quot;JAVA_OPT&#x3D;%JAVA_OPT% -Dnacos.standalone&#x3D;true&quot; ) else ( set &quot;JAVA_OPT&#x3D;%JAVA_OPT% -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize&#x3D;128m -XX:MaxMetaspaceSize&#x3D;320m&quot; set &quot;JAVA_OPT&#x3D;%JAVA_OPT% -XX:-OmitStackTraceInFastThrow XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;%BASE_DIR%\\logs\\java_heapdump.hprof&quot; set &quot;JAVA_OPT&#x3D;%JAVA_OPT% -XX:-UseLargePages&quot; ) 由于作者本地是windows，直接双击startup.cmd启动项目，出现以下界面则启动完成： ,--. ,--.&#39;| ,--,: : | Nacos 1.2.1 ,&#96;--.&#39;&#96;| &#39; : ,---. Running in stand alone mode, All function modules | : : | | &#39; ,&#39;\\ .--.--. Port: 8848 : | \\ | : ,--.--. ,---. &#x2F; &#x2F; | &#x2F; &#x2F; &#39; Pid: 872 | : &#39; &#39;; | &#x2F; \\ &#x2F; \\. ; ,. :| : &#x2F;&#96;.&#x2F; Console: http:&#x2F;&#x2F;192.168.56.1:8848&#x2F;nacos&#x2F;index.html &#39; &#39; ;. ;.--. .-. | &#x2F; &#x2F; &#39;&#39; | |: :| : ;_ | | | \\ | \\__\\&#x2F;: . .. &#39; &#x2F; &#39; | .; : \\ \\ &#96;. https:&#x2F;&#x2F;nacos.io &#39; : | ; .&#39; ,&quot; .--.; |&#39; ; :__| : | &#96;----. \\ | | &#39;&#96;--&#39; &#x2F; &#x2F; ,. |&#39; | &#39;.&#39;|\\ \\ &#x2F; &#x2F; &#x2F;&#96;--&#39; &#x2F; &#39; : | ; : .&#39; \\ : : &#96;----&#39; &#39;--&#39;. &#x2F; ; |.&#39; | , .-.&#x2F;\\ \\ &#x2F; &#96;--&#39;---&#39; &#39;---&#39; &#96;--&#96;---&#39; &#96;----&#39; 2022-06-13 00:48:19,027 INFO Bean &#39;org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration&#39; of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$cbd40a56] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-06-13 00:48:19,113 INFO Bean &#39;objectPostProcessor&#39; of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-06-13 00:48:19,115 INFO Bean &#39;org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@1a245833&#39; of type [org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-06-13 00:48:19,118 INFO Bean &#39;org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration&#39; of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$f0a8ad08] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-06-13 00:48:19,123 INFO Bean &#39;methodSecurityMetadataSource&#39; of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-06-13 00:48:20,160 INFO Tomcat initialized with port(s): 8848 (http) 2022-06-13 00:48:20,303 INFO Root WebApplicationContext: initialization completed in 3139 ms 2022-06-13 00:48:24,089 INFO Initializing ExecutorService &#39;applicationTaskExecutor&#39; 2022-06-13 00:48:24,308 INFO Adding welcome page: class path resource [static&#x2F;index.html] 2022-06-13 00:48:24,643 INFO Creating filter chain: Ant [pattern&#x3D;&#39;&#x2F;**&#39;], [] 2022-06-13 00:48:24,683 INFO Creating filter chain: any request, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@7a8fa663, org.springframework.security.web.context.SecurityContextPersistenceFilter@f0e995e, org.springframework.security.web.header.HeaderWriterFilter@4f2c9ba6, org.springframework.security.web.csrf.CsrfFilter@2bef51f2, org.springframework.security.web.authentication.logout.LogoutFilter@50fe837a, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@73db4768, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@150ab4ed, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@5ce33a58, org.springframework.security.web.session.SessionManagementFilter@53f48368, org.springframework.security.web.access.ExceptionTranslationFilter@30f5a68a] 2022-06-13 00:48:24,789 INFO Exposing 2 endpoint(s) beneath base path &#39;&#x2F;actuator&#39; 2022-06-13 00:48:24,822 INFO Initializing ExecutorService &#39;taskScheduler&#39; 2022-06-13 00:48:24,939 INFO Tomcat started on port(s): 8848 (http) with context path &#39;&#x2F;nacos&#39; 2022-06-13 00:48:24,950 INFO Nacos logs files: E:\\Springcloud\\nacos\\logs\\ 2022-06-13 00:48:24,950 INFO Nacos conf files: E:\\Springcloud\\nacos\\conf\\ 2022-06-13 00:48:24,950 INFO Nacos data files: E:\\Springcloud\\nacos\\data\\ 2022-06-13 00:48:24,951 INFO Nacos started successfully in stand alone mode. 2022-06-13 00:48:25,078 INFO Initializing Servlet &#39;dispatcherServlet&#39; 2022-06-13 00:48:25,092 INFO Completed initialization in 14 ms 在浏览器输入http://localhost:8848/nacos进入Nacos的登录界面。 用户名：nacos；密码：nacos 登录成功的界面如下： 服务注册与发现 微服务的服务注册和发现相信都用过Eureka，要自己本地构建一个Eureka微服务，但是整合了Alibaba的Nacos则不用那么复杂，直接启动Alibaba提供的Nacos服务即可，这样让程序员把全部精力放在业务上，下面是一个简单的架构图 参照上面架构图，分别创建了两个模块，分别是nacos-provider(服务提供者)、nacos-consumer(服务消费者)，职责如下： nacos-provider：注册进入nacos-server，对外暴露服务 nacos-consumer：注册进入nacos-server，调用nacos-provider的服务 nacos-provider 添加Maven依赖 nacos-consumer 文档 五十五张图告诉你微服务的灵魂摆渡者Nacos究竟有多强？ 对于初学者当然是官方文档了，下面作者列出了Nacos相关的官方文档： https://nacos.io/zh-cn/docs/what-is-nacos.html（中英文兼备） https://spring-cloud-alibaba-group.github.io/github-pages/hoxton/en-us/index.html（英文） https://github.com/alibaba/nacos（Nacos项目仓库） 问题 @RefreshScope原理","categories":[{"name":"spring-cloud-alibaba","slug":"spring-cloud-alibaba","permalink":"https://qinglei1989.github.io/categories/spring-cloud-alibaba/"}],"tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/tags/spring-cloud/"}]},{"title":"服务发现技术选型","slug":"spring-cloud-registry","date":"2022-06-05T15:37:21.000Z","updated":"2022-06-05T17:20:16.848Z","comments":true,"path":"2022/06/05/spring-cloud-registry/","link":"","permalink":"https://qinglei1989.github.io/2022/06/05/spring-cloud-registry/","excerpt":"服务容错保护Spring Cloud Hystrix实现了断路器、线程隔离等一系列服务保护功能。它也是基于Netflix 的开源框架 Hystrix实现的，该框架的目标在于通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备服务降级、服务熔断、线程和信号隔离、请求缓存、请求合并以及服务监控等强大功能。","text":"服务容错保护Spring Cloud Hystrix实现了断路器、线程隔离等一系列服务保护功能。它也是基于Netflix 的开源框架 Hystrix实现的，该框架的目标在于通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备服务降级、服务熔断、线程和信号隔离、请求缓存、请求合并以及服务监控等强大功能。 Spring Cloud Hystrix 服务发现技术选型 分布式之CAP原则详解 分布式系统有个重要的CAP原则 一致性（Consistency）：数据一致性，即数据在存在多副本的情况下，可能由于网络、机器故障、软件系统等问题导致数据写入部分副本成功，部分副本失败，进而造成副本之间数据不一致，存在冲突。满足一致性则要求对数据的更新操作成功之后，多副本的数据保持一致。 可用性（Availability）：在任何时候客户端对集群进行读写操作时，请求能够正常响应，即在一定的延时内完成。 分区容错性（Partition tolerance）：发生通信故障的时候，整个集群被分割为多个无法相互通信的分区时，集群仍然可用。 对于分布式系统来说，一般网络条件相对不可控，出现网络分区是不可避免的，因此系统必须具备分区容忍性。在这个前提下分布式系统的设计则在AP及CP之间进行选择。不过不能理解为CAP三者之间必须三选二，它们三者之间不是对等和可以相互替换的。在分布式系统领域，P是一个客观存在的事实，不可绕过，所以P与AC之间不是对等关系。 对于ZooKeeper，它是”C”P的，之所以C加引号是因为ZooKeeper默认并不是严格的强一致，比如客户端A提交一个写操作，ZooKeeper在过半数节点操作成功之后就返回，此时假设客户端B的读操作请求到的是A写操作尚未同步到的节点，那么读取到的就不是客户端A写操作成功之后的数据。如果在使用的时候需要强一致，则需要在读取数据的时候先执行一下sync操作，即与leader节点先同步下数据，这样才能保证强一致。在极端的情况下发生网络分区的时候，如果leader节点不在non-quorum分区，那么对这个分区上节点的读写请求将会报错，无法满足Availability特性。Eureka是在部署在AWS的背景下设计的，其设计者认为，在云端，特别是在大规模部署的情况下，失败是不可避免的，可能因为Eureka自身部署失败，注册的服务不可用，或者由于网络分区导致服务不可用，因此不能回避这个问题。要拥抱这个问题，就需要Eureka 在","categories":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/categories/spring-cloud/"}],"tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/tags/spring-cloud/"}]},{"title":"spring-boot-starter","slug":"spring-boot-async","date":"2022-06-03T16:08:43.000Z","updated":"2022-09-04T18:11:44.421Z","comments":true,"path":"2022/06/04/spring-boot-async/","link":"","permalink":"https://qinglei1989.github.io/2022/06/04/spring-boot-async/","excerpt":"","text":"http://www.45fan.com/article.php?aid=1CX5Merhoy2AMVh6 https://zhuanlan.zhihu.com/p/346086161 引用 徒手撸一个Spring Boot中的starter，解密自动化配置 天天在用SpringBoot，手撸一个的Starter试试！ 只需4步，自己搞个 Spring Boot Starter ！ 如何使用SpringBoot封装自己的Starter SpringBoot 系列三 : SpringBoot 自定义 Starter SpringBoot：认认真真梳理一遍自动装配原理 SpringBoot四大核心组件，你知道几个？","categories":[{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://qinglei1989.github.io/tags/spring-boot/"}]},{"title":"spring-boot-starter","slug":"spring-boot-starter","date":"2022-06-03T16:08:43.000Z","updated":"2023-01-09T16:13:57.245Z","comments":true,"path":"2022/06/04/spring-boot-starter/","link":"","permalink":"https://qinglei1989.github.io/2022/06/04/spring-boot-starter/","excerpt":"Spring Boot的出现，得益于“习惯优于配置”的理念，没有繁琐的配置、难以集成的内容（大多数流行第三方技术都被集成），这是基于Spring 4.x提供的按条件配置Bean的能力。","text":"Spring Boot的出现，得益于“习惯优于配置”的理念，没有繁琐的配置、难以集成的内容（大多数流行第三方技术都被集成），这是基于Spring 4.x提供的按条件配置Bean的能力。 Springboot自动装配 命名规范 Srping官方命名格式为：spring-boot-starter-{name} 非Spring官方建议命名格式：{name}-spring-boot-starter Spring Boot的配置文件 Spring Boot有一个全局配置文件：application.properties或application.yml。 常用属性配置 工作原理剖析 Spring Boot关于自动配置的源码在spring-boot-autoconfigure-x.x.x.x.jar中： Spring Boot的启动类上有一个@SpringBootApplication注解，这个注解是Spring Boot项目必不可少的注解。那么自动配置原理一定和这个注解有着千丝万缕的联系！ @EnableAutoConfiguration @SpringBootApplication是一个复合注解或派生注解，在@SpringBootApplication中有一个注解@EnableAutoConfiguration，翻译成人话就是开启自动配置，其定义如下： 而这个注解也是一个派生注解，其中的关键功能由@Import提供，其导入的AutoConfigurationImportSelector的selectImports()方法通过SpringFactoriesLoader.loadFactoryNames()扫描所有具有META-INF/spring.factories 的jar包。spring-boot-autoconfigure-x.x.x.x.jar里就有一个这样的spring.factories文件。 这个spring.factories文件也是一组一组的key=value的形式，其中一个key是EnableAutoConfiguration类的全类名，而它的value是一个xxxxAutoConfiguration的类名的列表，这些类名以逗号分隔，如下图所示： 这个@EnableAutoConfiguration注解通过@SpringBootApplication被间接的标记在了Spring Boot的启动类上。在SpringApplication.run(...)的内部就会执行selectImports()方法，找到所有JavaConfig自动配置类的全限定名对应的class，然后将所有自动配置类加载到Spring容器中。 自动配置生效 每一个XxxxAutoConfiguration自动配置类都是在某些条件之下才会生效的，这些条件的限制在Spring Boot中以注解的形式体现，常见的条件注解有如下几项： @ConditionalOnBean：当容器里有指定的bean的条件下。 @ConditionalOnMissingBean：当容器里不存在指定bean的条件下。 @ConditionalOnClass：当类路径下有指定类的条件下。 @ConditionalOnMissingClass：当类路径下不存在指定类的条件下。 @ConditionalOnProperty：指定的属性是否有指定的值，比如@ConditionalOnProperties(prefix=”xxx.xxx”, value=”enable”, matchIfMissing=true)，代表当xxx.xxx为enable时条件的布尔值为true，如果没有设置的情况下也为true。 以ServletWebServerFactoryAutoConfiguration配置类为例，解释一下全局配置文件中的属性如何生效，比如：server.port=8081，是如何生效的（当然不配置也会有默认值，这个默认值来自于org.apache.catalina.startup.Tomcat）。 在ServletWebServerFactoryAutoConfiguration类上，有一个@EnableConfigurationProperties注解：开启配置属性，而它后面的参数是一个ServerProperties类，这就是习惯优于配置的最终落地点。 在这个类上，我们看到了一个非常熟悉的注解：@ConfigurationProperties，它的作用就是从配置文件中绑定属性到对应的bean上，而@EnableConfigurationProperties负责导入这个已经绑定了属性的bean到spring容器中（见上面截图）。那么所有其他的和这个类相关的属性都可以在全局配置文件中定义，也就是说，真正“限制”我们可以在全局配置文件中配置哪些属性的类就是这些XxxxProperties类，它与配置文件中定义的prefix关键字开头的一组属性是唯一对应的。 至此，我们大致可以了解。在全局配置的属性如：server.port等，通过@ConfigurationProperties注解，绑定到对应的XxxxProperties配置实体类上封装为一个bean，然后再通过@EnableConfigurationProperties注解导入到Spring容器中。 而诸多的XxxxAutoConfiguration自动配置类，就是Spring容器的JavaConfig形式，作用就是为Spring 容器导入bean，而所有导入的bean所需要的属性都通过xxxxProperties的bean来获得。 可能到目前为止还是有所疑惑，但面试的时候，其实远远不需要回答的这么具体，你只需要这样回答： Spring Boot启动的时候会通过@EnableAutoConfiguration注解找到META-INF/spring.factories配置文件中的所有自动配置类，并对其进行加载，而这些自动配置类都是以AutoConfiguration结尾来命名的，它实际上就是一个JavaConfig形式的Spring容器配置类，它能通过以Properties结尾命名的类中取得在全局配置文件中配置的属性如：server.port，而XxxxProperties类是通过@ConfigurationProperties注解与全局配置文件中对应的属性进行绑定的。 开发示例 POM引入依赖 &lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt; &lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt; &lt;version&gt;2.5.13&lt;&#x2F;version&gt; &lt;relativePath&#x2F;&gt; &lt;!-- lookup parent from repository --&gt; &lt;&#x2F;parent&gt; &lt;groupId&gt;com.rrc&lt;&#x2F;groupId&gt; &lt;artifactId&gt;rrc-log-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;&#x2F;version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;&#x2F;project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;8&lt;&#x2F;maven.compiler.source&gt; &lt;maven.compiler.target&gt;8&lt;&#x2F;maven.compiler.target&gt; &lt;&#x2F;properties&gt; &lt;dependencies&gt; &lt;!-- 提供了自动装配功能--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;!-- 在编译时会自动收集配置类的条件，写到一个META-INF&#x2F;spring-autoconfigure-metadata.json中--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;!--记录日志会用到切面，所以需要引入--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;&#x2F;groupId&gt; &lt;artifactId&gt;lombok&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;&#x2F;dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;&#x2F;artifactId&gt; &lt;version&gt;2.2.1&lt;&#x2F;version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;&#x2F;id&gt; &lt;goals&gt; &lt;goal&gt;jar-no-fork&lt;&#x2F;goal&gt; &lt;&#x2F;goals&gt; &lt;&#x2F;execution&gt; &lt;&#x2F;executions&gt; &lt;&#x2F;plugin&gt; &lt;&#x2F;plugins&gt; &lt;&#x2F;build&gt; &lt;&#x2F;project&gt; spring-boot-autoconfigure: 提供自动化装配功能，是为了Spring Boot 应用在各个模块提供自动化配置的作用；即加入对应 pom，就会有对应配置其作用；所以我们想要自动装配功能，就需要引入这个依赖。 spring-boot-configuration-processor： 将自定义的配置类生成配置元数据，所以在引用自定义STARTER的工程的YML文件中，给自定义配置初始化时，会有属性名的提示；确保在使用@ConfigurationProperties注解时，可以优雅的读取配置信息，引入该依赖后，IDEA不会出现“spring boot configuration annotation processor not configured”的错误；编译之后会在META-INF 下生成一个spring-configuration-metadata.json 文件，大概内容就是定义的配置的元数据；效果如下截图。 定义属性配置 package com.rrc.config; import lombok.Data; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; @ConfigurationProperties(prefix &#x3D; &quot;rrc&quot;) @Data public class LogProperties &#123; &#x2F;** * 是否开启日志 *&#x2F; private boolean enable; &#x2F;** * 平台：不同服务使用的区分，默认取 spring.application.name *&#x2F; @Value(&quot;$&#123;spring.application.name:#&#123;null&#125;&#125;&quot;) private String platform; &#125; @ConfigurationProperties：该注解和@Value 注解作用类似，用于获取配置文件中属性定义并绑定到Java Bean 或者属性中；换句话来说就是将配置文件中的配置封装到JAVA 实体对象，方便使用和管理。 这边我们定义两个属性，一个是是否开启日志的开关，一个是标识平台的名称。 定义自动配置类 package com.rrc; import com.rrc.config.LogProperties; import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; @Configuration @ComponentScan(&quot;com.rrc&quot;) @ConditionalOnProperty(prefix &#x3D; &quot;rrc&quot;,name &#x3D; &quot;enable&quot;,havingValue &#x3D; &quot;true&quot;,matchIfMissing &#x3D; false) @EnableConfigurationProperties(&#123;LogProperties.class&#125;) public class RrcLogAutoConfiguration &#123; &#125; 这个类最关键了，它是整个starter 最重要的类，它就是将配置自动装载进spring-boot的；具体是怎么实现的，下面在讲解原理的时候会再详细说说，这里先完成示例。 引用 徒手撸一个Spring Boot中的starter，解密自动化配置 天天在用SpringBoot，手撸一个的Starter试试！ 只需4步，自己搞个 Spring Boot Starter ！ 如何使用SpringBoot封装自己的Starter SpringBoot 系列三 : SpringBoot 自定义 Starter SpringBoot：认认真真梳理一遍自动装配原理 SpringBoot四大核心组件，你知道几个？","categories":[{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://qinglei1989.github.io/tags/spring-boot/"}]},{"title":"异常处理的思考","slug":"spring-boot-exception","date":"2022-05-29T16:04:15.000Z","updated":"2022-05-29T18:02:04.681Z","comments":true,"path":"2022/05/30/spring-boot-exception/","link":"","permalink":"https://qinglei1989.github.io/2022/05/30/spring-boot-exception/","excerpt":"业务代码不显式地对异常进行捕获、处理，而异常肯定还是处理的，不然系统岂不是动不动就崩溃了，所以必须得有其他地方捕获并处理这些异常。","text":"业务代码不显式地对异常进行捕获、处理，而异常肯定还是处理的，不然系统岂不是动不动就崩溃了，所以必须得有其他地方捕获并处理这些异常。 Springboot整合redis","categories":[{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://qinglei1989.github.io/tags/spring-boot/"}]},{"title":"nginx服务器","slug":"web-server-nginx","date":"2022-05-28T17:06:31.000Z","updated":"2023-01-16T14:11:48.688Z","comments":true,"path":"2022/05/29/web-server-nginx/","link":"","permalink":"https://qinglei1989.github.io/2022/05/29/web-server-nginx/","excerpt":"","text":"Nginx (engine x) 是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP服务器。它也是一种轻量级的Web服务器，可以作为独立的服务器部署网站（类似Tomcat）。它高性能和低消耗内存的结构受到很多大公司青睐，如淘宝网站架设。 nginx服务器 windows下安装nginx 下载地址：nginx官网 下载之后，解压到指定的目录，就可以看到以下的目录 D:\\Program Files\\nginx-1.8.1&gt;start nginx D:\\Program Files\\nginx-1.8.1&gt; nginx命令 start nginx 开启nginx服务 nginx.exe -s stop 关闭nginx服务，快速停止nginx，可能并不保存相关信息 nginx.exe -s quit 关闭nginx服务，完整有序的停止nginx，并保存相关信息 nginx.exe -s reload 重载nginx服务，当你改变了nginx配置信息并需要重新载入这些配置时可以使用此命令重载nginx nginx的配置文件是conf目录下的nginx.conf，默认配置的nginx监听的端口为80 #user nobody; worker_processes 1; #error_log logs&#x2F;error.log; #error_log logs&#x2F;error.log notice; #error_log logs&#x2F;error.log info; #pid logs&#x2F;nginx.pid; events &#123; worker_connections 1024; &#125; http &#123; include mime.types; default_type application&#x2F;octet-stream; #log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; # &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; # &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; #access_log logs&#x2F;access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs&#x2F;host.access.log main; location &#x2F; &#123; root html; index index.html index.htm; &#125; #error_page 404 &#x2F;404.html; # redirect server error pages to the static page &#x2F;50x.html # error_page 500 502 503 504 &#x2F;50x.html; location &#x3D; &#x2F;50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http:&#x2F;&#x2F;127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME &#x2F;scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#39;s document root # concurs with nginx&#39;s one # #location ~ &#x2F;\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location &#x2F; &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location &#x2F; &#123; # root html; # index index.html index.htm; # &#125; #&#125; &#125; 当我们修改了nginx的配置文件nginx.conf 时，不需要关闭nginx后重新启动nginx，只需要执行命令 nginx -s reload 即可让改动生效 在Nginx服务器上安装证书 在Nginx独立服务器上安装证书 下载证书，存放证书 配置nginx.conf server &#123; listen 443 ssl; server_name m.yipinxieli.com; ssl_certificate cert&#x2F;m.yipinxieli.com.pem; ssl_certificate_key cert&#x2F;m.yipinxieli.com.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location &#x2F; &#123; root html; index index.html index.htm; &#125; &#125; 设置HTTP请求自动跳转HTTPS Nginx 老版本的写法 server &#123; listen 80; server_name www.yipinxieli.com; #需要将yourdomain替换成证书绑定的域名。 rewrite ^(.*)$ https:&#x2F;&#x2F;$host$1; #将所有HTTP请求通过rewrite指令重定向到HTTPS。 location &#x2F; &#123; index index.html index.htm; &#125; &#125; 新版本推荐 return 301 https:&#x2F;&#x2F;$server_name$request_uri; #http跳转https Nginx负载均衡 #设定负载均衡的服务器列表 upstream load_balance_server &#123; #weigth参数表示权值，权值越高被分配到的几率越大 server 172.20.241.141:80 weight&#x3D;5; server 172.20.241.151:80 weight&#x3D;1; &#125; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;load_balance_server ;#请求转向load_balance_server 定义的服务器列表 &#125; 负载均衡中的健康检查：http://t.zoukankan.com/larry-luo-p-10620263.html 正向代理与反向代理 正向代理 对目标服务器隐藏客户端（用户）。客户端（用户）知道目标服务器（github）,但是访问不到，可以通过代理（VPN）访问目标服务器，目标服务器只知道代理访问了自己，不知道客户端是谁。 反向代理 对客户端（用户）隐藏目标服务器。客户端只知道代理，不知道目标服务器，但通过代理客户端实际访问的是目标服务器，目标服务器知道客户端是谁。 最近用 Nginx 反向代理的几个网站经常出打不开，报 502 或 504 错误，重启 Nginx 后马上就好了。 实践问题： Nginx 反向代理的动态域名 IP 随时会变化（宽带重新拨号），但 IP 改变后 Nginx 的反向代理还是用的缓存的旧 IP。 https://www.nadeau.io/post/nginx-proxy_pass-dns-cache/ https://weiku.co/article/61/ location &#x3D; &#x2F; &#123; resolver 10.128.232.53 10.128.232.58 valid&#x3D;5 ipv6&#x3D;off; set $cdnurl http:&#x2F;&#x2F;feweb.58dns.org&#x2F;pro&#x2F;html&#x2F;authority-web; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass $cdnurl; proxy_intercept_errors on; &#125; 引用 在Nginx（或Tengine）服务器上安装证书 Windows nginx安装教程及简单实践 web中间件应用系列：正向代理和反向代理的区别","categories":[{"name":"服务器","slug":"服务器","permalink":"https://qinglei1989.github.io/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://qinglei1989.github.io/tags/nginx/"}]},{"title":"Spring Cloud Hystrix","slug":"spring-cloud-hystrix","date":"2022-05-04T07:18:05.000Z","updated":"2022-05-29T10:40:16.819Z","comments":true,"path":"2022/05/04/spring-cloud-hystrix/","link":"","permalink":"https://qinglei1989.github.io/2022/05/04/spring-cloud-hystrix/","excerpt":"服务容错保护Spring Cloud Hystrix实现了断路器、线程隔离等一系列服务保护功能。它也是基于Netflix 的开源框架 Hystrix实现的，该框架的目标在于通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备服务降级、服务熔断、线程和信号隔离、请求缓存、请求合并以及服务监控等强大功能。","text":"服务容错保护Spring Cloud Hystrix实现了断路器、线程隔离等一系列服务保护功能。它也是基于Netflix 的开源框架 Hystrix实现的，该框架的目标在于通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备服务降级、服务熔断、线程和信号隔离、请求缓存、请求合并以及服务监控等强大功能。 Spring Cloud Hystrix 雪崩效应 微服务架构的应用系统通常包含多个服务层。微服务之间通过网络进行通信，从而支撑起整个应用系统，因此，微服务之间难免存在依赖关系。我们知道，任何微服务都并非100%可用,网络往往也很脆弱，因此难免有些请求会失败。我们常把“基础服务故障”导致“级联故障”的现象称为雪崩效应。雪崩效应描述的是提供者不可用导致消费者不可用，并将不可用逐渐放大的过程。 可以看到, 当 C 服务挂掉时, B 服务还在不断地调用 C 服务期望获得结果, 结果在 B 服务内部产生了大量的调用等待和重试调用的线程, 随着新的请求不断地往这条调用链路上跑, 那么 B 服务的资源就会被这些线程耗尽, 从而导致 B 服务也不可用。同理, 当 B 服务也挂掉时, A 服务挂掉也只是时间的问题了。 在一个复杂的分布式系统中通常会有很多的依赖，如果我们不能对来自依赖的故障进行隔离，那么应用本身就会处于分险之中。在一个高流量的网站中，某一后端出现延迟，将会在数秒之内导致所有资源耗尽。 如何容错 要想防止雪崩效应，必须有一个强大的容错机制。该容错机制需实现以下两点。 必须为网络请求设置超时正常情况下，一个远程调用一般在几十毫秒内就能得到响应了。如果依赖的服务不可用或者网络有问题，那么响应时间就会变得很长（几十秒)。而一次远程调用对应着一个线程/进程。如果响应太慢，这个线程/进程就得不到释放。而线程/进程又对应着系统资源，如果得不到释放的线程/进程越积越多，资源就会逐渐被耗尽，最终导致服务的不可用。因此，必须为每个网络请求设置超时，让资源尽快释放。 使用断路器模式如果对某个微服务的请求有大量超时（常常说明该微服务不可用)，再去让新的请求访问该服务已经没有任何意义，只会消耗资源。例加设詈了超时时间为1秒，如果短时间内有大量的请求无法在1秒内得到响应，就没有必要再去请求依赖的服务了。 断路器可理解为对容易导致错误的操作的代理。这种代理能够统计一段时间内调用失败的次数，并决定是正常请求依赖的服务还是直接返回。断路器可以实现快速失败,如果它在一段时间内检测到许多类似的错误（例如超时)，就会在之后的一段时间内，强迫对该服务的调用快速失败，即不再请求所依赖的服务。这样，应用程序就无须再浪费CPU时间去等待长时间的超时断路器也可自动诊断依赖的服务是否已经恢复正常。如果发现依赖的服务已经恢复正常，那么就会恢复请求该服务。使用这种方式，就可以实现微服务的“自我修复”——当依赖的服务不正常时打开断路器时快速失败，从而防止雪崩效应;当发现依赖的服务恢复正常时,又会恢复请求。 初探Hystrix Hystrix官方代码托管在：https:github.com/Netflix/Hystrix。 Hystrix是由Netflix开源的一个延迟和容错库，旨在隔离远程系统、服务和第三方库，阻止级联故障，从而提升系统的可用性与容错性。Hystrix主要通过以下几点实现延迟和容错。 包裹请求: 使用HystrixCommand (或HystrixObservableCommand)包裹对依赖的调用逻辑，每个命令在独立线程中执行。这使用到了设计模式中的“命令模式”。。跳闸机制:当某服务的错误率超过一定阈值时，Hystrix可以自动或者手动跳闸，停止请求该服务一段时间。资源隔离: Hystrix为每个依赖都维护了一个小型的线程池（或者信号量)。如果该线程池已满，发往该依赖的请求就被立即拒绝，而不是排队等候，从而加速失败判定。 。监控:Hystrix可以近乎实时地监控运行指标和配置的变化，例如成功、失败、超时、以及被拒绝的请求等。。回退机制:当请求失败、超时、被拒绝，或当断路器打开时，执行回退逻辑。回退逻辑可由开发人员自行提供，例如返回一个缺省值。。自我修复:断路器打开一段时间后，会自动进入“半开”状态。断路器打开、关闭、半开的逻辑转换，前面已经详细探讨过了，本节不再赘述。 Hystrix入门 关窗户 引用 Hystrix原理与实战 https://www.136.la/jingpin/show-107253.html https://blog.csdn.net/qiongjingpang9161/article/details/113872056 https://blog.csdn.net/theludlows/article/details/82904263?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-0.pc_relevant_default&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3 https://www.bilibili.com/video/BV1di4y14765?p=94 https://mp.weixin.qq.com/s/jsaG_w4ICkIK72UlZgw0qQ https://mp.weixin.qq.com/s/paZmZJ5MmcsuiJ65RHqirg https://mp.weixin.qq.com/s/gK0iQHOaBy8Cx-3sqS4OuA https://mp.weixin.qq.com/s/2ziyu-HvtfPxw8ktYNSNAA https://www.cnblogs.com/dabenxiang/p/13764076.html","categories":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/categories/spring-cloud/"}],"tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/tags/spring-cloud/"}]},{"title":"spring-cloud-eureka","slug":"spring-cloud-eureka","date":"2022-05-02T16:02:58.000Z","updated":"2022-06-19T14:35:54.646Z","comments":true,"path":"2022/05/03/spring-cloud-eureka/","link":"","permalink":"https://qinglei1989.github.io/2022/05/03/spring-cloud-eureka/","excerpt":"","text":"Eureka注册中心 Eureka体系结构 搭建服务注册中心 application.yml server: # 应用端口号 port: 8888 eureka: instance: # 应用所在的主机名 hostname: localhost # 关闭自我保护机制，默认为true代表启动 enable-self-preservation: false # 指定自我保护机制的开启阈值，默认0.85 # renewal-percent-threshold: 0.7 client: # 本身为注册中心, 不向注册中心注册自己 registerWithEureka: false # 注册中心的职责是维护服务实例，它并不需要去检索服务，所以设置为false fetchRegistry: false serviceUrl: defaultZone: http:&#x2F;&#x2F;$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;&#x2F;eureka&#x2F; spring: application: # 应用名称 name: eureka-server 主类EurekaServerApplication： package com.wql; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; &#x2F;** * @author Zhouzc * @description TODO * @className com.wql.EurekaServerApplication * @date 2019&#x2F;10&#x2F;21 * @Version **&#x2F; &#x2F;&#x2F; 通过@EnableEurekaServer注解启动一个服务注册中心提供给其他应用 @EnableEurekaServer @SpringBootApplication public class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125; &#125; 注册服务提供者 eureka: client: serviceUrl: # 指定服务注册中心地址 defaultZone: http:&#x2F;&#x2F;localhost:8888&#x2F;eureka&#x2F; instance: prefer-ip-address: true # 自定义 Eureka 的 InstanceID 主机名：服务名称：服务端口 instance-id: $&#123;spring.application.name&#125;:$&#123;spring.cloud.client.ipAddress&#125;:$&#123;server.port&#125; status-page-url:www.wql.com server: port: 80 spring: application: # 应用名称 name: hello-service 主类HelloServiceApplication package com.wql; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; &#x2F;** * @author Zhouzc * @description 配置中心服务 * @className ConfigServerApplication * @date 2019&#x2F;10&#x2F;22 * @Version **&#x2F; &#x2F;&#x2F; @EnableDiscoveryClient和@EnableEurekaClient共同点就是：都是能够让注册中心能够发现，扫描到改服务。@EnableEurekaClient只适用于Eureka作为注册中心，@EnableDiscoveryClient 可以是其他注册中心,通用性更强。 @EnableDiscoveryClient @SpringBootApplication public class HelloServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HelloServiceApplication.class, args); &#125; &#125; 启动注册中心与hello-service服务后 hello-service日志信息： 2022-05-03 01:07:21.088 INFO 2368 --- [ main] com.netflix.discovery.DiscoveryClient : The response status is 200 2022-05-03 01:07:21.088 INFO 2368 --- [ main] com.netflix.discovery.DiscoveryClient : Starting heartbeat executor: renew interval is: 30 2022-05-03 01:07:21.090 INFO 2368 --- [ main] c.n.discovery.InstanceInfoReplicator : InstanceInfoReplicator onDemand update allowed rate per min is 4 2022-05-03 01:07:21.093 INFO 2368 --- [ main] com.netflix.discovery.DiscoveryClient : Discovery Client initialized at timestamp 1651511241093 with initial instances count: 0 2022-05-03 01:07:21.112 INFO 2368 --- [ main] o.s.c.n.e.s.EurekaServiceRegistry : Registering application hello-service with eureka with status UP 2022-05-03 01:07:21.113 INFO 2368 --- [ main] com.netflix.discovery.DiscoveryClient : Saw local status change event StatusChangeEvent [timestamp&#x3D;1651511241113, current&#x3D;UP, previous&#x3D;STARTING] 2022-05-03 01:07:21.114 INFO 2368 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_HELLO-SERVICE&#x2F;LAPTOP-CNEAHR20:hello-service:80: registering service... 2022-05-03 01:07:21.251 INFO 2368 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 80 (http) 2022-05-03 01:07:21.252 INFO 2368 --- [ main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 80 2022-05-03 01:07:21.254 INFO 2368 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_HELLO-SERVICE&#x2F;LAPTOP-CNEAHR20:hello-service:80 - registration status: 204 2022-05-03 01:07:21.256 INFO 2368 --- [ main] com.wql.HelloServiceApplication : Started HelloServiceApplication in 10.054 seconds (JVM running for 12.462) 注册中心控制台： 2022-05-03 01:33:32.697 INFO 28780 --- [io-8888-exec-10] c.n.e.registry.AbstractInstanceRegistry : Registered instance HELLO-SERVICE&#x2F;LAPTOP-CNEAHR20:hello-service:80 with status DOWN (replication&#x3D;false) 2022-05-03 01:34:03.478 INFO 28780 --- [nio-8888-exec-9] c.n.e.registry.AbstractInstanceRegistry : Registered instance HELLO-SERVICE&#x2F;LAPTOP-CNEAHR20:hello-service:80 with status UP (replication&#x3D;false) 2022-05-03 01:34:19.425 INFO 28780 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 13ms 2022-05-03 01:35:19.425 INFO 28780 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms 2022-05-03 01:36:18.232 INFO 28780 --- [hresholdUpdater] c.n.e.r.PeerAwareInstanceRegistryImpl : Current renewal threshold is : 3 高可用注册中心 Eureka Server的高可用实际上就是将自己作为服务向其他服务注册中心注册自己，这样就可以形成一组互相注册的服务注册中心，以实现服务清单的互相同步，达到高可用的效果。 application-peer1.yml server: port: 1111 eureka: instance: hostname: localhost client: registerWithEureka: true fetchRegistry: true serviceUrl: defaultZone: http:&#x2F;&#x2F;peer2:1112&#x2F;eureka&#x2F; spring: application: name: eureka-server application-peer2.yml server: port: 1112 eureka: instance: hostname: localhost client: registerWithEureka: true fetchRegistry: true serviceUrl: defaultZone: http:&#x2F;&#x2F;peer1:1111&#x2F;eureka&#x2F; spring: application: name: eureka-server 设置IDEA并行运行 设置启动参数： --spring.profiles.active&#x3D;peer1 --spring.profiles.active&#x3D;peer2 Eureka高可用部署，启动多个注册中心后，节点均出现在unavailable-replicas。具体的解决方案如下：Eureka集群搭建，unavailable-replicas服务节点不可用 同一主机上配置多个节点，则各节点的eureka.instance.hostname（实例的主机名）不能一样。为各节点配置不同的hostname，然后修改主机的hosts文件，增加映射。 127.0.0.1 peer1 127.0.0.1 peer2 在设置了多节点的服务注册中心之后，服务提供方还需要做一些简单的配置才能将服务注册到 Eureka Server集群中。我们以hello-service为例，修改application.properties 配置文件，如下所示: eureka.client.serviceUrl.defaultZone&#x3D;http:&#x2F;&#x2F;peer1:11l1&#x2F;eureka&#x2F;, http:&#x2F;&#x2F;peer2:1112&#x2F;eureka&#x2F; 如我们不想使用主机名来定义注册中心的地址，也可以使用IP地址的形式，但是需要在配置文件中增加配置参数 eureka.instance.prefer-ip-address=true，该值默认为false。 服务发现与消费 主类ConsumerApplication package com.didispace; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.web.client.RestTemplate; @EnableCircuitBreaker @EnableDiscoveryClient @SpringBootApplication public class ConsumerApplication &#123; @Bean @LoadBalanced RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class, args); &#125; &#125; 自我保护机制 在 Eureka 服务页面中看到如下红色字体内容，表示当前 EurekaServer 启动了自我保护机制，进入了自我保护模式。 默认情况下，EurekaServer 在 90 秒内没有收到到服务列表中某微服务续约心跳，则会自动将该微服务从服务列表中删除。 Eureka服务端会检查最近15分钟内所有Eureka 实例正常心跳占比，如果低于85%就会触发自我保护机制。触发了保护机制，Eureka将暂时把这些失效的服务保护起来，不让其过期，但这些服务也并不是永远不会过期。Eureka在启动完成后，每隔60秒会检查一次服务健康状态，如果这些被保护起来失效的服务过一段时间后（默认90秒）还是没有恢复，就会把这些服务剔除。如果在此期间服务恢复了并且实例心跳占比高于85%时，就会自动关闭自我保护机制。 实践是：自我保护状态一旦开启，除非客户端恢复导致退出自我保护状态，否则实例永不删除。 https://blog.csdn.net/qq_35976271/article/details/102314965 eureka详情 ![服务治理](service governance.png) 服务提供者 服务注册 eureka.client.register-with-eureka&#x3D;true 服务同步 服务续约 # 服务续约任务的调用时间间隔，默认30s eureka.instance.lease-renewal-interval-in-seconds&#x3D;30 # 服务失效的时间，默认90s eureka.instance.lease-expiration-duration-in-seconds&#x3D;90 服务消费者 获取服务 # Eureka Server 会维护一份只读的服务清单来返回给客户端，同时该缓存清单会每隔30秒更新一次。若希望修改缓存清单的更新时间，可以通过参数进行修改，该参数默认值为30s。 eureka.client.reaistry-fetch-interval-seconds&#x3D;30 服务调用 注册中心 失效剔除 对于非正常的服务下线，Eureka Server在启动的时候会创建一个定时任务，默认每隔一段时间（默认为60秒)将当前清单中超时（默认为90秒)没有续约的服务剔除出去。 自我保护 服务注册到Eureka Server之后，会维护一个心跳连接。Eureka Server在运行期间,会统计心跳失败的比例在15分钟之内是否低于85%,如果出现低于的情况(在单机调试的时候很容易满足，实际在生产环境上通常是由于网络不稳定导致)，EurekaServer会将当前的实例注册信息保护起来，让这些实例不会过期，尽可能保护这些注册信息。但是，在这段保护期间内实例若出现问题，那么客户端很容易拿到实际已经不存在的服务实例，会出现调用失败的情况，所以客户端必须要有容错机制,比如可以使用请求重试、断路器等机制。 在本地进行开发的时候，可以使用eureka.server.enable-self-preservation=false参数来关闭保护机制，以确保注册中心可以将不可用的实例正确剔除。 源码分析 @EnableDiscoveryClient注解用来开启DiscoveryClient实例 DiscoveryClient类用于帮助与 Eureka Server互相协作。 Eureka Client负责下面的任务: ​ 向Eureka Server注册服务实例 ​ 向Eureka Server服务租约 ​ 当服务关闭期间，向Eureka Server取消租约 ​ 查询Eureka Server中的服务实例列表 Eureka Client 还需要配置一个Eureka Server的URL 列表。 SpringCloud 中的Eureka默认使用的Region为us-east-1。 Eureka的缓存机制/三级缓存 https://segmentfault.com/a/1190000011668299 https://blog.csdn.net/qq_34680763/article/details/123736997 https://blog.csdn.net/weixin_41947378/category_10361937.html","categories":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/categories/spring-cloud/"}],"tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/tags/spring-cloud/"}]},{"title":"spring-boot-yml","slug":"spring-boot-yml","date":"2022-05-01T17:18:06.000Z","updated":"2022-07-27T17:06:08.858Z","comments":true,"path":"2022/05/02/spring-boot-yml/","link":"","permalink":"https://qinglei1989.github.io/2022/05/02/spring-boot-yml/","excerpt":"SpringBoot读取properties（yml）文件中配置信息","text":"SpringBoot读取properties（yml）文件中配置信息 Springboot读取YML配置文件 @Value 该注解作用的作用是将我们配置文件的属性读出来，有@Value(“${}”)和@Value(“#{}”)两种方式 ① ${ property : default_value }② #{ obj.property? :default_value } application-prod.yml配置文件内容如下： server: port: 80 rrc: name: lq birthday: 199009 admin: menggudashuishen 对应的JAVA代码 @Value(&quot;$&#123;admin&#125;&quot;) private String admin; @Value(&quot;$&#123;server.port&#125;&quot;) private String port; #{}是不能以第一种方式来进行取值，否则会报错。#{}里面包含的是obj，所以需要配合bean来使用，现在创建一个UserBean，并且给某个字段加上@Value(“#{}”)注解（按自己的需求任意添加注解） 定义Bean： package com.rrc.dto.base; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; &#x2F;** * @author: wangql * @Title: Rrc * @ProjectName: SpringBoot * @Description: * @date: 2022&#x2F;4&#x2F;27 0:40 *&#x2F; @Component @ConfigurationProperties(&quot;rrc&quot;) public class Rrc &#123; private String name; private String birthday; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name &#x3D; name; &#125; public String getBirthday() &#123; return birthday; &#125; public void setBirthday(String birthday) &#123; this.birthday &#x3D; birthday; &#125; &#125; 获取值： @Value(&quot;#&#123;rrc.birthday&#125;&quot;) private String birthday; SpringBoot中使用@Value()只能给普通变量注入值，不能直接给静态变量赋值。如果是静态变量那么拿到的属性值则为null。解决办法是给其属性值加上set方法，并且给其类上添加@Component注解 @Value这个注解估计很熟悉了，Spring中从属性取值的注解，支持SPEL表达式，不支持复杂的数据类型，比如List。 @ConfigurationProperties 使用@Value注解可以直接读取application.yml配置文件中的配置信息。使用@ConfigurationProperties也可以读取application.yml文件中的配置信息。使用@ConfigurationProperties和@PropertySource可以读取指定properties配置文件中的配置信息。 @ConfigurationProperties注解提供了我们将多个配置选项注入复杂对象的能力。它要求我们指定配置的共同前缀。支持从驼峰camel-case到短横分隔命名kebab-case的自动转换。 ini.properties rrc.name-&#x3D;wql11 rrc.birthday&#x3D;19990510 对应的实体类为 package com.rrc.dto.base; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.PropertySource; import org.springframework.stereotype.Component; &#x2F;** * @author: wangql * @Title: Rrc * @ProjectName: SpringBoot * @Description: * @date: 2022&#x2F;4&#x2F;27 0:40 *&#x2F; @Component @PropertySource(&quot;classpath:ini.properties&quot;) @ConfigurationProperties(&quot;rrc&quot;) public class Rrc &#123; private String name; private String birthday; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name &#x3D; name; &#125; public String getBirthday() &#123; return birthday; &#125; public void setBirthday(String birthday) &#123; this.birthday &#x3D; birthday; &#125; &#125; @ConfigurationProperties注解能够很轻松的从配置文件中取值，优点如下： 支持批量的注入属性，只需要指定一个前缀prefix 支持复杂的数据类型，比如List、Map 对属性名匹配的要求较低，比如user-name，user_name，userName，USER_NAME都可以取值 支持JAVA的JSR303数据校验 注意：@ConfigurationProperties这个注解仅仅是支持从Spring Boot的默认配置文件中取值，比如application.properties、application.yml 多环境配置 自定义配置文件是我们日常开发中经常会使用的资源，而spring只提供了类似application-* 的这中匹配方式，并不支持我们自定义的配置文件名称，例如：customize-dev.properties,但是spring提供了一个注解可以方便加载我们的自定义配置文件，它就是@PropertySource 自定义配置文件ini-dev.properties rrc.name-&#x3D;wql22 rrc.birthday&#x3D;19990510 对应的实体类 package com.rrc.dto.base; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.PropertySource; import org.springframework.stereotype.Component; &#x2F;** * @author: wangql * @Title: Rrc * @ProjectName: SpringBoot * @Description: * @date: 2022&#x2F;4&#x2F;27 0:40 *&#x2F; @Component @PropertySource(&quot;classpath:ini-$&#123;customize.profiles.active&#125;.properties&quot;) @ConfigurationProperties(prefix &#x3D; &quot;rrc&quot;, ignoreInvalidFields &#x3D; true) public class Rrc &#123; private String name; private String birthday; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name &#x3D; name; &#125; public String getBirthday() &#123; return birthday; &#125; public void setBirthday(String birthday) &#123; this.birthday &#x3D; birthday; &#125; &#125; 启动参数： -Dcustomize.profiles.active&#x3D;dev 自定义配置文件获取值 Spring Boot在启动的时候会自动加载application.xxx和bootsrap.xxx，但是为了区分，有时候需要自定义一个配置文件，那么如何从自定义的配置文件中取值呢？此时就需要配合@PropertySource这个注解使用了。 只需要在配置类上标注@PropertySource并指定你自定义的配置文件即可完成。如下","categories":[{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://qinglei1989.github.io/tags/spring-boot/"}]},{"title":"jvm-command-jmap","slug":"jvm-command-jmap","date":"2022-04-17T14:07:10.000Z","updated":"2022-04-17T15:47:16.206Z","comments":true,"path":"2022/04/17/jvm-command-jmap/","link":"","permalink":"https://qinglei1989.github.io/2022/04/17/jvm-command-jmap/","excerpt":"jmap（Memory Map for Java）命令用来生成堆转储快照。 jmap的作用并不仅仅是为了生成堆转储快照文件，还可以查看finalize执行队列、Java堆和方法区的详细信息，比如空间使用率、当前使用的什么垃圾回收器、分代情况等等。","text":"jmap（Memory Map for Java）命令用来生成堆转储快照。 jmap的作用并不仅仅是为了生成堆转储快照文件，还可以查看finalize执行队列、Java堆和方法区的详细信息，比如空间使用率、当前使用的什么垃圾回收器、分代情况等等。 Java内存映像工具jmap 语法 jmap [ option ] vmid option选项 选项 作用 -dump 生成java堆转储快照，格式为jmap -dump:[live,]format=b,file= -finalizerinfo 显示在F-Queue中等待Finalizer线程执行finalize方法的对象。 -heap 显示Java堆详细信息，如使用了那种回收器、参数配置、分代状况等。 -histo 显示堆中对象统计信息，包括类、实例数量、合计容器 -permstat 以ClassLoader为统计口径显示永久代内存状态 -F 当虚拟机进程对-dump选项没有响应时，可使用这个选项强制生成dump快照 使用 jmap命令的可选参数。如果没有指定这个参数，jinfo命令会显示Java虚拟机进程的内存映像信息，如下图： work@authority-web-v1-78f4d45f98-zpnx6:~$ jps 854586 Jps 47 authority-web.jar work@authority-web-v1-78f4d45f98-zpnx6:~$ jmap 47 Attaching to process ID 47, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.222-b10 0x0000000000400000 8K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;bin&#x2F;java 0x00007fb7079e3000 82K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libresolv-2.24.so 0x00007fb707bfa000 22K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnss_dns-2.24.so 0x00007fb74049a000 90K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libgcc_s.so.1 0x00007fb7406b1000 260K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;libsunec.so 0x00007fb76c7ca000 92K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;libnio.so 0x00007fb76c9dc000 51K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;libmanagement.so 0x00007fb76cbe6000 114K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;libnet.so 0x00007fb781dd5000 123K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;libzip.so 0x00007fb781ff1000 46K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnss_files-2.24.so 0x00007fb782203000 46K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnss_nis-2.24.so 0x00007fb78240f000 86K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnsl-2.24.so 0x00007fb782627000 30K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libnss_compat-2.24.so 0x00007fb78282f000 50K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;libinstrument.so 0x00007fb782a3a000 202K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;libjava.so 0x00007fb782c64000 68K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;libverify.so 0x00007fb782e74000 31K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;librt-2.24.so 0x00007fb78307c000 1038K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libm-2.24.so 0x00007fb783380000 15953K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;server&#x2F;libjvm.so 0x00007fb7842e7000 1649K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libc-2.24.so 0x00007fb784686000 14K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libdl-2.24.so 0x00007fb78488a000 334K &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;lib&#x2F;amd64&#x2F;jli&#x2F;libjli.so 0x00007fb784aa1000 132K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libpthread-2.24.so 0x00007fb784cbe000 149K &#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;ld-2.24.so work@authority-web-v1-78f4d45f98-zpnx6:~$ work@authority-web-v1-78f4d45f98-zpnx6:~$ -heap显示Java堆的如下信息： work@authority-web-v1-78f4d45f98-zpnx6:~$ ^C work@authority-web-v1-78f4d45f98-zpnx6:~$ jmap -heap 47 Attaching to process ID 47, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.222-b10 using parallel threads in the new generation. using thread-local object allocation. Concurrent Mark-Sweep GC Heap Configuration: MinHeapFreeRatio &#x3D; 40 MaxHeapFreeRatio &#x3D; 70 MaxHeapSize &#x3D; 161480704 (154.0MB) NewSize &#x3D; 53084160 (50.625MB) MaxNewSize &#x3D; 53084160 (50.625MB) OldSize &#x3D; 108396544 (103.375MB) NewRatio &#x3D; 2 SurvivorRatio &#x3D; 8 MetaspaceSize &#x3D; 21807104 (20.796875MB) CompressedClassSpaceSize &#x3D; 1073741824 (1024.0MB) MaxMetaspaceSize &#x3D; 17592186044415 MB G1HeapRegionSize &#x3D; 0 (0.0MB) Heap Usage: New Generation (Eden + 1 Survivor Space): capacity &#x3D; 47775744 (45.5625MB) used &#x3D; 14542552 (13.868858337402344MB) free &#x3D; 33233192 (31.693641662597656MB) 30.439195253557955% used Eden Space: capacity &#x3D; 42467328 (40.5MB) used &#x3D; 14496264 (13.824714660644531MB) free &#x3D; 27971064 (26.67528533935547MB) 34.135097927517364% used From Space: capacity &#x3D; 5308416 (5.0625MB) used &#x3D; 46288 (0.0441436767578125MB) free &#x3D; 5262128 (5.0183563232421875MB) 0.8719738618827161% used To Space: capacity &#x3D; 5308416 (5.0625MB) used &#x3D; 0 (0.0MB) free &#x3D; 5308416 (5.0625MB) 0.0% used concurrent mark-sweep generation: capacity &#x3D; 108396544 (103.375MB) used &#x3D; 69763232 (66.53140258789062MB) free &#x3D; 38633312 (36.843597412109375MB) 64.35927698949516% used 38279 interned Strings occupying 4296008 bytes. work@authority-web-v1-78f4d45f98-zpnx6:~$ -histo[:live]显示Java堆中对象的统计信息，包括：对象数量、占用内存大小(单位：字节)和类的完全限定名 work@authority-web-v1-78f4d45f98-zpnx6:~$ jmap -histo 47 num #instances #bytes class name ---------------------------------------------- 1: 203570 17317376 [C 2: 8015 8330368 [I 3: 11785 5102672 [B 4: 200710 4817040 java.lang.String 5: 54046 4756048 java.lang.reflect.Method 6: 52052 3601488 [Ljava.util.Hashtable$Entry; 7: 51912 2491776 java.util.Hashtable 8: 69610 2227520 java.util.concurrent.ConcurrentHashMap$Node 9: 42359 1694360 java.util.LinkedHashMap$Entry 10: 14754 1648040 java.lang.Class 11: 46595 1491040 java.util.Hashtable$Entry 12: 24749 1364792 [Ljava.lang.Object; 13: 16400 1307848 [Ljava.util.HashMap$Node; 14: 51139 1227336 net.sourceforge.pinyin4j.multipinyin.Trie 15: 35509 1136288 java.util.HashMap$Node 16: 18233 1021048 java.util.LinkedHashMap 17: 43037 938448 [Ljava.lang.Class; 18: 652 728768 [Ljava.util.concurrent.ConcurrentHashMap$Node; 19: 9540 686880 java.lang.reflect.Field 20: 18791 450984 java.util.ArrayList work@authority-web-v1-78f4d45f98-zpnx6:~$ jmap -histo:live 47 num #instances #bytes class name ---------------------------------------------- 1: 187827 15633816 [C 2: 186246 4469904 java.lang.String 3: 51818 3547824 [Ljava.util.Hashtable$Entry; 4: 37131 3267528 java.lang.reflect.Method 5: 51730 2483040 java.util.Hashtable 6: 68132 2180224 java.util.concurrent.ConcurrentHashMap$Node 7: 7198 1953120 [B 8: 14565 1628384 java.lang.Class 9: 38624 1544960 java.util.LinkedHashMap$Entry 10: 41707 1334624 java.util.Hashtable$Entry 11: 6902 1276800 [I 12: 21838 1237912 [Ljava.lang.Object; 13: 51139 1227336 net.sourceforge.pinyin4j.multipinyin.Trie 14: 14954 1096368 [Ljava.util.HashMap$Node; 15: 17222 964432 java.util.LinkedHashMap 16: 25508 816256 java.util.HashMap$Node 17: 558 704480 [Ljava.util.concurrent.ConcurrentHashMap$Node; 18: 22133 485168 [Ljava.lang.Class; 19: 25426 406816 java.lang.Object 20: 16800 403200 java.util.ArrayList 生成Java虚拟机的堆转储快照dump文件 live参数是可选的，如果指定，则只转储堆中的活动对象；如果没有指定，则转储堆中的所有对象。 format=b表示以hprof二进制格式转储Java堆的内存。 file=&lt;filename&gt;用于指定快照dump文件的文件名。 work@authority-web-v1-78f4d45f98-zpnx6:~$ jmap -dump:live,format&#x3D;b,file&#x3D;&#x2F;home&#x2F;work&#x2F;dump 47 Dumping heap to &#x2F;home&#x2F;work&#x2F;dump ... Heap dump file created work@authority-web-v1-78f4d45f98-zpnx6:~$ -clstats 显示Java堆中元空间的类加载器的统计信息 -F 强制模式。如果指定的pid没有响应，可以配合-dump或-histo一起使用。此模式下，不支持live参数。 引用 记录一次线上JVM调优","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"jvm-command-jstack","slug":"jvm-command-jstack","date":"2022-04-05T14:07:10.000Z","updated":"2022-04-17T15:05:29.485Z","comments":true,"path":"2022/04/05/jvm-command-jstack/","link":"","permalink":"https://qinglei1989.github.io/2022/04/05/jvm-command-jstack/","excerpt":"jstack是JDK自带的线程堆栈分析工具，使用该命令可以查看或导出 java 应用程序中线程堆栈信息。 jstack用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。","text":"jstack是JDK自带的线程堆栈分析工具，使用该命令可以查看或导出 java 应用程序中线程堆栈信息。 jstack用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。 Java堆栈跟踪工具jstack 语法 jstack [ option ] [ vmid ] 使用方式 说明 jstack [ option ] pid 查看当前时间点，指定进程的dump堆栈信息 jstack [ option ] pid &gt; 文件 将当前时间点的指定进程的dump堆栈信息，写入到指定文件中 jstack [ option ] executable core 查看当前时间点，core文件的dump堆栈信息 jstack [ option ] [server_id@] 查看当前时间点，远程机器的dump堆栈信息 option选项 选项 作用 -F 当进程挂起了，此时’jstack [-l] pid’是没有相应的，可使用此参数来强制打印堆栈信息 -m 打印java和native c/c++框架的所有栈信息。一般排查不需要 -l 除堆栈外，打印关于锁的附加信息。会使得JVM停顿得长久得多-l 建议不要用。一般情况不需要使用。 使用 jps查看java进程 work@authority-api-v1-66c44d77d6-8hhkv:~$ jps 132 Jps 47 authority-api.jar jstack查看指定进程的当前堆栈情况 work@authority-api-v1-66c44d77d6-8hhkv:~$ jstack 47 2022-04-05 23:12:22 Full thread dump OpenJDK 64-Bit Server VM (25.222-b10 mixed mode): &quot;Attach Listener&quot; #53 daemon prio&#x3D;9 os_prio&#x3D;0 tid&#x3D;0x00007f3668001000 nid&#x3D;0x98 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE &quot;http-nio-0.0.0.0-8081-exec-10&quot; #52 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007f3608011800 nid&#x3D;0x67 waiting on condition [0x00007f3630f86000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000e73b9c28&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8081-exec-9&quot; #51 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007f3608010000 nid&#x3D;0x66 waiting on condition [0x00007f3631087000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000e73b9c28&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) 将指定进程的当前堆栈情况记录到某个文件中： work@authority-api-v1-66c44d77d6-8hhkv:~$ jstack 47 &gt; &#x2F;home&#x2F;work&#x2F;wangql.txt work@authority-api-v1-66c44d77d6-8hhkv:~$ jstack实战之高cpu占用率排查 测试代码： package com.tudou.util; import lombok.Synchronized; import java.util.concurrent.Executor; import java.util.concurrent.Executors; public class JstackTest &#123; public static Executor executor &#x3D; Executors.newFixedThreadPool(5); public static Object lock &#x3D; new Object(); public static void main(String[] args) &#123; Task task1 &#x3D; new Task(); Task task2 &#x3D; new Task(); executor.execute(task1); executor.execute(task2); &#125; static class Task implements Runnable &#123; @Override public void run() &#123; synchronized(lock) &#123; Calculate(); &#125; &#125; public void Calculate() &#123; int i &#x3D; 0; while(true) &#123; i++; &#125; &#125; &#125; &#125; top命令查看各个进程的cpu使用情况，默认按cpu使用率排序 work@authority-web-v1-7688dc9bf7-kr48z:~$ top top - 23:06:56 up 302 days, 7:36, 0 users, load average: 8.21, 8.46, 7.72 Tasks: 7 total, 1 running, 6 sleeping, 0 stopped, 0 zombie %Cpu(s): 6.5 us, 1.8 sy, 0.0 ni, 90.9 id, 0.7 wa, 0.0 hi, 0.2 si, 0.0 st KiB Mem : 19706059+total, 5289860 free, 71409256 used, 12036147+buff&#x2F;cache KiB Swap: 0 total, 0 free, 0 used. 12377960+avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 47 work 20 0 5003608 332432 16292 S 47.3 0.2 1:24.66 java 1 work 20 0 4280 692 628 S 0.0 0.0 0:01.44 sh 6 work 20 0 19728 3112 2804 S 0.0 0.0 0:00.00 bootstrap 16 work 20 0 19880 3204 2756 S 0.0 0.0 0:00.00 authority-web.j 1552 work 20 0 21116 4484 2984 S 0.0 0.0 0:00.02 bash 5218 work 20 0 21028 4676 3048 S 0.0 0.0 0:00.01 bash 5537 work 20 0 42812 3408 2908 R 0.0 0.0 0:00.01 top 从上图中可以看出pid为47的java进程占用了较多的cpu资源； 通过top -Hp 47可以查看该进程下各个线程的cpu使用情况 work@authority-web-v1-7688dc9bf7-kr48z:~$ top -Hp 47 top - 23:07:51 up 302 days, 7:37, 0 users, load average: 6.47, 7.91, 7.58 Threads: 48 total, 1 running, 47 sleeping, 0 stopped, 0 zombie %Cpu(s): 5.7 us, 1.3 sy, 0.0 ni, 91.7 id, 1.1 wa, 0.0 hi, 0.2 si, 0.0 st KiB Mem : 19706059+total, 4971968 free, 71714896 used, 12037372+buff&#x2F;cache KiB Swap: 0 total, 0 free, 0 used. 12350040+avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 5433 work 20 0 5070172 332464 16292 R 46.8 0.2 0:53.10 pool-4-thread-1 1266 work 20 0 5070172 332464 16292 S 0.3 0.2 0:00.17 Abandoned conne 47 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 java 48 work 20 0 5070172 332464 16292 S 0.0 0.2 0:13.52 java 49 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.88 java 50 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.92 java 51 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.08 java 52 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.09 java 53 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.52 java 54 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.37 VM Thread 55 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.01 Reference Handl 56 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.03 Finalizer 57 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 Surrogate Locke 58 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 Signal Dispatch 59 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 server-timer 61 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.03 Thread-2 62 work 20 0 5070172 332464 16292 S 0.0 0.2 0:23.11 C2 CompilerThre 63 work 20 0 5070172 332464 16292 S 0.0 0.2 0:06.03 C1 CompilerThre 64 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.13 Service Thread 65 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.41 VM Periodic Tas 69 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 Log4j2-Log4j2Sc 74 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 commons-pool-Ev 75 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 Timer-0 76 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 ContainerBackgr 77 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 container-0 78 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 Thread-6 79 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.00 pool-9-thread-1 80 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.06 pool-10-thread- 81 work 20 0 5070172 332464 16292 S 0.0 0.2 0:03.46 redisMessageLis 110 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.03 pool-13-thread- 160 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.03 NioBlockingSele 170 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.06 http-nio-0.0.0. 184 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.03 http-nio-0.0.0. 185 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.02 http-nio-0.0.0. 186 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.39 http-nio-0.0.0. 196 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.16 http-nio-0.0.0. 293 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.29 http-nio-0.0.0. 388 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.05 http-nio-0.0.0. 402 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.06 http-nio-0.0.0. 495 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.11 http-nio-0.0.0. 612 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.75 http-nio-0.0.0. 651 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.12 http-nio-0.0.0. 846 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.11 http-nio-0.0.0. 973 work 20 0 5070172 332464 16292 S 0.0 0.2 0:00.10 http-nio-0.0.0. 上图中可以看出pid为5433的线程占了较多的cpu资源，利用jstack命令可以继续查看该线程当前的堆栈状态。 拿到线程的16进制 work@authority-web-v1-7688dc9bf7-kr48z:~$ printf &quot;%x&quot; 5433 1539 work@authority-web-v1-7688dc9bf7-kr48z:~$ jstack命令生成的thread dump信息包含了JVM中所有存活的线程，为了分析指定线程，必须找出对应线程的调用栈，应该如何找？ 在top命令中，已经获取到了占用cpu资源较高的线程pid，将该pid转成16进制的值，在thread dump中每个线程都有一个nid，找到对应的nid即可；隔段时间再执行一次stack命令获取thread dump，区分两份dump是否有差别，在nid=0x1539的线程调用栈中，发现该线程一直在执行HealthController类第48行的calculate方法，得到这个信息，就可以检查对应的代码是否有问题。 work@authority-web-v1-7688dc9bf7-kr48z:~$ jstack 47 2022-04-06 23:11:42 Full thread dump OpenJDK 64-Bit Server VM (25.222-b10 mixed mode): &quot;Attach Listener&quot; #7763 daemon prio&#x3D;9 os_prio&#x3D;0 tid&#x3D;0x00007fba44002000 nid&#x3D;0x1ec2 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE &quot;pool-4-thread-2&quot; #5355 prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba00016000 nid&#x3D;0x153a waiting for monitor entry [0x00007fb9dbdfc000] java.lang.Thread.State: BLOCKED (on object monitor) at com.rrc.authority.web.controller.HealthController$Task.run(HealthController.java:41) - waiting to lock &lt;0x00000000fbe5dd70&gt; (a java.lang.Object) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) &quot;pool-4-thread-1&quot; #5354 prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba0000b000 nid&#x3D;0x1539 runnable [0x00007fb9db5f6000] java.lang.Thread.State: RUNNABLE at com.rrc.authority.web.controller.HealthController$Task.Calculate(HealthController.java:48) at com.rrc.authority.web.controller.HealthController$Task.run(HealthController.java:41) - locked &lt;0x00000000fbe5dd70&gt; (a java.lang.Object) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) &quot;Okio Watchdog&quot; #4584 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9c8237800 nid&#x3D;0x1223 in Object.wait() [0x00007fb9db1f4000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.Object.wait(Object.java:502) at okio.AsyncTimeout.awaitTimeout(AsyncTimeout.java:338) - locked &lt;0x00000000fa902db0&gt; (a java.lang.Class for okio.AsyncTimeout) at okio.AsyncTimeout$Watchdog.run(AsyncTimeout.java:313) &quot;Abandoned connection cleanup thread&quot; #1216 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9c8134000 nid&#x3D;0x4f2 in Object.wait() [0x00007fb9dbbfa000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144) - locked &lt;0x00000000fd104958&gt; (a java.lang.ref.ReferenceQueue$Lock) at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43) &quot;Tomcat JDBC Pool Cleaner[1112280004:1649256969328]&quot; #1215 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9c804d800 nid&#x3D;0x4f1 in Object.wait() [0x00007fb9db9f8000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.util.TimerThread.mainLoop(Timer.java:552) - locked &lt;0x00000000fd104970&gt; (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:505) &quot;http-nio-0.0.0.0-8088-exec-10&quot; #923 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9e4018800 nid&#x3D;0x3cd waiting on condition [0x00007fb9dbaf9000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd1049a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-exec-9&quot; #796 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9e4027800 nid&#x3D;0x34e waiting on condition [0x00007fb9dbefd000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd1049a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-exec-8&quot; #601 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9e4026800 nid&#x3D;0x28b waiting on condition [0x00007fba24960000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd1049a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-exec-7&quot; #562 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9e4025800 nid&#x3D;0x264 waiting on condition [0x00007fb9dbcfb000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd1049a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-exec-6&quot; #445 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9e4024800 nid&#x3D;0x1ef waiting on condition [0x00007fb9dbffe000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd1049a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-exec-5&quot; #352 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9e4023800 nid&#x3D;0x192 waiting on condition [0x00007fba24d64000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd1049a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-exec-4&quot; #338 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9e4022800 nid&#x3D;0x184 waiting on condition [0x00007fba24c63000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd1049a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-exec-3&quot; #243 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9e4021800 nid&#x3D;0x125 waiting on condition [0x00007fba2415a000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd1049a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-exec-2&quot; #146 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9e4021000 nid&#x3D;0xc4 waiting on condition [0x00007fba2475e000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd1049a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;DestroyJavaVM&quot; #136 prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba8400d800 nid&#x3D;0x30 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE &quot;http-nio-0.0.0.0-8088-exec-1&quot; #135 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fb9e4029000 nid&#x3D;0xba waiting on condition [0x00007fba2425b000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd1049a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-AsyncTimeout&quot; #133 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba855a2800 nid&#x3D;0xb9 waiting on condition [0x00007fba24a61000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at org.apache.coyote.AbstractProtocol$AsyncTimeout.run(AbstractProtocol.java:1137) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-Acceptor-0&quot; #132 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba855a2000 nid&#x3D;0xb8 runnable [0x00007fba24b62000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method) at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422) at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250) - locked &lt;0x00000000fd0fd220&gt; (a java.lang.Object) at org.apache.tomcat.util.net.NioEndpoint$Acceptor.run(NioEndpoint.java:456) at java.lang.Thread.run(Thread.java:748) &quot;http-nio-0.0.0.0-8088-ClientPoller-0&quot; #118 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba84fcc800 nid&#x3D;0xaa runnable [0x00007fba2445d000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) - locked &lt;0x00000000fd0fd088&gt; (a sun.nio.ch.Util$3) - locked &lt;0x00000000fd0fd070&gt; (a java.util.Collections$UnmodifiableSet) - locked &lt;0x00000000fd1380b8&gt; (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) at org.apache.tomcat.util.net.NioEndpoint$Poller.run(NioEndpoint.java:790) at java.lang.Thread.run(Thread.java:748) &quot;NioBlockingSelector.BlockPoller-1&quot; #108 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba85611800 nid&#x3D;0xa0 runnable [0x00007fba2435c000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) - locked &lt;0x00000000fd0fcef0&gt; (a sun.nio.ch.Util$3) - locked &lt;0x00000000fd0fced8&gt; (a java.util.Collections$UnmodifiableSet) - locked &lt;0x00000000fd138148&gt; (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) at org.apache.tomcat.util.net.NioBlockingSelector$BlockPoller.run(NioBlockingSelector.java:339) &quot;pool-13-thread-1&quot; #58 prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba857a6000 nid&#x3D;0x6e waiting on condition [0x00007fba2485f000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fd0e8a68&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) &quot;redisMessageListenerContainer-1&quot; #29 prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba85612800 nid&#x3D;0x51 runnable [0x00007fba24e65000] java.lang.Thread.State: RUNNABLE at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:171) at java.net.SocketInputStream.read(SocketInputStream.java:141) at java.net.SocketInputStream.read(SocketInputStream.java:127) at redis.clients.util.RedisInputStream.ensureFill(RedisInputStream.java:195) at redis.clients.util.RedisInputStream.readByte(RedisInputStream.java:40) at redis.clients.jedis.Protocol.process(Protocol.java:141) at redis.clients.jedis.Protocol.read(Protocol.java:205) at redis.clients.jedis.Connection.readProtocolWithCheckingBroken(Connection.java:297) at redis.clients.jedis.Connection.getRawObjectMultiBulkReply(Connection.java:242) at redis.clients.jedis.BinaryJedisPubSub.process(BinaryJedisPubSub.java:87) at redis.clients.jedis.BinaryJedisPubSub.proceedWithPatterns(BinaryJedisPubSub.java:75) at redis.clients.jedis.BinaryJedis.psubscribe(BinaryJedis.java:2989) at org.springframework.data.redis.connection.jedis.JedisConnection.pSubscribe(JedisConnection.java:3050) at org.springframework.data.redis.listener.RedisMessageListenerContainer$SubscriptionTask.eventuallyPerformSubscription(RedisMessageListenerContainer.java:779) at org.springframework.data.redis.listener.RedisMessageListenerContainer$SubscriptionTask.run(RedisMessageListenerContainer.java:746) at java.lang.Thread.run(Thread.java:748) &quot;pool-10-thread-1&quot; #28 prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba85cc4000 nid&#x3D;0x50 waiting on condition [0x00007fba25166000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fc9a1f00&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) &quot;pool-9-thread-1&quot; #27 prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba84ebd000 nid&#x3D;0x4f waiting on condition [0x00007fba483f9000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fc8f1d50&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492) at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680) at sun.nio.fs.AbstractWatchService.take(AbstractWatchService.java:118) at com.renrenche.config.refresh.LocalMonitor.watchFile(LocalMonitor.java:57) at com.renrenche.config.refresh.LocalMonitor.run(LocalMonitor.java:46) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) &quot;Thread-6&quot; #26 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba85ca9000 nid&#x3D;0x4e runnable [0x00007fba26eea000] java.lang.Thread.State: RUNNABLE at sun.nio.fs.LinuxWatchService.poll(Native Method) at sun.nio.fs.LinuxWatchService.access$600(LinuxWatchService.java:47) at sun.nio.fs.LinuxWatchService$Poller.run(LinuxWatchService.java:314) at java.lang.Thread.run(Thread.java:748) &quot;container-0&quot; #25 prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba84c78800 nid&#x3D;0x4d waiting on condition [0x00007fba268e6000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at org.apache.catalina.core.StandardServer.await(StandardServer.java:427) at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer$1.run(TomcatEmbeddedServletContainer.java:166) &quot;ContainerBackgroundProcessor[StandardEngine[Tomcat]]&quot; #24 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba84734000 nid&#x3D;0x4c waiting on condition [0x00007fba269e7000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.run(ContainerBase.java:1339) at java.lang.Thread.run(Thread.java:748) &quot;Timer-0&quot; #23 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba1c3b5000 nid&#x3D;0x4b in Object.wait() [0x00007fba26de9000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.util.TimerThread.mainLoop(Timer.java:552) - locked &lt;0x00000000fa673d48&gt; (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:505) &quot;commons-pool-EvictionTimer&quot; #22 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba1c09e000 nid&#x3D;0x4a in Object.wait() [0x00007fba26ce8000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.util.TimerThread.mainLoop(Timer.java:552) - locked &lt;0x00000000fa394b50&gt; (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:505) &quot;Log4j2-Log4j2Scheduled-3&quot; #17 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba848b3800 nid&#x3D;0x45 waiting on condition [0x00007fba486fa000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000fa48b5e8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) &quot;Service Thread&quot; #12 daemon prio&#x3D;9 os_prio&#x3D;0 tid&#x3D;0x00007fba84268000 nid&#x3D;0x40 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE &quot;C1 CompilerThread1&quot; #11 daemon prio&#x3D;9 os_prio&#x3D;0 tid&#x3D;0x00007fba8425b000 nid&#x3D;0x3f waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE &quot;C2 CompilerThread0&quot; #10 daemon prio&#x3D;9 os_prio&#x3D;0 tid&#x3D;0x00007fba8425a800 nid&#x3D;0x3e waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE &quot;Thread-2&quot; #9 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba38001000 nid&#x3D;0x3d runnable [0x00007fba6c1d5000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) - locked &lt;0x00000000f98c50b0&gt; (a sun.nio.ch.Util$3) - locked &lt;0x00000000f98c5098&gt; (a java.util.Collections$UnmodifiableSet) - locked &lt;0x00000000f98c6de0&gt; (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) at sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:352) at java.lang.Thread.run(Thread.java:748) &quot;server-timer&quot; #7 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007fba84243800 nid&#x3D;0x3b in Object.wait() [0x00007fba6c3d7000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.util.TimerThread.mainLoop(Timer.java:552) - locked &lt;0x00000000f98e5f90&gt; (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:505) &quot;Signal Dispatcher&quot; #5 daemon prio&#x3D;9 os_prio&#x3D;0 tid&#x3D;0x00007fba84126000 nid&#x3D;0x3a runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE &quot;Surrogate Locker Thread (Concurrent GC)&quot; #4 daemon prio&#x3D;9 os_prio&#x3D;0 tid&#x3D;0x00007fba84124800 nid&#x3D;0x39 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE &quot;Finalizer&quot; #3 daemon prio&#x3D;8 os_prio&#x3D;0 tid&#x3D;0x00007fba840f0800 nid&#x3D;0x38 in Object.wait() [0x00007fba6ceb2000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144) - locked &lt;0x00000000f9a8b6f8&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216) &quot;Reference Handler&quot; #2 daemon prio&#x3D;10 os_prio&#x3D;0 tid&#x3D;0x00007fba840ee000 nid&#x3D;0x37 in Object.wait() [0x00007fba6cfb3000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x00000000f9a8b728&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153) &quot;VM Thread&quot; os_prio&#x3D;0 tid&#x3D;0x00007fba840e4000 nid&#x3D;0x36 runnable &quot;Gang worker#0 (Parallel GC Threads)&quot; os_prio&#x3D;0 tid&#x3D;0x00007fba8401e800 nid&#x3D;0x31 runnable &quot;Gang worker#1 (Parallel GC Threads)&quot; os_prio&#x3D;0 tid&#x3D;0x00007fba84020000 nid&#x3D;0x32 runnable &quot;Concurrent Mark-Sweep GC Thread&quot; os_prio&#x3D;0 tid&#x3D;0x00007fba84051000 nid&#x3D;0x35 runnable &quot;Gang worker#0 (Parallel CMS Threads)&quot; os_prio&#x3D;0 tid&#x3D;0x00007fba8404d800 nid&#x3D;0x33 runnable &quot;Gang worker#1 (Parallel CMS Threads)&quot; os_prio&#x3D;0 tid&#x3D;0x00007fba8404f000 nid&#x3D;0x34 runnable &quot;VM Periodic Task Thread&quot; os_prio&#x3D;0 tid&#x3D;0x00007fba8426a800 nid&#x3D;0x41 waiting on condition JNI global references: 351 work@authority-web-v1-7688dc9bf7-kr48z:~$ 很明显：线程1获取到锁，处于RUNNABLE状态，线程2处于BLOCK状态1、locked &lt;0x00000000fbe5dd70&gt;说明线程1对地址为0x00000000fbe5dd70对象进行了加锁；2、waiting to lock &lt;0x00000000fbe5dd70&gt; 说明线程2在等待地址为0x00000000fbe5dd70对象上的锁；3、waiting for monitor entry [0x00007fb9dbdfc000]说明线程1是通过synchronized关键字进入了监视器的临界区，并处于”Entry Set”队列，等待monitor。 测试代码 package com.tudou.util; import lombok.Synchronized; import java.util.concurrent.Executor; import java.util.concurrent.Executors; public class JstackTest &#123; public static Executor executor &#x3D; Executors.newFixedThreadPool(5); public static Object lock &#x3D; new Object(); public static void main(String[] args) &#123; Task task1 &#x3D; new Task(); Task task2 &#x3D; new Task(); executor.execute(task1); executor.execute(task2); &#125; static class Task implements Runnable &#123; @Override public void run() &#123; synchronized(lock) &#123; &#x2F;&#x2F;Calculate(); try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public void Calculate() &#123; int i &#x3D; 0; while(true) &#123; i++; &#125; &#125; &#125; &#125; 线程1和2都处于WAITING状态1、线程1和2都是先locked &lt;0x000000076bf62500&gt;，再waiting on &lt;0x000000076bf62500&gt;，之所以先锁再等同一个对象，是因为wait方法需要先通过synchronized获得该地址对象的monitor；2、waiting on &lt;0x000000076bf62500&gt;说明线程执行了wait方法之后，释放了monitor，进入到”Wait Set”队列，等待其它线程执行地址为0x000000076bf62500对象的notify方法，并唤醒自己。 jstack Dump 日志文件中的线程状态 dump 文件里，值得关注的线程状态有： 死锁，Deadlock（重点关注） 执行中，Runnable 等待资源，Waiting on condition（重点关注） 等待获取监视器，Waiting on monitor entry（重点关注） 暂停，Suspended 对象等待中，Object.wait() 或 TIMED_WAITING 阻塞，Blocked（重点关注） 停止，Parked 引用 如何使用jstack分析线程状态 一次应用 CPU 飙高的血案排查过程 jstack","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"JAVA配置信息工具jinfo","slug":"jvm-command-jinfo","date":"2022-03-29T09:48:06.000Z","updated":"2022-05-01T17:26:47.275Z","comments":true,"path":"2022/03/29/jvm-command-jinfo/","link":"","permalink":"https://qinglei1989.github.io/2022/03/29/jvm-command-jinfo/","excerpt":"jinfo 是 JDK 自带的命令，可以用来查看正在运行的 java 应用程序的扩展参数，包括Java System属性和JVM命令行参数；也可以动态的修改正在运行的 JVM 一些参数。当系统崩溃时，jinfo可以从core文件里面知道崩溃的Java应用程序的配置信息。 jps -v口令只能查看到显示指定的参数，如果想要查看未被显示指定的参数的值就要使用jinfo口令","text":"jinfo 是 JDK 自带的命令，可以用来查看正在运行的 java 应用程序的扩展参数，包括Java System属性和JVM命令行参数；也可以动态的修改正在运行的 JVM 一些参数。当系统崩溃时，jinfo可以从core文件里面知道崩溃的Java应用程序的配置信息。 jps -v口令只能查看到显示指定的参数，如果想要查看未被显示指定的参数的值就要使用jinfo口令 JAVA配置信息工具jinfo 命令格式 jinfo [option] pid option no option 输出全部的参数和系统属性 -flag name 输出对应名称的参数 -flag [+|-]name 开启或者关闭对应名称的参数 -flag name&#x3D;value 设定对应名称的参数 -flags 输出全部的参数 -sysprops 输出系统属性。 示例 no option work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jinfo 47 Attaching to process ID 47, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.222-b10 Java System Properties: &#x2F;&#x2F; 第一部分: Java System Properties java.runtime.name &#x3D; OpenJDK Runtime Environment java.vm.version &#x3D; 25.222-b10 sun.boot.library.path &#x3D; &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64 java.protocol.handler.pkgs &#x3D; org.springframework.boot.loader java.vendor.url &#x3D; http:&#x2F;&#x2F;java.oracle.com&#x2F; java.vm.vendor &#x3D; Oracle Corporation path.separator &#x3D; : file.encoding.pkg &#x3D; sun.io java.vm.name &#x3D; OpenJDK 64-Bit Server VM sun.os.patch.level &#x3D; unknown sun.java.launcher &#x3D; SUN_STANDARD user.dir &#x3D; &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-schedule&#x2F;lib java.vm.specification.name &#x3D; Java Virtual Machine Specification PID &#x3D; 47 java.runtime.version &#x3D; 1.8.0_222-b10 java.awt.graphicsenv &#x3D; sun.awt.X11GraphicsEnvironment os.arch &#x3D; amd64 java.endorsed.dirs &#x3D; &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;endorsed line.separator &#x3D; java.io.tmpdir &#x3D; &#x2F;tmp java.vm.specification.vendor &#x3D; Oracle Corporation os.name &#x3D; Linux sun.jnu.encoding &#x3D; UTF-8 java.library.path &#x3D; &#x2F;usr&#x2F;java&#x2F;packages&#x2F;lib&#x2F;amd64:&#x2F;usr&#x2F;lib64:&#x2F;lib64:&#x2F;lib:&#x2F;usr&#x2F;lib spring.beaninfo.ignore &#x3D; true java.specification.name &#x3D; Java Platform API Specification java.class.version &#x3D; 52.0 sun.management.compiler &#x3D; HotSpot 64-Bit Tiered Compilers os.version &#x3D; 4.18.20-2.el7.wuba.lp.x86_64 user.home &#x3D; &#x2F;home&#x2F;work user.timezone &#x3D; Asia&#x2F;Shanghai catalina.useNaming &#x3D; false java.awt.printerjob &#x3D; sun.print.PSPrinterJob file.encoding &#x3D; UTF-8 java.specification.version &#x3D; 1.8 catalina.home &#x3D; &#x2F;tmp&#x2F;tomcat.1163525377000352696.8080 org.springframework.boot.logging.LoggingSystem &#x3D; com.renrenche.log.Log4J2LoggingSystemPatch user.name &#x3D; work java.class.path &#x3D; &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-schedule&#x2F;lib&#x2F;authority-schedule.jar:&#x2F;usr&#x2F;local&#x2F;jmx-exporter&#x2F;jmx_prometheus_javaagent-0.14.0.jar java.vm.specification.version &#x3D; 1.8 sun.arch.data.model &#x3D; 64 sun.java.command &#x3D; &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-schedule&#x2F;lib&#x2F;authority-schedule.jar --server.address&#x3D;0.0.0.0 --spring.config.location&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-schedule&#x2F;conf&#x2F; --spring.profiles.active&#x3D;production --logging.config&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-schedule&#x2F;conf&#x2F;log4j2.yml java.home &#x3D; &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre user.language &#x3D; en java.specification.vendor &#x3D; Oracle Corporation sun.misc.URLClassPath.disableJarChecking &#x3D; true awt.toolkit &#x3D; sun.awt.X11.XToolkit java.vm.info &#x3D; mixed mode java.version &#x3D; 1.8.0_222 java.ext.dirs &#x3D; &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;ext:&#x2F;usr&#x2F;java&#x2F;packages&#x2F;lib&#x2F;ext sun.boot.class.path &#x3D; &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;resources.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;rt.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;sunrsasign.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;jsse.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;jce.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;charsets.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;jfr.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;classes java.awt.headless &#x3D; true java.vendor &#x3D; Oracle Corporation catalina.base &#x3D; &#x2F;tmp&#x2F;tomcat.1163525377000352696.8080 file.separator &#x3D; &#x2F; java.vendor.url.bug &#x3D; http:&#x2F;&#x2F;bugreport.sun.com&#x2F;bugreport&#x2F; sun.io.unicode.encoding &#x3D; UnicodeLittle sun.cpu.endian &#x3D; little LOG_PATH &#x3D; &#x2F;mnt&#x2F;logs&#x2F;authority-schedule sun.cpu.isalist &#x3D; VM Flags: &#x2F;&#x2F; 第二部分:jvm 参数 Non-default VM flags: -XX:CICompilerCount&#x3D;2 -XX:CMSInitiatingOccupancyFraction&#x3D;70 -XX:+CMSParallelRemarkEnabled -XX:+CMSScavengeBeforeRemark -XX:ConcGCThreads&#x3D;2 -XX:ErrorFile&#x3D;null -XX:GCLogFileSize&#x3D;52428800 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;null -XX:InitialHeapSize&#x3D;645922816 -XX:InitialRAMPercentage&#x3D;null -XX:MaxHeapSize&#x3D;645922816 -XX:MaxNewSize&#x3D;174456832 -XX:MaxRAMPercentage&#x3D;null -XX:MaxTenuringThreshold&#x3D;6 -XX:MinHeapDeltaBytes&#x3D;196608 -XX:MinRAMPercentage&#x3D;null -XX:NewSize&#x3D;174456832 -XX:NumberOfGCLogFiles&#x3D;1 -XX:OldPLABSize&#x3D;16 -XX:OldSize&#x3D;471465984 -XX:ParallelGCThreads&#x3D;2 -XX:+PrintGC -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -XX:+ScavengeBeforeFullGC -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseGCLogFileRotation -XX:+UseParNewGC Command line: -Dsun.misc.URLClassPath.disableJarChecking&#x3D;true -DLOG_PATH&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-schedule -XX:MaxRAMPercentage&#x3D;30.0 -XX:InitialRAMPercentage&#x3D;30.0 -XX:MinRAMPercentage&#x3D;30.0 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-schedule&#x2F;jvm -XX:ErrorFile&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-schedule&#x2F;jvm&#x2F;jvm_err.log -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:ConcGCThreads&#x3D;2 -XX:ParallelGCThreads&#x3D;2 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction&#x3D;70 -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles&#x3D;1 -XX:GCLogFileSize&#x3D;50M -verbose:gc -XX:+PrintHeapAtGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime -Xloggc:&#x2F;mnt&#x2F;logs&#x2F;authority-schedule&#x2F;jvm&#x2F;gc.log -javaagent:&#x2F;usr&#x2F;local&#x2F;jmx-exporter&#x2F;jmx_prometheus_javaagent-0.14.0.jar&#x3D;9990:&#x2F;usr&#x2F;local&#x2F;jmx-exporter&#x2F;prometheus-jmx-config.yaml -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ -flag name 查看指定的 jvm 参数的值 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jinfo -flag PrintGC 47 -XX:+PrintGC work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jinfo -flag PrintGCDetails 47 -XX:+PrintGCDetails work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jinfo -flag PrintGCTimeStamps 47 -XX:+PrintGCTimeStamps work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ -flag [+|-]name 使用 jinfo 可以在不重启虚拟机的情况下，可以动态的修改 jvm 的参数。尤其在线上的环境特别有用。 work@authority-schedule-v1-679dd585c4-9rsf9:~$ jinfo -flag +PrintGC 47 work@authority-schedule-v1-679dd585c4-9rsf9:~$ work@authority-schedule-v1-679dd585c4-9rsf9:~$ jinfo -flag PrintGC 47 -XX:+PrintGC work@authority-schedule-v1-679dd585c4-9rsf9:~$ jinfo -flag -PrintGC 47 work@authority-schedule-v1-679dd585c4-9rsf9:~$ jinfo -flag PrintGC 47 -XX:-PrintGC work@authority-schedule-v1-679dd585c4-9rsf9:~$ -flag name=value 上一个示例主要是针对 boolean 值的参数设置的。如果是设置 value值，则需要使用 name=value 的形式。 work@authority-schedule-v1-679dd585c4-9rsf9:~$ jinfo -flag HeapDumpPath 47 -XX:HeapDumpPath&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-schedule&#x2F;jvm work@authority-schedule-v1-679dd585c4-9rsf9:~$ jinfo -flag HeapDumpPath&#x3D;&#x2F; 47 work@authority-schedule-v1-679dd585c4-9rsf9:~$ jinfo -flag HeapDumpPath 47 -XX:HeapDumpPath&#x3D;&#x2F; work@authority-schedule-v1-679dd585c4-9rsf9:~$ jinfo -flag HeapDumpPath&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-schedule&#x2F;jvm 47 work@authority-schedule-v1-679dd585c4-9rsf9:~$ jinfo -flag HeapDumpPath 47 -XX:HeapDumpPath&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-schedule&#x2F;jvm -sysprops 输出当前 jvm 进行的全部的系统属性 work@authority-schedule-v1-679dd585c4-9rsf9:~$ jinfo -sysprops 47 Attaching to process ID 47, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.222-b10 java.runtime.name &#x3D; OpenJDK Runtime Environment java.vm.version &#x3D; 25.222-b10 sun.boot.library.path &#x3D; &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;amd64 java.protocol.handler.pkgs &#x3D; org.springframework.boot.loader java.vendor.url &#x3D; http:&#x2F;&#x2F;java.oracle.com&#x2F; java.vm.vendor &#x3D; Oracle Corporation path.separator &#x3D; : file.encoding.pkg &#x3D; sun.io java.vm.name &#x3D; OpenJDK 64-Bit Server VM sun.os.patch.level &#x3D; unknown sun.java.launcher &#x3D; SUN_STANDARD user.dir &#x3D; &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-schedule&#x2F;lib java.vm.specification.name &#x3D; Java Virtual Machine Specification PID &#x3D; 47 java.runtime.version &#x3D; 1.8.0_222-b10 java.awt.graphicsenv &#x3D; sun.awt.X11GraphicsEnvironment os.arch &#x3D; amd64 java.endorsed.dirs &#x3D; &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;endorsed line.separator &#x3D; java.io.tmpdir &#x3D; &#x2F;tmp java.vm.specification.vendor &#x3D; Oracle Corporation os.name &#x3D; Linux sun.jnu.encoding &#x3D; UTF-8 java.library.path &#x3D; &#x2F;usr&#x2F;java&#x2F;packages&#x2F;lib&#x2F;amd64:&#x2F;usr&#x2F;lib64:&#x2F;lib64:&#x2F;lib:&#x2F;usr&#x2F;lib spring.beaninfo.ignore &#x3D; true java.specification.name &#x3D; Java Platform API Specification java.class.version &#x3D; 52.0 sun.management.compiler &#x3D; HotSpot 64-Bit Tiered Compilers os.version &#x3D; 4.18.20-2.el7.wuba.lp.x86_64 user.home &#x3D; &#x2F;home&#x2F;work user.timezone &#x3D; Asia&#x2F;Shanghai catalina.useNaming &#x3D; false java.awt.printerjob &#x3D; sun.print.PSPrinterJob file.encoding &#x3D; UTF-8 java.specification.version &#x3D; 1.8 catalina.home &#x3D; &#x2F;tmp&#x2F;tomcat.1577318281902238479.8082 org.springframework.boot.logging.LoggingSystem &#x3D; com.renrenche.log.Log4J2LoggingSystemPatch user.name &#x3D; work java.class.path &#x3D; &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-schedule&#x2F;lib&#x2F;authority-schedule.jar:&#x2F;usr&#x2F;local&#x2F;jmx-exporter&#x2F;jmx_prometheus_javaagent-0.14.0.jar java.vm.specification.version &#x3D; 1.8 sun.arch.data.model &#x3D; 64 sun.java.command &#x3D; &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-schedule&#x2F;lib&#x2F;authority-schedule.jar --server.address&#x3D;0.0.0.0 --spring.config.location&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-schedule&#x2F;conf&#x2F; --spring.profiles.active&#x3D;testing --logging.config&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-schedule&#x2F;conf&#x2F;log4j2.yml java.home &#x3D; &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre user.language &#x3D; en java.specification.vendor &#x3D; Oracle Corporation sun.misc.URLClassPath.disableJarChecking &#x3D; true awt.toolkit &#x3D; sun.awt.X11.XToolkit java.vm.info &#x3D; mixed mode java.version &#x3D; 1.8.0_222 java.ext.dirs &#x3D; &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;ext:&#x2F;usr&#x2F;java&#x2F;packages&#x2F;lib&#x2F;ext sun.boot.class.path &#x3D; &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;resources.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;rt.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;sunrsasign.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;jsse.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;jce.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;charsets.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;lib&#x2F;jfr.jar:&#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;jre&#x2F;classes java.awt.headless &#x3D; true java.vendor &#x3D; Oracle Corporation catalina.base &#x3D; &#x2F;tmp&#x2F;tomcat.1577318281902238479.8082 file.separator &#x3D; &#x2F; java.vendor.url.bug &#x3D; http:&#x2F;&#x2F;bugreport.sun.com&#x2F;bugreport&#x2F; sun.io.unicode.encoding &#x3D; UnicodeLittle sun.cpu.endian &#x3D; little LOG_PATH &#x3D; &#x2F;mnt&#x2F;logs&#x2F;authority-schedule sun.cpu.isalist &#x3D; work@authority-schedule-v1-679dd 注意 jinfo虽然可以在java程序运行时动态地修改虚拟机参数，但并不是所有的参数都支持动态修改。参数只有被标记 manageable的flag可以被实时修改。 查看被标记为manageable的参数 work@authority-schedule-v1-679dd585c4-9rsf9:~$ java -XX:+PrintFlagsFinal -version | grep manageable intx CMSAbortablePrecleanWaitMillis &#x3D; 100 &#123;manageable&#125; intx CMSTriggerInterval &#x3D; -1 &#123;manageable&#125; intx CMSWaitDuration &#x3D; 2000 &#123;manageable&#125; bool HeapDumpAfterFullGC &#x3D; false &#123;manageable&#125; bool HeapDumpBeforeFullGC &#x3D; false &#123;manageable&#125; bool HeapDumpOnOutOfMemoryError &#x3D; false &#123;manageable&#125; ccstr HeapDumpPath &#x3D; &#123;manageable&#125; uintx MaxHeapFreeRatio &#x3D; 70 &#123;manageable&#125; uintx MinHeapFreeRatio &#x3D; 40 &#123;manageable&#125; bool PrintClassHistogram &#x3D; false &#123;manageable&#125; bool PrintClassHistogramAfterFullGC &#x3D; false &#123;manageable&#125; bool PrintClassHistogramBeforeFullGC &#x3D; false &#123;manageable&#125; bool PrintConcurrentLocks &#x3D; false &#123;manageable&#125; bool PrintGC &#x3D; false &#123;manageable&#125; bool PrintGCDateStamps &#x3D; false &#123;manageable&#125; bool PrintGCDetails &#x3D; false &#123;manageable&#125; bool PrintGCID &#x3D; false &#123;manageable&#125; bool PrintGCTimeStamps &#x3D; false &#123;manageable&#125; openjdk version &quot;1.8.0_222&quot; OpenJDK Runtime Environment (build 1.8.0_222-b10) OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode) work@authority-schedule-v1-679dd585c4-9rsf9:~$ 引用 jinfo介绍 jvm 性能调优工具之 jinfo","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"线程池","slug":"java-thread-factory","date":"2022-03-29T04:17:31.000Z","updated":"2022-03-29T02:58:45.164Z","comments":true,"path":"2022/03/29/java-thread-factory/","link":"","permalink":"https://qinglei1989.github.io/2022/03/29/java-thread-factory/","excerpt":"线程的创建和销毁都需要映射到操作系统，因此其代价是比较高昂的。出于避免频繁创建、销毁线程以及方便线程管理的需要，线程池应运而生。 在项目工程中，基于池化思想的技术应用很多，例如基于线程池的任务并发执行，中间件服务的连接池配置，通过对共享资源的管理，降低资源的占用消耗，提升效率和服务性能。","text":"线程的创建和销毁都需要映射到操作系统，因此其代价是比较高昂的。出于避免频繁创建、销毁线程以及方便线程管理的需要，线程池应运而生。 在项目工程中，基于池化思想的技术应用很多，例如基于线程池的任务并发执行，中间件服务的连接池配置，通过对共享资源的管理，降低资源的占用消耗，提升效率和服务性能。 线程池 线程池 在内存中频繁的创建和销毁对象是很影响性能的，而线程作为进程中运行的基本单位，通过线程池的方式重复使用已创建的线程，在任务执行动作上避免或减少线程的频繁创建动作。 线程池中维护多个线程，当收到调度任务时可以避免创建线程直接执行，并以此降低服务资源的消耗，把相对不确定的并发任务管理在相对确定的线程池中，提高系统服务的稳定性。 原理 Executor 接口 public interface Executor &#123; void execute(Runnable command); &#125; 将来会执行命令，任务提交和执行两个动作会被解耦，传入Runnable任务对象即可，线程池会执行相应调度和任务处理。Executor虽然是ThreadPoolExecutor线程池的顶层接口，但是其本身只是抽象了任务的处理思想。 ExecutorService 接口 扩展Executor接口，单个或批量的给任务的执行结果生成Future，并增添任务中断或终止的管理方法。 package java.util.concurrent; import java.util.List; import java.util.Collection; public interface ExecutorService extends Executor &#123; void shutdown(); List&lt;Runnable&gt; shutdownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; &#125; AbstractExecutorService 抽象类 提供对ExecutorService接口定义的任务执行方法（submit，invokeAll）等默认实现，提供newTaskFor方法用于构建RunnableFuture对象。 ThreadPoolExecutor 类 维护线程池生命周期，管理线程和任务，通过相应调度机制实现任务的并发执行。 ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 public class ThreadPoolExecutor extends AbstractExecutorService &#123; public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); &#125; 生命周期 这里从源码开始逐步分析线程池的核心逻辑，首先看看对于生命周期的状态描述，涉及如下几个核心字段： private final AtomicInteger ctl &#x3D; new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS &#x3D; Integer.SIZE - 3; private static final int CAPACITY &#x3D; (1 &lt;&lt; COUNT_BITS) - 1; &#x2F;&#x2F; 状态描述 &#x2F;&#x2F; ctl高3位为111 接受新的任务并处理阻塞队列中的任务 private static final int RUNNING &#x3D; -1 &lt;&lt; COUNT_BITS; &#x2F;&#x2F; ctl高3位为000 不接受新任务但是处理阻塞队列中的任务 private static final int SHUTDOWN &#x3D; 0 &lt;&lt; COUNT_BITS; &#x2F;&#x2F; ctl高3位为001 不接受新任务也不处理阻塞队列中的任务并且中断所有线程池中正在运行的任务 private static final int STOP &#x3D; 1 &lt;&lt; COUNT_BITS; &#x2F;&#x2F; ctl高3位为010 所有任务都被终止，工作线程为0 private static final int TIDYING &#x3D; 2 &lt;&lt; COUNT_BITS; &#x2F;&#x2F; ctl高3位为011 不接受新任务也不处理阻塞队列中的任务并且中断所有线程池中正在运行的任务 private static final int TERMINATED &#x3D; 3 &lt;&lt; COUNT_BITS; &#x2F;&#x2F;在某些情况下用来存储任务，并将任务提供给线程池中的工作线程 private final BlockingQueue&lt;Runnable&gt; workQueue; &#x2F;&#x2F;用来对pooSize、corePoolSize、maximumPoolSize、runState、workers修改时候同步 private final ReentrantLock mainLock &#x3D; new ReentrantLock(); &#x2F;&#x2F;线程池中所有线程的集合，访问和修改需要mainLock的配合 private final HashSet&lt;Worker&gt; workers &#x3D; new HashSet&lt;Worker&gt;(); &#x2F;&#x2F;用来支持waitTemination private final Condition termination &#x3D; mainLock.newCondition(); &#x2F;&#x2F;跟踪线程池中线程的最大值，具体的猜测是为了矫正poolsize，访问和修改需要配合mainLock private int largestPoolSize; &#x2F;&#x2F;已完成任务的数量，在任务处于Terminate状态时才更新，访问和修改需要mainLock的配合 private long completedTaskCount; &#x2F;&#x2F;线程工厂，用户可以自定义，以便在想线程池创建线程时附加一些个人操作 private volatile ThreadFactory threadFactory; &#x2F;&#x2F;当线程池处于shutdown或者处于饱和时执行的拒绝策略 private volatile RejectedExecutionHandler handler; &#x2F;&#x2F;设置线程池中空闲线程等待多时毫秒被回收 private volatile long keepAliveTime; &#x2F;&#x2F;指定线程池中的空闲线程是否一段时间被回收，false一直存活 private volatile boolean allowCoreThreadTimeOut; &#x2F;&#x2F;核心线程池大小，若allowCoreThreadTimeOut被设置，全部空闲超时被回收的情况下会为0 private volatile int corePoolSize; &#x2F;&#x2F;最大线程池大小，不得超过CAPACITY private volatile int maximumPoolSize; ctl控制线程池的状态，包含两个概念字段：workerCount线程池内有效线程数，runState运行状态，具体的运行有5种状态描述： RUNNING：接受新任务，处理阻塞队列中的任务； SHUTDOWN：不接受新任务，处理阻塞队列中已存在的任务； STOP：不接受新任务，不处理阻塞队列中的任务，中断正在进行的任务； TIDYING：所有任务都已终止，workerCount=0，线程池进入该状态后会执行terminated()方法； TERMINATED: 执行terminated()方法完后进入该状态； 线程池总共有5种状态，用int值的高3位来表示线程状态。剩下29个就可以表示线程数量（所以线程数量最大值就是29位上全是1）。 所以ctl的值为： private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 那么又是读取线程状态和数量的值呢,以下参数c即ctl：读取状态利用以下方法： private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125; 读取线程数量利用以下方法： private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; CAPACITY的值为(00011111 11111111 11111111 11111111)； 状态之间的转换逻辑如下： 任务调度 调度逻辑 从整体上看，任务调度被放在三个分支步骤中判断，即：核心线程池、任务队列、拒绝策略，下面再细看每个分支的处理逻辑； public void execute(Runnable command) &#123; if (command &#x3D;&#x3D; null) throw new NullPointerException(); &#x2F;&#x2F; 上文描述的workerCount与runState int c &#x3D; ctl.get(); &#x2F;&#x2F; 核心线程池 if (workerCountOf(c) &lt; corePoolSize) &#123; &#x2F;&#x2F; 如果有效线程数小于核心线程数，新建线程并绑定当前任务 if (addWorker(command, true)) return; &#x2F;* 添加失败（可能是线程池状态是SHUTDOWN或以上的状态（SHUTDOWN状态下不再接收 新任务），也可能是线程数超过阈值了），就重新获取一下ctl的值，走下面的逻辑 *&#x2F; c &#x3D; ctl.get(); &#125; &#x2F;&#x2F; 任务队列 &#x2F;* 走到这里说明当前线程数大于等于核心线程数，又或者是上面添加核心线程失败中解释的情况 此时就判断一下当前线程池是否是RUNNING状态，如果是的话就往阻塞队列入队 这里offer跟put的区别是如果队列已满，offer不会被阻塞，而是立即返回false *&#x2F; &#x2F;&#x2F; 如果线程池是运行状态，并且任务添加队列成功 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; &#x2F;&#x2F; 二次校验如果是非运行状态，则移除该任务，执行拒绝策略 int recheck &#x3D; ctl.get(); &#x2F;* 这里会再次检查一次当前线程池是否是RUNNING状态，可能此时线程池已经shutdown了 如果不是RUNNING状态，就删除上面入队的任务，并执行相应的拒绝策略 *&#x2F; if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); &#x2F;&#x2F; 如果有效线程数是0，执行addWorker添加方法 &#x2F;* 此时还会去判断一下是否当前的工作线程数已经为0了（可能这些线程在上次workerCountOf 检查后（第10行代码处）被销毁了（allowCoreThreadTimeOut设置为true）），如果是 的话就新创建一个空任务的非核心线程。注意，这里传进addWorker方法的是空任务，因为任务 已经在阻塞队列中存在了，所以这个Worker执行的时候，会直接从阻塞队列中取出任务来执行 所以说这里的意义也就是要保证线程池在RUNNING状态下必须要有一个线程来执行任务 *&#x2F; else if (workerCountOf(recheck) &#x3D;&#x3D; 0) addWorker(null, false); &#125; &#x2F;&#x2F; 拒绝策略 &#x2F;&#x2F; 再次执行addWorker方法，如果失败则拒绝该任务 &#x2F;* 走到这里说明线程池不是RUNNING状态，或者阻塞队列已满，此时创建一个非核心线程去执行 如果创建失败，说明线程池的状态已经不是RUNNING了，又或者当前线程数已经大于等于最大线程数了 那么就执行相应的拒绝策略 *&#x2F; else if (!addWorker(command, false)) reject(command); &#125; Worker线程 线程池内工作线程被封装在Worker类中，继承AQS并实现Runnable接口，维护线程的创建和任务的执行： private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; &#x2F;&#x2F; 持有线程 final Thread thread; &#x2F;&#x2F; 初始化任务 Runnable firstTask; addWorker(Runnable firstTask, boolean core) 方法，顾名思义，向线程池添加一个带有任务的工作线程。 private boolean addWorker(Runnable firstTask, boolean core) &#123; &#x2F;&#x2F; 外层循环：判断线程池状态 retry: for (;;) &#123; int c &#x3D; ctl.get(); int rs &#x3D; runStateOf(c); &#x2F;** * 1.线程池为非Running状态（Running状态则既可以新增核心线程也可以接受任务） * 2.线程为shutdown状态且firstTask为空且队列不为空 * 3.满足条件1且条件2不满足，则返回false * 4.条件2解读：线程池为shutdown状态时且任务队列不为空时，可以新增空任务的线程来处理队列中的任务 *&#x2F; if (rs &gt;&#x3D; SHUTDOWN &amp;&amp; ! (rs &#x3D;&#x3D; SHUTDOWN &amp;&amp; firstTask &#x3D;&#x3D; null &amp;&amp; ! workQueue.isEmpty())) return false; &#x2F;&#x2F; 内层循环：线程池添加核心线程并返回是否添加成功的结果 for (;;) &#123; int wc &#x3D; workerCountOf(c); &#x2F;&#x2F; 校验线程池已有线程数量是否超限： &#x2F;&#x2F; 1.线程池最大上限CAPACITY &#x2F;&#x2F; 2.corePoolSize或maximumPoolSize（取决于入参core） if (wc &gt;&#x3D; CAPACITY || wc &gt;&#x3D; (core ? corePoolSize : maximumPoolSize)) return false; &#x2F;&#x2F; 通过CAS操作使工作线程数+1，跳出外层循环 if (compareAndIncrementWorkerCount(c)) break retry; &#x2F;&#x2F; 线程+1失败，重读ctl c &#x3D; ctl.get(); &#x2F;&#x2F; Re-read ctl &#x2F;&#x2F; 如果此时线程池状态不再是running，则重新进行外层循环 if (runStateOf(c) !&#x3D; rs) continue retry; &#x2F;&#x2F; else CAS failed due to workerCount change; retry inner loop &#125; &#125; &#x2F;** * 核心线程数量+1成功的后续操作：添加到工作线程集合，并启动工作线程 *&#x2F; boolean workerStarted &#x3D; false; boolean workerAdded &#x3D; false; Worker w &#x3D; null; try &#123; w &#x3D; new Worker(firstTask); final Thread t &#x3D; w.thread; if (t !&#x3D; null) &#123; &#x2F;&#x2F; 下面代码需要加锁：线程池主锁 final ReentrantLock mainLock &#x3D; this.mainLock; mainLock.lock(); try &#123; &#x2F;&#x2F; 持锁期间重新检查，线程工厂创建线程失败或获取锁之前关闭的情况发生时，退出 int rs &#x3D; runStateOf(ctl.get()); &#x2F;&#x2F; 再次检验线程池是否是running状态或线程池shutdown但线程任务为空 if (rs &lt; SHUTDOWN || (rs &#x3D;&#x3D; SHUTDOWN &amp;&amp; firstTask &#x3D;&#x3D; null)) &#123; &#x2F;&#x2F; 线程已经启动，则抛出非法线程状态异常 &#x2F;&#x2F; 为什么会存在这种状态呢？未解决 if (t.isAlive()) &#x2F;&#x2F; precheck that t is startable throw new IllegalThreadStateException(); &#x2F;&#x2F;加入线程池 workers.add(w); int s &#x3D; workers.size(); &#x2F;&#x2F; 如果当前工作线程数超过线程池曾经出现过的最大线程数，刷新后者值 if (s &gt; largestPoolSize) largestPoolSize &#x3D; s; workerAdded &#x3D; true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; &#x2F;&#x2F; 工作线程添加成功，启动该线程 if (workerAdded) &#123; t.start(); workerStarted &#x3D; true; &#125; &#125; &#125; finally &#123; &#x2F;&#x2F;线程启动失败，则进入addWorkerFailed if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125; getTask()方法 getTask()方法是工作线程在while死循环中获取任务队列中的任务对象的方法 final void runWorker(Worker w) &#123; Thread wt &#x3D; Thread.currentThread(); Runnable task &#x3D; w.firstTask; w.firstTask &#x3D; null; &#x2F;&#x2F; allow interrupts &#x2F;&#x2F; new Worker()是state&#x3D;&#x3D;-1，此处是调用Worker类的tryRelease()方法，将state置为0，而interruptIfStarted()中只有state&gt;&#x3D;0才允许调用中断 w.unlock(); &#x2F;&#x2F; 线程退出的原因，true是任务导致，false是线程正常退出 boolean completedAbruptly &#x3D; true; try &#123; &#x2F;&#x2F; 当前任务和从任务队列中获取的任务都为空，方停止循环 while (task !&#x3D; null || (task &#x3D; getTask()) !&#x3D; null) &#123; &#x2F;&#x2F;上锁可以防止在shutdown()时终止正在运行的worker，而不是应对并发 w.lock(); &#x2F;&#x2F; If pool is stopping, ensure thread is interrupted; &#x2F;&#x2F; if not, ensure thread is not interrupted. This &#x2F;&#x2F; requires a recheck in second case to deal with &#x2F;&#x2F; shutdownNow race while clearing interrupt &#x2F;** * 判断1：确保只有在线程处于stop状态且wt未中断时，wt才会被设置中断标识 * 条件1：线程池状态&gt;&#x3D;STOP,即STOP或TERMINATED * 条件2：一开始判断线程池状态&lt;STOP，接下来检查发现Thread.interrupted()为true，即线程已经被中断，再次检查线程池状态是否&gt;&#x3D;STOP（以消除该瞬间shutdown方法生效，使线程池处于STOP或TERMINATED）， * 条件1与条件2任意满意一个，且wt不是中断状态，则中断wt，否则进入下一步 *&#x2F; if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); &#x2F;&#x2F;当前线程调用interrupt()中断 try &#123; &#x2F;&#x2F;执行前（空方法，由子类重写实现） beforeExecute(wt, task); Throwable thrown &#x3D; null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown &#x3D; x; throw x; &#125; catch (Error x) &#123; thrown &#x3D; x; throw x; &#125; catch (Throwable x) &#123; thrown &#x3D; x; throw new Error(x); &#125; finally &#123; &#x2F;&#x2F;执行后（空方法，由子类重写实现） afterExecute(task, thrown); &#125; &#125; finally &#123; task &#x3D; null; w.completedTasks++; &#x2F;&#x2F;完成任务数+1 w.unlock(); &#x2F;&#x2F;释放锁 &#125; &#125; &#x2F;&#x2F; completedAbruptly &#x3D; false; &#125; finally &#123; &#x2F;&#x2F;处理worker的退出 processWorkerExit(w, completedAbruptly); &#125; &#125; private Runnable getTask() &#123; &#x2F;&#x2F; 记录上一次从队列中拉取的时候是否超时 boolean timedOut &#x3D; false; &#x2F;&#x2F; Did the last poll() time out? &#x2F;&#x2F; 注意这是死循环 for (;;) &#123; int c &#x3D; ctl.get(); int rs &#x3D; runStateOf(c); &#x2F;&#x2F; Check if queue empty only if necessary. &#x2F;&#x2F; 第一个if：如果线程池状态至少为SHUTDOWN，也就是rs &gt;&#x3D; SHUTDOWN(0)，则需要判断两种情况（或逻辑）： &#x2F;&#x2F; 1. 线程池状态至少为STOP(1)，也就是线程池正在停止，一般是调用了shutdownNow()方法 &#x2F;&#x2F; 2. 任务队列为空 &#x2F;&#x2F; 如果在线程池至少为SHUTDOWN状态并且满足上面两个条件之一，则工作线程数wc减去1，然后直接返回null if (rs &gt;&#x3D; SHUTDOWN &amp;&amp; (rs &gt;&#x3D; STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; &#x2F;&#x2F; 跑到这里说明线程池还处于RUNNING状态，重新获取一次工作线程数 int wc &#x3D; workerCountOf(c); &#x2F;&#x2F; Are workers subject to culling? &#x2F;&#x2F; timed临时变量用于线程超时控制，决定是否需要通过poll()此带超时的非阻塞方法进行任务队列的任务拉取 &#x2F;&#x2F; 1.allowCoreThreadTimeOut默认值为false，如果设置为true，则允许核心线程也能通过poll()方法从任务队列中拉取任务 &#x2F;&#x2F; 2.工作线程数大于核心线程数的时候，说明线程池中创建了额外的非核心线程，这些非核心线程一定是通过poll()方法从任务队列中拉取任务 boolean timed &#x3D; allowCoreThreadTimeOut || wc &gt; corePoolSize; &#x2F;&#x2F; 第二个if： &#x2F;&#x2F; 1.wc &gt; maximumPoolSize说明当前的工作线程总数大于maximumPoolSize，是通过setMaximumPoolSize()方法减少了线程池容量 &#x2F;&#x2F; 2.timed &amp;&amp; timedOut说明了线程命中了超时控制并且上一轮循环通过poll()方法从任务队列中拉取任务为null &#x2F;&#x2F; 3. 工作线程总数大于1或者任务队列为空，则通过CAS把线程数减去1，同时返回null， &#x2F;&#x2F; CAS把线程数减去1失败会进入下一轮循环做重试 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; &#x2F;&#x2F; 如果timed为true，通过poll()方法做超时拉取，keepAliveTime时间内没有等待到有效的任务，则返回null &#x2F;&#x2F; 如果timed为false，通过take()做阻塞拉取，会阻塞到有下一个有效的任务时候再返回（一般不会是null） Runnable r &#x3D; timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r !&#x3D; null) return r; &#x2F;&#x2F; 跑到这里说明上一次从任务队列中获取到的任务为null，一般是workQueue.poll()方法超时返回null timedOut &#x3D; true; &#125; catch (InterruptedException retry) &#123; timedOut &#x3D; false; &#125; &#125; &#125; processWorkerExit(Worker w, boolean completedAbruptly) private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; &#x2F;** * 1.工作线程-1操作 * 1）如果completedAbruptly 为true，说明工作线程发生异常，那么将正在工作的线程数量-1 * 2）如果completedAbruptly 为false，说明工作线程无任务可以执行，由getTask()执行worker-1操作 *&#x2F; if (completedAbruptly) &#x2F;&#x2F; If abrupt, then workerCount wasn&#39;t adjusted decrementWorkerCount(); &#x2F;&#x2F; 2.从线程set集合中移除工作线程，该过程需要加锁 final ReentrantLock mainLock &#x3D; this.mainLock; mainLock.lock(); try &#123; &#x2F;&#x2F; 将该worker已完成的任务数追加到线程池已完成的任务数 completedTaskCount +&#x3D; w.completedTasks; &#x2F;&#x2F; HashSet&lt;Worker&gt;中移除该worker workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; &#x2F;&#x2F; 3.根据线程池状态进行判断是否结束线程池 tryTerminate(); &#x2F;** * 4.是否需要增加工作线程 * 线程池状态是running 或 shutdown * 如果当前线程是突然终止的，addWorker() * 如果当前线程不是突然终止的，但当前线程数量 &lt; 要维护的线程数量，addWorker() * 故如果调用线程池shutdown()，直到workQueue为空前，线程池都会维持corePoolSize个线程，然后再逐渐销毁这corePoolSize个线程 *&#x2F; int c &#x3D; ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min &#x3D; allowCoreThreadTimeOut ? 0 : corePoolSize; if (min &#x3D;&#x3D; 0 &amp;&amp; ! workQueue.isEmpty()) min &#x3D; 1; if (workerCountOf(c) &gt;&#x3D; min) return; &#x2F;&#x2F; replacement not needed &#125; addWorker(null, false); &#125; &#125; 核心参数7个 corePoolSize：核心线程数。 maximumPoolSize：最大线程数。 keepAliveTime：空闲线程存活时间。 当允许核心线程超时，也就是allowCoreThreadTimeOut设置为true的时候，此时keepAliveTime表示空闲的工作线程的存活周期。 默认情况下不允许核心线程超时，此时keepAliveTime表示空闲的非核心线程的存活周期。 TimeUnit：时间单位。 BlockingQueue：线程池任务队列。 ThreadFactory：创建线程的工厂。 RejectedExecutionHandler：拒绝策略。 defaultThreadFactory默认线程工厂 static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber &#x3D; new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber &#x3D; new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s &#x3D; System.getSecurityManager(); group &#x3D; (s !&#x3D; null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix &#x3D; &quot;pool-&quot; + poolNumber.getAndIncrement() + &quot;-thread-&quot;; &#125; public Thread newThread(Runnable r) &#123; Thread t &#x3D; new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() !&#x3D; Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125; &#125; 默认拒绝策略 private static final RejectedExecutionHandler defaultHandler &#x3D; new AbortPolicy(); public static class AbortPolicy implements RejectedExecutionHandler &#123; &#x2F;** * Creates an &#123;@code AbortPolicy&#125;. *&#x2F; public AbortPolicy() &#123; &#125; &#x2F;** * Always throws RejectedExecutionException. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task * @throws RejectedExecutionException always *&#x2F; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(&quot;Task &quot; + r.toString() + &quot; rejected from &quot; + e.toString()); &#125; &#125; ThreadPoolExecutor提供了动态调整线程池容量大小的方法： 「setCorePoolSize」：设置核心池大小 「setMaximumPoolSize」：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。 拒绝策略：当线程池的任务超出线程池队列可以存储的最大值之后，执行的策略。默认的拒绝策略有以下 4 种： AbortPolicy：拒绝并抛出异常。 CallerRunsPolicy：使用当前调用的线程来执行此任务。 DiscardOldestPolicy：抛弃队列头部（最旧）的一个任务，并执行当前任务。 DiscardPolicy：忽略并抛弃当前任务。 线程池如何配置合理参数 线程数 （1）CPU密集型：定义：CPU密集型的意思就是该任务需要大量运算，而没有阻塞，CPU一直全速运行。 CPU密集型任务只有在真正的多核CPU上才可能得到加速（通过多线程）。 CPU密集型任务配置尽可能少的线程数。 CPU密集型线程数配置公式：(CPU核数+1)个线程的线程池 （2）IO密集型：定义：IO密集型，即该任务需要大量的IO，即大量的阻塞。 在单线程上运行IO密集型任务会导致浪费大量的CPU运算能力浪费在等待。 所以IO密集型任务中使用多线程可以大大的加速程序运行，即使在单核CPU上，这种加速主要利用了被浪费掉的阻塞时间。 第一种配置方式： 由于IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程。 配置公式：CPU核数 * 2。 第二种配置方式： IO密集型时，大部分线程都阻塞，故需要多配置线程数。 配置公式：CPU核数 / (1 – 阻塞系数)（0.8~0.9之间） 比如：8核 / (1 – 0.9) = 80个线程数 其余思路： 核心线程数的设计需要依据任务的处理时间和每秒产生的任务数量来确定,例如:执行一个任务需要0.1秒,系统百分之80的时间每秒都会产生100个任务,那么要想在1秒内处理完这100个任务,就需要10个线程,此时我们就可以设计核心线程数为10; 任务队列长度(workQueue) 任务队列长度一般设计为:核心线程数/单个任务执行时间*2即可;例如上面的场景中,核心线程数设计为10,单个任务执行时间为0.1秒,则队列长度可以设计为200; 最大线程数 最大线程数的设计除了需要参照核心线程数的条件外,还需要参照系统每秒产生的最大任务数决定:例如:上述环境中,如果系统每秒最大产生的任务是1000个,那么,最大线程数=(最大任务数-任务队列长度)*单个任务执行时间;既: 最大线程数=(1000-200)*0.1=80个; 最大空闲时间(keepAliveTime) 此参数的设计完全参考系统运行环境和硬件压力设定,没有固定的参考值,可以根据经验和系统产生任务的时间间隔合理设置一个值即可; 引用 从简单代码入手，分析线程池原理 10问10答：你真的了解线程池吗？ 面试官：说一下线程池7个参数的含义？ 用了这么久线程池，你真的知道如何合理配置线程数吗？ 线程池很难么？带你从头到尾捋一遍，不信你听不懂！ 面试官：详细说一下Java线程池，从设计思想到源码解读！","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"Thread","slug":"Thread","permalink":"https://qinglei1989.github.io/tags/Thread/"}]},{"title":"Java 虚拟机进程状态工具jstat","slug":"jvm-command-jstat","date":"2022-03-28T09:48:06.000Z","updated":"2022-09-23T12:20:03.830Z","comments":true,"path":"2022/03/28/jvm-command-jstat/","link":"","permalink":"https://qinglei1989.github.io/2022/03/28/jvm-command-jstat/","excerpt":"利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了对进程的classloader，compiler，gc情况；可以用来监视VM内存内的各种堆和非堆的大小及其内存使用量，以及加载类的数量。","text":"利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了对进程的classloader，compiler，gc情况；可以用来监视VM内存内的各种堆和非堆的大小及其内存使用量，以及加载类的数量。 Java 虚拟机进程状态工具JSTAT 语法 jstat [option vmid [interval [s|ms][count]] [count]] ] options work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -options -class -compiler -gc -gccapacity -gccause -gcmetacapacity -gcnew -gcnewcapacity -gcold -gcoldcapacity -gcutil -printcompilation jstat工具主要选项 选项 作用 -class 监视类装载、卸载数量、总空间以及类装载所耗费的时间 -compiler 输出JIT编译器编译过的方法、耗时等信息 -gc 监视Java堆状况，包括Eden区、两个survivor区、老年代、元空间的容量、已用空间、GC时间合计等信息 -gccapacity 监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间 -gccause 与-gcutil功能一样，但是会额外输出导致上一次GC产生的原因 -gcmetacapacity 输出元数据用到的最大、最小空间 -gcnew 监视新生代GC状况 -gcnewcapacity 监视内容与-gcnew基本相同，输出主要关注使用到的最大、最小空间 -gcold 监视老年代状况 -gcoldcapacity 监视内容与-gcold基本相同，输出主要关注用到的最大、最小空间 -gcutil 监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比 -printcompilation 输出已经被JIT编译的方法 示例： 以下输出空间单位都是KB，时间单位都是s 类加载统计 Loaded:加载class的数量 Bytes：所占用空间大小 Unloaded：未加载数量 Bytes:未加载占用空间 Time：时间 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -class 47 Loaded Bytes Unloaded Bytes Time 12225 23448.0 0 0.0 16.53 编译统计 Compiled：编译数量。 Failed：失败数量 Invalid：不可用数量 Time：时间 FailedType：失败类型 FailedMethod：失败的方法 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -compiler 47 Compiled Failed Invalid Time FailedType FailedMethod 14158 1 0 71.73 1 com&#x2F;mysql&#x2F;jdbc&#x2F;AbandonedConnectionCleanupThread run 垃圾回收统计 S0C：第一个幸存区的大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 OC：老年代大小 OU：老年代使用大小 MC：方法区大小 MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -gc 47 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 17024.0 17024.0 0.0 22.7 136320.0 60520.6 460416.0 88295.8 76212.0 74725.3 8392.0 8040.4 223 1.986 4 0.277 2.263 堆内存统计 NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量 S0C：第一个幸存区大小 S1C：第二个幸存区的大小 EC：伊甸园区的大小 OGCMN：老年代最小容量 OGCMX：老年代最大容量 OGC：当前老年代大小 OC:当前老年代大小 MCMN:最小元数据容量 MCMX：最大元数据容量 MC：当前元数据空间大小 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：年轻代gc次数 FGC：老年代GC次数 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -gccapacity 47 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 170368.0 170368.0 170368.0 17024.0 17024.0 136320.0 460416.0 460416.0 460416.0 460416.0 0.0 1118208.0 76212.0 0.0 1048576.0 8392.0 223 4 新生代垃圾回收统计 S0C：第一个幸存区大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 TT:对象在新生代存活的次数 MTT:对象在新生代存活的最大次数 DSS:期望的幸存区大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -gcnew 47 S0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT 17024.0 17024.0 0.0 22.7 6 6 8512.0 136320.0 63300.2 223 1.986 新生代内存统计 NGCMN：新生代最小容量 NGCMX：新生代最大容量 NGC：当前新生代容量 S0CMX：最大幸存1区大小 S0C：当前幸存1区大小 S1CMX：最大幸存2区大小 S1C：当前幸存2区大小 ECMX：最大伊甸园区大小 EC：当前伊甸园区大小 YGC：年轻代垃圾回收次数 FGC：老年代回收次数 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -gcnewcapacity 47 NGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC 170368.0 170368.0 170368.0 17024.0 17024.0 17024.0 17024.0 136320.0 136320.0 223 4 老年代垃圾回收统计 MC：方法区大小 MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 OC：老年代大小 OU：老年代使用大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -gcold 47 MC MU CCSC CCSU OC OU YGC FGC FGCT GCT 76212.0 74725.3 8392.0 8040.4 460416.0 88295.8 223 4 0.277 2.263 老年代内存统计 OGCMN：老年代最小容量 OGCMX：老年代最大容量 OGC：当前老年代大小 OC：老年代大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -gcoldcapacity 47 OGCMN OGCMX OGC OC YGC FGC FGCT GCT 460416.0 460416.0 460416.0 460416.0 223 4 0.277 2.263 元数据空间统计 MCMN:最小元数据容量 MCMX：最大元数据容量 MC：当前元数据空间大小 CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -gcmetacapacity 47 MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC FGCT GCT 0.0 1118208.0 76212.0 0.0 1048576.0 8392.0 223 4 0.277 2.263 总结垃圾回收统计 S0：幸存1区当前使用比例 S1：幸存2区当前使用比例 E：Eden区使用比例 O：老年代使用比例 M：元数据区使用比例 CCS：压缩使用比例 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 work@authority-schedule-v1-fbf4cfd6d-86zhw:~$ jstat -gcutil 47 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 0.13 55.01 19.18 98.05 95.81 223 1.986 4 0.277 2.263 分析jstat输出的工具 jstat的挑战之一是您需要手动分析生成的统计信息。 正如您看到的那样，仅了解/解释一行内容将花费很长时间，这将很繁琐。 您可以使用GCeasy工具 ，该工具可以解析jstat输出并生成具有洞察力的图形和指标。 jstat局限性 它没有提供有关GC活动的丰富详细信息。 它仅提供足够的信息。 例如，从jstat您将不知道： 如果一次样本中报告了多个GC事件，那么我们将不知道每个GC事件的暂停时间是多少。 用户（即Java层），系统（即内核）和用户花费了多少时间。 有多少个GC线程正在工作，并占用了多少时间？ 一个GC事件具有几个子阶段（例如初始标记，清理，备注，并发标记……）。 无法提供信息分类。 每个GC事件回收多少字节。 有时，jstat报告的数据也会产生误导 。 如果您想进行准确的GC分析，GC日志是更可靠的方法。 引用 【JVM】jstat命令详解—JVM的统计监测工具","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"mysql-isolation-level","slug":"mysql-isolation-level","date":"2022-03-26T11:30:44.000Z","updated":"2022-04-13T17:09:59.326Z","comments":true,"path":"2022/03/26/mysql-isolation-level/","link":"","permalink":"https://qinglei1989.github.io/2022/03/26/mysql-isolation-level/","excerpt":"Mysql数据库隔离级别 未完待续","text":"Mysql数据库隔离级别 未完待续 MYSQL事务隔离级别 脏读 不可重复读 幻读 这周末搞定 四种隔离级别 InnoDB解决幻读的方案–LBCC&amp;MVCC InnoDB默认的事务隔离级别是RR，它为了解决该隔离级别下的幻读的并发问题，提出了LBCC和MVCC两种方案。其中LBCC解决的是当前读情况下的幻读，MVCC解决的是普通读（快照读）的幻读。 知识点 InnoDB的RR隔离级别并没有完全解决幻读的问题。如果在同一个事务里面，只是总是执行普通的select快照读，是不会产生幻读的。 但是如果在这个事务里面通过当前读或者先更新然后快照读的形式来读取数据，就会产生幻读。 测试用表 -- auto-generated definition create table test_read ( id bigint auto_increment comment &#39;主键&#39; primary key, name varchar(32) default &#39;&#39; null comment &#39;姓名&#39; ) comment &#39;幻读测试表&#39;; 初始化数据 insert into test_read (id, name) values (1, &#39;wang&#39;); insert into test_read (id, name) values (2, &#39;zhang&#39;); 幻读情形1 打开两个终端，连上mysql，分别启动事务1和事务2。 事务1 事务2 start transaction; start transaction; insert into test_read (name) values (‘zhao’); – select * from test_read; select * from test_read; 查询出来的结果如下： 事务1： 1,wang 2,zhang 3,zhao 事务2： 1,wang 2,zhang 很明显事务2没有查询到事务1未提交的新插入数据。原因也很简单，因为普通的select语句是快照读，而事务b启动时，它的快照数据就已经被版本锁定了。 如果事务2进行当前读是否能够读取到事务1未提交的新插入数据呢？ 我们在事务2里面执行如下命令来看看执行结果： select * from test_read lock in share mode; 执行完成之后我们发现事务b此时会block住，原因是事务1的insert语句排它锁住了id为3的新插入数据，而事务2想请求所有行的共享锁，肯定是需要等待的。 事务1提交之后，事务2依然无法读取到事务a新插入的数据，因为事务b还是读取到的是快照数据，所以不包含事务a提交之后的新数据。 如果此时事务b使用当前读，能否获取到事务a已提交的新插入数据呢？ 事务1 事务2 start transaction; start transaction; insert into test_read (name) values (‘zhao’); – select * from test_read; select * from test_read; commit; – – select * from test_read lock in share mode; 查询出来的结果如下： 1,wang 2,zhang 3,zhao 可以查询到事务a已提交的新数据，所以此时使用当前读就产生了幻读。 幻读情形2 事务1 事务2 start transaction; start transaction; insert into test_read (name) values (‘zhao’); – select * from test_read; select * from test_read; commit; – – update test_read set name=’bbb’ where id = 3; – select * from test_read; 第一条命令使用update更新了事务a已提交的新数据，第二条命令通过普通的select语句查看快照数据。 查询出来的结果如下： 1,wang 2,zhang 3,bbb 可以看到事务a已提交的新数据被事务b使用update语句更新了，并且通过普通的select语句给查询出来了，很显然，出现了幻读。 引用 InnoDB解决幻读的方案–LBCC&amp;MVCC","categories":[{"name":"数据库","slug":"数据库","permalink":"https://qinglei1989.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://qinglei1989.github.io/tags/mysql/"}]},{"title":"synchronized锁升级与降级","slug":"java-synchronized","date":"2022-03-19T16:17:31.000Z","updated":"2022-04-07T12:33:30.055Z","comments":true,"path":"2022/03/20/java-synchronized/","link":"","permalink":"https://qinglei1989.github.io/2022/03/20/java-synchronized/","excerpt":"针对Synchronized。在Java 5通过引入锁升级的机制来实现高效Synchronized。这三种锁的状态是通过对象监视器在对象头中的字段来表明的。偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。","text":"针对Synchronized。在Java 5通过引入锁升级的机制来实现高效Synchronized。这三种锁的状态是通过对象监视器在对象头中的字段来表明的。偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。 Synchronized锁升级与降级 对象的内存布局 在HotSpot虚拟机中，对象的内存布局可以划分为三部分：对象头（header）、实例对象（Instance Data）和对齐填充（Padding）。 HotSpot虚拟机对象的对象头包含两类信息。第一类是用于存储对象本身的运行时数据，如哈希码、GC分代年龄、锁状态标志等，官方称之为（Mark Word）。对象头的另一部分为类型指针（klass word），即指向它的类型元数据的指针，JAVA虚拟机通过这个指针来确定该对象是哪个类的实例。此外，如果对象是一个数组，那么对象头里边还必须有一块用于记录数组长度的数据。 实例数据部分是对象真正存储的有效信息，即我们在程序中定义的各种类型的字段内容。HotSpot虚拟机默认的分配顺序为longs/doubles、ints、shorts/chars、bytes/booleans、oops（Ordinary Object Pointers，OOPs），从以上默认的分配策略中可以看到，相同宽度的字段总是被分配到一起存放，在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前。如果HotSpot虚拟机的+XX：CompactFields参数值为true（默认就为true），那子类之中较窄的变量也允许插入父类变量的空隙之中，以节省出一点点空间。 对象的第三部分为对齐填充，这并不是必然存在的，仅起占位符的作用，因为虚拟机要求对象的起始地址必须是8字节的整数倍，换句话说就是任何对象的大小都必须是8字节的整数倍。对象头部分已经被精心设计成正好是8字节的倍数（1倍或者2倍），因此，如果对象实例数据部分没有对齐的话，就需要通过对齐填充来补全。 对象信息查看分析 POM文件中引入JOL包 &lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;&#x2F;groupId&gt; &lt;artifactId&gt;jol-core&lt;&#x2F;artifactId&gt; &lt;version&gt;0.16&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; 测试类 package com.rrc.util; import org.openjdk.jol.info.ClassLayout; public class ObjectSee &#123; public static void main(String[] args) &#123; ObjectSee a &#x3D; new ObjectSee(); System.out.println(ClassLayout.parseInstance(a).toPrintable()); &#125; &#125; 打印结果： com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 从打印日志我们发现整个对象一共16B，其中对象头（Object header）12B，还有4B是对齐的字节（因为在64位虚拟机上对象的大小必 须是8的倍数）, 由于这个对象里面没有任何字段，故而对象的实例数据为0B。 为对象增加boolean类型属性 package com.rrc.util; import org.openjdk.jol.info.ClassLayout; public class ObjectSee &#123; private boolean flag; public static void main(String[] args) &#123; ObjectSee a &#x3D; new ObjectSee(); &#x2F;&#x2F;System.out.println(Integer.toHexString(a.hashCode())); System.out.println(ClassLayout.parseInstance(a).toPrintable()); &#125; &#125; 打印结果： com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 1 boolean ObjectSee.flag false 13 3 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total 整个对象的大小还是没有改变一共16B，其中对象头（Object header）12B，boolean字段flag（对象的实例数据）占 1B、剩下的3B就是对齐字节。 由此我们可以认为一个对象的布局大体分为三个部分分别是:对象头（Object header）、 对象的实例数据和字节对齐 对象头信息查看分析 根据上述利用JOL打印的对象头信息可以知道一个对象头是12B，其中8B是mark word 那么剩下的4B就是klass word了，和锁相关的就是mark word了。 手动计算HashCode package com.rrc.util; import sun.misc.Unsafe; import java.lang.reflect.Field; public class HashUtil &#123; public static void countHash(Object object) throws NoSuchFieldException, IllegalAccessException &#123; &#x2F;&#x2F; 手动计算HashCode Field field &#x3D; Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); field.setAccessible(true); Unsafe unsafe &#x3D; (Unsafe) field.get(null); long hashCode &#x3D; 0; for (long index &#x3D; 7; index &gt; 0; index--) &#123; &#x2F;&#x2F; 取Mark Word中的每一个Byte进行计算 hashCode |&#x3D; (unsafe.getByte(object, index) &amp; 0xFF) &lt;&lt; ((index - 1) * 8); &#125; String code &#x3D; Long.toHexString(hashCode); System.out.println(&quot;util-----------0x&quot;+code); &#125; &#125; package com.rrc.util; import org.openjdk.jol.info.ClassLayout; public class ObjectSee &#123; private boolean flag; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; ObjectSee b &#x3D; new ObjectSee(); System.out.println(&quot;befor hash&quot;); &#x2F;&#x2F;没有计算HASHCODE之前的对象头 System.out.println(ClassLayout.parseInstance(b).toPrintable()); &#x2F;&#x2F;JVM 计算的hashcode System.out.println(&quot;jvm------------0x&quot;+Integer.toHexString(b.hashCode())); HashUtil.countHash(b); &#x2F;&#x2F;当计算完hashcode之后，我们可以查看对象头的信息变化 System.out.println(&quot;after hash&quot;); System.out.println(ClassLayout.parseInstance(b).toPrintable()); &#125; &#125; 运行结果为： befor hash com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 1 boolean ObjectSee.flag false 13 3 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total jvm------------0x7a92922 util-----------0x7a92922 after hash com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 22 29 a9 (00000001 00100010 00101001 10101001) (-1456922111) 4 4 (object header) 07 00 00 00 (00000111 00000000 00000000 00000000) (7) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 1 boolean ObjectSee.flag false 13 3 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total 分析结果： 没有进行hashcode之前的对象头信息，可以看到的56bit没有值，打印完hashcode之后就有值了，为什 么是1-7B，不是0-6B呢？因为是小端存储。 两行打印的hashcode结果相同，所以可以确定java对象头当中的mark work里面的后七个字节存储的是hashcode信息。 那么第一个字节当中的八位分别存的就是分带年龄、偏向锁信息，和对象状态，这个8bit分别表示的信息如下图（其实上图也有信息），这个图会随着对象状态改变而改变， 下图是无锁状态下 关于对象状态一共分为五种状态，分别是无锁、偏向锁、轻量锁、重量锁、GC标记， 那么2bit，如何能表示五种状 态（2bit最多只能表示4中状态分别是：00,01,10,11）， jvm做的比较好的是把偏向锁和无锁状态表示为同一个状态，然 后根据图中偏向锁的标识再去标识是无锁还是偏向锁状态。 从上面打印的信息可以看到无锁状态下的信息00000001(无锁不可偏向)。 Synchronized锁 从JDK6开始，就对synchronized的实现机制进行了较大调整，包括使用JDK5引进的CAS自旋之外，还增加了自适应的CAS自旋、锁消除、锁粗化、偏向锁、轻量级锁这些优化策略。 在 JDK 1.6 中默认是开启偏向锁的。 可以通过-XX:-UseBiasedLocking来禁用偏向锁。使用-XX:-UseSpinning参数关闭自旋锁优化；-XX:PreBlockSpin参数修改默认的自旋次数。偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。重量级锁：有实际竞争，且锁竞争时间长。 偏向锁默认配置 work@call-center-portal-v1-77466db6dc-cbw8d:~$ java -XX:+PrintFlagsFinal -version | grep &quot;BiasedLocking&quot; intx BiasedLockingBulkRebiasThreshold &#x3D; 20 &#123;product&#125; intx BiasedLockingBulkRevokeThreshold &#x3D; 40 &#123;product&#125; intx BiasedLockingDecayTime &#x3D; 25000 &#123;product&#125; intx BiasedLockingStartupDelay &#x3D; 4000 &#123;product&#125; bool TraceBiasedLocking &#x3D; false &#123;product&#125; bool UseBiasedLocking &#x3D; true &#123;product&#125; openjdk version &quot;1.8.0_222&quot; OpenJDK Runtime Environment (build 1.8.0_222-b10) OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode) work@call-center-portal-v1-77466db6dc-cbw8d:~$ 如上： BiasedLockingStartupDelay值为4000毫秒，因为JDK1.8 的偏向锁默认延迟4s生效的 UseBiasedLocking=true，表示程序默认开启偏向锁。如果设置为false则程序默认会进入轻量级锁。 -XX:+PrintSafepointStatistics可打印安全点事件,与偏向锁有关的可重点可关注EnableBiasedLocking,RevokeBias和BulkRevokeBias。 选项-XX:+TraceBiasedLocking可以帮助生成一个详细描述jvm做出的偏向锁决策的日志。 JDK1.8锁升级与降级 接下来我们写一个偏向锁的例子看结果。 package com.rrc.util; import org.openjdk.jol.info.ClassLayout; public class ObjectSee &#123; private boolean flag; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; ObjectSee b &#x3D; new ObjectSee(); System.out.println(&quot;befor lock&quot;); System.out.println(ClassLayout.parseInstance(b).toPrintable()); synchronized (b)&#123; System.out.println(&quot;lock ing&quot;); System.out.println(ClassLayout.parseInstance(b).toPrintable()); &#125; System.out.println(&quot;after lock&quot;); System.out.println(ClassLayout.parseInstance(b).toPrintable()); &#125; &#125; 运行结果为： com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 1 boolean ObjectSee.flag false 13 3 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total lock ing com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 90 b9 7a 0c (10010000 10111001 01111010 00001100) (209369488) 4 4 (object header) 03 00 00 00 (00000011 00000000 00000000 00000000) (3) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 1 boolean ObjectSee.flag false 13 3 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total after lock com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 1 boolean ObjectSee.flag false 13 3 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total 上面这个程序只有一个线程去调用sync方法，故而讲道理应该是偏向锁，但是此时却是轻量级锁。 而且你会发现最后输出的结果依然是00000001和无锁的时候一模一样，其实这是因为虚拟机在启动的时候对于偏向锁有延迟。 此时我们选择关闭JDK1.8的默认偏向锁延迟（-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0） 此时运行结果如下： befor lock com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 1 boolean ObjectSee.flag false 13 3 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total lock ing com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 18 01 e4 (00000101 00011000 00000001 11100100) (-469690363) 4 4 (object header) c9 7f 00 00 (11001001 01111111 00000000 00000000) (32713) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 1 boolean ObjectSee.flag false 13 3 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total after lock com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 18 01 e4 (00000101 00011000 00000001 11100100) (-469690363) 4 4 (object header) c9 7f 00 00 (11001001 01111111 00000000 00000000) (32713) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 1 boolean ObjectSee.flag false 13 3 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total 此时的00000101标识可偏向已锁定 。 延迟偏向是因为JVM启动的时候会有很多操作,运行时存在大量的同步方法,很多都不是偏向锁,而偏向锁升级为轻/重量级锁的很费时间和资源,因此jvm会延迟4秒左右再开启偏向锁。 需要注意的after lock，退出同步后依然保持了偏向信息（Mark Word中保存有线程ID）。 偏向锁使用了一种等到竞争出现才释放锁的机制，即一个线程在执行完同步代码块以后，并不会尝试将MarkWord中的thread ID赋回原值。这样做的好处是：如果该线程需要再次对这个对象加锁，而这个对象之前一直没有被其他线程尝试获取过锁，依旧停留在可偏向的状态下，即可在不修改对象头的情况下，直接认为偏向成功。 轻量级锁（JVM options:-XX:-UseBiasedLocking） package com.rrc.util; import org.openjdk.jol.info.ClassLayout; public class ObjectSee &#123; private static ObjectSee a; public static void main(String[] args) throws Exception &#123; a &#x3D; new ObjectSee(); System.out.println(&quot;befre lock&quot;); System.out.println(ClassLayout.parseInstance(a).toPrintable()); synchronized (a)&#123; System.out.println(&quot;lock ing&quot;); System.out.println(ClassLayout.parseInstance(a).toPrintable()); &#125; System.out.println(&quot;after lock&quot;); System.out.println(ClassLayout.parseInstance(a).toPrintable()); &#125; &#125; 运行结果为： befre lock com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total lock ing com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 98 59 b6 09 (10011000 01011001 10110110 00001001) (162945432) 4 4 (object header) 03 00 00 00 (00000011 00000000 00000000 00000000) (3) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total after lock com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 在关闭偏向锁后，使用synchronized加锁后直接升级为轻量级锁。 偏向锁的撤销（Revoke） 操作并不是将对象恢复到无锁可偏向的状态，而是指在获取偏向锁的过程因为不满足条件导致要将锁对象改为非偏向锁状态；释放是指退出同步块时的过程，即将内存最低的对应的lock Record的obj置为null，需要注意撤销与释放的区别。 偏向锁的撤销，是轻量级锁的前提。 需要注意的after lock，退出同步后回到了无锁的状态（Mark Word中线程ID消失）。 重量级锁（JVM options:-XX:-UseBiasedLocking）： package com.rrc.util; import org.openjdk.jol.info.ClassLayout; public class ObjectSee &#123; private static ObjectSee a; public static void main(String[] args) throws Exception &#123; &#x2F;&#x2F;Thread.sleep(5000); a &#x3D; new ObjectSee(); System.out.println(&quot;befre lock&quot;); System.out.println(ClassLayout.parseInstance(a).toPrintable());&#x2F;&#x2F;无锁 Thread t1&#x3D; new Thread()&#123; public void run() &#123; synchronized (a)&#123; try &#123; Thread.sleep(5000); System.out.println(&quot;t1 release&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;; t1.start(); Thread.sleep(1000); System.out.println(&quot;t1 lock ing&quot;); System.out.println(ClassLayout.parseInstance(a).toPrintable());&#x2F;&#x2F;轻量锁 sync(); System.out.println(&quot;after lock&quot;); System.out.println(ClassLayout.parseInstance(a).toPrintable());&#x2F;&#x2F;重量锁 System.gc(); System.out.println(&quot;after gc()&quot;); System.out.println(ClassLayout.parseInstance(a).toPrintable());&#x2F;&#x2F;无锁---gc &#125; public static void sync() throws InterruptedException &#123; synchronized (a)&#123; System.out.println(&quot;t1 main lock&quot;); System.out.println(ClassLayout.parseInstance(a).toPrintable());&#x2F;&#x2F;重量锁 &#125; &#125; &#125; 运行结果如下： befre lock com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total t1 lock ing com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) b0 d9 d7 09 (10110000 11011001 11010111 00001001) (165140912) 4 4 (object header) 03 00 00 00 (00000011 00000000 00000000 00000000) (3) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total t1 release t1 main lock com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 4a 7b 81 21 (01001010 01111011 10000001 00100001) (562133834) 4 4 (object header) 8f 7f 00 00 (10001111 01111111 00000000 00000000) (32655) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total after lock com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 4a 7b 81 21 (01001010 01111011 10000001 00100001) (562133834) 4 4 (object header) 8f 7f 00 00 (10001111 01111111 00000000 00000000) (32655) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total after gc() com.rrc.util.ObjectSee object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 09 00 00 00 (00001001 00000000 00000000 00000000) (9) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c1 00 f8 (00000101 11000001 00000000 11111000) (-134168315) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total after lock之后依然是重量级锁，但是经过gc之后变成了无锁状态。Hotspot 在 1.8 开始有了锁降级。在 STW 期间 JVM 进入安全点时如果发现有闲置的 monitor(重量级锁对象)，会进行锁降级。 由上述实验可总结下图: 批量重偏向和批量撤销 当只有一个线程反复进入同步块时，偏向锁带来的性能开销基本可以忽略，但是当有其他线程尝试获得锁时，就需要等到safe point时将偏向锁撤销为无锁状态或升级为轻量级/重量级锁。safe point这个词我们在GC中经常会提到，其代表了一个状态，在该状态下所有线程都是暂停的。总之，偏向锁的撤销是有一定成本的，如果说运行时的场景本身存在多线程竞争的，那偏向锁的存在不仅不能提高性能，而且会导致性能下降。因此，JVM中增加了一种批量重偏向/撤销的机制。 1 批量重偏向锁：当对某个类的对象偏向锁批量撤销20次，则偏向锁认为，后面的锁需要重新偏向新的线程（批量重偏向） 2 批量撤销：当某个类的对象的偏向锁累计被撤销到阈值40次（从40次开始），则偏向锁认为偏向锁撤销过于频繁，则后面的对象包括新生成的对象（标识为101和001）如果需要使用锁，则直接轻量级锁，不在使用偏向锁（即禁用了偏向锁） 存在如下两种情况： 一个线程创建了大量对象并执行了初始的同步操作，之后在另一个线程中将这些对象作为锁进行之后的操作。这种case下，会导致大量的偏向锁撤销操作。 存在明显多线程竞争的场景下使用偏向锁是不合适的，例如生产者/消费者队列。 批量重偏向（bulk rebias）机制是为了解决第一种场景。批量撤销（bulk revoke）则是为了解决第二种场景。 其做法是：以class为单位，为每个class维护一个偏向锁撤销计数器，每一次该class的对象发生偏向撤销操作时，该计数器+1，当这个值达到重偏向阈值（默认20，jvm参数BiasedLockingBulkRebiasThreshold控制）时，JVM就认为该class的偏向锁有问题，因此会进行批量重偏向。 当达到重偏向阈值后，假设该class计数器继续增长，当其达到批量撤销的阈值后（默认40，jvm参数BiasedLockingBulkRevokeThreshold控制），JVM就认为该class的使用场景存在多线程竞争，执行批量撤销，会标记该class为不可偏向，之后，对于该class的锁，直接走轻量级锁的逻辑。 BiasedLockingDecayTime是开启一次新的批量重偏向距离上次批量重偏向的后的延迟时间，默认25000。也就是开启批量重偏向后，如果经过了一段较长的时间（&gt;=BiasedLockingDecayTime），撤销计数器才超过阈值，那我们会重置计数器。 批量撤销相关DEMO如下： package com.rrc.util; import org.openjdk.jol.info.ClassLayout; import java.util.ArrayList; import java.util.List; import java.util.concurrent.locks.LockSupport; &#x2F;** * Hello world! * -XX:+PrintFlagsFinal * -Xms1g -Xmx1g -XX:+PrintGCDetails -XX:BiasedLockingStartupDelay&#x3D;0 偏向延迟关闭参数 *&#x2F; public class Test4 &#123; static Thread t1 &#x3D; null; static Thread t2 &#x3D; null; static Thread t3 &#x3D; null; static int count &#x3D; 39;&#x2F;&#x2F;39 则正好是经历了，40次偏向锁撤销，以后新创建的对象为无锁不可偏向标识，那加锁则直接为轻量级锁（撤销了偏向锁这个步骤） public static void main(String[] args) throws InterruptedException &#123; &#x2F;&#x2F; System.out.println(String.format(&quot; 新对象锁标识：%s &quot;, ClassLayout.parseInstance(new B()).toPrintable())); B b2 &#x3D; new B(); &#x2F;&#x2F;保存锁对象列表 List&lt;B&gt; list &#x3D; new ArrayList&lt;&gt;(); &#x2F;&#x2F;第一个线程 加锁了38次 t1 &#x3D; new Thread() &#123; @Override public void run() &#123; for (int i &#x3D; 0; i &lt; count; i++) &#123; B b &#x3D; new B(); list.add(b); System.out.println(String.format(&quot;线程名称 %s 执行的次数 %d &quot;, Thread.currentThread().getName(), i)); System.out.println(ClassLayout.parseInstance(b).toPrintable()); synchronized (b) &#123; &#x2F;&#x2F;打印第一个线程加锁后 ，对象头变化 System.out.println(ClassLayout.parseInstance(b).toPrintable()); &#125; System.out.println(ClassLayout.parseInstance(b).toPrintable()); &#125; LockSupport.unpark(t2); &#125; &#125;; t2 &#x3D; new Thread() &#123; @Override public void run() &#123; LockSupport.park(); System.out.println(&quot;线程2开始执行&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;); for (int i &#x3D; 0; i &lt; count; i++) &#123; System.out.println(String.format(&quot;线程名称 %s 执行的次数 %d &quot;, Thread.currentThread().getName(), i)); B b &#x3D; list.get(i); System.out.println(ClassLayout.parseInstance(b).toPrintable()); synchronized (list.get(i)) &#123; &#x2F;&#x2F;打印第二个线程对对象加锁，对象头变化（线程前20次为偏向锁升级轻量级锁，从20次开始偏向锁偏向线程t2，发生线程重偏向） System.out.println(ClassLayout.parseInstance(b).toPrintable()); &#125; System.out.println(ClassLayout.parseInstance(b).toPrintable()); &#125; LockSupport.unpark(t3); &#125; &#125;; t3 &#x3D; new Thread(() -&gt; &#123; LockSupport.park(); System.out.println(&quot;线程3开始执行&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;); for (int i &#x3D; 0; i &lt; count; i++) &#123; System.out.println(String.format(&quot;线程名称 %s 执行的次数 %d &quot;, Thread.currentThread().getName(), i)); B b &#x3D; list.get(i); System.out.println(ClassLayout.parseInstance(b).toPrintable()); synchronized (b) &#123; &#x2F;&#x2F;线程从20个开始进行偏向锁撤销直到发生撤销40次到达阈值，则后面的对象发生 偏向锁 批量撤销 System.out.println(ClassLayout.parseInstance(b).toPrintable()); &#125; System.out.println(ClassLayout.parseInstance(b).toPrintable()); &#125; &#125;); t1.setName(&quot;线程t1 &quot;); t2.setName(&quot;线程t2 &quot;); t3.setName(&quot;线程t3 &quot;); t1.start(); t2.start(); t3.start(); t1.join(); t2.join(); t3.join(); System.out.println(&quot;&#x3D; 主线程新&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;); &#x2F;&#x2F;发生批量撤销后线程加锁，转换为轻量级锁 System.out.println(String.format(&quot; 新对象锁标识：%s &quot;, ClassLayout.parseInstance(b2).toPrintable())); synchronized (b2) &#123; System.out.println(String.format(&quot; 新对象锁标识：%s &quot;, ClassLayout.parseInstance(b2).toPrintable())); &#125; &#125; &#125; class B &#123; &#125; 部分运行结果如下： 线程t1 count为39次，for循环进行39次（0-38，线程t1最后一次运行结果如下，最开始对象为可偏向无锁状态，进入同步代码块后Mark Word中塞入了线程ID（a8 03 7a bb 7f 00 00），退出同步代码块后依然保持了偏向信息（Mark Word中保存有线程ID）。 count为39， 线程 线程名称 线程t1 执行的次数 38 com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 a8 03 7a (00000101 10101000 00000011 01111010) (2047059973) 4 4 (object header) bb 7f 00 00 (10111011 01111111 00000000 00000000) (32699) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 a8 03 7a (00000101 10101000 00000011 01111010) (2047059973) 4 4 (object header) bb 7f 00 00 (10111011 01111111 00000000 00000000) (32699) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 线程t2 可以看到进入同步代码块后Mark Word中塞入了t2的线程ID（d9 00 0e 03 00 00 00），锁升级为轻量级锁，在退出同步代码块后锁状态变成不可偏向无锁，Mark Word中线程ID清除。 线程名称 线程t2 执行的次数 0 com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 a8 03 7a (00000101 10101000 00000011 01111010) (2047059973) 4 4 (object header) bb 7f 00 00 (10111011 01111111 00000000 00000000) (32699) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) a8 d9 00 0e (10101000 11011001 00000000 00001110) (234936744) 4 4 (object header) 03 00 00 00 (00000011 00000000 00000000 00000000) (3) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 线程t2执行到第19次时，符合默认的批量重偏向的条件，从对象头中可以看出，加锁后锁依然为偏向锁，但是已不再偏向t1线程。但是为什么对象头中的线程ID与前18次的线程ID不一致呢？ 线程名称 线程t2 执行的次数 19 com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 a8 03 7a (00000101 10101000 00000011 01111010) (2047059973) 4 4 (object header) bb 7f 00 00 (10111011 01111111 00000000 00000000) (32699) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 a1 92 7a (00000101 10100001 10010010 01111010) (2056429829) 4 4 (object header) bb 7f 00 00 (10111011 01111111 00000000 00000000) (32699) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 a1 92 7a (00000101 10100001 10010010 01111010) (2056429829) 4 4 (object header) bb 7f 00 00 (10111011 01111111 00000000 00000000) (32699) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 线程t3执行完毕之后相当于对象b已经经历超过40次的偏向撤销，对应类B的新对象虽然为可偏向无锁定状态（Mark Word中没有线程ID），但是进入同步代码块后将直接变为轻量级锁。 &#x3D; 主线程新&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 新对象锁标识：com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 新对象锁标识：com.rrc.util.B object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 88 e9 9b 0c (10001000 11101001 10011011 00001100) (211544456) 4 4 (object header) 03 00 00 00 (00000011 00000000 00000000 00000000) (3) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 引用 java对象头信息和三种锁的性能对比 synchronized原理和锁优化策略(偏向/轻量级/重量级) Synchronized 锁 批量重偏向 和批量撤销 分析对象内部结构，并详解synchronized锁膨胀升级和降级的过程 java中关于锁知识的整理 synchronized原理","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"Thread","slug":"Thread","permalink":"https://qinglei1989.github.io/tags/Thread/"}]},{"title":"垃圾回收器常用参数","slug":"jvm-param","date":"2022-03-12T16:17:31.000Z","updated":"2022-03-29T10:25:25.965Z","comments":true,"path":"2022/03/13/jvm-param/","link":"","permalink":"https://qinglei1989.github.io/2022/03/13/jvm-param/","excerpt":"垃圾收集器常用参数总结","text":"垃圾收集器常用参数总结 垃圾回收器常用参数 JVM 参数及默认值 Java 每个大版本间，都会有些参数变动，所以在写 JVM 配置前，一定要先看下你选择的参数是否还支持。Oracle 官网文档肯定是个途径，但不是最便捷的。下面这条命令可以立马查看所有参数及其默认值，而且还不用运行应用。 java -XX:+PrintFlagsFinal -version 表格的每一行包括五列，来表示一个参数。第一列表示参数的数据类型，第二列是名称，第四列为值，第五列是参数的类别。第三列”=”表示第四列是参数的默认值，而”:=” 表明了参数被用户或者JVM赋值了。 可以进行过滤，仅查看被修改项： java -XX:+PrintFlagsFinal -version | grep &quot;:&quot; work@permission-center-portal-6df6466c6c-qhhwq:~$ java -XX:+PrintFlagsFinal -version [Global flags] intx ActiveProcessorCount &#x3D; -1 &#123;product&#125; uintx AdaptiveSizeDecrementScaleFactor &#x3D; 4 &#123;product&#125; uintx AdaptiveSizeMajorGCDecayTimeScale &#x3D; 10 &#123;product&#125; uintx AdaptiveSizePausePolicy &#x3D; 0 &#123;product&#125; uintx AdaptiveSizePolicyCollectionCostMargin &#x3D; 50 &#123;product&#125; uintx AdaptiveSizePolicyInitializingSteps &#x3D; 20 &#123;product&#125; uintx AdaptiveSizePolicyOutputInterval &#x3D; 0 &#123;product&#125; uintx AdaptiveSizePolicyWeight &#x3D; 10 &#123;product&#125; uintx AdaptiveSizeThroughPutPolicy &#x3D; 0 &#123;product&#125; uintx AdaptiveTimeWeight &#x3D; 25 &#123;product&#125; bool AdjustConcurrency &#x3D; false &#123;product&#125; bool AggressiveHeap &#x3D; false &#123;product&#125; bool AggressiveOpts &#x3D; false &#123;product&#125; intx AliasLevel &#x3D; 3 &#123;C2 product&#125; bool AlignVector &#x3D; false &#123;C2 product&#125; intx AllocateInstancePrefetchLines &#x3D; 1 &#123;product&#125; intx AllocatePrefetchDistance &#x3D; 192 &#123;product&#125; intx AllocatePrefetchInstr &#x3D; 3 &#123;product&#125; intx AllocatePrefetchLines &#x3D; 4 &#123;product&#125; intx AllocatePrefetchStepSize &#x3D; 64 &#123;product&#125; intx AllocatePrefetchStyle &#x3D; 1 &#123;product&#125; bool AllowJNIEnvProxy &#x3D; false &#123;product&#125; bool AllowNonVirtualCalls &#x3D; false &#123;product&#125; bool AllowParallelDefineClass &#x3D; false &#123;product&#125; bool AllowUserSignalHandlers &#x3D; false &#123;product&#125; bool AlwaysActAsServerClassMachine &#x3D; false &#123;product&#125; bool AlwaysCompileLoopMethods &#x3D; false &#123;product&#125; bool AlwaysLockClassLoader &#x3D; false &#123;product&#125; bool AlwaysPreTouch &#x3D; false &#123;product&#125; bool AlwaysRestoreFPU &#x3D; false &#123;product&#125; bool AlwaysTenure &#x3D; false &#123;product&#125; bool AssertOnSuspendWaitFailure &#x3D; false &#123;product&#125; bool AssumeMP &#x3D; false &#123;product&#125; intx AutoBoxCacheMax &#x3D; 128 &#123;C2 product&#125; uintx AutoGCSelectPauseMillis &#x3D; 5000 &#123;product&#125; intx BCEATraceLevel &#x3D; 0 &#123;product&#125; intx BackEdgeThreshold &#x3D; 100000 &#123;pd product&#125; bool BackgroundCompilation &#x3D; true &#123;pd product&#125; uintx BaseFootPrintEstimate &#x3D; 268435456 &#123;product&#125; intx BiasedLockingBulkRebiasThreshold &#x3D; 20 &#123;product&#125; intx BiasedLockingBulkRevokeThreshold &#x3D; 40 &#123;product&#125; intx BiasedLockingDecayTime &#x3D; 25000 &#123;product&#125; intx BiasedLockingStartupDelay &#x3D; 4000 &#123;product&#125; bool BindGCTaskThreadsToCPUs &#x3D; false &#123;product&#125; bool BlockLayoutByFrequency &#x3D; true &#123;C2 product&#125; intx BlockLayoutMinDiamondPercentage &#x3D; 20 &#123;C2 product&#125; bool BlockLayoutRotateLoops &#x3D; true &#123;C2 product&#125; bool BranchOnRegister &#x3D; false &#123;C2 product&#125; bool BytecodeVerificationLocal &#x3D; false &#123;product&#125; bool BytecodeVerificationRemote &#x3D; true &#123;product&#125; bool C1OptimizeVirtualCallProfiling &#x3D; true &#123;C1 product&#125; bool C1ProfileBranches &#x3D; true &#123;C1 product&#125; bool C1ProfileCalls &#x3D; true &#123;C1 product&#125; bool C1ProfileCheckcasts &#x3D; true &#123;C1 product&#125; bool C1ProfileInlinedCalls &#x3D; true &#123;C1 product&#125; bool C1ProfileVirtualCalls &#x3D; true &#123;C1 product&#125; bool C1UpdateMethodData &#x3D; true &#123;C1 product&#125; intx CICompilerCount :&#x3D; 2 &#123;product&#125; bool CICompilerCountPerCPU &#x3D; true &#123;product&#125; bool CITime &#x3D; false &#123;product&#125; bool CMSAbortSemantics &#x3D; false &#123;product&#125; uintx CMSAbortablePrecleanMinWorkPerIteration &#x3D; 100 &#123;product&#125; intx CMSAbortablePrecleanWaitMillis &#x3D; 100 &#123;manageable&#125; uintx CMSBitMapYieldQuantum &#x3D; 10485760 &#123;product&#125; uintx CMSBootstrapOccupancy &#x3D; 50 &#123;product&#125; bool CMSClassUnloadingEnabled &#x3D; true &#123;product&#125; uintx CMSClassUnloadingMaxInterval &#x3D; 0 &#123;product&#125; bool CMSCleanOnEnter &#x3D; true &#123;product&#125; bool CMSCompactWhenClearAllSoftRefs &#x3D; true &#123;product&#125; uintx CMSConcMarkMultiple &#x3D; 32 &#123;product&#125; bool CMSConcurrentMTEnabled &#x3D; true &#123;product&#125; uintx CMSCoordinatorYieldSleepCount &#x3D; 10 &#123;product&#125; bool CMSDumpAtPromotionFailure &#x3D; false &#123;product&#125; bool CMSEdenChunksRecordAlways &#x3D; true &#123;product&#125; uintx CMSExpAvgFactor &#x3D; 50 &#123;product&#125; bool CMSExtrapolateSweep &#x3D; false &#123;product&#125; uintx CMSFullGCsBeforeCompaction &#x3D; 0 &#123;product&#125; uintx CMSIncrementalDutyCycle &#x3D; 10 &#123;product&#125; uintx CMSIncrementalDutyCycleMin &#x3D; 0 &#123;product&#125; bool CMSIncrementalMode &#x3D; false &#123;product&#125; uintx CMSIncrementalOffset &#x3D; 0 &#123;product&#125; bool CMSIncrementalPacing &#x3D; true &#123;product&#125; uintx CMSIncrementalSafetyFactor &#x3D; 10 &#123;product&#125; uintx CMSIndexedFreeListReplenish &#x3D; 4 &#123;product&#125; intx CMSInitiatingOccupancyFraction &#x3D; -1 &#123;product&#125; uintx CMSIsTooFullPercentage &#x3D; 98 &#123;product&#125; double CMSLargeCoalSurplusPercent &#x3D; 0.950000 &#123;product&#125; double CMSLargeSplitSurplusPercent &#x3D; 1.000000 &#123;product&#125; bool CMSLoopWarn &#x3D; false &#123;product&#125; uintx CMSMaxAbortablePrecleanLoops &#x3D; 0 &#123;product&#125; intx CMSMaxAbortablePrecleanTime &#x3D; 5000 &#123;product&#125; uintx CMSOldPLABMax &#x3D; 1024 &#123;product&#125; uintx CMSOldPLABMin &#x3D; 16 &#123;product&#125; uintx CMSOldPLABNumRefills &#x3D; 4 &#123;product&#125; uintx CMSOldPLABReactivityFactor &#x3D; 2 &#123;product&#125; bool CMSOldPLABResizeQuicker &#x3D; false &#123;product&#125; uintx CMSOldPLABToleranceFactor &#x3D; 4 &#123;product&#125; bool CMSPLABRecordAlways &#x3D; true &#123;product&#125; uintx CMSParPromoteBlocksToClaim &#x3D; 16 &#123;product&#125; bool CMSParallelInitialMarkEnabled &#x3D; true &#123;product&#125; bool CMSParallelRemarkEnabled &#x3D; true &#123;product&#125; bool CMSParallelSurvivorRemarkEnabled &#x3D; true &#123;product&#125; uintx CMSPrecleanDenominator &#x3D; 3 &#123;product&#125; uintx CMSPrecleanIter &#x3D; 3 &#123;product&#125; uintx CMSPrecleanNumerator &#x3D; 2 &#123;product&#125; bool CMSPrecleanRefLists1 &#x3D; true &#123;product&#125; bool CMSPrecleanRefLists2 &#x3D; false &#123;product&#125; bool CMSPrecleanSurvivors1 &#x3D; false &#123;product&#125; bool CMSPrecleanSurvivors2 &#x3D; true &#123;product&#125; uintx CMSPrecleanThreshold &#x3D; 1000 &#123;product&#125; bool CMSPrecleaningEnabled &#x3D; true &#123;product&#125; bool CMSPrintChunksInDump &#x3D; false &#123;product&#125; bool CMSPrintEdenSurvivorChunks &#x3D; false &#123;product&#125; bool CMSPrintObjectsInDump &#x3D; false &#123;product&#125; uintx CMSRemarkVerifyVariant &#x3D; 1 &#123;product&#125; bool CMSReplenishIntermediate &#x3D; true &#123;product&#125; uintx CMSRescanMultiple &#x3D; 32 &#123;product&#125; uintx CMSSamplingGrain &#x3D; 16384 &#123;product&#125; bool CMSScavengeBeforeRemark &#x3D; false &#123;product&#125; uintx CMSScheduleRemarkEdenPenetration &#x3D; 50 &#123;product&#125; uintx CMSScheduleRemarkEdenSizeThreshold &#x3D; 2097152 &#123;product&#125; uintx CMSScheduleRemarkSamplingRatio &#x3D; 5 &#123;product&#125; double CMSSmallCoalSurplusPercent &#x3D; 1.050000 &#123;product&#125; double CMSSmallSplitSurplusPercent &#x3D; 1.100000 &#123;product&#125; bool CMSSplitIndexedFreeListBlocks &#x3D; true &#123;product&#125; intx CMSTriggerInterval &#x3D; -1 &#123;manageable&#125; uintx CMSTriggerRatio &#x3D; 80 &#123;product&#125; intx CMSWaitDuration &#x3D; 2000 &#123;manageable&#125; uintx CMSWorkQueueDrainThreshold &#x3D; 10 &#123;product&#125; bool CMSYield &#x3D; true &#123;product&#125; uintx CMSYieldSleepCount &#x3D; 0 &#123;product&#125; uintx CMSYoungGenPerWorker &#x3D; 67108864 &#123;pd product&#125; uintx CMS_FLSPadding &#x3D; 1 &#123;product&#125; uintx CMS_FLSWeight &#x3D; 75 &#123;product&#125; uintx CMS_SweepPadding &#x3D; 1 &#123;product&#125; uintx CMS_SweepTimerThresholdMillis &#x3D; 10 &#123;product&#125; uintx CMS_SweepWeight &#x3D; 75 &#123;product&#125; bool CheckEndorsedAndExtDirs &#x3D; false &#123;product&#125; bool CheckJNICalls &#x3D; false &#123;product&#125; bool ClassUnloading &#x3D; true &#123;product&#125; bool ClassUnloadingWithConcurrentMark &#x3D; true &#123;product&#125; intx ClearFPUAtPark &#x3D; 0 &#123;product&#125; bool ClipInlining &#x3D; true &#123;product&#125; uintx CodeCacheExpansionSize &#x3D; 65536 &#123;pd product&#125; uintx CodeCacheMinimumFreeSpace &#x3D; 512000 &#123;product&#125; bool CollectGen0First &#x3D; false &#123;product&#125; bool CompactFields &#x3D; true &#123;product&#125; intx CompilationPolicyChoice &#x3D; 3 &#123;product&#125; ccstrlist CompileCommand &#x3D; &#123;product&#125; ccstr CompileCommandFile &#x3D; &#123;product&#125; ccstrlist CompileOnly &#x3D; &#123;product&#125; intx CompileThreshold &#x3D; 10000 &#123;pd product&#125; bool CompilerThreadHintNoPreempt &#x3D; true &#123;product&#125; intx CompilerThreadPriority &#x3D; -1 &#123;product&#125; intx CompilerThreadStackSize &#x3D; 0 &#123;pd product&#125; uintx CompressedClassSpaceSize &#x3D; 1073741824 &#123;product&#125; uintx ConcGCThreads &#x3D; 0 &#123;product&#125; intx ConditionalMoveLimit &#x3D; 3 &#123;C2 pd product&#125; intx ContendedPaddingWidth &#x3D; 128 &#123;product&#125; bool ConvertSleepToYield &#x3D; true &#123;pd product&#125; bool ConvertYieldToSleep &#x3D; false &#123;product&#125; bool CrashOnOutOfMemoryError &#x3D; false &#123;product&#125; bool CreateMinidumpOnCrash &#x3D; false &#123;product&#125; bool CriticalJNINatives &#x3D; true &#123;product&#125; bool DTraceAllocProbes &#x3D; false &#123;product&#125; bool DTraceMethodProbes &#x3D; false &#123;product&#125; bool DTraceMonitorProbes &#x3D; false &#123;product&#125; bool Debugging &#x3D; false &#123;product&#125; uintx DefaultMaxRAMFraction &#x3D; 4 &#123;product&#125; intx DefaultThreadPriority &#x3D; -1 &#123;product&#125; intx DeferPollingPageLoopCount &#x3D; -1 &#123;product&#125; intx DeferThrSuspendLoopCount &#x3D; 4000 &#123;product&#125; bool DeoptimizeRandom &#x3D; false &#123;product&#125; bool DisableAttachMechanism &#x3D; false &#123;product&#125; bool DisableExplicitGC &#x3D; false &#123;product&#125; bool DisplayVMOutputToStderr &#x3D; false &#123;product&#125; bool DisplayVMOutputToStdout &#x3D; false &#123;product&#125; bool DoEscapeAnalysis &#x3D; true &#123;C2 product&#125; bool DontCompileHugeMethods &#x3D; true &#123;product&#125; bool DontYieldALot &#x3D; false &#123;pd product&#125; ccstr DumpLoadedClassList &#x3D; &#123;product&#125; bool DumpReplayDataOnError &#x3D; true &#123;product&#125; bool DumpSharedSpaces &#x3D; false &#123;product&#125; bool EagerXrunInit &#x3D; false &#123;product&#125; intx EliminateAllocationArraySizeLimit &#x3D; 64 &#123;C2 product&#125; bool EliminateAllocations &#x3D; true &#123;C2 product&#125; bool EliminateAutoBox &#x3D; true &#123;C2 product&#125; bool EliminateLocks &#x3D; true &#123;C2 product&#125; bool EliminateNestedLocks &#x3D; true &#123;C2 product&#125; intx EmitSync &#x3D; 0 &#123;product&#125; bool EnableContended &#x3D; true &#123;product&#125; bool EnableTracing &#x3D; false &#123;product&#125; uintx ErgoHeapSizeLimit &#x3D; 0 &#123;product&#125; ccstr ErrorFile &#x3D; &#123;product&#125; ccstr ErrorReportServer &#x3D; &#123;product&#125; double EscapeAnalysisTimeout &#x3D; 20.000000 &#123;C2 product&#125; bool EstimateArgEscape &#x3D; true &#123;product&#125; bool ExitOnOutOfMemoryError &#x3D; false &#123;product&#125; bool ExplicitGCInvokesConcurrent &#x3D; false &#123;product&#125; bool ExplicitGCInvokesConcurrentAndUnloadsClasses &#x3D; false &#123;product&#125; bool ExtendedDTraceProbes &#x3D; false &#123;product&#125; ccstr ExtraSharedClassListFile &#x3D; &#123;product&#125; bool FLSAlwaysCoalesceLarge &#x3D; false &#123;product&#125; uintx FLSCoalescePolicy &#x3D; 2 &#123;product&#125; double FLSLargestBlockCoalesceProximity &#x3D; 0.990000 &#123;product&#125; bool FailOverToOldVerifier &#x3D; true &#123;product&#125; bool FastTLABRefill &#x3D; true &#123;product&#125; intx FenceInstruction &#x3D; 0 &#123;ARCH product&#125; intx FieldsAllocationStyle &#x3D; 1 &#123;product&#125; bool FilterSpuriousWakeups &#x3D; true &#123;product&#125; bool ForceNUMA &#x3D; false &#123;product&#125; bool ForceTimeHighResolution &#x3D; false &#123;product&#125; intx FreqInlineSize &#x3D; 325 &#123;pd product&#125; double G1ConcMarkStepDurationMillis &#x3D; 10.000000 &#123;product&#125; uintx G1ConcRSHotCardLimit &#x3D; 4 &#123;product&#125; uintx G1ConcRSLogCacheSize &#x3D; 10 &#123;product&#125; intx G1ConcRefinementGreenZone &#x3D; 0 &#123;product&#125; intx G1ConcRefinementRedZone &#x3D; 0 &#123;product&#125; intx G1ConcRefinementServiceIntervalMillis &#x3D; 300 &#123;product&#125; uintx G1ConcRefinementThreads &#x3D; 0 &#123;product&#125; intx G1ConcRefinementThresholdStep &#x3D; 0 &#123;product&#125; intx G1ConcRefinementYellowZone &#x3D; 0 &#123;product&#125; uintx G1ConfidencePercent &#x3D; 50 &#123;product&#125; uintx G1HeapRegionSize &#x3D; 0 &#123;product&#125; uintx G1HeapWastePercent &#x3D; 5 &#123;product&#125; uintx G1MixedGCCountTarget &#x3D; 8 &#123;product&#125; intx G1RSetRegionEntries &#x3D; 0 &#123;product&#125; uintx G1RSetScanBlockSize &#x3D; 64 &#123;product&#125; intx G1RSetSparseRegionEntries &#x3D; 0 &#123;product&#125; intx G1RSetUpdatingPauseTimePercent &#x3D; 10 &#123;product&#125; intx G1RefProcDrainInterval &#x3D; 10 &#123;product&#125; uintx G1ReservePercent &#x3D; 10 &#123;product&#125; uintx G1SATBBufferEnqueueingThresholdPercent &#x3D; 60 &#123;product&#125; intx G1SATBBufferSize &#x3D; 1024 &#123;product&#125; intx G1UpdateBufferSize &#x3D; 256 &#123;product&#125; bool G1UseAdaptiveConcRefinement &#x3D; true &#123;product&#125; uintx GCDrainStackTargetSize &#x3D; 64 &#123;product&#125; uintx GCHeapFreeLimit &#x3D; 2 &#123;product&#125; uintx GCLockerEdenExpansionPercent &#x3D; 5 &#123;product&#125; bool GCLockerInvokesConcurrent &#x3D; false &#123;product&#125; uintx GCLogFileSize &#x3D; 8192 &#123;product&#125; uintx GCPauseIntervalMillis &#x3D; 0 &#123;product&#125; uintx GCTaskTimeStampEntries &#x3D; 200 &#123;product&#125; uintx GCTimeLimit &#x3D; 98 &#123;product&#125; uintx GCTimeRatio &#x3D; 99 &#123;product&#125; uintx HeapBaseMinAddress &#x3D; 2147483648 &#123;pd product&#125; bool HeapDumpAfterFullGC &#x3D; false &#123;manageable&#125; bool HeapDumpBeforeFullGC &#x3D; false &#123;manageable&#125; bool HeapDumpOnOutOfMemoryError &#x3D; false &#123;manageable&#125; ccstr HeapDumpPath &#x3D; &#123;manageable&#125; uintx HeapFirstMaximumCompactionCount &#x3D; 3 &#123;product&#125; uintx HeapMaximumCompactionInterval &#x3D; 20 &#123;product&#125; uintx HeapSizePerGCThread &#x3D; 87241520 &#123;product&#125; bool IgnoreEmptyClassPaths &#x3D; false &#123;product&#125; bool IgnoreUnrecognizedVMOptions &#x3D; false &#123;product&#125; uintx IncreaseFirstTierCompileThresholdAt &#x3D; 50 &#123;product&#125; bool IncrementalInline &#x3D; true &#123;C2 product&#125; uintx InitialBootClassLoaderMetaspaceSize &#x3D; 4194304 &#123;product&#125; uintx InitialCodeCacheSize &#x3D; 2555904 &#123;pd product&#125; uintx InitialHeapSize :&#x3D; 16777216 &#123;product&#125; uintx InitialRAMFraction &#x3D; 64 &#123;product&#125; double InitialRAMPercentage &#x3D; 1.562500 &#123;product&#125; uintx InitialSurvivorRatio &#x3D; 8 &#123;product&#125; uintx InitialTenuringThreshold &#x3D; 7 &#123;product&#125; uintx InitiatingHeapOccupancyPercent &#x3D; 45 &#123;product&#125; bool Inline &#x3D; true &#123;product&#125; ccstr InlineDataFile &#x3D; &#123;product&#125; intx InlineSmallCode &#x3D; 2000 &#123;pd product&#125; bool InlineSynchronizedMethods &#x3D; true &#123;C1 product&#125; bool InsertMemBarAfterArraycopy &#x3D; true &#123;C2 product&#125; intx InteriorEntryAlignment &#x3D; 16 &#123;C2 pd product&#125; intx InterpreterProfilePercentage &#x3D; 33 &#123;product&#125; bool JNIDetachReleasesMonitors &#x3D; true &#123;product&#125; bool JavaMonitorsInStackTrace &#x3D; true &#123;product&#125; intx JavaPriority10_To_OSPriority &#x3D; -1 &#123;product&#125; intx JavaPriority1_To_OSPriority &#x3D; -1 &#123;product&#125; intx JavaPriority2_To_OSPriority &#x3D; -1 &#123;product&#125; intx JavaPriority3_To_OSPriority &#x3D; -1 &#123;product&#125; intx JavaPriority4_To_OSPriority &#x3D; -1 &#123;product&#125; intx JavaPriority5_To_OSPriority &#x3D; -1 &#123;product&#125; intx JavaPriority6_To_OSPriority &#x3D; -1 &#123;product&#125; intx JavaPriority7_To_OSPriority &#x3D; -1 &#123;product&#125; intx JavaPriority8_To_OSPriority &#x3D; -1 &#123;product&#125; intx JavaPriority9_To_OSPriority &#x3D; -1 &#123;product&#125; bool LIRFillDelaySlots &#x3D; false &#123;C1 pd product&#125; uintx LargePageHeapSizeThreshold &#x3D; 134217728 &#123;product&#125; uintx LargePageSizeInBytes &#x3D; 0 &#123;product&#125; bool LazyBootClassLoader &#x3D; true &#123;product&#125; intx LiveNodeCountInliningCutoff &#x3D; 40000 &#123;C2 product&#125; bool LoadExecStackDllInVMThread &#x3D; true &#123;product&#125; intx LoopMaxUnroll &#x3D; 16 &#123;C2 product&#125; intx LoopOptsCount &#x3D; 43 &#123;C2 product&#125; intx LoopUnrollLimit &#x3D; 60 &#123;C2 pd product&#125; intx LoopUnrollMin &#x3D; 4 &#123;C2 product&#125; bool LoopUnswitching &#x3D; true &#123;C2 product&#125; bool ManagementServer &#x3D; false &#123;product&#125; uintx MarkStackSize &#x3D; 4194304 &#123;product&#125; uintx MarkStackSizeMax &#x3D; 536870912 &#123;product&#125; uintx MarkSweepAlwaysCompactCount &#x3D; 4 &#123;product&#125; uintx MarkSweepDeadRatio &#x3D; 5 &#123;product&#125; intx MaxBCEAEstimateLevel &#x3D; 5 &#123;product&#125; intx MaxBCEAEstimateSize &#x3D; 150 &#123;product&#125; uintx MaxDirectMemorySize &#x3D; 0 &#123;product&#125; bool MaxFDLimit &#x3D; true &#123;product&#125; uintx MaxGCMinorPauseMillis &#x3D; 18446744073709551615 &#123;product&#125; uintx MaxGCPauseMillis &#x3D; 18446744073709551615 &#123;product&#125; uintx MaxHeapFreeRatio &#x3D; 70 &#123;manageable&#125; uintx MaxHeapSize :&#x3D; 268435456 &#123;product&#125; intx MaxInlineLevel &#x3D; 9 &#123;product&#125; intx MaxInlineSize &#x3D; 35 &#123;product&#125; intx MaxJNILocalCapacity &#x3D; 65536 &#123;product&#125; intx MaxJavaStackTraceDepth &#x3D; 1024 &#123;product&#125; intx MaxJumpTableSize &#x3D; 65000 &#123;C2 product&#125; intx MaxJumpTableSparseness &#x3D; 5 &#123;C2 product&#125; intx MaxLabelRootDepth &#x3D; 1100 &#123;C2 product&#125; intx MaxLoopPad &#x3D; 11 &#123;C2 product&#125; uintx MaxMetaspaceExpansion &#x3D; 5451776 &#123;product&#125; uintx MaxMetaspaceFreeRatio &#x3D; 70 &#123;product&#125; uintx MaxMetaspaceSize &#x3D; 18446744073709547520 &#123;product&#125; uintx MaxNewSize :&#x3D; 89456640 &#123;product&#125; intx MaxNodeLimit &#x3D; 75000 &#123;C2 product&#125; uint64_t MaxRAM &#x3D; 137438953472 &#123;pd product&#125; uintx MaxRAMFraction &#x3D; 4 &#123;product&#125; double MaxRAMPercentage &#x3D; 25.000000 &#123;product&#125; intx MaxRecursiveInlineLevel &#x3D; 1 &#123;product&#125; uintx MaxTenuringThreshold &#x3D; 15 &#123;product&#125; intx MaxTrivialSize &#x3D; 6 &#123;product&#125; intx MaxVectorSize &#x3D; 32 &#123;C2 product&#125; uintx MetaspaceSize &#x3D; 21807104 &#123;pd product&#125; bool MethodFlushing &#x3D; true &#123;product&#125; uintx MinHeapDeltaBytes :&#x3D; 196608 &#123;product&#125; uintx MinHeapFreeRatio &#x3D; 40 &#123;manageable&#125; intx MinInliningThreshold &#x3D; 250 &#123;product&#125; intx MinJumpTableSize &#x3D; 10 &#123;C2 pd product&#125; uintx MinMetaspaceExpansion &#x3D; 339968 &#123;product&#125; uintx MinMetaspaceFreeRatio &#x3D; 40 &#123;product&#125; uintx MinRAMFraction &#x3D; 2 &#123;product&#125; double MinRAMPercentage &#x3D; 50.000000 &#123;product&#125; uintx MinSurvivorRatio &#x3D; 3 &#123;product&#125; uintx MinTLABSize &#x3D; 2048 &#123;product&#125; intx MonitorBound &#x3D; 0 &#123;product&#125; bool MonitorInUseLists &#x3D; false &#123;product&#125; intx MultiArrayExpandLimit &#x3D; 6 &#123;C2 product&#125; bool MustCallLoadClassInternal &#x3D; false &#123;product&#125; uintx NUMAChunkResizeWeight &#x3D; 20 &#123;product&#125; uintx NUMAInterleaveGranularity &#x3D; 2097152 &#123;product&#125; uintx NUMAPageScanRate &#x3D; 256 &#123;product&#125; uintx NUMASpaceResizeRate &#x3D; 1073741824 &#123;product&#125; bool NUMAStats &#x3D; false &#123;product&#125; ccstr NativeMemoryTracking &#x3D; off &#123;product&#125; bool NeedsDeoptSuspend &#x3D; false &#123;pd product&#125; bool NeverActAsServerClassMachine &#x3D; false &#123;pd product&#125; bool NeverTenure &#x3D; false &#123;product&#125; uintx NewRatio &#x3D; 2 &#123;product&#125; uintx NewSize :&#x3D; 5570560 &#123;product&#125; uintx NewSizeThreadIncrease &#x3D; 5320 &#123;pd product&#125; intx NmethodSweepActivity &#x3D; 10 &#123;product&#125; intx NmethodSweepCheckInterval &#x3D; 5 &#123;product&#125; intx NmethodSweepFraction &#x3D; 16 &#123;product&#125; intx NodeLimitFudgeFactor &#x3D; 2000 &#123;C2 product&#125; uintx NumberOfGCLogFiles &#x3D; 0 &#123;product&#125; intx NumberOfLoopInstrToAlign &#x3D; 4 &#123;C2 product&#125; intx ObjectAlignmentInBytes &#x3D; 8 &#123;lp64_product&#125; uintx OldPLABSize &#x3D; 1024 &#123;product&#125; uintx OldPLABWeight &#x3D; 50 &#123;product&#125; uintx OldSize :&#x3D; 11206656 &#123;product&#125; bool OmitStackTraceInFastThrow &#x3D; true &#123;product&#125; ccstrlist OnError &#x3D; &#123;product&#125; ccstrlist OnOutOfMemoryError &#x3D; &#123;product&#125; intx OnStackReplacePercentage &#x3D; 140 &#123;pd product&#125; bool OptimizeFill &#x3D; true &#123;C2 product&#125; bool OptimizePtrCompare &#x3D; true &#123;C2 product&#125; bool OptimizeStringConcat &#x3D; true &#123;C2 product&#125; bool OptoBundling &#x3D; false &#123;C2 pd product&#125; intx OptoLoopAlignment &#x3D; 16 &#123;pd product&#125; bool OptoScheduling &#x3D; false &#123;C2 pd product&#125; uintx PLABWeight &#x3D; 75 &#123;product&#125; bool PSChunkLargeArrays &#x3D; true &#123;product&#125; intx ParGCArrayScanChunk &#x3D; 50 &#123;product&#125; uintx ParGCDesiredObjsFromOverflowList &#x3D; 20 &#123;product&#125; bool ParGCTrimOverflow &#x3D; true &#123;product&#125; bool ParGCUseLocalOverflow &#x3D; false &#123;product&#125; uintx ParallelGCBufferWastePct &#x3D; 10 &#123;product&#125; uintx ParallelGCThreads &#x3D; 0 &#123;product&#125; bool ParallelGCVerbose &#x3D; false &#123;product&#125; uintx ParallelOldDeadWoodLimiterMean &#x3D; 50 &#123;product&#125; uintx ParallelOldDeadWoodLimiterStdDev &#x3D; 80 &#123;product&#125; bool ParallelRefProcBalancingEnabled &#x3D; true &#123;product&#125; bool ParallelRefProcEnabled &#x3D; false &#123;product&#125; bool PartialPeelAtUnsignedTests &#x3D; true &#123;C2 product&#125; bool PartialPeelLoop &#x3D; true &#123;C2 product&#125; intx PartialPeelNewPhiDelta &#x3D; 0 &#123;C2 product&#125; uintx PausePadding &#x3D; 1 &#123;product&#125; intx PerBytecodeRecompilationCutoff &#x3D; 200 &#123;product&#125; intx PerBytecodeTrapLimit &#x3D; 4 &#123;product&#125; intx PerMethodRecompilationCutoff &#x3D; 400 &#123;product&#125; intx PerMethodTrapLimit &#x3D; 100 &#123;product&#125; bool PerfAllowAtExitRegistration &#x3D; false &#123;product&#125; bool PerfBypassFileSystemCheck &#x3D; false &#123;product&#125; intx PerfDataMemorySize &#x3D; 32768 &#123;product&#125; intx PerfDataSamplingInterval &#x3D; 50 &#123;product&#125; ccstr PerfDataSaveFile &#x3D; &#123;product&#125; bool PerfDataSaveToFile &#x3D; false &#123;product&#125; bool PerfDisableSharedMem &#x3D; false &#123;product&#125; intx PerfMaxStringConstLength &#x3D; 1024 &#123;product&#125; intx PreInflateSpin &#x3D; 10 &#123;pd product&#125; bool PreferContainerQuotaForCPUCount &#x3D; true &#123;product&#125; bool PreferInterpreterNativeStubs &#x3D; false &#123;pd product&#125; intx PrefetchCopyIntervalInBytes &#x3D; 576 &#123;product&#125; intx PrefetchFieldsAhead &#x3D; 1 &#123;product&#125; intx PrefetchScanIntervalInBytes &#x3D; 576 &#123;product&#125; bool PreserveAllAnnotations &#x3D; false &#123;product&#125; bool PreserveFramePointer &#x3D; false &#123;pd product&#125; uintx PretenureSizeThreshold &#x3D; 0 &#123;product&#125; bool PrintAdaptiveSizePolicy &#x3D; false &#123;product&#125; bool PrintCMSInitiationStatistics &#x3D; false &#123;product&#125; intx PrintCMSStatistics &#x3D; 0 &#123;product&#125; bool PrintClassHistogram &#x3D; false &#123;manageable&#125; bool PrintClassHistogramAfterFullGC &#x3D; false &#123;manageable&#125; bool PrintClassHistogramBeforeFullGC &#x3D; false &#123;manageable&#125; bool PrintCodeCache &#x3D; false &#123;product&#125; bool PrintCodeCacheOnCompilation &#x3D; false &#123;product&#125; bool PrintCommandLineFlags &#x3D; false &#123;product&#125; bool PrintCompilation &#x3D; false &#123;product&#125; bool PrintConcurrentLocks &#x3D; false &#123;manageable&#125; intx PrintFLSCensus &#x3D; 0 &#123;product&#125; intx PrintFLSStatistics &#x3D; 0 &#123;product&#125; bool PrintFlagsFinal :&#x3D; true &#123;product&#125; bool PrintFlagsInitial &#x3D; false &#123;product&#125; bool PrintGC &#x3D; false &#123;manageable&#125; bool PrintGCApplicationConcurrentTime &#x3D; false &#123;product&#125; bool PrintGCApplicationStoppedTime &#x3D; false &#123;product&#125; bool PrintGCCause &#x3D; true &#123;product&#125; bool PrintGCDateStamps &#x3D; false &#123;manageable&#125; bool PrintGCDetails &#x3D; false &#123;manageable&#125; bool PrintGCID &#x3D; false &#123;manageable&#125; bool PrintGCTaskTimeStamps &#x3D; false &#123;product&#125; bool PrintGCTimeStamps &#x3D; false &#123;manageable&#125; bool PrintHeapAtGC &#x3D; false &#123;product rw&#125; bool PrintHeapAtGCExtended &#x3D; false &#123;product rw&#125; bool PrintHeapAtSIGBREAK &#x3D; true &#123;product&#125; bool PrintJNIGCStalls &#x3D; false &#123;product&#125; bool PrintJNIResolving &#x3D; false &#123;product&#125; bool PrintOldPLAB &#x3D; false &#123;product&#125; bool PrintOopAddress &#x3D; false &#123;product&#125; bool PrintPLAB &#x3D; false &#123;product&#125; bool PrintParallelOldGCPhaseTimes &#x3D; false &#123;product&#125; bool PrintPromotionFailure &#x3D; false &#123;product&#125; bool PrintReferenceGC &#x3D; false &#123;product&#125; bool PrintSafepointStatistics &#x3D; false &#123;product&#125; intx PrintSafepointStatisticsCount &#x3D; 300 &#123;product&#125; intx PrintSafepointStatisticsTimeout &#x3D; -1 &#123;product&#125; bool PrintSharedArchiveAndExit &#x3D; false &#123;product&#125; bool PrintSharedDictionary &#x3D; false &#123;product&#125; bool PrintSharedSpaces &#x3D; false &#123;product&#125; bool PrintStringDeduplicationStatistics &#x3D; false &#123;product&#125; bool PrintStringTableStatistics &#x3D; false &#123;product&#125; bool PrintTLAB &#x3D; false &#123;product&#125; bool PrintTenuringDistribution &#x3D; false &#123;product&#125; bool PrintTieredEvents &#x3D; false &#123;product&#125; bool PrintVMOptions &#x3D; false &#123;product&#125; bool PrintVMQWaitTime &#x3D; false &#123;product&#125; bool PrintWarnings &#x3D; true &#123;product&#125; uintx ProcessDistributionStride &#x3D; 4 &#123;product&#125; bool ProfileInterpreter &#x3D; true &#123;pd product&#125; bool ProfileIntervals &#x3D; false &#123;product&#125; intx ProfileIntervalsTicks &#x3D; 100 &#123;product&#125; intx ProfileMaturityPercentage &#x3D; 20 &#123;product&#125; bool ProfileVM &#x3D; false &#123;product&#125; bool ProfilerPrintByteCodeStatistics &#x3D; false &#123;product&#125; bool ProfilerRecordPC &#x3D; false &#123;product&#125; uintx PromotedPadding &#x3D; 3 &#123;product&#125; uintx QueuedAllocationWarningCount &#x3D; 0 &#123;product&#125; uintx RTMRetryCount &#x3D; 5 &#123;ARCH product&#125; bool RangeCheckElimination &#x3D; true &#123;product&#125; intx ReadPrefetchInstr &#x3D; 0 &#123;ARCH product&#125; bool ReassociateInvariants &#x3D; true &#123;C2 product&#125; bool ReduceBulkZeroing &#x3D; true &#123;C2 product&#125; bool ReduceFieldZeroing &#x3D; true &#123;C2 product&#125; bool ReduceInitialCardMarks &#x3D; true &#123;C2 product&#125; bool ReduceSignalUsage &#x3D; false &#123;product&#125; intx RefDiscoveryPolicy &#x3D; 0 &#123;product&#125; bool ReflectionWrapResolutionErrors &#x3D; true &#123;product&#125; bool RegisterFinalizersAtInit &#x3D; true &#123;product&#125; bool RelaxAccessControlCheck &#x3D; false &#123;product&#125; ccstr ReplayDataFile &#x3D; &#123;product&#125; bool RequireSharedSpaces &#x3D; false &#123;product&#125; uintx ReservedCodeCacheSize &#x3D; 251658240 &#123;pd product&#125; bool ResizeOldPLAB &#x3D; true &#123;product&#125; bool ResizePLAB &#x3D; true &#123;product&#125; bool ResizeTLAB &#x3D; true &#123;pd product&#125; bool RestoreMXCSROnJNICalls &#x3D; false &#123;product&#125; bool RestrictContended &#x3D; true &#123;product&#125; bool RewriteBytecodes &#x3D; true &#123;pd product&#125; bool RewriteFrequentPairs &#x3D; true &#123;pd product&#125; intx SafepointPollOffset &#x3D; 256 &#123;C1 pd product&#125; intx SafepointSpinBeforeYield &#x3D; 2000 &#123;product&#125; bool SafepointTimeout &#x3D; false &#123;product&#125; intx SafepointTimeoutDelay &#x3D; 10000 &#123;product&#125; bool ScavengeBeforeFullGC &#x3D; true &#123;product&#125; intx SelfDestructTimer &#x3D; 0 &#123;product&#125; uintx SharedBaseAddress &#x3D; 34359738368 &#123;product&#125; ccstr SharedClassListFile &#x3D; &#123;product&#125; uintx SharedMiscCodeSize &#x3D; 122880 &#123;product&#125; uintx SharedMiscDataSize &#x3D; 4194304 &#123;product&#125; uintx SharedReadOnlySize &#x3D; 16777216 &#123;product&#125; uintx SharedReadWriteSize &#x3D; 16777216 &#123;product&#125; bool ShowMessageBoxOnError &#x3D; false &#123;product&#125; intx SoftRefLRUPolicyMSPerMB &#x3D; 1000 &#123;product&#125; bool SpecialEncodeISOArray &#x3D; true &#123;C2 product&#125; bool SplitIfBlocks &#x3D; true &#123;C2 product&#125; intx StackRedPages &#x3D; 1 &#123;pd product&#125; intx StackShadowPages &#x3D; 20 &#123;pd product&#125; bool StackTraceInThrowable &#x3D; true &#123;product&#125; intx StackYellowPages &#x3D; 2 &#123;pd product&#125; bool StartAttachListener &#x3D; false &#123;product&#125; intx StarvationMonitorInterval &#x3D; 200 &#123;product&#125; bool StressLdcRewrite &#x3D; false &#123;product&#125; uintx StringDeduplicationAgeThreshold &#x3D; 3 &#123;product&#125; uintx StringTableSize &#x3D; 60013 &#123;product&#125; bool SuppressFatalErrorMessage &#x3D; false &#123;product&#125; uintx SurvivorPadding &#x3D; 3 &#123;product&#125; uintx SurvivorRatio &#x3D; 8 &#123;product&#125; intx SuspendRetryCount &#x3D; 50 &#123;product&#125; intx SuspendRetryDelay &#x3D; 5 &#123;product&#125; intx SyncFlags &#x3D; 0 &#123;product&#125; ccstr SyncKnobs &#x3D; &#123;product&#125; intx SyncVerbose &#x3D; 0 &#123;product&#125; uintx TLABAllocationWeight &#x3D; 35 &#123;product&#125; uintx TLABRefillWasteFraction &#x3D; 64 &#123;product&#125; uintx TLABSize &#x3D; 0 &#123;product&#125; bool TLABStats &#x3D; true &#123;product&#125; uintx TLABWasteIncrement &#x3D; 4 &#123;product&#125; uintx TLABWasteTargetPercent &#x3D; 1 &#123;product&#125; uintx TargetPLABWastePct &#x3D; 10 &#123;product&#125; uintx TargetSurvivorRatio &#x3D; 50 &#123;product&#125; uintx TenuredGenerationSizeIncrement &#x3D; 20 &#123;product&#125; uintx TenuredGenerationSizeSupplement &#x3D; 80 &#123;product&#125; uintx TenuredGenerationSizeSupplementDecay &#x3D; 2 &#123;product&#125; intx ThreadPriorityPolicy &#x3D; 0 &#123;product&#125; bool ThreadPriorityVerbose &#x3D; false &#123;product&#125; uintx ThreadSafetyMargin &#x3D; 52428800 &#123;product&#125; intx ThreadStackSize &#x3D; 1024 &#123;pd product&#125; uintx ThresholdTolerance &#x3D; 10 &#123;product&#125; intx Tier0BackedgeNotifyFreqLog &#x3D; 10 &#123;product&#125; intx Tier0InvokeNotifyFreqLog &#x3D; 7 &#123;product&#125; intx Tier0ProfilingStartPercentage &#x3D; 200 &#123;product&#125; intx Tier23InlineeNotifyFreqLog &#x3D; 20 &#123;product&#125; intx Tier2BackEdgeThreshold &#x3D; 0 &#123;product&#125; intx Tier2BackedgeNotifyFreqLog &#x3D; 14 &#123;product&#125; intx Tier2CompileThreshold &#x3D; 0 &#123;product&#125; intx Tier2InvokeNotifyFreqLog &#x3D; 11 &#123;product&#125; intx Tier3BackEdgeThreshold &#x3D; 60000 &#123;product&#125; intx Tier3BackedgeNotifyFreqLog &#x3D; 13 &#123;product&#125; intx Tier3CompileThreshold &#x3D; 2000 &#123;product&#125; intx Tier3DelayOff &#x3D; 2 &#123;product&#125; intx Tier3DelayOn &#x3D; 5 &#123;product&#125; intx Tier3InvocationThreshold &#x3D; 200 &#123;product&#125; intx Tier3InvokeNotifyFreqLog &#x3D; 10 &#123;product&#125; intx Tier3LoadFeedback &#x3D; 5 &#123;product&#125; intx Tier3MinInvocationThreshold &#x3D; 100 &#123;product&#125; intx Tier4BackEdgeThreshold &#x3D; 40000 &#123;product&#125; intx Tier4CompileThreshold &#x3D; 15000 &#123;product&#125; intx Tier4InvocationThreshold &#x3D; 5000 &#123;product&#125; intx Tier4LoadFeedback &#x3D; 3 &#123;product&#125; intx Tier4MinInvocationThreshold &#x3D; 600 &#123;product&#125; bool TieredCompilation &#x3D; true &#123;pd product&#125; intx TieredCompileTaskTimeout &#x3D; 50 &#123;product&#125; intx TieredRateUpdateMaxTime &#x3D; 25 &#123;product&#125; intx TieredRateUpdateMinTime &#x3D; 1 &#123;product&#125; intx TieredStopAtLevel &#x3D; 4 &#123;product&#125; bool TimeLinearScan &#x3D; false &#123;C1 product&#125; bool TraceBiasedLocking &#x3D; false &#123;product&#125; bool TraceClassLoading &#x3D; false &#123;product rw&#125; bool TraceClassLoadingPreorder &#x3D; false &#123;product&#125; bool TraceClassPaths &#x3D; false &#123;product&#125; bool TraceClassResolution &#x3D; false &#123;product&#125; bool TraceClassUnloading &#x3D; false &#123;product rw&#125; bool TraceDynamicGCThreads &#x3D; false &#123;product&#125; bool TraceGen0Time &#x3D; false &#123;product&#125; bool TraceGen1Time &#x3D; false &#123;product&#125; ccstr TraceJVMTI &#x3D; &#123;product&#125; bool TraceLoaderConstraints &#x3D; false &#123;product rw&#125; bool TraceMetadataHumongousAllocation &#x3D; false &#123;product&#125; bool TraceMonitorInflation &#x3D; false &#123;product&#125; bool TraceParallelOldGCTasks &#x3D; false &#123;product&#125; intx TraceRedefineClasses &#x3D; 0 &#123;product&#125; bool TraceSafepointCleanupTime &#x3D; false &#123;product&#125; bool TraceSuspendWaitFailures &#x3D; false &#123;product&#125; intx TrackedInitializationLimit &#x3D; 50 &#123;C2 product&#125; bool TransmitErrorReport &#x3D; false &#123;product&#125; bool TrapBasedNullChecks &#x3D; false &#123;pd product&#125; bool TrapBasedRangeChecks &#x3D; false &#123;C2 pd product&#125; intx TypeProfileArgsLimit &#x3D; 2 &#123;product&#125; uintx TypeProfileLevel &#x3D; 111 &#123;pd product&#125; intx TypeProfileMajorReceiverPercent &#x3D; 90 &#123;C2 product&#125; intx TypeProfileParmsLimit &#x3D; 2 &#123;product&#125; intx TypeProfileWidth &#x3D; 2 &#123;product&#125; intx UnguardOnExecutionViolation &#x3D; 0 &#123;product&#125; bool UnlinkSymbolsALot &#x3D; false &#123;product&#125; bool Use486InstrsOnly &#x3D; false &#123;ARCH product&#125; bool UseAES &#x3D; true &#123;product&#125; bool UseAESIntrinsics &#x3D; true &#123;product&#125; intx UseAVX &#x3D; 2 &#123;ARCH product&#125; bool UseAdaptiveGCBoundary &#x3D; false &#123;product&#125; bool UseAdaptiveGenerationSizePolicyAtMajorCollection &#x3D; true &#123;product&#125; bool UseAdaptiveGenerationSizePolicyAtMinorCollection &#x3D; true &#123;product&#125; bool UseAdaptiveNUMAChunkSizing &#x3D; true &#123;product&#125; bool UseAdaptiveSizeDecayMajorGCCost &#x3D; true &#123;product&#125; bool UseAdaptiveSizePolicy &#x3D; true &#123;product&#125; bool UseAdaptiveSizePolicyFootprintGoal &#x3D; true &#123;product&#125; bool UseAdaptiveSizePolicyWithSystemGC &#x3D; false &#123;product&#125; bool UseAddressNop &#x3D; true &#123;ARCH product&#125; bool UseAltSigs &#x3D; false &#123;product&#125; bool UseAutoGCSelectPolicy &#x3D; false &#123;product&#125; bool UseBMI1Instructions &#x3D; true &#123;ARCH product&#125; bool UseBMI2Instructions &#x3D; true &#123;ARCH product&#125; bool UseBiasedLocking &#x3D; true &#123;product&#125; bool UseBimorphicInlining &#x3D; true &#123;C2 product&#125; bool UseBoundThreads &#x3D; true &#123;product&#125; bool UseCLMUL &#x3D; true &#123;ARCH product&#125; bool UseCMSBestFit &#x3D; true &#123;product&#125; bool UseCMSCollectionPassing &#x3D; true &#123;product&#125; bool UseCMSCompactAtFullCollection &#x3D; true &#123;product&#125; bool UseCMSInitiatingOccupancyOnly &#x3D; false &#123;product&#125; bool UseCRC32Intrinsics &#x3D; true &#123;product&#125; bool UseCodeCacheFlushing &#x3D; true &#123;product&#125; bool UseCompiler &#x3D; true &#123;product&#125; bool UseCompilerSafepoints &#x3D; true &#123;product&#125; bool UseCompressedClassPointers :&#x3D; true &#123;lp64_product&#125; bool UseCompressedOops :&#x3D; true &#123;lp64_product&#125; bool UseConcMarkSweepGC &#x3D; false &#123;product&#125; bool UseCondCardMark &#x3D; false &#123;C2 product&#125; bool UseContainerSupport &#x3D; true &#123;product&#125; bool UseCountLeadingZerosInstruction &#x3D; true &#123;ARCH product&#125; bool UseCountTrailingZerosInstruction &#x3D; true &#123;ARCH product&#125; bool UseCountedLoopSafepoints &#x3D; false &#123;C2 product&#125; bool UseCounterDecay &#x3D; true &#123;product&#125; bool UseDivMod &#x3D; true &#123;C2 product&#125; bool UseDynamicNumberOfGCThreads &#x3D; false &#123;product&#125; bool UseFPUForSpilling &#x3D; true &#123;C2 product&#125; bool UseFastAccessorMethods &#x3D; false &#123;product&#125; bool UseFastEmptyMethods &#x3D; false &#123;product&#125; bool UseFastJNIAccessors &#x3D; true &#123;product&#125; bool UseFastStosb &#x3D; true &#123;ARCH product&#125; bool UseG1GC &#x3D; false &#123;product&#125; bool UseGCLogFileRotation &#x3D; false &#123;product&#125; bool UseGCOverheadLimit &#x3D; true &#123;product&#125; bool UseGCTaskAffinity &#x3D; false &#123;product&#125; bool UseHeavyMonitors &#x3D; false &#123;product&#125; bool UseHugeTLBFS &#x3D; false &#123;product&#125; bool UseInlineCaches &#x3D; true &#123;product&#125; bool UseInterpreter &#x3D; true &#123;product&#125; bool UseJumpTables &#x3D; true &#123;C2 product&#125; bool UseLWPSynchronization &#x3D; true &#123;product&#125; bool UseLargePages &#x3D; false &#123;pd product&#125; bool UseLargePagesInMetaspace &#x3D; false &#123;product&#125; bool UseLargePagesIndividualAllocation &#x3D; false &#123;pd product&#125; bool UseLinuxPosixThreadCPUClocks &#x3D; true &#123;product&#125; bool UseLockedTracing &#x3D; false &#123;product&#125; bool UseLoopCounter &#x3D; true &#123;product&#125; bool UseLoopInvariantCodeMotion &#x3D; true &#123;C1 product&#125; bool UseLoopPredicate &#x3D; true &#123;C2 product&#125; bool UseMathExactIntrinsics &#x3D; true &#123;C2 product&#125; bool UseMaximumCompactionOnSystemGC &#x3D; true &#123;product&#125; bool UseMembar &#x3D; false &#123;pd product&#125; bool UseMontgomeryMultiplyIntrinsic &#x3D; true &#123;C2 product&#125; bool UseMontgomerySquareIntrinsic &#x3D; true &#123;C2 product&#125; bool UseMulAddIntrinsic &#x3D; true &#123;C2 product&#125; bool UseMultiplyToLenIntrinsic &#x3D; true &#123;C2 product&#125; bool UseNUMA &#x3D; false &#123;product&#125; bool UseNUMAInterleaving &#x3D; false &#123;product&#125; bool UseNewLongLShift &#x3D; false &#123;ARCH product&#125; bool UseOSErrorReporting &#x3D; false &#123;pd product&#125; bool UseOldInlining &#x3D; true &#123;C2 product&#125; bool UseOnStackReplacement &#x3D; true &#123;pd product&#125; bool UseOnlyInlinedBimorphic &#x3D; true &#123;C2 product&#125; bool UseOprofile &#x3D; false &#123;product&#125; bool UseOptoBiasInlining &#x3D; true &#123;C2 product&#125; bool UsePSAdaptiveSurvivorSizePolicy &#x3D; true &#123;product&#125; bool UseParNewGC &#x3D; false &#123;product&#125; bool UseParallelGC &#x3D; false &#123;product&#125; bool UseParallelOldGC &#x3D; false &#123;product&#125; bool UsePerfData &#x3D; true &#123;product&#125; bool UsePopCountInstruction &#x3D; true &#123;product&#125; bool UseRDPCForConstantTableBase &#x3D; false &#123;C2 product&#125; bool UseRTMDeopt &#x3D; false &#123;ARCH product&#125; bool UseRTMLocking &#x3D; false &#123;ARCH product&#125; bool UseSHA &#x3D; false &#123;product&#125; bool UseSHA1Intrinsics &#x3D; false &#123;product&#125; bool UseSHA256Intrinsics &#x3D; false &#123;product&#125; bool UseSHA512Intrinsics &#x3D; false &#123;product&#125; bool UseSHM &#x3D; false &#123;product&#125; intx UseSSE &#x3D; 4 &#123;product&#125; bool UseSSE42Intrinsics &#x3D; true &#123;product&#125; bool UseSerialGC &#x3D; false &#123;product&#125; bool UseSharedSpaces &#x3D; false &#123;product&#125; bool UseSignalChaining &#x3D; true &#123;product&#125; bool UseSquareToLenIntrinsic &#x3D; true &#123;C2 product&#125; bool UseStoreImmI16 &#x3D; false &#123;ARCH product&#125; bool UseStringDeduplication &#x3D; false &#123;product&#125; bool UseSuperWord &#x3D; true &#123;C2 product&#125; bool UseTLAB &#x3D; true &#123;pd product&#125; bool UseThreadPriorities &#x3D; true &#123;pd product&#125; bool UseTransparentHugePages &#x3D; false &#123;product&#125; bool UseTypeProfile &#x3D; true &#123;product&#125; bool UseTypeSpeculation &#x3D; true &#123;C2 product&#125; bool UseUnalignedLoadStores &#x3D; true &#123;ARCH product&#125; bool UseVMInterruptibleIO &#x3D; false &#123;product&#125; bool UseXMMForArrayCopy &#x3D; true &#123;product&#125; bool UseXmmI2D &#x3D; false &#123;ARCH product&#125; bool UseXmmI2F &#x3D; false &#123;ARCH product&#125; bool UseXmmLoadAndClearUpper &#x3D; true &#123;ARCH product&#125; bool UseXmmRegToRegMoveAll &#x3D; true &#123;ARCH product&#125; bool VMThreadHintNoPreempt &#x3D; false &#123;product&#125; intx VMThreadPriority &#x3D; -1 &#123;product&#125; intx VMThreadStackSize &#x3D; 1024 &#123;pd product&#125; intx ValueMapInitialSize &#x3D; 11 &#123;C1 product&#125; intx ValueMapMaxLoopSize &#x3D; 8 &#123;C1 product&#125; intx ValueSearchLimit &#x3D; 1000 &#123;C2 product&#125; bool VerifyMergedCPBytecodes &#x3D; true &#123;product&#125; bool VerifySharedSpaces &#x3D; false &#123;product&#125; intx WorkAroundNPTLTimedWaitHang &#x3D; 1 &#123;product&#125; uintx YoungGenerationSizeIncrement &#x3D; 20 &#123;product&#125; uintx YoungGenerationSizeSupplement &#x3D; 80 &#123;product&#125; uintx YoungGenerationSizeSupplementDecay &#x3D; 8 &#123;product&#125; uintx YoungPLABSize &#x3D; 4096 &#123;product&#125; bool ZeroTLAB &#x3D; false &#123;product&#125; intx hashCode &#x3D; 5 &#123;product&#125; openjdk version &quot;1.8.0_222&quot; OpenJDK Runtime Environment (build 1.8.0_222-b10) OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode) 加上 grep 立马能看到参数的默认值，比如在我的机器上 ParallelGCThreads 默认值为 0 work@permission-center-portal-6df6466c6c-qhhwq:~$ java -XX:+PrintFlagsFinal -version | grep &quot;ParallelGCThreads&quot; uintx ParallelGCThreads &#x3D; 0 &#123;product&#125; openjdk version &quot;1.8.0_222&quot; OpenJDK Runtime Environment (build 1.8.0_222-b10) OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode) work@permission-center-portal-6df6466c6c-qhhwq:~$ -XX:+PrintFlagsInitial 是打印所有的默认参数设置-XX:+PrintFlagsFinal 是打印最终值，如果某个默认值被新值覆盖，显示新值-XX:+PrintCommandLineFlags 是打印那些被新值覆盖的项 打印那些被新值覆盖的项 work@authority-schedule-v1-679dd585c4-9rsf9:~$ java -XX:+PrintCommandLineFlags -version -XX:InitialHeapSize&#x3D;8388608 -XX:MaxHeapSize&#x3D;134217728 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops openjdk version &quot;1.8.0_222&quot; OpenJDK Runtime Environment (build 1.8.0_222-b10) OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode) work@authority-schedule-v1-679dd585c4-9rsf9:~$ 垃圾回收器相关 CMS -XX:+UseConcMarkSweepGC -XX:+UseParNewGC 显式声明垃圾回收器为CMS+parNew+Serial Old集合，Serial Old收集器将作为CMS回收器出现”Concurrent Mode Failure”失败后的备用收集器。 -XX:CMSInitiatingOccupancyFraction&#x3D;75 -XX:+UseCMSInitiatingOccupancyOnly 这两个设置一般配合使用,一般用于『降低CMS GC频率或者增加频率、减少GC时长』的需求。前一个参数是指设定CMS在对内存占用率达到70%的时候开始GC(因为CMS会有浮动垃圾,所以一般都较早启动GC);后一个参数只是用设定的回收阈值(上面指定的75%),如果不指定,JVM仅在第一次使用设定值,后续则自动调整。 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction&#x3D;0 CMS GC是并发的垃圾回收器，它采用的是标记清除算法，而不是压缩算法。意味着随着时间的推移，碎片会越来越多，JVM终究会触发内存整理这个动作。 -XX:+UseCMSCompactAtFullCollection 表示开启压缩 -XX:CMSFullGCsBeforeCompaction=0 表示在压缩（compaction）内存之前需要发生多少次不压缩内存的FGC。CMS GC不是FGC，在CMS GC搞不定的时候（比如：concurrent mode failure），会触发完全STW但不压缩内存的FGC（假定命名为NoCompactFGC），或者触发完全STW并且压缩内存的FGC（假定命名为CompactFGC）。所以，这个参数的意思就是，连续多少次NoCompactFGC后触发CompactFGC。如果中间出现了CMS GC，那么又需要重新计数NoCompactFGC发生的次数。 -XX:+CMSScavengeBeforeRemark 在CMS GC前启动一次ygc，目的在于减少old gen对ygc gen的引用，降低remark时的开销—–一般CMS的GC耗时 80%都在remark阶段 -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasse 1、只有在使用CMS时才有效。 2、当调用System.gc()时会用CMS这个并行垃圾回收器去进行回收（比如大量使用DirectByteBuffer进行堆外内存操作，需要FGC来回收堆外内存的场景。就可以通过该参数让本来需要FGC才能搞定的事情用CMS GC就可以搞定了）。 3、除了能唤起并行垃圾回收器，还能卸载类。 -XX:ConcGCThreads&#x3D;2 CMS默认启动的并发线程数 ConcGCThreads =（ParallelGCThreads + 3）/4 -XX:+CMSParallelRemarkEnabled 为了减少重新标记第二次暂停的时间，开启并行remark -XX:+CMSScavengeBeforeRemark 如果remark还是过长的话，可以开启-XX:+CMSScavengeBeforeRemark选项，强制remark之前开始一次minor gc，减少remark的暂停时间，但是在remark之后也将立即开始又一次minor gc。 ParNew -XX:ParallelGCThreads&#x3D;2 ParallelGCThreads 是使用 ParNew 收集器时，使用的并行GC线程数。 从OpenJdk 8 源码中可以看出，CPU数量决定了ParallelGCThreads 的取值（如果CPU开启了超线程，ncpus 实际上是逻辑CPU数）： 当CPU数量小于8时，ParallelGCThreads = ncpus 当CPU数量大于8时，ParallelGCThreads = 8 + (ncpus - 8 ) ( 5/8 ) 如果你希望降低这个线程数，可以通过-XX:ParallelGCThreads= N 来调整。 JMM内存参数 堆 -Xmx4g -Xms4g -Xmn1512m 通过堆的最小值参数-Xms参数与堆的最大值参数-Xmx设置为一样4G，避免堆自动扩展。通过-Xmn设置年轻代大概是1.5G，老年代也就是剩余大概是2.5G。 建议：-Xmx=最大物理内存*[0.60.8]。物理内存4G，Xmx为2.4g3.2g为佳。 栈 -Xss256k JDK8默认的线程栈大小为1M，有点偏大。以笔者的经验，绝大部分微服务项目是可以调整为512k，甚至256k的（笔者的项目就是256k，运行的棒棒哒）。 元数据空间 -XX:MaxMetaspaceSize&#x3D;256m -XX:MetaspaceSize&#x3D;256M 如果是微服务架构，那么对于绝大部分应用来说，128M的元数据完全够用。不过，JDK8的元数据空间并不是指定多少就初始化多大的空间。而是按需扩展元数据空间。所以，我们可以设置256M。如果不设置这两个参数的话，元数据空间默认初始化只有20M出头，那么就会在应用启动过程中，Metaspace扩容发生FGC。 -XX:MaxDirectMemorySize -XX:NewRatio -XX:G1NewSizePercent&#x3D;5 -XX:G1MaxNewSizePercent&#x3D;60 GC相关 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xloggc:&#x2F;data&#x2F;log&#x2F;gclog&#x2F;gc.log 输出虚拟机中GC的详细情况。 -verbose:gc //在控制台输出GC情况 -XX:+PrintGCDetails //在控制台输出详细的GC情况 -XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式） -XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800） -Xloggc: filepath //将GC日志输出到指定文件中 [Full GC 168K-&gt;97K(1984K)， 0.0253873 secs] 解读如下: 箭头前后的数据168K和97K分别表示垃圾收集GC前后所有存活对象使用的内存容量，说明有168K-97K=71K的对象容量被回收，括号内的数据1984K为堆内存的总容量，收集所需要的时间是0.0253873秒（这个时间在每次执行的时候会有所不同） -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;data&#x2F;log&#x2F;jvmdump&#x2F; 设定如下两个参数（需要说明的是，HeapDumpPath参数指定的路径需要提前创建好，JVM没办法在生成dump文件时创建该目录），当JVM内存导致导致JVM进程退出时能自动在该目录下生成dump文件。 -XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息 -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles&#x3D;5 -XX:GCLogFileSize&#x3D;50M -Xloggc:&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;var&#x2F;log&#x2F;gc.log 不推荐 -XX:+UseGCLogFileRotation。打开或关闭GC日志滚动记录功能，要求必须设置 -Xloggc参数 -XX:NumberOfGCLogFiles 设置滚动日志文件的个数，必须大于等于1 -XX:GCLogFileSize 设置滚动日志文件的大小，必须大于8k。当前写日志文件大小超过该参数值时，日志将写入下一个文件 https://zhuanlan.zhihu.com/p/71221926 -XX:ErrorFile&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;var&#x2F;log&#x2F;jvm_err.log 其他 参数校验 校验JVM参数的网址：https://opts.console.heapdump.cn/ 引用 听我的！生产环境的CMS垃圾回收，一定要这样配置参数 JVM认知的常见10个误区 一次帮助云上客户 JVM 调优的记录 JVM GC算法 CMS 详解(转) CMS GC启动参数优化配置","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"CMS垃圾回收器","slug":"jvm-cms","date":"2022-03-12T09:48:06.000Z","updated":"2022-03-12T03:25:06.321Z","comments":true,"path":"2022/03/12/jvm-cms/","link":"","permalink":"https://qinglei1989.github.io/2022/03/12/jvm-cms/","excerpt":"CMS(Concurrent Mark Sweep)收集器，以获取最短回收停顿时间【也就是指Stop The World的停顿时间】为目标，多数应用于互联网站或者B/S系统的服务器端上。其中Concurrent并发是指垃圾收集的线程和用户执行的线程是可以同时执行的。","text":"CMS(Concurrent Mark Sweep)收集器，以获取最短回收停顿时间【也就是指Stop The World的停顿时间】为目标，多数应用于互联网站或者B/S系统的服务器端上。其中Concurrent并发是指垃圾收集的线程和用户执行的线程是可以同时执行的。 CMS 垃圾回收器 CMS垃圾回收特点 cms只会回收老年代和永久带（1.8开始为元数据区，需要设置CMSClassUnloadingEnabled），不会收集年轻代；cms是一种预处理垃圾回收器，它不能等到old内存用尽时回收，需要在内存用尽前，完成回收操作，否则会导致并发回收失败；所以cms垃圾回收器开始执行回收操作，有一个触发阈值，JDK1.6之后默认是老年代或永久带达到92%； CMS默认启动的回收线程是（处理器核心数量+3 / 4 CMS收集器 CMS是基于“标记-清除”算法实现的，整个过程分为4个步骤：1、初始标记（CMS initial mark）。2、并发标记（CMS concurrent mark）。3、重新标记（CMS remark）。4、并发清除（CMS concurrent sweep）。 注意：“标记”是指将存活的对象和要回收的对象都给标记出来，而“清除”是指清除掉将要回收的对象。 其中，初始标记、重新标记这两个步骤仍然需要“Stop The World”。 初始标记只是标记一下GC Roots能直接关联到的对象，速度很快。 并发标记阶段就是从GC Roots开始找到它能引用的所有其它对象的过程。 重新标记阶段则是为了修正并发标记期间因用户程序继续动作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 CMS收集器的动作步骤如下图所示，在整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，因此，从总体上看，CMS收集器的内存回收过程是与用户线程一起并发执行的： 优点：并发收集、低停顿【注意：这里的停顿指的是停止用户线程】 缺点：1、CMS收集器对CPU资源非常敏感2、CMS收集器无法处理浮动垃圾（Floating Garbage，就是指在之前判断该对象不是垃圾，由于用户线程同时也是在运行过程中的，所以会导致判断不准确的， 可能在判断完成之后在清除之前这个对像已经变成了垃圾对象，所以有可能本该此垃圾被回收但是没有被回收，只能等待下一次GC再将该对象回收，所以这种对像就是浮动垃圾）,可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。如果在应用中老年代增长不是太快，可能适当调高参数-XX：CMSInitiatingOccupancyFraction的值来提高触发百分比，以便降低内存回收次数从而获取更好的性能。要是CMS运行期间预留的内存无法满足程序需要时，虚拟机将启动后备预案:临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX：CMSInitiatingOccupancyFraction设置得太高很容易导致大量“Concurrent Mode Failure”失败，性能反而降低。3、收集结束时会有大量空间碎片产生，空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前进行一次Full GC。CMS收集器提供了一个-XX:+UseCMSCompactAtFullCollection开关参数（默认就是开启的），用于在CMS收集器顶不住要进行Full GC时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。 空间分配担保 在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。当大量对象在Minor GC后仍然存活，就需要老年代进行空间分配担保，把Survivor无法容纳的对象直接进入老年代。如果老年代判断到剩余空间不足（根据以往每一次回收晋升到老年代对象空间的平均值作为经验值），则进行一次Full GC。 CMS运行期间预留的内存无法满足程序分配新对象的需要，就会出现一次‘’并发失败‘，这时候虚拟机将不得不启动后备预案：冻结用户县城的执行，临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样老年代的停顿时间更长了。 引用 CMS垃圾收集器深入详解 CMS垃圾回收器详解 听我的！生产环境的CMS垃圾回收，一定要这样配置参数 从实际案例聊聊Java应用的GC优化","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"Parallel Scanvenge收集器","slug":"jvm-Parallel Scanvenge","date":"2022-03-06T16:17:31.000Z","updated":"2022-03-06T16:57:46.496Z","comments":true,"path":"2022/03/07/jvm-Parallel Scanvenge/","link":"","permalink":"https://qinglei1989.github.io/2022/03/07/jvm-Parallel%20Scanvenge/","excerpt":"如果说垃圾回收算法是内存回收的方法论，那么垃圾收集器就是具体实现。jvm会结合针对不同的场景及用户的配置使用不同的收集器。","text":"如果说垃圾回收算法是内存回收的方法论，那么垃圾收集器就是具体实现。jvm会结合针对不同的场景及用户的配置使用不同的收集器。 Parallel Scanvenge垃圾回收器 Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器，看上去和ParNew一样，但是Parallel Scanvenge更关注系统的吞吐量 。 吞吐量 = 运行用户代码的时间 / (运行用户代码的时间 + 垃圾收集时间) 比如虚拟机总共运行了120秒，垃圾收集时间用了1秒，吞吐量=(120-1)/120=99.167%。 若吞吐量越大，意味着垃圾收集的时间越短，则用户代码可以充分利用CPU资源，尽快完成程序的运算任务。 可设置参数： -XX:MaxGCPauseMillis控制最大的垃圾收集停顿时间， -XX:GC Time Ratio直接设置吞吐量的大小。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"ParNew收集器","slug":"jvm-parNew","date":"2022-03-06T16:17:31.000Z","updated":"2022-11-16T06:14:10.504Z","comments":true,"path":"2022/03/07/jvm-parNew/","link":"","permalink":"https://qinglei1989.github.io/2022/03/07/jvm-parNew/","excerpt":"如果说垃圾回收算法是内存回收的方法论，那么垃圾收集器就是具体实现。jvm会结合针对不同的场景及用户的配置使用不同的收集器。","text":"如果说垃圾回收算法是内存回收的方法论，那么垃圾收集器就是具体实现。jvm会结合针对不同的场景及用户的配置使用不同的收集器。 ParNew垃圾回收器 ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数（例如：-XX:SurvivorRatio、 -XX:PretenureSizeThreshold、-XX:HandlePromotionFailure等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样，实现上这两种收集器也共用了相当多的代码。ParNew收集器的工作过程如图3-7所示。 ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证能超越Serial收集器。当然，随着可以使用的CPU的数量的增加，它对于GC时系统资源的利用还是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多（譬如32个，现在CPU动辄就4核加超线程，服务器超过32个逻辑CPU的情况越来越多了）的环境下，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。 可以把这个收集器理解为Serial收集器的多线程版本。 它是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。 ParNew收集器也是使用 -XX: +UseConcMarkSweepGC选项后的默认新生代收集器，也可以使用 -XX:+UseParNewGC选项来强制指定它。 优点：在多CPU时，比Serial效率高。 缺点：收集过程暂停所有应用程序线程，单CPU时比Serial效率差。 算法：复制算法 应用：早期运行在Server模式下的虚拟机中首选的新生代收集器","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"Java 虚拟机进程状态工具jps","slug":"jvm-command-jps","date":"2022-03-01T09:48:06.000Z","updated":"2022-04-05T14:07:41.653Z","comments":true,"path":"2022/03/01/jvm-command-jps/","link":"","permalink":"https://qinglei1989.github.io/2022/03/01/jvm-command-jps/","excerpt":"JPS列出目标系统上的Java虚拟机，即Java进程。","text":"JPS列出目标系统上的Java虚拟机，即Java进程。 Java 虚拟机进程状态工具JPS 语法 jps [ options ] [ hostid ] 用于列出HotSpot虚拟机； 需要有访问权限才能显示在列表中； 如果没有指定hostid，列出本机的JVMs； 指定了hostid，则使用指定的协议和端口搜索目标主机上的JVMs； jps命令为搜索到的JVMs会列出本地的JVM标识或者lvmid；如果没有任何指定，则是lmid，加上应用或者jar文件名称的简写（省略包信息或者jar的路径）； jps通过Java启动器来查找main方法的类名和参数，如果JVM是自定义启动器，main方法的类或者jar文件的名称和参数不可用，输出 Unknown； jps列出JVMs受执行该命令的用户权限限制； C:\\Users\\wang&gt;jps 16324 8676 RemoteMavenServer36 19960 Application 22808 Jps 10668 RemoteJdbcServer 12668 22124 RemoteJdbcServer options q禁止输出main方法的类或者jar文件的名称和参数 C:\\Users\\wang&gt;jps -q 16324 8676 19960 10668 12668 22124 6492 m输出main方法的参数，JVM自带参数不会输出 C:\\Users\\wang&gt;jps -m 16324 19060 Jps -m 8676 RemoteMavenServer36 19960 Application 10668 RemoteJdbcServer com.mysql.cj.jdbc.Driver 12668 22124 RemoteJdbcServer com.mysql.jdbc.Driver l输出应用主类的完整包路径名称或者jar文件的全路径名称 C:\\Users\\wang&gt;jps -l 16324 8676 org.jetbrains.idea.maven.server.RemoteMavenServer36 1272 sun.tools.jps.Jps 19960 com.rrcq.authority.api.Application 10668 com.intellij.database.remote.RemoteJdbcServer 12668 22124 com.intellij.database.remote.RemoteJdbcServer v输出JVM的参数 C:\\Users\\wang&gt;jps -v 16324 exit -XX:ReservedCodeCacheSize&#x3D;512m -Xmx2026m -Xms128m -XX:+UseG1GC -XX:SoftRefLRUPolicyMSPerMB&#x3D;50 -XX:CICompilerCount&#x3D;2 -XX:+HeapDumpOnOutOfMemoryError -XX:-OmitStackTraceInFastThrow -ea -Dsun.io.useCanonCaches&#x3D;false -Djdk.http.auth.tunneling.disabledSchemes&#x3D;&quot;&quot; -Djdk.attach.allowAttachSelf&#x3D;true -Djdk.module.illegalAccess.silent&#x3D;true -Dkotlinx.coroutines.debug&#x3D;off -Djb.vmOptionsFile&#x3D;C:\\Users\\wang\\AppData\\Roaming\\JetBrains\\DataGrip2021.2\\datagrip64.exe.vmoptions -Djava.system.class.loader&#x3D;com.intellij.util.lang.PathClassLoader -Didea.vendor.name&#x3D;JetBrains -Didea.paths.selector&#x3D;DataGrip2021.2 -Didea.platform.prefix&#x3D;DataGrip -Dide.native.launcher&#x3D;true -XX:ErrorFile&#x3D;C:\\Users\\wang\\java_error_in_datagrip64_%p.log -XX:HeapDumpPath&#x3D;C:\\Users\\wang\\java_error_in_datagrip64.hprof 8676 RemoteMavenServer36 -Djava.awt.headless&#x3D;true -Dmaven.defaultProjectBuilder.disableGlobalModelCache&#x3D;true -Didea.version&#x3D;2021.1.3 -Didea.maven.embedder.version&#x3D;3.6.3 -Xmx768m -Dfile.encoding&#x3D;GBK 19960 Application -agentlib:jdwp&#x3D;transport&#x3D;dt_socket,address&#x3D;127.0.0.1:1065,suspend&#x3D;y,server&#x3D;n -XX:TieredStopAtLevel&#x3D;1 -Xverify:none -Dspring.output.ansi.enabled&#x3D;always -javaagent:C:\\Users\\wang\\AppData\\Local\\JetBrains\\IntelliJIdea2021.1\\captureAgent\\debugger-agent.jar -Dcom.sun.management.jmxremote -Dspring.jmx.enabled&#x3D;true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled&#x3D;true -Dfile.encoding&#x3D;UTF-8 10668 RemoteJdbcServer -Djava.rmi.server.hostname&#x3D;127.0.0.1 -Duser.timezone&#x3D;UTC -Xmx2026m -Xms128m -Dfile.encoding&#x3D;UTF-8 12668 exit -Xms128m -Xmx2026m -XX:ReservedCodeCacheSize&#x3D;512m -XX:+UseG1GC -XX:SoftRefLRUPolicyMSPerMB&#x3D;50 -XX:CICompilerCount&#x3D;2 -XX:+HeapDumpOnOutOfMemoryError -XX:-OmitStackTraceInFastThrow -ea -Dsun.io.useCanonCaches&#x3D;false -Djdk.http.auth.tunneling.disabledSchemes&#x3D;&quot;&quot; -Djdk.attach.allowAttachSelf&#x3D;true -Djdk.module.illegalAccess.silent&#x3D;true -Dkotlinx.coroutines.debug&#x3D;off -Djb.vmOptionsFile&#x3D;C:\\Users\\wang\\AppData\\Roaming\\JetBrains\\IntelliJIdea2021.1\\idea64.exe.vmoptions -Didea.jre.check&#x3D;true -Dide.native.launcher&#x3D;true -Didea.vendor.name&#x3D;JetBrains -Didea.paths.selector&#x3D;IntelliJIdea2021.1 -XX:ErrorFile&#x3D;C:\\Users\\wang\\java_error_in_idea64_%p.log -XX:HeapDumpPath&#x3D;C:\\Users\\wang\\java_error_in_idea64.hprof 22124 RemoteJdbcServer -Djava.rmi.server.hostname&#x3D;127.0.0.1 -Duser.timezone&#x3D;UTC -Xmx2026m -Xms128m -Dfile.encoding&#x3D;UTF-8 9964 Jps -Dapplication.home&#x3D;C:\\Program Files\\Java\\jdk1.8.0_121 -Xms8m 引用 JPS Java自带JVM监控工具jps使用详细说明","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"Serial收集器","slug":"jvm-serial","date":"2022-02-27T16:17:31.000Z","updated":"2022-03-01T06:05:34.681Z","comments":true,"path":"2022/02/28/jvm-serial/","link":"","permalink":"https://qinglei1989.github.io/2022/02/28/jvm-serial/","excerpt":"如果说垃圾回收算法是内存回收的方法论，那么垃圾收集器就是具体实现。jvm会结合针对不同的场景及用户的配置使用不同的收集器。","text":"如果说垃圾回收算法是内存回收的方法论，那么垃圾收集器就是具体实现。jvm会结合针对不同的场景及用户的配置使用不同的收集器。 Serial垃圾回收器 现代的商用虚拟机的都是采用分代收集的，不同的区域用不同的收集器。常用的7种收集器，其适用的范围如图所示 年轻代收集器 Serial、ParNew、Parallel Scavenge 老年代收集器 Serial Old、Parallel Old、CMS收集器 特殊收集器 G1收集器[新型，不在年轻、老年代范畴内] Serial Serial 收集器是最基础、历史最悠久的收集器，曾经（JDK1.3.1之前） 是HotSpot 新生代收集器的唯一选择，对应的老年代是 Serial Old 收集器。 Serial:基于复制算法，Serial Old：基于标记-整理算法。 两大特点： 1.使用一个处理器或一条收集线程取完成垃圾收集工作； 2.进行垃圾收集时，必须暂停其他所有工作线程，直到它收集结束。 缺点： 多线程环境下，效率低下。 优点： 1.简单而高效，迄今为止仍然时HotSpot 虚拟机在客户端模式下的默认新生代收集器； 2.在所有收集器里额外内存消耗最小。 查看JVM使用的默认的垃圾收集器 cmd执行命令： java -XX:+PrintCommandLineFlags -version 输出如下（举例）： C:\\Users\\wang&gt;java -XX:+PrintCommandLineFlags -version -XX:InitialHeapSize&#x3D;265625408 -XX:MaxHeapSize&#x3D;4250006528 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGC java version &quot;1.8.0_121&quot; Java(TM) SE Runtime Environment (build 1.8.0_121-b13) Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode) 自JDK7u4开始的JDK7u系列与JDK8系列，如果指定了：-XX:+UseParallelGC，则会默认开启：XX:+UseParallelOldGC 。 验证默认垃圾回收器 简单的controller代码 @RestController @RequestMapping(&quot;&#x2F;jvm&quot;) @Slf4j public class JvmController &#123; static List&lt;Object&gt; list &#x3D; new ArrayList&lt;&gt;(); @RequestMapping(&quot;&#x2F;addlist&quot;) public void lust(@RequestParam(&quot;value&quot;) Integer value) throws InterruptedException &#123; byte[] bytes &#x3D; new byte[value * 1024 * 1024]; list.add(bytes); &#125; @RequestMapping(&quot;&#x2F;clearlist&quot;) public void clearlist() throws InterruptedException &#123; list.clear(); &#125; &#125; JVM参数,显式使用-XX:+UseParallelGC -Xms100M -Xmx100M -Xmn70M -XX:PretenureSizeThreshold&#x3D;5M -XX:+UseParallelGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCCause -Xloggc:gc-old.log -verbose:gc 启动SpringBoot项目 C:\\Users\\wang&gt;jps 14864 RemoteJdbcServer 16324 1716 Launcher 21492 Jps 10492 Application 10668 RemoteJdbcServer 10796 RemoteMavenServer36 12668 C:\\Users\\wang&gt;jmap -heap 10492 Attaching to process ID 10492, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.121-b13 using thread-local object allocation. Parallel GC with 8 thread(s) Heap Configuration: MinHeapFreeRatio &#x3D; 0 MaxHeapFreeRatio &#x3D; 100 MaxHeapSize &#x3D; 104857600 (100.0MB) NewSize &#x3D; 73400320 (70.0MB) MaxNewSize &#x3D; 73400320 (70.0MB) OldSize &#x3D; 31457280 (30.0MB) NewRatio &#x3D; 2 SurvivorRatio &#x3D; 8 MetaspaceSize &#x3D; 21807104 (20.796875MB) CompressedClassSpaceSize &#x3D; 1073741824 (1024.0MB) MaxMetaspaceSize &#x3D; 17592186044415 MB G1HeapRegionSize &#x3D; 0 (0.0MB) Heap Usage: PS Young Generation Eden Space: capacity &#x3D; 31457280 (30.0MB) used &#x3D; 14946488 (14.254081726074219MB) free &#x3D; 16510792 (15.745918273925781MB) 47.51360575358073% used From Space: capacity &#x3D; 20971520 (20.0MB) used &#x3D; 13754640 (13.117446899414062MB) free &#x3D; 7216880 (6.8825531005859375MB) 65.58723449707031% used To Space: capacity &#x3D; 20971520 (20.0MB) used &#x3D; 0 (0.0MB) free &#x3D; 20971520 (20.0MB) 0.0% used PS Old Generation capacity &#x3D; 31457280 (30.0MB) used &#x3D; 20363760 (19.420394897460938MB) free &#x3D; 11093520 (10.579605102539062MB) 64.73464965820312% used 20519 interned Strings occupying 1861040 bytes. 然后我们不断地调用 http://localhost/jvm/addlist?value=10 很容易就能触发old gc。 此时，查看我们的gc日志，下边红色我标出了ParOldGen字样： 2022-03-01T11:14:24.031+0800: 451.667: [Full GC (Ergonomics) [PSYoungGen: 12566K-&gt;3792K(51712K)] [ParOldGen: 30158K-&gt;30275K(30720K)] 42725K-&gt;34067K(82432K), [Metaspace: 53823K-&gt;53480K(1099776K)], 0.1418099 secs] [Times: user&#x3D;0.70 sys&#x3D;0.00, real&#x3D;0.14 secs] 2022-03-01T11:14:25.402+0800: 453.037: [Full GC (Ergonomics) [PSYoungGen: 25764K-&gt;23188K(51712K)] [ParOldGen: 30275K-&gt;27887K(30720K)] 56039K-&gt;51076K(82432K), [Metaspace: 53480K-&gt;53480K(1099776K)], 0.1561581 secs] [Times: user&#x3D;0.69 sys&#x3D;0.00, real&#x3D;0.16 secs] 2022-03-01T11:14:25.559+0800: 453.194: [Full GC (Allocation Failure) [PSYoungGen: 23188K-&gt;23176K(51712K)] [ParOldGen: 27887K-&gt;27720K(30720K)] 51076K-&gt;50897K(82432K), [Metaspace: 53480K-&gt;53457K(1099776K)], 0.2252083 secs] [Times: user&#x3D;0.91 sys&#x3D;0.00, real&#x3D;0.22 secs] 2022-03-01T11:14:25.986+0800: 453.621: [Full GC (Ergonomics) [PSYoungGen: 30028K-&gt;23978K(51712K)] [ParOldGen: 27720K-&gt;27661K(30720K)] 57749K-&gt;51639K(82432K), [Metaspace: 53928K-&gt;53928K(1099776K)], 0.2050496 secs] [Times: user&#x3D;0.70 sys&#x3D;0.03, real&#x3D;0.20 secs] 说明启用了Parallel Old这个老年代收集器。 使用Jconsole连接该程序，切换到VM概要这个tab，注意下图红圈圈出来的地方： JVM参数 显式使用-XX:+UseSerialGC -Xms100M -Xmx100M -Xmn70M -XX:PretenureSizeThreshold&#x3D;5M -client -XX:+UseSerialGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCCause -Xloggc:gc-old.log -verbose:gc gc日志如下: Java HotSpot(TM) 64-Bit Server VM (25.121-b13) for windows-amd64 JRE (1.8.0_121-b13), built on Dec 12 2016 18:21:36 by &quot;java_re&quot; with MS VC++ 10.0 (VS2010) Memory: 4k page, physical 16601588k(5142084k free), swap 26038772k(4551612k free) CommandLine flags: -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:InitialHeapSize&#x3D;104857600 -XX:+ManagementServer -XX:MaxHeapSize&#x3D;104857600 -XX:MaxNewSize&#x3D;73400320 -XX:NewSize&#x3D;73400320 -XX:PretenureSizeThreshold&#x3D;5242880 -XX:+PrintGC -XX:+PrintGCCause -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:TieredStopAtLevel&#x3D;1 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-UseLargePagesIndividualAllocation -XX:+UseSerialGC 2022-03-01T11:23:14.044+0800: 1.617: [GC (Allocation Failure) 2022-03-01T11:23:14.044+0800: 1.618: [DefNew: 57344K-&gt;5487K(64512K), 0.0091428 secs] 57344K-&gt;5487K(95232K), 0.0093811 secs] [Times: user&#x3D;0.02 sys&#x3D;0.00, real&#x3D;0.01 secs] 2022-03-01T11:23:14.527+0800: 2.100: [GC (Allocation Failure) 2022-03-01T11:23:14.527+0800: 2.100: [DefNew: 62831K-&gt;5807K(64512K), 0.0139393 secs] 62831K-&gt;8566K(95232K), 0.0139920 secs] [Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.01 secs] 2022-03-01T11:23:14.643+0800: 2.216: [Full GC (Metadata GC Threshold) 2022-03-01T11:23:14.643+0800: 2.216: [Tenured: 2758K-&gt;6966K(30720K), 0.0211325 secs] 28297K-&gt;6966K(95232K), [Metaspace: 20450K-&gt;20450K(1067008K)], 0.0212119 secs] [Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.02 secs] 此时，新生代是DefNew，老年代是Tenured，明显和前面使用了 -XX:+UseParallelGC时候不一样。 引用 JVM经典垃圾回收器之 serial 收集器 和 serialOld 收集器 查看JVM使用的默认的垃圾收集器","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"JAVA内存模型","slug":"jvm-jmm","date":"2022-02-26T16:32:02.000Z","updated":"2022-03-06T16:14:03.684Z","comments":true,"path":"2022/02/27/jvm-jmm/","link":"","permalink":"https://qinglei1989.github.io/2022/02/27/jvm-jmm/","excerpt":"","text":"Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。 5大内存区域 程序计数器 程序计数器是一块很小的内存空间，它是线程私有的，可以认作为当前线程的行号指示器。 这块内存区域是虚拟机规范中唯一没有OutOfMemoryError的区域 Java栈（虚拟机栈） 同计数器也为线程私有，生命周期与相同，就是我们平时说的栈，栈描述的是Java方法执行的内存模型。栈帧大小在编译期已经确定，不受运行期数据影响。 每个方法被执行的时候都会创建一个栈帧用于存储局部变量表，操作栈，动态链接，方法出口等信息。每一个方法被调用的过程就对应一个栈帧在虚拟机栈中从入栈到出栈的过程。 Java虚拟机栈可能出现两种类型的异常： 线程请求的栈深度大于虚拟机允许的栈深度，将抛出StackOverflowError。 虚拟机栈空间可以动态扩展，当动态扩展是无法申请到足够的空间时，抛出OutOfMemory异常。 本地方法栈 本地方法栈是与虚拟机栈发挥的作用十分相似,区别是虚拟机栈执行的是Java方法服务，而本地方法栈则为虚拟机使用到的native方法服务，可能底层调用的c或者c++。 堆 堆是java虚拟机管理内存最大的一块内存区域，因为堆存放的对象是线程共享的，所以多线程的时候也需要同步机制。因此需要重点了解下。java虚拟机规范对这块的描述是:所有对象实例及数组都要在堆上分配内存，但随着JIT编译器的发展和逃逸分析技术的成熟，这个说法也不是那么绝对，但是大多数情况都是这样的。 它是所有线程共享的，它的目的是存放对象实例。同时它也是GC所管理的主要区域，因此常被称为GC堆，根据虚拟机规范，Java堆可以存在物理上不连续的内存空间，就像磁盘空间只要逻辑是连续的即可。它的内存大小可以设为固定大小，也可以扩展。当前主流的虚拟机如HotPot都能按扩展实现(通过设置 -Xmx和-Xms)，如果堆中没有内存内存完成实例分配，而且堆无法扩展将报OOM错误(OutOfMemoryError) 方法区(永久代) 方法区同堆一样，是所有线程共享的内存区域。用于存储已被虚拟机加载的类信息、常量、静态变量，如static修饰的变量加载类的时候就被加载到方法区中。 运行时常量池是方法区的一部分，class文件除了有类的字段、接口、方法等描述信息之外，还有常量池用于存放编译期间生成的各种字面量和符号引用。 JDK8真正开始废弃永久代，而使用元空间(Metaspace) 垃圾回收 既然我们要做垃圾回收，首先我们得搞清楚垃圾的定义是什么，哪些内存是需要回收的。 引用计数器法 引用计数算法（Reachability Counting）是通过在对象头中分配一个空间来保存该对象被引用的次数（Reference Count）。如果该对象被其它对象引用，则它的引用计数加1，如果删除对该对象的引用，那么它的引用计数就减1，当该对象的引用计数为0时，那么该对象就会被回收。 缺点：无法解决循环依赖问题 可达性分析算法 可达性分析算法（Reachability Analysis）的基本思路是，通过一些被称为引用链（GC Roots）的对象作为起点，从这些节点开始向下搜索，搜索走过的路径被称为（Reference Chain)，当一个对象到 GC Roots 没有任何引用链相连时（即从 GC Roots 节点到该节点不可达），则证明该对象是不可用的。 怎么回收垃圾 标记清除算法 缺点：内存碎片化的问题 复制算法 缺点：不用考虑内存碎片等复杂情况，但是空间利用率低 标记整理算法 缺点：标记整理算法一方面在标记清除算法上做了升级，解决了内存碎片的问题，也规避了复制算法只能利用一半内存区域的弊端。看起来很美好，但从上图可以看到，它对内存变动更频繁，需要整理所有存活对象的引用地址，在效率上比复制算法要差很多。 分代收集算法分代收集算法 严格来说并不是一种思想或理论，而是融合上述3种基础的算法思想，而产生的针对不同情况所采用不同算法的一套组合拳。对象存活周期的不同将内存划分为几块。一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用标记-清理或者标记——整理算法来进行回收。 内存模型与回收策略 Java 堆主要分为2个区域-年轻代与老年代，其中年轻代又分 Eden 区和 Survivor 区，其中 Survivor 区又分 From 和 To 2个区。 Eden 区 大多数情况下，对象会在新生代 Eden 区中进行分配，当 Eden 区没有足够空间进行分配时，虚拟机会发起一次 Minor GC，Minor GC 相比 Major GC 更频繁，回收速度也更快。通过 Minor GC 之后，Eden 会被清空，Eden 区中绝大部分对象会被回收，而那些无需回收的存活对象，将会进到 Survivor 的 From 区（若 From 区不够，则直接进入 Old 区）。 Survivor 区 Survivor 区相当于是 Eden 区和 Old 区的一个缓冲，存在意义就是减少被送到老年代的对象，进而减少 Major GC 的发生。Survivor 的预筛选保证，只有经历16次 Minor GC 还能在新生代中存活的对象，才会被送到老年代。Survivor 又分为2个区，一个是 From 区，一个是 To 区。每次执行 Minor GC，会将 Eden 区和 From 存活的对象放到 Survivor 的 To 区（如果 To 区不够，则直接进入 Old 区）。 设置两个 Survivor 区最大的好处就是解决内存碎片化与效率问题 我觉得本质问题还是考虑得效率的问题。如果如博主说的，产生内存碎片化问题，那么我单独再采用一次整理算法也可以解决碎片化问题，而为什么没有采用算法，而是采用了使用两块survivor，实际上还是考虑到整理空间所消耗的性能远远大于使用两块survivor通过复制算法解决。两块 Survivor 区可能是经过权衡之后的最佳方案。 Old 区 老年代占据着2/3的堆内存空间，只有在 Major GC 的时候才会进行清理，每次 GC 都会触发“Stop-The-World”。内存越大，STW 的时间也越长，所以内存也不仅仅是越大就越好。老年代这里采用的是标记整理算法。 除了上述所说，在内存担保机制下，无法安置的对象会直接进到老年代，以下几种情况也会进入老年代。 ★ 大对象 大对象指需要大量连续内存空间的对象，这部分对象不管是不是“朝生夕死”，都会直接进到老年代。这样做主要是为了避免在 Eden 区及2个 Survivor 区之间发生大量的内存复制。当你的系统有非常多“朝生夕死”的大对象时，得注意了。 ★ 长期存活对象 虚拟机给每个对象定义了一个对象年龄（Age）计数器。正常情况下对象会不断的在 Survivor 的 From 区与 To 区之间移动，对象在 Survivor 区中每经历一次 Minor GC，年龄就增加1岁。当年龄增加到15岁时，这时候就会被转移到老年代。当然，这里的15，JVM 也支持进行特殊设置。 ★ 动态对象年龄 虚拟机并不重视要求对象年龄必须到15岁，才会放入老年区，如果 Survivor 空间中相同年龄所有对象大小的总合大于 Survivor 空间的一半，年龄大于等于该年龄的对象就可以直接进去老年区，无需等你“成年”。 引用 咱们从头到尾说一次 Java 的垃圾回收 深入理解JVM-内存模型（jmm）和GC Java内存模型（JMM）总结","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"JWT","slug":"tools-jwt","date":"2022-02-23T14:18:03.000Z","updated":"2022-02-24T03:40:06.717Z","comments":true,"path":"2022/02/23/tools-jwt/","link":"","permalink":"https://qinglei1989.github.io/2022/02/23/tools-jwt/","excerpt":"Json web token (JWT)，是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准。 JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。","text":"Json web token (JWT)，是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准。 JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。 JWTjwt由.号分隔的三部分组成，第一部分我们称它为头部（header)，第二部分我们称其为载荷（payload)，第三部分是签名（signature)。 示例：xxxxx.yyyyy.zzzzz Header jwt的头部承载两部分信息： 声明类型：这里是jwt； 声明加密的算法：通常直接使用 HMAC SHA256。 完整的头部就像下面这样的JSON： &#123; &quot;alg&quot;: &quot;HS256&quot;, &quot;typ&quot;: &quot;JWT&quot; &#125; 然后进行base64编码，构成了第一部分。 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9 Payload 载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分： 标准中注册的声明； 公共的声明； 私有的声明。 标准中注册的声明 (建议但不强制使用) ： iss: jwt签发者； sub: jwt所面向的用户； aud: 接收jwt的一方； exp: jwt的过期时间，这个过期时间必须要大于签发时间； nbf: 定义在什么时间之前，该jwt都是不可用的.； iat: jwt的签发时间； jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。 公共的声明 ：公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密。 私有的声明 ：私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。 定义一个payload： &#123; &quot;sub&quot;: &quot;1234567890&quot;, &quot;name&quot;: &quot;John Doe&quot;, &quot;admin&quot;: true &#125; 然后将其进行base64编码，得到Jwt的第二部分。 TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ Signature jwt的第三部分是一个签名信息，这个签名信息由三部分组成： header (base64后的) payload (base64后的) secret 这个部分需要base64编码后的header和base64编码后的payload使用.连接组成的字符串，然后通过header中声明的加密方式进行加盐secret组合加密，然后就构成了jwt的第三部分。 HMACSHA256( base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload), secret) 生成的Signature为 nuHomjWUwAeeGBK-bDGl_xL7Cx-SjRnZEjSQzbvMZF4 将这三部分用.连接成一个完整的字符串,构成了最终的jwt。 标准携带方式 一般是在请求头里加入Authorization，并加上Bearer 标注： &#39;Authorization&#39;: &#39;Bearer &#39; + token 验证 通过base64解码payload，验证iss（key），为空或不正确返回403； 验证payload中的exp（过期时间戳），为空或过期返回403； 通过对第一二段字符串拼接，再次根据数据库中次key对应的secret进行HS256加密，与token中的第三段字符串进行比对，不一致返回403。 Jwt token生成验证 引用 传说中的jwt 基于 JWT + Refresh Token 的用户认证实践 [采用JWT有效期内刷新Token方案]","categories":[{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"jwt","slug":"jwt","permalink":"https://qinglei1989.github.io/tags/jwt/"}]},{"title":"Eclipse Memory Analysis使用","slug":"jvm-eclipse","date":"2022-02-21T08:40:20.000Z","updated":"2022-02-22T02:24:01.642Z","comments":true,"path":"2022/02/21/jvm-eclipse/","link":"","permalink":"https://qinglei1989.github.io/2022/02/21/jvm-eclipse/","excerpt":"Eclipse Memory Analyzer是一个快速而功能丰富的Java堆分析器，可帮助您查找内存泄漏并减少内存消耗。使用内存分析器分析数亿个对象的生产性堆转储，快速计算保留的对象大小，查看谁阻止垃圾收集器收集对象，运行报告以自动提取泄漏的嫌疑人。","text":"Eclipse Memory Analyzer是一个快速而功能丰富的Java堆分析器，可帮助您查找内存泄漏并减少内存消耗。使用内存分析器分析数亿个对象的生产性堆转储，快速计算保留的对象大小，查看谁阻止垃圾收集器收集对象，运行报告以自动提取泄漏的嫌疑人。 Eclipse Memory Analyzer 安装 下载Eclipse并安装，下载地址：https://www.eclipse.org/downloads/。 在Eclipse help -&gt; Eclipse Marketplace下搜索Memory.找到图中的软件，默认安装就可以。 测试代码 package org.fenixsoft.jvm.chapter2; import java.util.ArrayList; import java.util.List; &#x2F;** * VM Args：-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError * * @author zzm *&#x2F; public class HeapOOM &#123; static class OOMObject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMObject&gt; list &#x3D; new ArrayList&lt;OOMObject&gt;(); while (true) &#123; list.add(new OOMObject()); &#125; &#125; &#125; VM options配置 -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;d:\\test.hprof HeapDumpOnOutOfMemoryError 内存溢出时dump文件保存在HeapDumpPath指定的位置，-XX:HeapDumpPath&#x3D;&#x2F;usr&#x2F;local&#x2F;tomcat 这样可以只指定保持的目录 -Xms20m 指定JVM初始内存为20m，-Xmx20m 指定JVM最大可用内存为20m idea中异常信息打印： org.fenixsoft.jvm.chapter2.HeapOOM java.lang.OutOfMemoryError: Java heap space Dumping heap to java_pid21692.hprof ... Heap dump file created [28257710 bytes in 0.164 secs] Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3210) at java.util.Arrays.copyOf(Arrays.java:3181) at java.util.ArrayList.grow(ArrayList.java:261) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227) at java.util.ArrayList.add(ArrayList.java:458) at org.fenixsoft.jvm.chapter2.HeapOOM.main(HeapOOM.java:20) Process finished with exit code 1 分析 在Eclipse Memory Analyzer试图中，选择File -&gt; Open Heap Dump Overview页面 在窗口上方的位置可以看到 heapDump 的 size，以及类、对象和类加载器的数量。在窗口中最醒目的饼图直观地显示了 dump 中最大的几个对象。鼠标光标划过饼图中代表某个对象的区块时可以在左侧 Inspector 窗口中看到对象的细节，在区块上点击鼠标左键可以通过菜单项钻取到关于其对应的对象更多的细节。 我们可以看到占用很大一部分内存的有几个深色的饼区，这些就可以当做我们稍后着重看的地方 这里看到最大的那个占用内存的对象，对象名称，Shallow Size也就是本身在堆内存中120B并不大，但是Retained Size有15.5M，说明这个大对象中包含的引用对象很多。 Histogram 点开Histogram，点击Shallow Heap或Retained Heap排序，可以看见前排占用大量空间的有哪些 Shallow Heap浅堆：java对象占用的内存 Retained Heap深堆：java对象及对象引用的类占用的内存 ，jvm gc回收时释放的内存 Retained Heap深堆大于等于Shallow Heap浅堆 如果想看这个具体有哪些对象，可以点击这个右键-&gt;show objects by class -&gt; by outgoing Reference Incomming Reference 指的是引用当前对象的外部对象； Outgoing Reference 指的是当前对象引用的外部对象。对象的 incomming reference 保证对象处于 alive 从而免于被垃圾回收掉。Outgoing reference 则展示了对象的具体内容， 有助于我们发现对象的用处。 比如可以看到Object[]这个对象本身就很大，它的引用外部对象很小，说明它的内存主要是由于本身定义的过大引起的。第二个对象就是由于引用外部对象过多引起的。 Dominator Tree Dominator Tree 展示了 Heap Dump 中最大的几个对象。 如果 dominator tree 中对象的父节点被移除的话那么， 那么相应对象及其后代节点也面临被回收的状态。 如果想探究一个对象持有了哪些对象并使之处于 alive， Dominator Tree 会是个很有用的工具。 此外还可以在 Dominator Tree 上按照 classloader 或 package 进行分组， 从而简化分析的过程。 可以点击左边你的三角展开查看持有的alive对象。 Top Consumers Top Consumer 与Override页类似，Top Consumer 页按照对象、类、 类加载器和包也分别提供了对应的类似图表信息 Leak Suspects 通过前面简单的了解，我们大致了解了什么地方的内存比较占用高，最后这个报告是Mat帮我们分析的可能怀疑内存泄露的地方 引用 Eclipse Memory Analyzer入门学习笔记 Eclipse Memory Analysis的安装和使用+分析","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"}]},{"title":"ps命令","slug":"linux-ps","date":"2022-02-20T14:32:20.000Z","updated":"2022-02-19T18:02:25.016Z","comments":true,"path":"2022/02/20/linux-ps/","link":"","permalink":"https://qinglei1989.github.io/2022/02/20/linux-ps/","excerpt":"Linux ps （英文全拼：process status）命令用于显示当前进程的状态，类似于 windows 的任务管理器。","text":"Linux ps （英文全拼：process status）命令用于显示当前进程的状态，类似于 windows 的任务管理器。 Linux ps 命令 语法 ps [options][--help] 常用参数 -A 列出所有的进程 -w 显示加宽可以显示较多的资讯 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 au(x) 输出格式 : USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND USER: 行程拥有者 PID: pid %CPU: 占用的 CPU 使用率 %MEM: 占用的记忆体使用率 VSZ: 占用的虚拟记忆体大小 RSS: 占用的记忆体大小 TTY: 终端的次要装置号码 (minor device number of tty) STAT: 该行程的状态: D: 无法中断的休眠状态 (通常 IO 的进程) R: 正在执行中 S: 静止状态 T: 暂停执行 Z: 不存在但暂时无法消除 W: 没有足够的记忆体分页可分配 &lt;: 高优先序的行程 N: 低优先序的行程 L: 有记忆体分页分配并锁在记忆体内 (实时系统或捱A I&#x2F;O) START: 行程开始时间 TIME: 执行的时间 COMMAND:所执行的指令 应用举例 ps -l只能查看自己bash的进程 work@authority-api-v1-6944b5848b-6x5d2:~$ ps -l F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 4 S 1000 1519 0 0 80 0 - 5283 wait pts&#x2F;0 00:00:00 bash 0 R 1000 1536 1519 0 80 0 - 7486 - pts&#x2F;0 00:00:00 ps work@authority-api-v1-6944b5848b-6x5d2:~$ ps aux所有系统运行的进程，按照PID的顺序来排序显示 work@authority-api-v1-6944b5848b-6x5d2:~$ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND work 1 0.0 0.0 4280 64 ? Ss Feb15 0:00 &#x2F;bin&#x2F;sh -c PROJECT_DIR&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api $PROJECT_DIR&#x2F;bin&#x2F;bootstrap work 6 0.0 0.0 19728 992 ? S Feb15 0:00 &#x2F;bin&#x2F;bash &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;bin&#x2F;bootstrap run work 16 0.0 0.0 19880 1152 ? S Feb15 0:00 &#x2F;bin&#x2F;bash &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;bin&#x2F;..&#x2F;&#x2F;lib&#x2F;authority-api.jar run work 47 0.8 0.3 7494192 686500 ? Sl Feb15 56:13 &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;bin&#x2F;java -Dsun.misc.URLClassPath.disableJarChecking&#x3D;true - work 1519 0.0 0.0 21132 4696 pts&#x2F;0 Ss 00:56 0:00 bash work 1544 0.0 0.0 38384 3072 pts&#x2F;0 R+ 01:35 0:00 ps aux 查找指定进程 work@authority-api-v1-6944b5848b-6x5d2:~$ ps -ef | grep java| grep auth work 47 16 0 Feb15 ? 00:56:13 &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;bin&#x2F;java -Dsun.misc.URLClassPath.disableJarChecking&#x3D;true -DLOG_PATH&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-api -server -XX:MaxRAMPercentage&#x3D;30.0 -XX:InitialRAMPercentage&#x3D;30.0 -XX:MinRAMPercentage&#x3D;30.0 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-api&#x2F;jvm -XX:ErrorFile&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-api&#x2F;jvm&#x2F;jvm_err.log -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:ConcGCThreads&#x3D;2 -XX:ParallelGCThreads&#x3D;2 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction&#x3D;70 -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles&#x3D;1 -XX:GCLogFileSize&#x3D;50M -verbose:gc -XX:+PrintHeapAtGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime -Xloggc:&#x2F;mnt&#x2F;logs&#x2F;authority-api&#x2F;jvm&#x2F;gc.log -javaagent:&#x2F;usr&#x2F;local&#x2F;jmx-exporter&#x2F;jmx_prometheus_javaagent-0.14.0.jar&#x3D;9990:&#x2F;usr&#x2F;local&#x2F;jmx-exporter&#x2F;prometheus-jmx-config.yaml -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -jar &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;lib&#x2F;authority-api.jar --server.address&#x3D;0.0.0.0 --spring.config.location&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;conf&#x2F; --spring.profiles.active&#x3D;testing --logging.config&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;conf&#x2F;log4j2.yml 显示指定用户信息 work@authority-api-v1-6944b5848b-6x5d2:~$ ps -u work PID TTY TIME CMD 1 ? 00:00:00 sh 6 ? 00:00:00 bootstrap 16 ? 00:00:00 authority-api.j 47 ? 00:56:13 java 1519 pts&#x2F;0 00:00:00 bash 1549 pts&#x2F;0 00:00:00 ps work@authority-api-v1-6944b5848b-6x5d2:~$ 显示所有进程信息，连同命令行 work@authority-api-v1-6944b5848b-6x5d2:~$ ps -ef UID PID PPID C STIME TTY TIME CMD work 1 0 0 Feb15 ? 00:00:00 &#x2F;bin&#x2F;sh -c PROJECT_DIR&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api $PROJECT_DIR&#x2F;bin&#x2F;bootstrap run work 6 1 0 Feb15 ? 00:00:00 &#x2F;bin&#x2F;bash &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;bin&#x2F;bootstrap run work 16 6 0 Feb15 ? 00:00:00 &#x2F;bin&#x2F;bash &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;bin&#x2F;..&#x2F;&#x2F;lib&#x2F;authority-api.jar run work 47 16 0 Feb15 ? 00:56:13 &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;bin&#x2F;java -Dsun.misc.URLClassPath.disableJarChecking&#x3D;true -DLOG_PATH&#x3D;&#x2F;mnt&#x2F; work 1519 0 0 00:56 pts&#x2F;0 00:00:00 bash work 1550 1519 0 01:40 pts&#x2F;0 00:00:00 ps -ef work@authority-api-v1-6944b5848b-6x5d2:~$ 根据 CPU 使用来升序排序 work@authority-api-v1-6944b5848b-6x5d2:~$ ps aux --sort -pcpu USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND work 47 0.8 0.3 7494192 686500 ? Sl Feb15 56:14 &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;bin&#x2F;java -Dsun.misc.URLClassPath.disableJarChecking&#x3D;true - work 1 0.0 0.0 4280 64 ? Ss Feb15 0:00 &#x2F;bin&#x2F;sh -c PROJECT_DIR&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api $PROJECT_DIR&#x2F;bin&#x2F;bootstrap work 6 0.0 0.0 19728 992 ? S Feb15 0:00 &#x2F;bin&#x2F;bash &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;bin&#x2F;bootstrap run work 16 0.0 0.0 19880 1152 ? S Feb15 0:00 &#x2F;bin&#x2F;bash &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;bin&#x2F;..&#x2F;&#x2F;lib&#x2F;authority-api.jar run work 1519 0.0 0.0 21132 4812 pts&#x2F;0 Ss 00:56 0:00 bash work 1555 0.0 0.0 38384 2984 pts&#x2F;0 R+ 01:45 0:00 ps aux --sort -pcpu work@authority-api-v1-6944b5848b-6x5d2:~$ 根据 内存使用来升序排序 work@authority-api-v1-6944b5848b-6x5d2:~$ ps -aux --sort -pmem USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND work 47 0.8 0.3 7494192 686500 ? Sl Feb15 56:14 &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;bin&#x2F;java -Dsun.misc.URLClassPath.disableJarChecking&#x3D;true - work 1519 0.0 0.0 21132 4812 pts&#x2F;0 Ss 00:56 0:00 bash work 1558 0.0 0.0 38384 3100 pts&#x2F;0 R+ 01:46 0:00 ps -aux --sort -pmem work 16 0.0 0.0 19880 1152 ? S Feb15 0:00 &#x2F;bin&#x2F;bash &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;bin&#x2F;..&#x2F;&#x2F;lib&#x2F;authority-api.jar run work 6 0.0 0.0 19728 992 ? S Feb15 0:00 &#x2F;bin&#x2F;bash &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;bin&#x2F;bootstrap run work 1 0.0 0.0 4280 64 ? Ss Feb15 0:00 &#x2F;bin&#x2F;sh -c PROJECT_DIR&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api $PROJECT_DIR&#x2F;bin&#x2F;bootstrap work@authority-api-v1-6944b5848b-6x5d2:~$ 我们也可以将它们合并到一个命令，并通过管道显示前10个结果： work@authority-api-v1-6944b5848b-6x5d2:~$ ps aux --sort -pcpu,+pmem | head -n 3 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND work 47 0.8 0.3 7494192 686500 ? Sl Feb15 56:14 &#x2F;usr&#x2F;local&#x2F;openjdk-8&#x2F;bin&#x2F;java -Dsun.misc.URLClassPath.disableJarChecking&#x3D;true -DLOG_PATH&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-api -server -XX:MaxRAMPercentage&#x3D;30.0 -XX:InitialRAMPercentage&#x3D;30.0 -XX:MinRAMPercentage&#x3D;30.0 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-api&#x2F;jvm -XX:ErrorFile&#x3D;&#x2F;mnt&#x2F;logs&#x2F;authority-api&#x2F;jvm&#x2F;jvm_err.log -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:ConcGCThreads&#x3D;2 -XX:ParallelGCThreads&#x3D;2 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction&#x3D;70 -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles&#x3D;1 -XX:GCLogFileSize&#x3D;50M -verbose:gc -XX:+PrintHeapAtGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime -Xloggc:&#x2F;mnt&#x2F;logs&#x2F;authority-api&#x2F;jvm&#x2F;gc.log -javaagent:&#x2F;usr&#x2F;local&#x2F;jmx-exporter&#x2F;jmx_prometheus_javaagent-0.14.0.jar&#x3D;9990:&#x2F;usr&#x2F;local&#x2F;jmx-exporter&#x2F;prometheus-jmx-config.yaml -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -jar &#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;lib&#x2F;authority-api.jar --server.address&#x3D;0.0.0.0 --spring.config.location&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;conf&#x2F; --spring.profiles.active&#x3D;testing --logging.config&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api&#x2F;conf&#x2F;log4j2.yml work 1 0.0 0.0 4280 64 ? Ss Feb15 0:00 &#x2F;bin&#x2F;sh -c PROJECT_DIR&#x3D;&#x2F;home&#x2F;work&#x2F;www&#x2F;authority-api $PROJECT_DIR&#x2F;bin&#x2F;bootstrap run work@authority-api-v1-6944b5848b-6x5d2:~$ 引用 10个重要的Linux ps命令实战","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"top命令","slug":"linux-top","date":"2022-02-20T14:32:20.000Z","updated":"2022-02-19T17:03:18.724Z","comments":true,"path":"2022/02/20/linux-top/","link":"","permalink":"https://qinglei1989.github.io/2022/02/20/linux-top/","excerpt":"top 命令用于实时显示系统资源使用情况。它可以显示系统摘要信息，以及内核当前正在管理的进程或线程的列表。 top 命令可以实时动态地查看系统的整体运行情况，是一个非常实用的系统性能和运行信息的监测工具。通过 top 命令所提供的互动式界面，用热键可以管理。","text":"top 命令用于实时显示系统资源使用情况。它可以显示系统摘要信息，以及内核当前正在管理的进程或线程的列表。 top 命令可以实时动态地查看系统的整体运行情况，是一个非常实用的系统性能和运行信息的监测工具。通过 top 命令所提供的互动式界面，用热键可以管理。 Linux top 命令相对于ps为某个时间点的进程状态，top则可以持续的检测进程进行的状态。默认更新进程资源的时间为5秒。可以使用-d来进行修改。top命令默认使用CPU的使用率作为排序的依据，如果要使用内存使用率的话，则按下M键。恢复P键 语法 top [options] 常用参数 -b #以批处理模式操作 -c #显示完整的治命令 -d #屏幕刷新间隔时间 -I #忽略失效过程 -s #保密模式 -S #累积模式 -i&lt;时间&gt; #设置间隔时间 -u&lt;用户名&gt; #指定用户名 -p&lt;进程号&gt; #指定进程 -n&lt;次数&gt; #循环显示的次数 top交互命令 h #显示帮助信息界面 k #终止一个进程 i #忽略闲置和僵死进程，这是一个开关式命令 q #退出程序 r #重新安排一个进程的优先级别 S #切换到累计模式 s #改变两次刷新之间的延迟时间（单位为s），默认值是5s f或者F #从当前显示中添加或者删除项目 o或者O #改变显示项目的顺序 l #切换显示平均负载和启动时间信息 m #切换显示内存信息 t #切换显示进程和CPU状态信息 c #切换显示命令名称和完整命令行 M #根据驻留内存大小进行排序 P #根据CPU使用百分比大小进行排序 T #根据时间&#x2F;累计时间进行排序 w #将当前设置写入~&#x2F;.toprc文件中 应用举例 top -c查看系统整体运行信息 top - 00:44:49 up 565 days, 12:38, 2 users, load average: 0.03, 0.09, 0.13 Tasks: 86 total, 1 running, 85 sleeping, 0 stopped, 0 zombie %Cpu(s): 2.8 us, 0.8 sy, 0.0 ni, 96.0 id, 0.2 wa, 0.0 hi, 0.2 si, 0.0 st KiB Mem : 3881692 total, 118724 free, 1708796 used, 2054172 buff&#x2F;cache KiB Swap: 0 total, 0 free, 0 used. 1892868 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 21399 work 20 0 6004700 1.296g 6752 S 3.7 35.0 639:24.06 &#x2F;home&#x2F;work&#x2F;java-current&#x2F;bin&#x2F;java -Dsun.misc.URLClassPath.disableJarChecking&#x3D;+ 4306 root 10 -10 137372 14500 5284 S 2.0 0.4 2303:51 &#x2F;usr&#x2F;local&#x2F;aegis&#x2F;aegis_client&#x2F;aegis_11_17&#x2F;AliYunDun 24092 root 20 0 795856 40192 7648 S 1.3 1.0 33:05.19 &#x2F;root&#x2F;filebeat-7.4.2-linux-x86_64&#x2F;filebeat -e -c &#x2F;root&#x2F;filebeat-7.4.2-linux-+ 9 root 20 0 0 0 0 S 0.3 0.0 365:09.14 [rcu_sched] 1191 root 20 0 2526540 86844 3320 S 0.3 2.2 4146:08 &#x2F;usr&#x2F;local&#x2F;cloudmonitor&#x2F;jre&#x2F;bin&#x2F;java -Djava.compiler&#x3D;none -XX:-UseGCOverhead+ 1755 work 20 0 84428 29432 996 S 0.3 0.8 1554:04 nginx: worker process 1756 work 20 0 84296 29436 1000 S 0.3 0.8 1479:33 nginx: worker process 1 root 20 0 53708 3144 1852 S 0.0 0.1 7:40.55 &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;systemd --switched-root --system --deserialize 21 2 root 20 0 0 0 0 S 0.0 0.0 0:00.14 [kthreadd] 3 root 20 0 0 0 0 S 0.0 0.0 6:04.15 [ksoftirqd&#x2F;0] 上述结果信息详细说明 top - 05:59:56 #当前系统时间 up 1 day #系统已经运行了1天 1 user #当前登录用户个数 load average: 0.06, 0.03, 0.05 #系统负载信息 Tasks: 92 total #总进程数 2 running #正在运行的进程数 90 sleeping #休眠的进程数 0 stopped #停止的进程数 0 zombie #冻结的进程数 %Cpu(s): 0.0 us #用户空间占用CPU的百分比 0.3 sy #内核空间占用CPU的百分比 0.0 ni #用户进程空间内改变过优先级的进程占用CPU百分比 99.7 id #空闲CPU百分比 0.0 wa #等待输入输出的CPU时间百分比 0.0 hi #硬中断占用CPU的百分比 0.0 si #软中断占用CPU的百分比 0.0 st #虚拟机占用百分比 KiB Mem : 995684 total #物理内存的总量 473120 free #剩余内存的总量 124960 used #已使用内存的总量 397604 buff&#x2F;cache #内核缓存所使用内存的量 KiB Swap: 2097148 total #交换分区的总量 2097148 free #交换分区剩余的总量 0 used #交换分区已使用的总量 698120 avail Mem #可用内存总量 PID #进程id USER #进程所有者 PR #任务的调度优先级，范围0-31，数值越低，优先级越高 NI #nice值，范围-20到+19，用于调整进程优先级 VIRT #进程所使用的虚拟内存总量（单位 KB） RES #任务已使用的未交换物理内存（单位 KB） SHR #共享内存大小（单位 KB） S #进程状态 &#39; D &#39;&#x3D;不间断的睡眠 &#39; R &#39;&#x3D;运行 &#39; S &#39;&#x3D;睡眠 &#39; T &#39;&#x3D;被跟踪或停止的 &#39; Z &#39;&#x3D;僵尸 %CPU #CPU的使用率 %MEM #内存使用率 TIME+ #CPU时间 COMMAND #进程名称（命令名&#x2F;命令行），显示用于启动任务的命令行或关联程序的名称。 将top命令执行两次，然后将信息存储 work@authority-api-v1-6944b5848b-6x5d2:~$ top -b -n 2 &gt; &#x2F;tmp&#x2F;top.txt 查看指定进程 work@authority-api-v1-6944b5848b-6x5d2:~$ echo $$ 1519 work@authority-api-v1-6944b5848b-6x5d2:~$ top -d 10 -p 1519 top - 01:00:33 up 256 days, 9:29, 0 users, load average: 17.69, 12.52, 12.51 Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombie %Cpu(s): 39.3 us, 12.0 sy, 0.0 ni, 45.7 id, 2.5 wa, 0.0 hi, 0.4 si, 0.0 st KiB Mem : 19706059+total, 2849084 free, 94349680 used, 99861824 buff&#x2F;cache KiB Swap: 0 total, 0 free, 0 used. 10241943+avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1519 work 20 0 21132 4352 2608 S 0.0 0.0 0:00.05 bash 引用 每天学一个 Linux 命令（48）：top","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"awk命令","slug":"linux-awk","date":"2022-02-08T14:32:20.000Z","updated":"2022-02-19T16:09:49.957Z","comments":true,"path":"2022/02/08/linux-awk/","link":"","permalink":"https://qinglei1989.github.io/2022/02/08/linux-awk/","excerpt":"awk 是一种编程语言，用于在linux/unix下对文本和数据进行处理。数据可以来自标准输(stdin)、一个或多个文件，或其它命令的输出。它在命令行中使用，但更多是作为脚本来使用。awk有很多内建的功能，比如数组、函数等，这是它和C语言的相同之处，灵活性是awk最大的优势。","text":"awk 是一种编程语言，用于在linux/unix下对文本和数据进行处理。数据可以来自标准输(stdin)、一个或多个文件，或其它命令的输出。它在命令行中使用，但更多是作为脚本来使用。awk有很多内建的功能，比如数组、函数等，这是它和C语言的相同之处，灵活性是awk最大的优势。 Linux awk 命令工作中遇到一个需求，需要从nginx日志中获取调用方上游IP，需要对nginx日志进行处理，所以学习一下linux命令。 原理 语法 awk [options] &#39;scripts&#39; var&#x3D;value filename 常用参数 -F 指定分隔符（可以是字符串或正则表达式） -f 从脚本文件中读取awk命令 -v var&#x3D;value 赋值变量，将外部变量传递给awk 脚本基本结构 awk &#39;BEGIN&#123; print &quot;start&quot; &#125; pattern&#123; commands &#125; END&#123; print &quot;end&quot; &#125;&#39; filename 一个awk脚本通常由BEGIN语句+模式匹配+END语句三部分组成,这三部分都是可选项. 工作原理: 第一步执行BEGIN 语句 第二步从文件或标准输入读取一行，然后再执行pattern语句，逐行扫描文件到文件全部被读取 第三步执行END语句 实例展示 echo &quot;hello &quot; | awk &#39;BEGIN&#123; print &quot;welcome&quot; &#125; END&#123; print &quot;2017-08-08&quot; &#125;&#39; welcome 2017-08-08 echo -e &quot;hello&quot; | awk &#39;BEGIN&#123; print &quot;welcome&quot; &#125; &#123;print&#125; END&#123; print &quot;2017-08-08&quot; &#125;&#39; welcome hello 2017-08-08 #不加print参数时默认只打印当前的行 echo|awk &#39;&#123; a&#x3D;&quot;hello&quot;; b&#x3D;&quot;nihao&quot;; c&#x3D;&quot;mingongge&quot;; print a,b,c; &#125;&#39; hello nihao mingongge #使用print以逗号分隔时，打印则是以空格分界 echo|awk &#39;&#123; a&#x3D;&quot;mgg&quot;; b&#x3D;&quot;mingg&quot;; c&#x3D;&quot;mingongge&quot;; print a&quot; is &quot;b&quot; or &quot;c; &#125;&#39; mgg is mingg or mingongge #awk的print语句中双引号其实就是个拼接作用 echo -e &quot;OK! \\n&quot; # -e 开启转义 内置变量 $0 #当前记录 $1~$n #当前记录的第N个字段 FS #输入字段分隔符（-F相同作用）默认空格 RS #输入记录分割符，默认换行符 NF #字段个数就是列 NR #记录数，就是行号，默认从1开始 OFS #输出字段分隔符，默认空格 ORS #输出记录分割符，默认换行符 外部变量 [root@localhost ~]# a&#x3D;7 [root@localhost ~]# b&#x3D;b [root@localhost ~]# b&#x3D;6 [root@localhost ~]# echo |awk &#39;&#123;print v1*v2 &#125;&#39; v1&#x3D;$a v2&#x3D;$b 42 AWK实例 以:为分隔符打印第二列 work@user-center-api-v1-85689f869-6htbw:&#x2F;mnt&#x2F;logs&#x2F;nginx$ awk -F&quot;:&quot; &#39;&#123;print $2&#125;&#39; &#x2F;etc&#x2F;passwd x x x x x x x x x x x x x x x x x x x x x x 以:分隔打印以work开头行的第三列内容 work@user-center-api-v1-85689f869-6htbw:&#x2F;mnt&#x2F;logs&#x2F;nginx$ awk -F : &#39;&#x2F;^work&#x2F;&#123;print $3&#125;&#39; &#x2F;etc&#x2F;passwd 1000 以:分隔打印以r或者w开头行的第一列内容 work@user-center-api-v1-85689f869-6htbw:&#x2F;mnt&#x2F;logs&#x2F;nginx$ awk -F : &#39;&#x2F;^[rw]&#x2F;&#123;print $1&#125;&#39; &#x2F;etc&#x2F;passwd root www-data work rd 获取nginx日志中的IP地址 日志格式如下： remote_addr=[127.0.0.6] http_x_forward=[172.26.0.131,172.26.0.2] time=[2022-02-06T23:40:01+08:00] request=[POST grep &quot;&#x2F;api&#x2F;v2&#x2F;userinfo&#x2F;get_usernames&quot; access-2022-02-06.log | awk -F&quot; &quot; &#39;&#123;print $2&#125;&#39;| awk -F &quot;[][]&quot; &#39;&#123;print $2&#125;&#39;| awk -F&quot;,&quot; &#39;&#123;print $1&quot;\\n&quot;$2&#125;&#39; | sort -r | uniq -c | more 204 172.26.0.3 228 172.26.0.2 432 172.26.0.131 匹配所有包含root的行 work@user-center-api-v1-85689f869-6htbw:&#x2F;mnt&#x2F;logs&#x2F;nginx$ awk &#39;&#x2F;root&#x2F;&#123;print $0&#125;&#39; &#x2F;etc&#x2F;passwd root:x:0:0:root:&#x2F;root:&#x2F;bin&#x2F;bash 以分号作为分隔符，匹配第5个字段是root的行 awk -F: &#39;$5~&#x2F;root&#x2F;&#123;print $0&#125;&#39; passwd 引用 每天一个 Linux 命令（4）：awk","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"Linux中&和&&,|和||","slug":"linux-logic","date":"2022-02-08T14:32:20.000Z","updated":"2022-02-01T15:12:14.918Z","comments":true,"path":"2022/02/08/linux-logic/","link":"","permalink":"https://qinglei1989.github.io/2022/02/08/linux-logic/","excerpt":"Linux中&amp;和&amp;&amp;,|和||","text":"Linux中&amp;和&amp;&amp;,|和|| Linux ls 命令 &amp; &amp; 表示任务在后台执行，如要在后台运行redis-server,则有 redis-server &amp; &amp;&amp; &amp;&amp; 表示前一条命令执行成功时，才执行后一条命令 ，如 echo ‘1‘ &amp;&amp; echo ‘2’ | | 表示管道，上一条命令的输出，作为下一条命令参数，如 echo ‘yes’ | wc -l || || 表示上一条命令执行失败后，才执行下一条命令，如 cat nofile || echo “fail”","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"docker相关命令","slug":"docker-command","date":"2021-09-14T16:26:54.000Z","updated":"2021-09-15T16:47:10.232Z","comments":true,"path":"2021/09/15/docker-command/","link":"","permalink":"https://qinglei1989.github.io/2021/09/15/docker-command/","excerpt":"","text":"Docker容器命令 docker pull **获取镜像 (image) ** D:\\hexoBlog&gt;docker pull mysql Using default tag: latest latest: Pulling from library&#x2F;mysql a330b6cecb98: Already exists 9c8f656c32b8: Pull complete 88e473c3f553: Pull complete 062463ea5d2f: Pull complete daf7e3bdf4b6: Pull complete 1839c0b7aac9: Pull complete cf0a0cfee6d0: Pull complete 1b42041bb11e: Pull complete 10459d86c7e6: Pull complete b7199599d5f9: Pull complete 1d6f51e17d45: Pull complete 50e0789bacad: Pull complete Digest: sha256:99e0989e7e3797cfbdb8d51a19d32c8d286dd8862794d01a547651a896bcf00c Status: Downloaded newer image for mysql:latest docker.io&#x2F;library&#x2F;mysql:latest docker build 使用 Dockerfile 创建镜像 (image) &#96;&#96;&#96; &gt; ### docker images **列出本地镜像 (image)** &#96;&#96;&#96; bash PS C:\\Users\\wang&gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest ad4c705f24d3 4 days ago 133MB mysql latest 0716d6ebcc1a 11 days ago 514MB docker&#x2F;getting-started latest 083d7564d904 3 months ago 28MB hub.c.163.com&#x2F;library&#x2F;nginx latest 46102226f2fd 4 years ago 109MB docker cp 用于容器与主机之间的数据拷贝 将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。 C:\\Users\\wang&gt;docker cp &#x2F;www&#x2F;runoob 9703d:&#x2F;www&#x2F; CreateFile C:\\www: The system cannot find the file specified. C:\\Users\\wang&gt;docker cp &#x2F;www&#x2F;runoob 9703d:&#x2F;www&#x2F; C:\\Users\\wang&gt;docker exec -it 9703d &#x2F;bin&#x2F;bash root@9703dcaf7efc:&#x2F;# cd &#x2F; root@9703dcaf7efc:&#x2F;# ls bin dev entrypoint.sh home lib64 mnt proc run srv tmp var boot docker-entrypoint-initdb.d etc lib media opt root sbin sys usr www root@9703dcaf7efc:&#x2F;# cd www root@9703dcaf7efc:&#x2F;www# ls 1.txt root@9703dcaf7efc:&#x2F;www# cat 1.txt 111111111111111 root@9703dcaf7efc:&#x2F;www# 将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中 C:\\Users\\wang&gt;docker cp 9703d:&#x2F;www &#x2F;tmp&#x2F; docker commit 从容器创建一个新的镜像 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] OPTIONS说明： **-a :**提交的镜像作者； **-c :**使用Dockerfile指令来创建镜像； **-m :**提交时的说明文字； **-p :**在commit时，将容器暂停。 C:\\Users\\wang&gt;docker commit -a &quot;wangql&quot; -m &quot;wangSQL&quot; 9703d wangSQL invalid reference format: repository name must be lowercase C:\\Users\\wang&gt;docker commit -a &quot;wangql&quot; -m &quot;wangSQL&quot; 9703d wangsql sha256:9cb7bdcd2ed312f18242775f8f964b7ef860e3fdd1c523842e256e942d9d1be4 C:\\Users\\wang&gt;docker images wangsql REPOSITORY TAG IMAGE ID CREATED SIZE wangsql latest 9cb7bdcd2ed3 9 seconds ago 514MB docker rmi 删除本地一个或多个镜像 (image) C:\\Users\\wang&gt;docker images REPOSITORY TAG IMAGE ID CREATED SIZE &lt;none&gt; &lt;none&gt; 0990594dba3d 38 minutes ago 514MB nginx latest ad4c705f24d3 5 days ago 133MB mysql latest 0716d6ebcc1a 12 days ago 514MB docker&#x2F;getting-started latest 083d7564d904 3 months ago 28MB hub.c.163.com&#x2F;library&#x2F;nginx latest 46102226f2fd 4 years ago 109MB C:\\Users\\wang&gt;docker rmi -f mysql nginx Untagged: mysql:latest Untagged: mysql@sha256:99e0989e7e3797cfbdb8d51a19d32c8d286dd8862794d01a547651a896bcf00c Untagged: nginx:latest Untagged: nginx@sha256:853b221d3341add7aaadf5f81dd088ea943ab9c918766e295321294b035f3f3e docker run 创建一个新的容器并运行一个命令 (container) docker ps 列出正在运行的容器列表 D:\\hexoBlog&gt;docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES da5001f28240 nginx &quot;&#x2F;docker-entrypoint.…&quot; 17 seconds ago Up 16 seconds 80&#x2F;tcp distracted_engelbart 显示所有的容器，包括未运行的 docker ps -a C:\\Users\\wang&gt;docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES da5001f28240 nginx &quot;&#x2F;docker-entrypoint.…&quot; 22 hours ago Exited (255) 13 minutes ago 80&#x2F;tcp distracted_engelbart 30402568e75b nginx &quot;&#x2F;docker-entrypoint.…&quot; 22 hours ago Exited (0) 22 hours ago happy_heyrovsky 08d4e5c65b09 docker&#x2F;getting-started &quot;&#x2F;docker-entrypoint.…&quot; 29 hours ago Exited (0) 29 hours ago pensive_robinson 1760a9cdaee1 hub.c.163.com&#x2F;library&#x2F;nginx &quot;nginx -g &#39;daemon of…&quot; 29 hours ago Exited (255) 29 hours ago 0.0.0.0:8080-&gt;80&#x2F;tcp, :::8080-&gt;80&#x2F;tcp frosty_hopper 2611bfa8785a docker&#x2F;getting-started &quot;&#x2F;docker-entrypoint.…&quot; 29 hours ago Exited (255) 29 hours ago 0.0.0.0:80-&gt;80&#x2F;tcp, :::80-&gt;80&#x2F;tcp priceless_rosalind da9c518b220b hub.c.163.com&#x2F;library&#x2F;nginx &quot;nginx -g &#39;daemon of…&quot; 30 hours ago Exited (0) 30 hours ago heuristic_rubin 790e60c35d23 nginx &quot;&#x2F;docker-entrypoint.…&quot; 3 days ago Exited (137) 3 days ago nginx-test 9ce1de13f46a docker&#x2F;getting-started:latest &quot;&#x2F;docker-entrypoint.…&quot; 3 days ago Exited (0) 3 days ago cool_hodgkin 424e2623c296 docker&#x2F;getting-started &quot;&#x2F;docker-entrypoint.…&quot; 3 days ago Exited (137) 3 days ago cool_fermat C:\\Users\\wang&gt; docker stop 关闭容器 D:\\hexoBlog&gt;docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES da5001f28240 nginx &quot;&#x2F;docker-entrypoint.…&quot; 17 seconds ago Up 16 seconds 80&#x2F;tcp distracted_engelbart D:\\hexoBlog&gt;docker stop da5001 da5001 D:\\hexoBlog&gt;docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES docker start 启动容器 D:\\hexoBlog&gt;docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES da5001f28240 nginx &quot;&#x2F;docker-entrypoint.…&quot; 17 seconds ago Up 16 seconds 80&#x2F;tcp distracted_engelbart D:\\hexoBlog&gt;docker stop da5001 da5001 D:\\hexoBlog&gt;docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES D:\\hexoBlog&gt;docker start da5001 da5001 D:\\hexoBlog&gt;docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES da5001f28240 nginx &quot;&#x2F;docker-entrypoint.…&quot; 7 minutes ago Up 5 seconds 80&#x2F;tcp distracted_engelbart docker restart 重启容器 D:\\hexoBlog&gt;docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES da5001f28240 nginx &quot;&#x2F;docker-entrypoint.…&quot; 7 minutes ago Up 5 seconds 80&#x2F;tcp distracted_engelbart D:\\hexoBlog&gt;docker restart da5001 da5001 docker attach | exec 进入容器内部 docker exec [OPTIONS] CONTAINER COMMAND [ARG...] OPTIONS说明： **-d :**分离模式: 在后台运行 **-i :**即使没有附加也保持STDIN 打开 **-t :**分配一个伪终端 C:\\Users\\wang&gt;docker exec -it 9703d &#x2F;bin&#x2F;bash root@9703dcaf7efc:&#x2F;# ls bin dev entrypoint.sh home lib64 mnt proc run srv tmp var boot docker-entrypoint-initdb.d etc lib media opt root sbin sys usr root@9703dcaf7efc:&#x2F;# cd &#x2F; root@9703dcaf7efc:&#x2F;# ls bin dev entrypoint.sh home lib64 mnt proc run srv tmp var boot docker-entrypoint-initdb.d etc lib media opt root sbin sys usr root@9703dcaf7efc:&#x2F;# root@9703dcaf7efc:&#x2F;# docker inspect 获取容器/镜像的元数据 docker inspect [OPTIONS] NAME|ID [NAME|ID...] OPTIONS说明： **-f :**指定返回值的模板文件。 **-s :**显示总的文件大小。 **–type :**为指定类型返回JSON。 C:\\Users\\wang&gt;docker inspect mysql [ &#123; &quot;Id&quot;: &quot;e701d96de9775da0bdbe419e368aea0153445fa3d984f0ac99d42cb891260fa6&quot;, &quot;Created&quot;: &quot;2021-09-15T15:17:49.314726Z&quot;, &quot;Path&quot;: &quot;docker-entrypoint.sh&quot;, &quot;Args&quot;: [ &quot;mysqld&quot; ], &quot;State&quot;: &#123; &quot;Status&quot;: &quot;exited&quot;, &quot;Running&quot;: false, &quot;Paused&quot;: false, &quot;Restarting&quot;: false, &quot;OOMKilled&quot;: false, &quot;Dead&quot;: false, &quot;Pid&quot;: 0, &quot;ExitCode&quot;: 1, &quot;Error&quot;: &quot;&quot;, &quot;StartedAt&quot;: &quot;2021-09-15T15:17:50.3746439Z&quot;, &quot;FinishedAt&quot;: &quot;2021-09-15T15:17:50.5453195Z&quot; &#125;, &quot;Image&quot;: &quot;sha256:0716d6ebcc1a61c5a296fcb187e71f93531e510d4e4400267e2e502103d0194c&quot;, &quot;ResolvConfPath&quot;: &quot;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F;e701d96de9775da0bdbe419e368aea0153445fa3d984f0ac99d42cb891260fa6&#x2F;resolv.conf&quot;, &quot;HostnamePath&quot;: &quot;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F;e701d96de9775da0bdbe419e368aea0153445fa3d984f0ac99d42cb891260fa6&#x2F;hostname&quot;, &quot;HostsPath&quot;: &quot;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F;e701d96de9775da0bdbe419e368aea0153445fa3d984f0ac99d42cb891260fa6&#x2F;hosts&quot;, &quot;LogPath&quot;: &quot;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F;e701d96de9775da0bdbe419e368aea0153445fa3d984f0ac99d42cb891260fa6&#x2F;e701d96de9775da0bdbe419e368aea0153445fa3d984f0ac99d42cb891260fa6-json.log&quot;, &quot;Name&quot;: &quot;&#x2F;mysql&quot;, &quot;RestartCount&quot;: 0, &quot;Driver&quot;: &quot;overlay2&quot;, &quot;Platform&quot;: &quot;linux&quot;, &quot;MountLabel&quot;: &quot;&quot;, &quot;ProcessLabel&quot;: &quot;&quot;, &quot;AppArmorProfile&quot;: &quot;&quot;, &quot;ExecIDs&quot;: null, &quot;HostConfig&quot;: &#123; &quot;Binds&quot;: null, &quot;ContainerIDFile&quot;: &quot;&quot;, &quot;LogConfig&quot;: &#123; &quot;Type&quot;: &quot;json-file&quot;, &quot;Config&quot;: &#123;&#125; &#125;, &quot;NetworkMode&quot;: &quot;default&quot;, &quot;PortBindings&quot;: &#123;&#125;, &quot;RestartPolicy&quot;: &#123; &quot;Name&quot;: &quot;no&quot;, &quot;MaximumRetryCount&quot;: 0 &#125;, &quot;AutoRemove&quot;: false, &quot;VolumeDriver&quot;: &quot;&quot;, &quot;VolumesFrom&quot;: null, &quot;CapAdd&quot;: null, &quot;CapDrop&quot;: null, &quot;CgroupnsMode&quot;: &quot;host&quot;, &quot;Dns&quot;: [], &quot;DnsOptions&quot;: [], &quot;DnsSearch&quot;: [], &quot;ExtraHosts&quot;: null, 获取正在运行的容器mymysql的 IP C:\\Users\\wang&gt;docker inspect --format &quot;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&quot; 970 172.17.0.2 C:\\Users\\wang&gt; C:\\Users\\wang&gt;docker inspect --format&#x3D;&quot;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&quot; mysql-test 172.17.0.2 docker logs 获取容器的日志 D:\\hexoBlog&gt;docker logs da5001 &#x2F;docker-entrypoint.sh: &#x2F;docker-entrypoint.d&#x2F; is not empty, will attempt to perform configuration &#x2F;docker-entrypoint.sh: Looking for shell scripts in &#x2F;docker-entrypoint.d&#x2F; &#x2F;docker-entrypoint.sh: Launching &#x2F;docker-entrypoint.d&#x2F;10-listen-on-ipv6-by-default.sh 10-listen-on-ipv6-by-default.sh: info: Getting the checksum of &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf 10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf &#x2F;docker-entrypoint.sh: Launching &#x2F;docker-entrypoint.d&#x2F;20-envsubst-on-templates.sh &#x2F;docker-entrypoint.sh: Launching &#x2F;docker-entrypoint.d&#x2F;30-tune-worker-processes.sh &#x2F;docker-entrypoint.sh: Configuration complete; ready for start up 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: using the &quot;epoll&quot; event method 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: nginx&#x2F;1.21.3 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: built by gcc 8.3.0 (Debian 8.3.0-6) 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: OS: Linux 5.10.16.3-microsoft-standard-WSL2 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: start worker processes 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: start worker process 32 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: start worker process 33 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: start worker process 34 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: start worker process 35 2021&#x2F;09&#x2F;14 17:21:58 [notice] 1#1: start worker process 36 docker top 查看容器中运行的进程信息 D:\\hexoBlog&gt;docker top da5001 UID PID PPID C STIME TTY TIME CMD root 2073 2053 0 17:30 ? 00:00:00 nginx: master process nginx -g daemon off; uuidd 2125 2073 0 17:30 ? 00:00:00 nginx: worker process uuidd 2126 2073 0 17:30 ? 00:00:00 nginx: worker process uuidd 2127 2073 0 17:30 ? 00:00:00 nginx: worker process uuidd 2128 2073 0 17:30 ? 00:00:00 nginx: worker process uuidd 2129 2073 0 17:30 ? 00:00:00 nginx: worker process uuidd 2130 2073 0 17:30 ? 00:00:00 nginx: worker process uuidd 2131 2073 0 17:30 ? 00:00:00 nginx: worker process uuidd 2132 2073 0 17:30 ? 00:00:00 nginx: worker process docker port 列出指定的容器的端口映射 C:\\Users\\wang&gt;docker run -itd --name mysql-test -p 3333:3306 -e MYSQL_ROOT_PASSWORD&#x3D;123456 mysql 9703dcaf7efc2614bbec8f89cecab3f3e72285f933154b310bd51e6c7a5127df C:\\Users\\wang&gt;docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9703dcaf7efc mysql &quot;docker-entrypoint.s…&quot; 5 seconds ago Up 4 seconds 33060&#x2F;tcp, 0.0.0.0:3333-&gt;3306&#x2F;tcp, :::3333-&gt;3306&#x2F;tcp mysql-test C:\\Users\\wang&gt;docker port 9703d 3306&#x2F;tcp -&gt; 0.0.0.0:3333 3306&#x2F;tcp -&gt; :::3333 docker wait 阻塞运行直到容器停止，然后打印出它的退出代码 docker wait CONTAINER C:\\Users\\wang&gt;docker wait 970 0 C:\\Users\\wang&gt; docker rm 删除容器 C:\\Users\\wang&gt;docker rm zhouzhichao zhouzhichao 链接： https://www.cnblogs.com/lgg20/p/13186776.html","categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"}]},{"title":"postman—使用变量","slug":"tools-postman-variable","date":"2021-09-12T14:18:03.000Z","updated":"2021-09-12T16:47:27.039Z","comments":true,"path":"2021/09/12/tools-postman-variable/","link":"","permalink":"https://qinglei1989.github.io/2021/09/12/tools-postman-variable/","excerpt":"变量允许我们在请求和脚本中存储和重用值。通过将值存储在变量中，我们可以在整个集合、环境和请求中引用它——如果您需要更新该值，您只需在一个地方更改它。使用变量可以提高工作效率，并最大限度地减少出错的可能性。","text":"变量允许我们在请求和脚本中存储和重用值。通过将值存储在变量中，我们可以在整个集合、环境和请求中引用它——如果您需要更新该值，您只需在一个地方更改它。使用变量可以提高工作效率，并最大限度地减少出错的可能性。 Postman(4)—变量了解变量变量是数据的符号表示，允许您访问一个值，而无需在任何需要的地方手动输入它。这在您在多个地方使用相同的值时尤其有用。通过抽象掉一些细节，变量使您的请求更加灵活和可读。 例如，如果您在多个请求中有相同的 URL——但 URL 可能会改变——您可以将它存储在一个变量中。如果 URL 发生变化，您只需要更改变量值，它就会反映在您的整个集合中，无论您在何处使用该变量名称。同样的原则适用于您请求中重复数据的任何部分。 Postman 中的变量是键值对。每个变量名代表它的键，因此引用变量名可以让你访问它的值。 例如，将请求的基本 URL 存储在名为 的变量中base_url，则可以在请求中使用&#123;&#123;base_url&#125;&#125;来引用它。如果基本 URL 值为https://httpbin.org，则对于&#123;&#123;base_url&#125;&#125;/get?customers=new，Postman 会将请求发送到https://httpbin.org/get?customers=new。 变量范围Postman 支持以下变量范围： 全局（Global） 全局变量允许您访问集合、请求、测试脚本和环境之间的数据。全局变量在整个工作区都可用。 集合（Collection） 集合变量在集合中的整个请求中都可用，并且与环境无关，因此不要根据所选环境进行更改。 环境（Environment） 环境变量允许您针对不同环境定制处理，例如本地开发与测试或生产。一次只能激活一个环境。 如果您只有一个环境，使用集合变量会更有效率，但是环境允许您指定基于角色的访问级别。 数据（Data） 数据变量来自外部 CSV 和 JSON 文件，用于定义在通过 Newman 或 Collection Runner 运行集合时可以使用的数据集。 本地（Local） 本地变量是临时的，只能在您的请求脚本中访问。本地变量值仅限于单个请求或集合运行，并且在运行完成后不再可用。 如果您需要一个值来覆盖所有其他变量范围，但不希望该值在执行结束后持续存在，则本地变量是合适的。 如果在两个不同的作用域中声明了同名变量，则将使用作用域最小的变量中存储的值——例如，如果有一个全局变量和一个本地变量都命名为username，则在请求时将使用本地值运行。 要尝试变量，请使用以下步骤： 单击Postman右上角的Environment 快速查看（眼睛按钮），然后单击Globals旁边的add/Edit。 添加一个名为的变量my_variable并为其赋予初始值 —Hello单击保存并关闭环境模式。 打开一个新的请求选项卡并输入https://postman-echo.com/get?var=&#123;&#123;my_variable&#125;&#125;URL。将鼠标悬停在变量名称上，您将看到该值。 发送请求。在响应中，您将看到 Postman 将变量值发送到 API。尝试更改环境快速查看中的值并再次发送请求。 定义变量 请求构造器中定义变量 在请求构建器的任何范围内创建变量，请选择您需要的数据，例如在地址、参数、标头或正文中。 选择设为变量**&gt;**设为新变量。 输入Name，验证Value并从下拉列表中选择一个范围。单击设置变量。 定义全局和环境变量 可以通过Postman左侧选择创建和编辑环境变量，或使用Postman右上角的环境快速浏览进行编辑。 如果您对整个环境具有编辑权限，则可以在环境中添加和编辑变量。如果您只有查看权限，则只能更新现有变量的当前值。您编辑的任何变量都只能由您访问，而您在工作区中协作者无法使用。 定义集合变量 您可以在创建集合时或之后的任何时间添加集合变量。要为现有集合创建或编辑变量，请在Postman 左侧的集合侧栏中选择该集合，然后选择Variables。 指定变量细节 您可以随时添加和编辑变量。您需要为新变量包含的只是一个名称——您可以选择提供一个初始值，但也可以稍后设置它，包括从脚本中设置。使用复选框启用或禁用变量。 当您共享集合或环境时，将共享初始值。当前值是本地的，不同步或共享。 访问变量 可以使用双花括号在整个 Postman 用户界面中引用变量。例如，要在请求身份验证设置中引用名为“username”的变量，您可以使用以下语法并在名称周围加上双花括号： &#123;&#123;username&#125;&#125; 或者，您可以有一个请求正文，通过将其引用括在双引号中来访问变量： &#123; \"customer_id\" : \"&#123;&#123;cust_id&#125;&#125;\" &#125; 当您将鼠标悬停在变量上时，您可以看到其当前状态的概览。当您在请求中键入变量时，Postman 会提示您输入当前定义的任何变量。 如果变量未解析，Postman 会将其突出显示为红色。 记录变量 您可以在请求运行时将变量值记录到Postman Console。从 Postman 左下角的按钮或从“查看”菜单打开控制台。要记录变量的值，请在脚本中使用以下语法： console.log(pm.variables.get(\"variable_key\")); [","categories":[{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"postman","slug":"postman","permalink":"https://qinglei1989.github.io/tags/postman/"}]},{"title":"postman—请求","slug":"tools-postman-request","date":"2021-09-09T16:21:28.000Z","updated":"2021-09-12T15:05:04.496Z","comments":true,"path":"2021/09/10/tools-postman-request/","link":"","permalink":"https://qinglei1989.github.io/2021/09/10/tools-postman-request/","excerpt":"在 Postman 中发送请求可以检索、添加、删除和更新数据。无论您是在构建或测试自己的 API，还是与第三方 API ，都可以在 Postman 中尝试发送您的请求。","text":"在 Postman 中发送请求可以检索、添加、删除和更新数据。无论您是在构建或测试自己的 API，还是与第三方 API ，都可以在 Postman 中尝试发送您的请求。 Postman(3)—请求构建请求当您发送请求时，Postman 将从 API 服务器收到的响应，让您可以进行可视化的检查、并在必要时对其进行故障排除。 请求方法 POST— 添加新数据 PUT——替换现有数据 PATCH— 更新一些现有的数据字段 DELETE——删除现有数据 发送参数 查询参数被附加到请求 URL 的末尾，?在键值对中跟随并列出，&amp;使用以下语法分隔：?id=1&amp;type=new 路径参数构成请求 URL 的一部分，并使用前面的占位符引用:，如下例所示：/customer/:id 参数不会自动进行 URL 编码。右键单击所选文本，然后选择EncodeURIComponent以手动编码参数值。 接收响应Postman 响应查看器有助于查看API响应的正确性。API 响应由正文、标头和状态代码组成。Postman 在不同的选项卡中组织正文和标题。API 调用的状态代码和完成时间显示在选项卡旁边。 保存响应","categories":[{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"postman","slug":"postman","permalink":"https://qinglei1989.github.io/tags/postman/"}]},{"title":"postman—账号与设置","slug":"tools-postman-account","date":"2021-09-07T15:42:36.000Z","updated":"2021-09-07T17:02:43.120Z","comments":true,"path":"2021/09/07/tools-postman-account/","link":"","permalink":"https://qinglei1989.github.io/2021/09/07/tools-postman-account/","excerpt":"Postman 帐户允许您同步和备份您的工作，以便您可以从不同的机器访问它。您还可以在您的 API 项目上与其他人协作。","text":"Postman 帐户允许您同步和备份您的工作，以便您可以从不同的机器访问它。您还可以在您的 API 项目上与其他人协作。 Postman(2)—账号与设置注册Postman帐户Postman的账号注册是可选的，没有帐户的Postman 应用程序依然可以使用。注册Postman 帐户方便我们同步和备份工作，我们可以登陆其他的不同的机器继续工作，也可以与其他人协作。 创建帐户 配置帐户当您第一次注册 Postman 帐户时，系统会提示您提供一些有关您自己的信息。输入您的详细信息，然后点击继续。 在这里可以选择创建或加入团队。 当选择登录 Postman 桌面版时，默认浏览器将自动打开一个网页，要求您登录 Postman。 同步您的工作 如果 Postman 无法连接，您可以切换到 Scratch Pad 并在本地工作。 登录 Postman 帐户时，同步可使您的所有 Postman 数据可用。更改（例如编辑、更新、添加或删除）会在与您的帐户关联的所有设备之间同步。 这些实体可以与服务器同步并保存到云端： 收藏 文件夹 要求 回应 标题预设 环境 环境变量 全局变量 收集运行结果 工作区 历史 注意： Postman 将每个帐户的并行使用限制为三个应用程序。 Scratch Pad 是一个您可以在没有连接或登录 Postman 的情况下在本地工作的空间。在 Scratch Pad 中所做的工作不会同步Postman，我们可以稍后将其导出并导入到工作区。 当您打开 Postman 或连接断开时，它会在开始同步之前显示“正在连接”。 单击该图标，我们会看到正在同步的在线状态。弹出窗口将指示有关当前同步状态的更多信息。 如果 Postman 与服务器同步，则右上角您姓名左侧的图标表示Online，并在悬停时显示一个显示In sync的弹出窗口 。 连接 Postman 时，如果遇到同步错误，它将指示错误状态。悬停以查看有关错误的详细信息。","categories":[{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"postman","slug":"postman","permalink":"https://qinglei1989.github.io/tags/postman/"}]},{"title":"junit5——入门","slug":"junit-introduction","date":"2021-09-06T16:10:59.000Z","updated":"2021-09-08T17:01:14.133Z","comments":true,"path":"2021/09/07/junit-introduction/","link":"","permalink":"https://qinglei1989.github.io/2021/09/07/junit-introduction/","excerpt":"本文档来自于自己对官方文档的学习和翻译。 JUnit 5是JUnit的下一代。目标是为JVM上的开发人员端测试创建一个最新的基础。这包括专注于Java 8及更高版本，以及启用许多不同风格的测试。","text":"本文档来自于自己对官方文档的学习和翻译。 JUnit 5是JUnit的下一代。目标是为JVM上的开发人员端测试创建一个最新的基础。这包括专注于Java 8及更高版本，以及启用许多不同风格的测试。 Junit 5 用户指南 概述 与以前版本的 JUnit 不同，JUnit 5 由来自三个不同子项目的几个不同模块组成。 JUnit 5 = JUnit Platform + JUnit Jupiter + JUnit Vintage JUnit Platform为在JVM上启动测试框架提供基础。它还定义了TestEngineAPI, 用来开发在平台上运行的测试框架。此外，平台提供了一个控制台启动器，用于从命令行启动平台，并为Gradle和Maven提供构建插件以及基于JUnit 4的Runner，用于在平台上运行任意TestEngine。 JUnit Jupiter是在JUnit 5中编写测试和扩展的新型[编程模型]和[扩展模型]的组合。Jupiter子项目提供了TestEngine，用于在平台上运行基于Jupiter的测试。 JUnit Vintage提供TestEngine，用于在平台上运行基于JUnit 3和JUnit 4的测试。 JUnit 5 在运行时需要 Java 8（或更高版本）。但是，您仍然可以测试使用以前版本的 JDK 编译的代码。 编写测试 第一个测试用例 package com.example.project; public class Calculator &#123; public int add(int a, int b) &#123; return a + b; &#125; &#125; 测试用例 package com.example.project; import static org.junit.jupiter.api.Assertions.assertEquals; import org.junit.jupiter.api.DisplayName; import org.junit.jupiter.api.Test; import org.junit.jupiter.params.ParameterizedTest; import org.junit.jupiter.params.provider.CsvSource; class CalculatorTests &#123; @Test @DisplayName(&quot;1 + 1 &#x3D; 2&quot;) void addsTwoNumbers() &#123; Calculator calculator &#x3D; new Calculator(); assertEquals(2, calculator.add(1, 1), &quot;1 + 1 should equal 2&quot;); &#125; &#125; 注解 JUnit Jupiter 支持以下用于配置测试和扩展框架的注解。 除非另有说明，所有核心注释都位于模块中的org.junit.jupiter.api包中junit-jupiter-api。 注解 描述 @Test 表示方法是测试方法。 @ParameterizedTest 表示方法是参数化测试。 @RepeatedTest 表示方法是重复测试的测试模板。 @TestFactory 表示方法是动态测试测试工厂。 @TestTemplate 表示方法是测试用例的模板，旨在根据注册提供程序返回的调用上下文的数量多次调用。这些方法是继承的，除非它们被覆盖。 @TestMethodOrder 用于为注解的测试类配置测试方法执行顺序。 @TestInstance 用于为带注释的测试类配置测试实例生命周期。 @DisplayName 声明测试类或测试方法的自定义显示名称。此类注释不会被继承。 @DisplayNameGeneration 为测试类声明一个自定义显示名称生成器。此类注释是继承的。 @BeforeEach 表示被注解的方法应该在当前类中的每个、、、 或方法之前 执行；类似于 JUnit 4 的. 这些方法是继承的，除非它们被覆盖。 @Test``@RepeatedTest``@ParameterizedTest``@TestFactory``@Before @AfterEach 表示该注释的方法应该被执行之后 每个 @Test，@RepeatedTest，@ParameterizedTest，或@TestFactory方法在当前类; 类似于 JUnit 4 的@After。 @BeforeAll 表示该注释的方法应该被执行之前 所有 @Test，@RepeatedTest，@ParameterizedTest，和@TestFactory方法在当前类; 类似于 JUnit 4 的@BeforeClass. 此类方法是继承的（除非它们被隐藏或覆盖）并且必须是static（除非使用“class“测试实例生命周期）。 @AfterAll 表示该注释的方法应该被执行之后 的所有 @Test，@RepeatedTest，@ParameterizedTest，和@TestFactory方法在当前类; 类似于 JUnit 4 的@AfterClass. 此类方法是继承的（除非它们被隐藏或覆盖）并且必须是static（除非使用“class”[测试实例生命周期]）。 标准测试类 import static org.junit.jupiter.api.Assertions.fail; import static org.junit.jupiter.api.Assumptions.assumeTrue; import org.junit.jupiter.api.AfterAll; import org.junit.jupiter.api.AfterEach; import org.junit.jupiter.api.BeforeAll; import org.junit.jupiter.api.BeforeEach; import org.junit.jupiter.api.Disabled; import org.junit.jupiter.api.Test; class StandardTests &#123; @BeforeAll static void initAll() &#123; &#125; @BeforeEach void init() &#123; &#125; @Test void succeedingTest() &#123; &#125; @Test void failingTest() &#123; fail(&quot;a failing test&quot;); &#125; @Test @Disabled(&quot;for demonstration purposes&quot;) void skippedTest() &#123; &#x2F;&#x2F; not executed &#125; @Test void abortedTest() &#123; assumeTrue(&quot;abc&quot;.contains(&quot;Z&quot;)); fail(&quot;test should have been aborted&quot;); &#125; @AfterEach void tearDown() &#123; &#125; @AfterAll static void tearDownAll() &#123; &#125; &#125;","categories":[{"name":"单元测试","slug":"单元测试","permalink":"https://qinglei1989.github.io/categories/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"junit","slug":"junit","permalink":"https://qinglei1989.github.io/tags/junit/"}]},{"title":"postman—入门","slug":"tools-postman-introduction","date":"2021-09-05T17:04:13.000Z","updated":"2021-09-07T15:03:43.019Z","comments":true,"path":"2021/09/06/tools-postman-introduction/","link":"","permalink":"https://qinglei1989.github.io/2021/09/06/tools-postman-introduction/","excerpt":"欢迎使用 Postman 文档！在这里可以找到有关如何在 API 项目中使用 Postman 的官方信息。","text":"欢迎使用 Postman 文档！在这里可以找到有关如何在 API 项目中使用 Postman 的官方信息。 Postman(1)—入门安装和更新Postman 可在网络上的go.postman.co/home上获得，并作为适用于 Mac、Windows（32 位/64 位）和 Linux（32 位/64 位）操作系统的本机桌面应用程序。 要获取最新版本的 Postman 桌面应用程序，请访问 下载页面 选择适用于您操作系统的安装程序。 Postman Chrome 应用程序已弃用 - 如果您使用 Chrome 应用程序，您可以在切换到本机应用程序时保留您的数据，方法是与您登录的 Postman 帐户同步，或者从 Chrome 导出并导入到原生应用。 Postman导航视图 左侧边栏提供对您的集合（collections）、[API]、环境变量(environments)、模拟服务器（mock servers）、监视器（monitors）和请求历史（history）。 顶部工具栏允许您创建工作区（Workspaces）、访问报告（Reports）、探索公共 API 网络（Explore）、在 Postman 中搜索（Search Postman）、查看同步状态和通知、移动和邀请协作者到工作区、捕获请求和 cookie、设置、帐户等。 中心区域是您构建和处理请求的地方。 底部的状态栏允许您显示/隐藏侧边栏、查找和替换（find-and-replace)以及打开左侧的控制台（Console）。在右侧，您可以启动Bootcamp、集合运行器（Runner）、垃圾箱（Trash）、窗格视图以及访问帮助资源。 您还可以在 Postman UI 中拖动以调整窗格的大小。 在右侧面板上，您将看到用于查看文档、评论、代码和请求信息的图标。 查找和替换您可以通过单击 Postman左下角的“查找和替换”或使用键盘快捷键Command + SHIFT + F/来搜索您的 Postman 工作区Control + SHIFT + F。 输入您的搜索字符串并可选择要返回的实体，如有必要，输入替换文本。 Postman 将搜索选项卡、集合和变量。您可以直接从搜索结果中单击以打开记录。 历史通过Postman 左侧的History选项卡访问您在 Postman 中提出的请求的历史记录。如果您已登录 Postman 帐户，您的历史记录将跨设备同步。 标签您可以通过打开选项卡在 Postman 中发送请求 - 单击屏幕中央的**+**，或按Command/Control + T。 发送请求要发送您的第一个 API 请求，请打开 Postman。单击**+**加号按钮打开一个新选项卡。在 URL 字段中输入。点击发送。您将在下方窗格中看到来自服务器的 JSON 数据响应。","categories":[{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"postman","slug":"postman","permalink":"https://qinglei1989.github.io/tags/postman/"}]},{"title":"mapper层的单元测试","slug":"junit-mapper","date":"2021-08-29T12:54:56.000Z","updated":"2021-08-30T15:04:34.081Z","comments":true,"path":"2021/08/29/junit-mapper/","link":"","permalink":"https://qinglei1989.github.io/2021/08/29/junit-mapper/","excerpt":"学习新技能，针对Mybatis中Mapper的单元测试。","text":"学习新技能，针对Mybatis中Mapper的单元测试。 单元测试 – mapper层的单元测试 使用H2数据库进行单元测试 H2 数据库是一个开源的嵌入型内存数据库，采用纯Java语言实现；程序非常小巧轻便，整个完整的Jar包也只有1.5M左右，很容易集成到项目中。在自动化环境中可能需要大量模拟接口，包括数据存储接口，此时内存数据库是不二之选。本身作为嵌入式数据库并不需要额外的看护成本；在程序退出时，所有数据都能保证完全清除。 MAVEN依赖 &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;&#x2F;groupId&gt; &lt;artifactId&gt;h2&lt;&#x2F;artifactId&gt; &lt;version&gt;1.4.200&lt;&#x2F;version&gt; &lt;scope&gt;test&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; application.properties(路径：test/resources) spring.datasource.driverClassName&#x3D;org.h2.Driver spring.datasource.url&#x3D;jdbc:h2:mem:db_users;MODE&#x3D;MYSQL;INIT&#x3D;RUNSCRIPT FROM &#39;.&#x2F;src&#x2F;test&#x2F;resources&#x2F;create_table.sql&#39; spring.datasource.username&#x3D; spring.datasource.password&#x3D; mybatis.configuration.map-underscore-to-camel-case&#x3D;true 测试类 package com.puhuijia.dao.mapper; import com.puhuijia.pojo.member.AreaBusiness; import org.junit.Assert; import org.junit.Test; import org.junit.runner.RunWith; import org.mybatis.spring.annotation.MapperScan; import org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import java.util.Date; @RunWith(SpringRunner.class) @MapperScan(&#123;&quot;com.puhuijia.dao.mapper&quot;&#125;) @SpringBootTest(classes &#x3D; &#123;DataSourceAutoConfiguration.class, MybatisAutoConfiguration.class&#125;) public class MembersMapperTest &#123; @Autowired private AreaBusinessMapper mapper; @Test public void queryProvinceList() &#123; int row &#x3D; mapper.deleteByPrimaryKey(1); Assert.assertEquals(row, 0); AreaBusiness areaBusiness &#x3D; new AreaBusiness(); areaBusiness.setName(&quot;33333&quot;); areaBusiness.setId(1); areaBusiness.setCreateTime(new Date()); areaBusiness.setUpdateTime(new Date()); mapper.insertSelective(areaBusiness); row &#x3D; mapper.deleteByPrimaryKey(1); Assert.assertEquals(row, 1); &#125; &#125; create_table.sql drop table if exists area_business; CREATE TABLE &#96;area_business&#96; ( &#96;id&#96; int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;|20181106&#39;, &#96;name&#96; varchar(50) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;|20181106&#39;, &#96;create_time&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;|20181106&#39;, &#96;update_time&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;|20181106&#39;, PRIMARY KEY (&#96;id&#96;), KEY &#96;idx_create_time&#96; (&#96;create_time&#96;), KEY &#96;idx_update_time&#96; (&#96;update_time&#96;) ) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;16 DEFAULT CHARSET&#x3D;utf8 COMMENT&#x3D;&#39;333&#39; h2数据库 jdbc:h2:mem:DBName;DB_CLOSE_DELAY&#x3D;-1 参数DB_CLOSE_DELAY是要求最后一个正在连接的连接断开后，不要关闭DB，因为下一个case可能还会有新连接进来。 H2与MySQL的一些常见区别 注释：不支持表级别的Comment 索引：H2中的索引是数据库内唯一，MySQL中的索引是每张表唯一 CURRENT_TIMESTAMP： H2不支持记录更新时自动刷新字段时间，也就是不支持语句ON UPDATE CURRENT_TIMESTAMP","categories":[{"name":"单元测试","slug":"单元测试","permalink":"https://qinglei1989.github.io/categories/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"junit","slug":"junit","permalink":"https://qinglei1989.github.io/tags/junit/"}]},{"title":"Windows Docker 安装","slug":"docker-install","date":"2021-08-26T16:00:01.000Z","updated":"2021-09-17T03:51:28.441Z","comments":true,"path":"2021/08/27/docker-install/","link":"","permalink":"https://qinglei1989.github.io/2021/08/27/docker-install/","excerpt":"Docker 实质上是在已经运行的 Linux 下制造了一个隔离的文件环境，因此它执行的效率几乎等同于所部署的 Linux 主机。 因此，Docker 必须部署在 Linux 内核的系统上。如果其他系统想部署 Docker 就必须安装一个虚拟 Linux 环境。","text":"Docker 实质上是在已经运行的 Linux 下制造了一个隔离的文件环境，因此它执行的效率几乎等同于所部署的 Linux 主机。 因此，Docker 必须部署在 Linux 内核的系统上。如果其他系统想部署 Docker 就必须安装一个虚拟 Linux 环境。 Windows Docker 安装Docker Desktop 是 Docker 在 Windows 10 和 macOS 操作系统上的官方安装方式，这个方法依然属于先在虚拟机中安装 Linux 然后再安装 Docker 的方法。 注意：此方法仅适用于 Windows 10 操作系统专业版、企业版、教育版和部分家庭版！ 官方文档：https://docs.docker.com/ Docker的安装与卸载：https://docs.docker.com/engine/install/ docker官方镜像列表地址：https://hub.docker.com/search?q=&amp;type=image 启动报错 Docker.ApiServices.WSL2.WslKernelUpdateNotInstalledException: 引发类型为“Docker.ApiServices.WSL2.WslKernelUpdateNotInstalledException”的异常。 在 Docker.ApiServices.WSL2.WslShortLivedCommandResult.LogAndThrowIfUnexpectedExitCode(String prefix, ILogger log, Int32 expectedExitCode) 位置 C:\\workspaces\\PR-16070\\src\\github.com\\docker\\pinata\\win\\src\\Docker.ApiServices\\WSL2\\WslCommand.cs:行号 140 在 Docker.Engines.WSL2.WSL2Provisioning.&lt;DeployDistroAsync&gt;d__17.MoveNext() 位置 C:\\workspaces\\PR-16070\\src\\github.com\\docker\\pinata\\win\\src\\Docker.Desktop\\Engines\\WSL2\\WSL2Provisioning.cs:行号 169 --- 引发异常的上一位置中堆栈跟踪的末尾 --- 解决方法:打开网站 https://czf-net.xyz/res/ 下载wsl.msi。安装完成后重启Docker解决！ 版本号查看 D:\\hexoBlog&gt;docker version Client: Cloud integration: 1.0.17 Version: 20.10.8 API version: 1.41 Go version: go1.16.6 Git commit: 3967b7d Built: Fri Jul 30 19:58:50 2021 OS&#x2F;Arch: windows&#x2F;amd64 Context: default Experimental: true Server: Docker Engine - Community Engine: Version: 20.10.8 API version: 1.41 (minimum version 1.12) Go version: go1.16.6 Git commit: 75249d8 Built: Fri Jul 30 19:52:10 2021 OS&#x2F;Arch: linux&#x2F;amd64 Experimental: false containerd: Version: 1.4.9 GitCommit: e25210fe30a0a703442421b0f60afac609f950a3 runc: Version: 1.0.1 GitCommit: v1.0.1-0-g4144b63 docker-init: Version: 0.19.0 GitCommit: de40ad0 D:\\hexoBlog&gt; Docker 镜像加速 配置阿里云加速 检查加速器是否生效 检查加速器是否生效配置加速器之后，如果拉取镜像仍然十分缓慢，请手动检查加速器配置是否生效，在命令行执行 docker info，如果从结果中看到了如下内容，说明配置成功。 D:\\hexoBlog&gt;docker info Client: Context: default Debug Mode: false Plugins: buildx: Build with BuildKit (Docker Inc., v0.6.1-docker) compose: Docker Compose (Docker Inc., v2.0.0-rc.1) scan: Docker Scan (Docker Inc., v0.8.0) Server: Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 20.10.8 Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runtime.v1.linux runc io.containerd.runc.v2 Default Runtime: runc Init Binary: docker-init containerd version: e25210fe30a0a703442421b0f60afac609f950a3 runc version: v1.0.1-0-g4144b63 init version: de40ad0 Security Options: seccomp Profile: default Kernel Version: 4.19.128-microsoft-standard Operating System: Docker Desktop OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 12.35GiB Name: docker-desktop ID: 4OUU:DRRA:23QZ:DXOD:CRAK:5NOL:XEWB:NODY:FJJI:2D74:656T:PC23 Docker Root Dir: &#x2F;var&#x2F;lib&#x2F;docker Debug Mode: false Registry: https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F; Labels: Experimental: false Insecure Registries: 127.0.0.0&#x2F;8 Registry Mirrors: https:&#x2F;&#x2F;docker.mirrors.ustc.edu.cn&#x2F; Live Restore Enabled: false WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: bridge-nf-call-iptables is disabled WARNING: bridge-nf-call-ip6tables is disabled D:\\hexoBlog&gt; docker run hello-world C:\\Users\\wang&gt;docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https:&#x2F;&#x2F;hub.docker.com&#x2F; For more examples and ideas, visit: https:&#x2F;&#x2F;docs.docker.com&#x2F;get-started&#x2F; C:\\Users\\wang&gt; 要是看到上面的示例 那就说明 你的Docker部署及运行成功了。 windows10安装Hyper-V 最近需要在windows10上安装Docker Desktop，然而docker Desktop依赖于Hyper-V。自己的电脑上控制面板功能里没有Hyper-V。这里记录一下解决方案。 复制以下代码，然后另存为do.cmd。在文件上右键，以管理员的身份运行。 pushd &quot;%~dp0&quot; dir &#x2F;b %SystemRoot%\\servicing\\Packages\\*Hyper-V*.mum &gt;hyper-v.txt for &#x2F;f %%i in (&#39;findstr &#x2F;i . hyper-v.txt 2^&gt;nul&#39;) do dism &#x2F;online &#x2F;norestart &#x2F;add-package:&quot;%SystemRoot%\\servicing\\Packages\\%%i&quot; del hyper-v.txt Dism &#x2F;online &#x2F;enable-feature &#x2F;featurename:Microsoft-Hyper-V-All &#x2F;LimitAccess &#x2F;ALL 执行的时间有点长，循环出现很多遍，等到执行完毕时，输入Y，重启电脑。 然后打开控制面板，就可以看到已经出现结果了","categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"}]},{"title":"Windows Docker安装Mysql8.0","slug":"docker-mysql","date":"2021-08-26T16:00:01.000Z","updated":"2022-01-29T15:22:49.256Z","comments":true,"path":"2021/08/27/docker-mysql/","link":"","permalink":"https://qinglei1989.github.io/2021/08/27/docker-mysql/","excerpt":"Docker 安装Mysql8.0","text":"Docker 安装Mysql8.0 Docker 安装Mysql访问 MySQL 镜像库地址：https://hub.docker.com/_/mysql?tab=tags。 可以通过 Sort by 查看其他版本的 MySQL，默认是最新版本 mysql:latest 。 此外，我们还可以用 docker search mysql 命令来查看可用版本(windows下无法显示tags)： NAME # 镜像仓库 DESCRIPTION # 镜像描述信息 STARS # 镜像收藏数 OFFICIAL # 是否为docker官方发布的镜像 AUTOMATED # 是否为自动化构建的镜像，关于自动化构建，可以查看官方文档：https:&#x2F;&#x2F;docs.docker.com&#x2F;docker-hub&#x2F;builds&#x2F;#how-automated-builds-work 拉取Mysql镜像 C:\\Users\\wang&gt;docker pull mysql:8.0.28 8.0.28: Pulling from library&#x2F;mysql 6552179c3509: Pull complete d69aa66e4482: Pull complete 3b19465b002b: Pull complete 7b0d0cfe99a1: Pull complete 9ccd5a5c8987: Pull complete 2dab00d7d232: Pull complete 64d3afdccd4a: Pull complete 82148d50b16c: Pull complete 8bb7d73a7d0c: Pull complete 74778cd68a75: Pull complete d7e5f9309140: Pull complete f2e376ecd59f: Pull complete Digest: sha256:92d27b8222bbcf53bc42c70ca7cd1010d6c0527efc61f14980ce77c50932bef4 Status: Downloaded newer image for mysql:8.0.28 docker.io&#x2F;library&#x2F;mysql:8.0.28 查看本地仓库镜像是否下载成功 C:\\Users\\wang&gt;docker images REPOSITORY TAG IMAGE ID CREATED SIZE mysql 8.0.28 d1dc36cf8d9e 2 days ago 519MB hello-world latest feb5d9fea6a5 4 months ago 13.3kB C:\\Users\\wang&gt;docker images mysql REPOSITORY TAG IMAGE ID CREATED SIZE mysql 8.0.28 d1dc36cf8d9e 2 days ago 519MB 运行docker mysql镜像 docker run -p 3308:3306 --name zsdmysql -e MYSQL_ROOT_PASSWORD&#x3D;123456 -d mysql:8.0.28 上述命令的参数，有如下含义: --name指定了你要取的名字。 -p对应，需要映射出来的端口。比如:3308:3306,意识表示为zsdmysql的容器里面的3306端口对应我外面这个虚拟机的3308端口。 -e是mysql的命令，设置root的密码为123456 -d是运行的镜像，这里是mysql 容器镜像 查看目前运行的容器 C:\\Users\\wang&gt;docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 622fe2b1bf2a mysql:8.0.28 &quot;docker-entrypoint.s…&quot; About a minute ago Up About a minute 33060&#x2F;tcp, 0.0.0.0:3308-&gt;3306&#x2F;tcp, :::3308-&gt;3306&#x2F;tcp zsdmysql 进入MySQL C:\\Users\\wang&gt;docker exec -it zsdmysql bash root@622fe2b1bf2a:&#x2F;# mysql -uroot -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 8 Server version: 8.0.28 MySQL Community Server - GPL Copyright (c) 2000, 2022, Oracle and&#x2F;or its affiliates. Oracle is a registered trademark of Oracle Corporation and&#x2F;or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement. mysql&gt; show tables -&gt; ; ERROR 1046 (3D000): No database selected mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) 使用datatrip连接数据库 目录映射 docker run -p 3308:3306 -e MYSQL_ROOT_PASSWORD&#x3D;123456 -v d:&#x2F;docker&#x2F;mysql&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql:rw -v d:&#x2F;docker&#x2F;mysql&#x2F;log:&#x2F;var&#x2F;log&#x2F;mysql:rw -v d:&#x2F;docker&#x2F;mysql&#x2F;mysql-files:&#x2F;var&#x2F;lib&#x2F;mysql-files&#x2F; --name mysql8.0 --restart&#x3D;always -d mysql:8.0.28 –restart=always参数能够使我们在重启docker时，自动启动相关容器。 新建d:/docker/mysql/conf/，拷贝配置文件到宿主机： C:\\Users\\wang&gt;docker cp mysql8.0:&#x2F;etc&#x2F;mysql&#x2F;my.cnf d:&#x2F;docker&#x2F;mysql&#x2F;conf&#x2F; 停止容器： docker stop mysql8.0 删除容器： docker rm mysql8.0 重新执行生成容器（增加了对配置文件my.cnf的映射，直接映射，容器启动会有问题，通过执行下面-v后面的映射，最终实现数据持久化，数据存放在宿主机而不是容器内）： docker run -p 3308:3306 -e MYSQL_ROOT_PASSWORD&#x3D;123456 -v d:&#x2F;docker&#x2F;mysql&#x2F;data:&#x2F;var&#x2F;lib&#x2F;mysql:rw -v d:&#x2F;docker&#x2F;mysql&#x2F;log:&#x2F;var&#x2F;log&#x2F;mysql:rw -v d:&#x2F;docker&#x2F;mysql&#x2F;conf&#x2F;my.cnf:&#x2F;etc&#x2F;mysql&#x2F;my.cnf:rw -v d:&#x2F;docker&#x2F;mysql&#x2F;mysql-files:&#x2F;var&#x2F;lib&#x2F;mysql-files&#x2F; --name mysql8.0 --restart&#x3D;always -d mysql:8.0.28 查看mysql8.0容器运行情况 docker ps 进入mysql 根据上面查询到的容器id执行 docker exec -it mysql8.0 bash 连接mysql mysql -uroot -p C:\\Users\\wang&gt;docker exec -it mysql8.0 bash root@c1192171b549:&#x2F;# mysql -uroot -p mysql: [Warning] World-writable config file &#39;&#x2F;etc&#x2F;mysql&#x2F;my.cnf&#39; is ignored. Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 10 Server version: 8.0.28 MySQL Community Server - GPL Copyright (c) 2000, 2022, Oracle and&#x2F;or its affiliates. Oracle is a registered trademark of Oracle Corporation and&#x2F;or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement. mysql&gt; create database todou -&gt; ; Query OK, 1 row affected (0.05 sec) mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | todou | +--------------------+ 5 rows in set (0.05 sec) mysql&gt; use todou Database changed mysql&gt; create person (id int(11) not null ) -&gt; ; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;person (id int(11) not null )&#39; at line 1 mysql&gt; create table person (id int(11) not null ); Query OK, 0 rows affected, 1 warning (0.06 sec) mysql&gt; show tables; +-----------------+ | Tables_in_todou | +-----------------+ | person | +-----------------+ 1 row in set (0.00 sec) 使用datatrip连接 引用 Docker 安装 MySQL8.0","categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"}]},{"title":"Windows Docker安装Mysql8.0","slug":"docker-springboot","date":"2021-08-26T16:00:01.000Z","updated":"2022-10-12T17:07:48.846Z","comments":true,"path":"2021/08/27/docker-springboot/","link":"","permalink":"https://qinglei1989.github.io/2021/08/27/docker-springboot/","excerpt":"Docker 安装SpringBoot项目","text":"Docker 安装SpringBoot项目 Docker部署SpringBoot项目 Docker插件安装 此步骤也可以不勾选 idea 安装docker插件 创建一个dockerfile文件 # Docker image for springboot application # VERSION 0.0.1 # Author: bolingcavalry ### 基础镜像，使用alpine操作系统，openjkd使用8u201 FROM openjdk:8u201-jdk-alpine3.9 #作者 MAINTAINER xiaomotou &lt;2365570419@qq.com&gt; #系统编码 ENV LANG&#x3D;C.UTF-8 LC_ALL&#x3D;C.UTF-8 #声明一个挂载点，容器内此路径会对应宿主机的某个文件夹 VOLUME &#x2F;tmp #应用构建成功后的jar文件被复制到镜像内，名字也改成了app.jar ADD target&#x2F;docker-learn.jar app.jar #启动容器时的进程 ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;&#x2F;app.jar&quot;] #暴露8080端口 EXPOSE 8080 配置dockerfile 运行","categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"}]},{"title":"查找相关的命令","slug":"linux-search","date":"2021-08-22T02:48:43.000Z","updated":"2021-08-26T15:47:49.701Z","comments":true,"path":"2021/08/22/linux-search/","link":"","permalink":"https://qinglei1989.github.io/2021/08/22/linux-search/","excerpt":"我们经常在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索： which 查看可执行文件的位置。 whereis 查看文件的位置。 locate 配合数据库查看文件位置。 find 实际搜寻硬盘查询文件名称。","text":"我们经常在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索： which 查看可执行文件的位置。 whereis 查看文件的位置。 locate 配合数据库查看文件位置。 find 实际搜寻硬盘查询文件名称。 which命令which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 查找文件、显示命令路径 [wang@localhost ~]$ which tree &#x2F;usr&#x2F;bin&#x2F;tree whereis 命令whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。 和find相比，whereis查找的速度非常快，这是因为linux系统会将 系统内的所有文件都记录在一个数据库文件中，当使用whereis和下面即将介绍的locate时，会从数据库中查找数据，而不是像find命令那样，通 过遍历硬盘来查找，效率自然会很高。 但是该数据库文件并不是实时更新，默认情况下时一星期更新一次，因此，我们在用whereis和locate 查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。 命令格式： whereis [-bfmsu][-B &lt;目录&gt;...][-M &lt;目录&gt;...][-S &lt;目录&gt;...][文件...] 参数： -b 只查找二进制文件。 -B&lt;目录&gt; 只在设置的目录下查找二进制文件。 -f 不显示文件名前的路径名称。 -m 只查找说明文件。 -M&lt;目录&gt; 只在设置的目录下查找说明文件。 -s 只查找原始代码文件。 -S&lt;目录&gt; 只在设置的目录下查找原始代码文件。 -u 查找不包含指定类型的文件。 使用指令”whereis”查看指令”bash”的位置 [wang@localhost ~]$ whereis bash bash: &#x2F;usr&#x2F;bin&#x2F;bash &#x2F;usr&#x2F;share&#x2F;man&#x2F;man1&#x2F;bash.1.gz 注意：以上输出信息从左至右分别为查询的程序名、bash路径、bash的man 手册页路径。 #显示bash 命令的二进制程序 [wang@localhost ~]$ whereis -b bash bash: &#x2F;usr&#x2F;bin&#x2F;bash #显示bash 命令的帮助文件 [wang@localhost ~]$ whereis -m bash bash: &#x2F;usr&#x2F;share&#x2F;man&#x2F;man1&#x2F;bash.1.gz #查找源文件 [wang@localhost ~]$ whereis -s bash bash: [wang@localhost ~]$ locate命令Linux locate命令用于查找符合条件的文档，他会去保存文档和目录名称的数据库内，查找合乎范本样式条件的文档或目录。 一般情况我们只需要输入 locate your_file_name 即可查找指定文件。 语法locate [-d ][--help][--version][范本样式...] 参数： -b, –basename – 仅匹配路径名的基本名称 -c, –count – 只输出找到的数量 -d, –database DBPATH – 使用 DBPATH 指定的数据库，而不是默认数据库 /var/lib/mlocate/mlocate.db -e, –existing – 仅打印当前现有文件的条目 -1 – 如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的 权限资料。 -0, –null – 在输出上带有NUL的单独条目 -S, –statistics – 不搜索条目，打印有关每个数据库的统计信息 -q – 安静模式，不会显示任何错误讯息。 -P, –nofollow, -H – 检查文件存在时不要遵循尾随的符号链接 -l, –limit, -n LIMIT – 将输出（或计数）限制为LIMIT个条目 -n – 至多显示 n个输出。 -m, –mmap – 被忽略，为了向后兼容 -r, –regexp REGEXP – 使用基本正则表达式 –regex – 使用扩展正则表达式 -q, –quiet – 安静模式，不会显示任何错误讯息 -s, –stdio – 被忽略，为了向后兼容 -o – 指定资料库存的名称。 -h, –help – 显示帮助 -i, –ignore-case – 忽略大小写 -V, –version – 显示版本信息 查找和pwd相关的所有文件 [wang@localhost ~]$ locate pwd &#x2F;etc&#x2F;.pwd.lock &#x2F;usr&#x2F;bin&#x2F;pwd &#x2F;usr&#x2F;bin&#x2F;pwdx &#x2F;usr&#x2F;lib&#x2F;modules&#x2F;3.10.0-123.el7.x86_64&#x2F;kernel&#x2F;drivers&#x2F;watchdog&#x2F;hpwdt.ko &#x2F;usr&#x2F;lib64&#x2F;cracklib_dict.pwd &#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;lib-dynload&#x2F;spwdmodule.so &#x2F;usr&#x2F;sbin&#x2F;unix_chkpwd &#x2F;usr&#x2F;share&#x2F;cracklib&#x2F;cracklib-small.pwd &#x2F;usr&#x2F;share&#x2F;cracklib&#x2F;pw_dict.pwd &#x2F;usr&#x2F;share&#x2F;doc&#x2F;krb5-workstation-1.11.3&#x2F;user&#x2F;pwd_mgmt.html &#x2F;usr&#x2F;share&#x2F;help&#x2F;C&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;ca&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;cs&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;de&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;el&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;en_GB&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;es&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;eu&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;fi&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;fr&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;gl&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;hu&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;it&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;ja&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;lv&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;pl&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;ru&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;sl&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;sv&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;te&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;help&#x2F;zh_CN&#x2F;empathy&#x2F;irc-join-pwd.page &#x2F;usr&#x2F;share&#x2F;man&#x2F;man0p&#x2F;pwd.h.0p.gz &#x2F;usr&#x2F;share&#x2F;man&#x2F;man1&#x2F;pwd.1.gz &#x2F;usr&#x2F;share&#x2F;man&#x2F;man1&#x2F;pwdx.1.gz &#x2F;usr&#x2F;share&#x2F;man&#x2F;man1p&#x2F;pwd.1p.gz &#x2F;usr&#x2F;share&#x2F;man&#x2F;man3&#x2F;lckpwdf.3.gz &#x2F;usr&#x2F;share&#x2F;man&#x2F;man3&#x2F;ulckpwdf.3.gz &#x2F;usr&#x2F;share&#x2F;man&#x2F;man8&#x2F;unix_chkpwd.8.gz [wang@localhost ~]$ 搜索etc目录下所有以sh开头的文件 [wang@localhost ~]$ locate &#x2F;etc&#x2F;sh &#x2F;etc&#x2F;shadow &#x2F;etc&#x2F;shadow- &#x2F;etc&#x2F;shells [wang@localhost ~]$ 附加说明locate 与 find 不同: find 是去硬盘找，locate 只在 /var/lib/slocate 资料库中找。 locate 的速度比 find 快，它并不是真的查找，而是查数据库，一般文件数据库在 /var/lib/slocate/slocate.db 中，所以 locate 的查找并不是实时的，而是以数据库的更新为准，一般是系统自己维护，也可以手工升级数据库 ，命令为： updatedb 默认情况下 updatedb 每天执行一次。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"head命令与tail命令","slug":"linux-head","date":"2021-08-21T17:11:39.000Z","updated":"2021-08-21T18:23:37.524Z","comments":true,"path":"2021/08/22/linux-head/","link":"","permalink":"https://qinglei1989.github.io/2021/08/22/linux-head/","excerpt":"head 与 tail 就像它的名字一样的浅显易懂，它是用来显示开头或结尾某个数量的文字区块，head 用来显示档案的开头至标准输出中，而 tail 想当然尔就是看档案的结尾。","text":"head 与 tail 就像它的名字一样的浅显易懂，它是用来显示开头或结尾某个数量的文字区块，head 用来显示档案的开头至标准输出中，而 tail 想当然尔就是看档案的结尾。 head命令head 命令可用于查看文件的开头部分的内容，有一个常用的参数 -n 用于显示行数，默认为 10，即显示 10 行的内容。 命令格式： head [参数] [文件] 参数： -q 隐藏文件名 -v 显示文件名 -c&lt;数目&gt; 显示的字节数。 -n&lt;行数&gt; 显示的行数。 [wang@localhost ~]$ head textfile2 1 11111111111111111 2 22222222222222222 3 3 4 5 6 4444444444444444 7 5555555555555555 8 6666666666666666 9 10 -- 显示 textfile2 文件的开头 5 行 [wang@localhost ~]$ head -n 5 textfile2 1 11111111111111111 2 22222222222222222 3 3 4 5 -- 显示文件前 20 个字节: [wang@localhost ~]$ head -c 20 textfile2 1 1111111111111[wang@localhost ~]$ -- 文件的除了最后n个字节以外的内容 [wang@localhost ~]$ cat textfile2 1 11111111111111111 2 22222222222222222 3 3 4 5 6 4444444444444444 7 5555555555555555 8 6666666666666666 9 10 11 99999999999999 eeeeeeeeeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeeeeeeZZ9 -- 文件的除了最后20个字节以外的内容 [wang@localhost ~]$ head -c -20 textfile2 1 11111111111111111 2 22222222222222222 3 3 4 5 6 4444444444444444 7 5555555555555555 8 6666666666666666 9 10 11 99999999999999 eeeeeeeeeeeeeeeeeee eeeeeeeeeeeee[wang@localhost ~]$ -- 输出文件除了最后n行的全部内容 [wang@localhost ~]$ head -n -5 textfile2 1 11111111111111111 2 22222222222222222 3 3 4 5 6 4444444444444444 7 5555555555555555 8 6666666666666666 [wang@localhost ~]$ tail命令tail 命令从指定点开始将文件写到标准输出.使用tail命令的-f选项可以方便的查阅正在改变的日志文件,tail -f filename会把filename里最尾部的内容显示在屏幕上,并且不但刷新,使你看到最新的文件内容. 命令格式： tail [参数] [文件] 参数： -f 循环读取 -q 不显示处理信息 -v 显示详细的处理信息 -c&lt;数目&gt; 显示的字节数 -n&lt;行数&gt; 显示文件的尾部 n 行内容 –pid=PID 与-f合用,表示在进程ID,PID死掉之后结束 -q, –quiet, –silent 从不输出给出文件名的首部 -s, –sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 显示文件末尾内容 -- 显示文件最后5行内容 [push_service_gateway-00 push_service]$ tail -n 5 push_service_gateway.log [] 2021-08-22 02:18:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:18:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:19:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:19:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:19:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [rd@线上-基础架构-车源-话务-push_service_gateway-00 push_service]$ -- 循环查看文件内容,一般用于查看日志 [push_service_gateway-00 push_service]$ tail -f push_service_gateway.log [] 2021-08-22 02:17:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:18:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:18:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:18:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:19:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:19:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:19:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 -- 从第5行开始显示文件 [push_service_gateway-00 push_service]$ tail -f -n5 push_service_gateway.log [] 2021-08-22 02:21:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:21:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:22:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:22:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新 [] 2021-08-22 02:22:30 - [INFO] [LocalMonitor:71 watchFile] 非受监控的文件发生变更，无需刷新","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"more命令与less命令","slug":"linux-more","date":"2021-08-21T09:08:36.000Z","updated":"2021-08-21T17:10:37.047Z","comments":true,"path":"2021/08/21/linux-more/","link":"","permalink":"https://qinglei1989.github.io/2021/08/21/linux-more/","excerpt":"Linux more 命令类似 cat ，不过会以一页一页的形式显示，更方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能（与 vi 相似），使用中的说明文件，请按 h 。 less 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。 在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup] [pagedown] 等按 键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。","text":"Linux more 命令类似 cat ，不过会以一页一页的形式显示，更方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能（与 vi 相似），使用中的说明文件，请按 h 。 less 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。 在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup] [pagedown] 等按 键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。 Linux more 命令与less命令 more 语法 more [-dlfpcsu] [-num] [+&#x2F;pattern] [+linenum] [fileNames..] 参数 -num 一次显示的行数 -d 提示使用者，在画面下方显示 [Press space to continue, ‘q’ to quit.] ，如果使用者按错键，则会显示 [Press ‘h’ for instructions.] 而不是 ‘哔’ 声 -l 取消遇见特殊字元 ^L（送纸字元）时会暂停的功能 -f 计算行数时，以实际上的行数，而非自动换行过后的行数（有些单行字数太长的会被扩展为两行或两行以上） -p 不以卷动的方式显示每一页，而是先清除萤幕后再显示内容 -c 跟 -p 相似，不同的是先显示内容再清除其他旧资料 -s 当遇到有连续两行以上的空白行，就代换为一行的空白行 -u 不显示下引号 （根据环境变数 TERM 指定的 terminal 而有所不同） +/pattern 在每个文档显示前搜寻该字串（pattern），然后从该字串之后开始显示 +num 从第 num 行开始显示 fileNames 欲显示内容的文档，可为复数个数 常用操作命令： Enter 向下n行，需要定义。默认为1行 Ctrl+F 向下滚动一屏 空格键 向下滚动一屏 Ctrl+B 返回上一屏 = 输出当前行的行号 ：f 输出文件名和当前行的行号 V 调用vi编辑器 !命令 调用Shell，并执行命令 q 退出more more -s push_service_ws.log 逐页显示日志文件中内容，如有连续两行以上空白行则以一行空白行显示。 [push_service_ws-00 push_service]$ more -s push_service_ws.log [] 2021-08-21 00:00:33 - [INFO] [DefaultDisconnectListener:19 onDisconnect] eefc6553-ddba-403b-be58-6d0e92543680 has disconnected [] 2021-08-21 00:00:33 - [INFO] [SessionManagerAspect:57 doBefore] [推送服务WS][AOP] 请求参数[方法名:removeSession 参数列表:[eefc6553-ddba-403b-be 58-6d0e92543680]] [] 2021-08-21 00:00:33 - [INFO] [SessionManagerAspect:123 removeMethodManage] [推送服务WS][AOP] REMOVE方法移除SESSION KEY [sessionId eefc6553-ddba -403b-be58-6d0e92543680] [] 2021-08-21 00:00:33 - [INFO] [SessionManagerAspect:124 removeMethodManage] [推送服务WS][AOP] REMOVE方法相关REDIS KEY设置完毕[sessionId eefc6553 -ddba-403b-be58-6d0e92543680] [] 2021-08-21 00:00:33 - [INFO] [DefaultDisconnectListener:19 onDisconnect] b441923b-2146-4f00-94b3-e819b5c8b926 has disconnected [] 2021-08-21 00:00:33 - [INFO] [SessionManagerAspect:57 doBefore] [推送服务WS][AOP] 请求参数[方法名:removeSession 参数列表:[b441923b-2146-4f00-94 b3-e819b5c8b926]] [] 2021-08-21 00:00:33 - [INFO] [SessionManagerAspect:123 removeMethodManage] [推送服务WS][AOP] REMOVE方法移除SESSION KEY [sessionId b441923b-2146 -4f00-94b3-e819b5c8b926] more +20 -s push_service_ws.log 从第 20 行开始显示 testfile 之文档内容 [push_service_ws-00 push_service]$ more +20 -s push_service_ws.log [] 2021-08-21 00:04:57 - [INFO] [VerifyListener:36 onData] 8f9b7791-7b30-4ee0-9107-e9b4b8ffdc03 verify token success, token:eyJ0eXAiOiJKV1QiLCJhbG ciOiJIUzI1NiJ9.eyJzdWIiOjYzODcwLCJpc3MiOiJjYzliZDRmNGIxOTQ0YzQwYjFmZDQ3NjhiNDA3ZDkwZCIsImV4cCI6MTYyOTQ3NTU1NywiaWF0IjoxNjI5NDc1NDk3fQ.Y4kiuRU0lOCo t5gbZF_ckTz4JDIRgu14qPFCtNkSVG0 [] 2021-08-21 00:04:57 - [INFO] [SessionManagerAspect:57 doBefore] [推送服务WS][AOP] 请求参数[方法名:add 参数列表:[63870, 8f9b7791-7b30-4ee0-9107- e9b4b8ffdc03]] [] 2021-08-21 00:04:57 - [INFO] [SessionManagerAspect:92 addMethodManage] [推送服务WS][AOP] ADD方法设置REDIS相关KEY完毕 [userId 63870| sessionId 8 f9b7791-7b30-4ee0-9107-e9b4b8ffdc03] [] 2021-08-21 00:04:57 - [INFO] [VerifyListener:36 onData] d9dca042-82bc-494c-b241-8ba1dd70b5b8 verify token success, token:eyJ0eXAiOiJKV1QiLCJhbG ciOiJIUzI1NiJ9.eyJzdWIiOjYzODcwLCJpc3MiOiJjYzliZDRmNGIxOTQ0YzQwYjFmZDQ3NjhiNDA3ZDkwZCIsImV4cCI6MTYyOTQ3NTU1NywiaWF0IjoxNjI5NDc1NDk3fQ.Y4kiuRU0lOCo t5gbZF_ckTz4JDIRgu14qPFCtNkSVG0 从文件中查找第一个出现”addMethodManage”字符串的行，并从该处前两行开始显示输出 [rd@线上-基础架构-车源-话务-push_service_ws-00 push_service]$ more +&#x2F;addMethodManage push_service_ws.log ...skipping [] 2021-08-21 00:04:57 - [INFO] [VerifyListener:36 onData] 3803cbb2-e7a0-469a-b20d-1f4e1a2deb5c verify token success, token:eyJ0eXAiOiJKV1QiLCJhbG ciOiJIUzI1NiJ9.eyJzdWIiOjYzODcwLCJpc3MiOiJjYzliZDRmNGIxOTQ0YzQwYjFmZDQ3NjhiNDA3ZDkwZCIsImlhdCI6MTYyOTQ3NTQ5N30.B9u0T0DbDOFJXHsPUtTnjEr96026UOzqaso imuNm2Gw [] 2021-08-21 00:04:57 - [INFO] [SessionManagerAspect:57 doBefore] [推送服务WS][AOP] 请求参数[方法名:add 参数列表:[63870, 3803cbb2-e7a0-469a-b20d- 1f4e1a2deb5c]] [] 2021-08-21 00:04:57 - [INFO] [SessionManagerAspect:92 addMethodManage] [推送服务WS][AOP] ADD方法设置REDIS相关KEY完毕 [userId 63870| sessionId 3 803cbb2-e7a0-469a-b20d-1f4e1a2deb5c] 设定每屏显示行数 [push_service_ws-00 push_service]$ more -5 push_service_ws.log [] 2021-08-21 00:00:33 - [INFO] [DefaultDisconnectListener:19 onDisconnect] eefc6553-ddba-403b-be58-6d0e92543680 has disconnected [] 2021-08-21 00:00:33 - [INFO] [SessionManagerAspect:57 doBefore] [推送服务WS][AOP] 请求参数[方法名:removeSession 参数列表:[eefc6553-ddba-403b-be 58-6d0e92543680]] [] 2021-08-21 00:00:33 - [INFO] [SessionManagerAspect:123 removeMethodManage] [推送服务WS][AOP] REMOVE方法移除SESSION KEY [sessionId eefc6553-ddba -403b-be58-6d0e92543680] --More--(0%) 一个目录下的文件，由于内容太多，我们应该学会用more来分页显示。这得和管道 | 结合起来 [push_service_ws-00 tmp]$ ls -l | more -5 total 8 srwxr-xr-x 1 root root 0 Feb 12 2020 Aegis-&lt;Guid(5A2C30A2-A87D-490A-9281-6765EDAD7CBA)&gt; drwxr-xr-x 2 root root 4096 Apr 13 2020 hsperfdata_root drwxr-xr-x 2 work work 4096 Jul 8 21:14 hsperfdata_work srwxrwxrwx 1 root root 0 May 24 2017 qtsingleapp-aegisG-46d2 --More-- less 语法 less [参数] 文件 参数说明： -b &lt;缓冲区大小&gt; 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x &lt;数字&gt; 将”tab”键显示为规定的数字空格 /字符串：向下搜索”字符串”的功能 ?字符串：向上搜索”字符串”的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） b 向上翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一页 回车键 滚动一行 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 查看文件 less log2013.log 可以按大写 F，就会有类似 tail -f 的效果，读取写入文件的最新内容， 按 ctrl+C 停止。 可以按 v 进入编辑模型， shift+ZZ 保存退出到 less 查看模式。 ps查看进程信息并通过less分页显示 ps -ef |less 浏览多个文件 less log2013.log log2014.log 说明：输入 ：n后，切换到 log2014.log输入 ：p 后，切换到log2013.log","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"cat命令","slug":"linux-cat","date":"2021-08-16T15:15:47.000Z","updated":"2021-08-16T15:44:23.520Z","comments":true,"path":"2021/08/16/linux-cat/","link":"","permalink":"https://qinglei1989.github.io/2021/08/16/linux-cat/","excerpt":"cat（英文全拼：concatenate）命令用于连接文件并打印到标准输出设备上。","text":"cat（英文全拼：concatenate）命令用于连接文件并打印到标准输出设备上。 cat命令语法格式cat [-AbeEnstTuv] [--help] [--version] fileName 参数说明：-n 或 –number：由 1 开始对所有输出的行数编号。 -b 或 –number-nonblank：和 -n 相似，只不过对于空白行不编号。 -s 或 –squeeze-blank：当遇到有连续两行以上的空白行，就代换为一行的空白行。 -v 或 –show-nonprinting：使用 ^ 和 M- 符号，除了 LFD 和 TAB 之外。 -E 或 –show-ends : 在每行结束处显示 $。 -T 或 –show-tabs: 将 TAB 字符显示为 ^I。 -A, –show-all：等价于 -vET。 -e：等价于”-vE”选项； -t：等价于”-vT”选项； 把 textfile1 的文档内容加上行号后输入 textfile2 这个文档里： [wang@localhost ~]$ cat textfile2 [wang@localhost ~]$ cat text cat: text: 没有那个文件或目录 [wang@localhost ~]$ cat textfile1 11111111111111111 22222222222222222 3 4444444444444444 5555555555555555 6666666666666666 999999999999999 [wang@localhost ~]$ cat -n textfile1 &gt; textfile2 [wang@localhost ~]$ cat textfile2 1 11111111111111111 2 22222222222222222 3 3 4 5 6 4444444444444444 7 5555555555555555 8 6666666666666666 9 10 11 999999999999999 清空 textfile2 文档内容： [wang@localhost ~]$ cat textfile2 1 11111111111111111 2 22222222222222222 3 3 4 5 6 4444444444444444 7 5555555555555555 8 6666666666666666 9 10 11 999999999999999 [wang@localhost ~]$ cat &#x2F;dev&#x2F;null &gt; textfile2 [wang@localhost ~]$ cat textfile2 [wang@localhost ~]$ cat text 把 textfile1 和 textfile2 的文件内容加上行号（空白行不加）之后将内容附加到 log.log 里。 [wang@localhost ~]$ cat -nb textfile1 textfile2 &gt; log.log [wang@localhost ~]$ ll 总用量 12 -rw-rw-r--. 1 wang wang 421 8月 16 23:40 log.log drwxrwxr-x. 5 wang wang 36 8月 14 22:57 scf drwxrwxr-x. 4 wang wang 66 8月 15 02:46 test -rw-rw-r--. 1 wang wang 109 8月 16 23:26 textfile1 -rw-rw-r--. 1 wang wang 186 8月 16 23:32 textfile2 drwxrwxr-x. 3 wang wang 53 8月 15 02:38 wangql drwxr-xr-x. 2 wang wang 6 8月 4 00:58 公共 drwxr-xr-x. 2 wang wang 6 8月 4 00:58 模板 drwxr-xr-x. 2 wang wang 6 8月 4 00:58 视频 drwxr-xr-x. 2 wang wang 6 8月 4 00:58 图片 drwxr-xr-x. 2 wang wang 6 8月 4 00:58 文档 drwxr-xr-x. 2 wang wang 6 8月 4 00:58 下载 drwxr-xr-x. 2 wang wang 6 8月 4 00:58 音乐 drwxr-xr-x. 2 wang wang 6 8月 4 00:58 桌面 [wang@localhost ~]$ cat log.log 1 11111111111111111 2 22222222222222222 3 3 4 4444444444444444 5 5555555555555555 6 6666666666666666 7 999999999999999 8 1 11111111111111111 9 2 22222222222222222 10 3 3 11 4 12 5 13 6 4444444444444444 14 7 5555555555555555 15 8 6666666666666666 16 9 17 10 18 11 999999999999999 [wang@localhost ~]$","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"与目录相关的操作命令","slug":"linux-dir","date":"2021-08-14T14:19:07.000Z","updated":"2021-08-15T03:01:13.665Z","comments":true,"path":"2021/08/14/linux-dir/","link":"","permalink":"https://qinglei1989.github.io/2021/08/14/linux-dir/","excerpt":"Linux与目录相关的操作命令学习","text":"Linux与目录相关的操作命令学习 与目录相关的操作命令 mkdir命令 用于创建目录,要求创建目录的用户在当前目录中具有写权限 语法 mkdir dirName 命令参数： -m 设定权限&lt;模式&gt; (类似 chmod)，而不是 rwxrwxrwx 减 umask -p 此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录; -v 每次创建新目录都显示信息 [wang@localhost ~]$ ls 公共 模板 视频 图片 文档 下载 音乐 桌面 [wang@localhost ~]$ mkdir wang [wang@localhost ~]$ mkdir wangql -v mkdir: 已创建目录 &quot;wangql&quot; [wang@localhost ~]$ mkdir -pv wang&#x2F;tieniu&#x2F;zhu mkdir: 已创建目录 &quot;wang&#x2F;tieniu&quot; mkdir: 已创建目录 &quot;wang&#x2F;tieniu&#x2F;zhu&quot; [wang@localhost ~]$ mkdir -vp scf&#x2F;&#123;lib&#x2F;,bin&#x2F;,doc&#x2F;&#123;info,product&#125;&#125; mkdir: 已创建目录 &quot;scf&quot; mkdir: 已创建目录 &quot;scf&#x2F;lib&#x2F;&quot; mkdir: 已创建目录 &quot;scf&#x2F;bin&#x2F;&quot; mkdir: 已创建目录 &quot;scf&#x2F;doc&quot; mkdir: 已创建目录 &quot;scf&#x2F;doc&#x2F;info&quot; mkdir: 已创建目录 &quot;scf&#x2F;doc&#x2F;product&quot; rmdir 命令 用于删除空白目录，删除某目录时也必须具有对父目录的写权限 语法 rmdir dirName 命令参数： - p 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。 -v 显示指令执行过程 [wang@localhost ~]$ rmdir doc rmdir: 删除 &quot;doc&quot; 失败: 没有那个文件或目录 [wang@localhost ~]$ ls scf test wang wangql 公共 模板 视频 图片 文档 下载 音乐 桌面 [wang@localhost ~]$ rmdir scf&#x2F;doc rmdir: 删除 &quot;scf&#x2F;doc&quot; 失败: 目录非空 [wang@localhost ~]$ rmdir scf&#x2F;doc&#x2F;info [wang@localhost ~]$ rmdir -v scf&#x2F;doc&#x2F;product rmdir: 正在删除目录 &quot;scf&#x2F;doc&#x2F;product&quot; [root@localhost wang]# tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── test ├── wang │ └── tieniu │ └── zhu ├── wangql ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 rm命令 删除一个目录中的一个或多个文件或目录，删除文件可以直接使用rm命令，若删除目录则必须配合选项”-r” 语法： rm dirName 命令参数： -f, –force 忽略不存在的文件，从不给出提示。 -i, –interactive 进行交互式删除 -r, -R, –recursive 指示rm将参数中列出的全部目录和子目录均递归地删除。 -v, –verbose 详细显示进行的步骤 [root@localhost wang]# ls scf test wang wangql wang.txt 公共 模板 视频 图片 文档 下载 音乐 桌面 [root@localhost wang]# rm wang.txt rm：是否删除普通空文件 &quot;wang.txt&quot;？y [root@localhost wang]# ls scf test wang wangql 公共 模板 视频 图片 文档 下载 音乐 桌面 [root@localhost wang]# -- 强制删除 [root@localhost wang]# ls scf test wang wangql wang.txt 公共 模板 视频 图片 文档 下载 音乐 桌面 [root@localhost wang]# rm -f wang wang&#x2F; wangql&#x2F; wang.txt [root@localhost wang]# rm -f wang.txt [root@localhost wang]# -- 删除前逐一询问确认 [root@localhost wang]# rm -i wang*.txt rm：是否删除普通空文件 &quot;wang1.txt&quot;？y rm：是否删除普通空文件 &quot;wang2.txt&quot;？y rm：是否删除普通空文件 &quot;wang3.txt&quot;？y [root@localhost wang]# -- 将 wang子目录及子目录中所有档案删除 [root@localhost wang]# mkdir -p wang&#x2F;wang1&#x2F;wang2&#x2F;wang3 [root@localhost wang]# tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── test ├── wang │ ├── tieniu │ │ └── zhu │ └── wang1 │ └── wang2 │ └── wang3 ├── wangql ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 20 directories, 0 files [root@localhost wang]# rm -r wang rm：是否进入目录&quot;wang&quot;? y rm：是否进入目录&quot;wang&#x2F;tieniu&quot;? y rm：是否删除目录 &quot;wang&#x2F;tieniu&#x2F;zhu&quot;？y rm：是否删除目录 &quot;wang&#x2F;tieniu&quot;？y rm：是否进入目录&quot;wang&#x2F;wang1&quot;? y rm：是否进入目录&quot;wang&#x2F;wang1&#x2F;wang2&quot;? y rm：是否删除目录 &quot;wang&#x2F;wang1&#x2F;wang2&#x2F;wang3&quot;？y rm：是否删除目录 &quot;wang&#x2F;wang1&#x2F;wang2&quot;？y rm：是否删除目录 &quot;wang&#x2F;wang1&quot;？y rm：是否删除目录 &quot;wang&quot;？y [root@localhost wang]# rm -rf [目录] 一个危险的命令会将目录及子目录中所有档案删除,并且不用一一确认。 mv命令 语法： mv [选项] 源文件或目录 目标文件或目录 命令参数： -b ：若需覆盖文件，则覆盖前先行备份。 -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖； -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖！ -u ：若目标文件已经存在，且 source 比较新，才会更新(update) 文件重命名：mv source_file(文件) dest_file(文件) [root@localhost wang]# touch wang.txt [root@localhost wang]# mv wang.txt rename.log [root@localhost wang]# ls rename.log scf test wangql 公共 模板 视频 图片 文档 下载 音乐 桌面 [root@localhost wang]# # 目标目录与原目录一致，指定了新文件名，效果就是仅仅重命名。 [root@localhost test]# touch wang.xtx [root@localhost test]# ls wang.xtx [root@localhost test]# pwd &#x2F;home&#x2F;wang&#x2F;test [root@localhost test]# mv &#x2F;home&#x2F;wang&#x2F;test&#x2F;wang.xtx &#x2F;home&#x2F;wang&#x2F;test&#x2F;rename.txt [root@localhost test]# ls rename.txt [root@localhost test]# 移动文件：mv source_file(文件) dest_directory(目录) [wang@localhost ~]$ tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── wangql │ └── test │ ├── rename.log │ └── rename.txt ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 14 directories, 2 files [wang@localhost ~]$ [wang@localhost ~]$ pwd &#x2F;home&#x2F;wang [wang@localhost ~]$ mv wang&#x2F;* test mv: 无法获取&quot;wang&#x2F;*&quot; 的文件状态(stat): 没有那个文件或目录 [wang@localhost ~]$ mv wangql&#x2F;* test [wang@localhost ~]$ tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── test │ ├── rename.log │ └── rename.txt ├── wangql ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 14 directories, 2 files [wang@localhost ~]$ mv source_directory(目录) dest_directory(目录) 目录名 dest_directory 已存在，将 source_directory 移动到目录名 dest_directory 中；目录名 dest_directory 不存在则 source_directory 改名为目录名 dest_directory [wang@localhost ~]$ tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── test │ ├── rename.log │ └── rename.txt ├── wangql ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 14 directories, 2 files [wang@localhost ~]$ mv test test11 [wang@localhost ~]$ tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── test11 │ ├── rename.log │ └── rename.txt ├── wangql ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 14 directories, 2 files [wang@localhost ~]$ mkdir test [wang@localhost ~]$ mv test11 test [wang@localhost ~]$ tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── test │ └── test11 │ ├── rename.log │ └── rename.txt ├── wangql ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 15 directories, 2 files [wang@localhost ~]$ 移动当前文件夹下的所有文件到上一级目录 mv * ../ [wang@localhost ~]$ tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── test │ └── test11 │ ├── rename.log │ └── rename.txt ├── wangql ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 15 directories, 2 files [wang@localhost ~]$ [wang@localhost ~]$ cd test&#x2F;test11 [wang@localhost test11]$ mv * ..&#x2F; [wang@localhost test11]$ tree -N . 0 directories, 0 files [wang@localhost test11]$ cd [wang@localhost ~]$ tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── test │ ├── rename.log │ ├── rename.txt │ └── test11 ├── wangql ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 15 directories, 2 files [wang@localhost ~]$ cp命令 主要用于复制文件或目录。 参数说明： -a：此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。 -d：复制时保留链接。这里所说的链接相当于 Windows 系统中的快捷方式。 -f：覆盖已经存在的目标文件而不给出提示。 -i：与 -f 选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答 y 时目标文件将被覆盖。 -p：除复制文件的内容外，还把修改时间和访问权限也复制到新文件中。 -r：若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。 -l：不复制文件，只是生成链接文件。 在没有带-a参数时，两个文件的时间是不一样的。在带了-a参数时，两个文件的时间是一致的。 [wang@localhost ~]$ tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── test │ ├── rename.log │ ├── rename.txt │ └── test11 ├── wangql ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 15 directories, 2 files [wang@localhost ~]$ cp -r test&#x2F;* wangql [wang@localhost ~]$ tree -N . ├── scf │ ├── bin │ ├── doc │ └── lib ├── test │ ├── rename.log │ ├── rename.txt │ └── test11 ├── wangql │ ├── rename.log │ ├── rename.txt │ └── test11 ├── 公共 ├── 模板 ├── 视频 ├── 图片 ├── 文档 ├── 下载 ├── 音乐 └── 桌面 16 directories, 4 files [wang@localhost ~]$ 目标文件存在时，会询问是否覆盖。这是因为cp是cp -i的别名。目标文件存在时，即使加了-f标志，也还会询问是否覆盖。 [root@localhost wang]# cp -r wangql&#x2F;rename.log test cp：是否覆盖&quot;test&#x2F;rename.log&quot;？ y [root@localhost wang]# cp -rf wangql&#x2F;rename.log test cp：是否覆盖&quot;test&#x2F;rename.log&quot;？ y [root@localhost wang]#","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"linux-cd-pwd","slug":"linux-cd-pwd","date":"2021-08-09T16:45:50.000Z","updated":"2021-08-10T16:04:02.668Z","comments":true,"path":"2021/08/10/linux-cd-pwd/","link":"","permalink":"https://qinglei1989.github.io/2021/08/10/linux-cd-pwd/","excerpt":"Linux cd（英文全拼：change directory）命令用于切换当前工作目录。 Linux pwd（英文全拼：print work directory） 命令用于显示工作目录。","text":"Linux cd（英文全拼：change directory）命令用于切换当前工作目录。 Linux pwd（英文全拼：print work directory） 命令用于显示工作目录。 Linux cd命令与pwd 命令cd命令语法：cd [dirName] dirName：要切换的目标目录 使用 cd 或cd ~命令进入当前用户主目录 [wang@localhost ~]$ cd &#x2F; [wang@localhost &#x2F;]$ cd [wang@localhost ~]$ cd &#x2F; [wang@localhost &#x2F;]$ cd ~ [wang@localhost ~]$ 使用cd - 返回进入此目录之前所在的目录 [wang@localhost ~]$ cd &#x2F;bin [wang@localhost bin]$ cd [wang@localhost ~]$ cd - &#x2F;bin [wang@localhost bin]$ pwd命令 用 pwd 命令查看默认工作目录的完整路径 [wang@localhost ~]$ pwd &#x2F;home&#x2F;wang [wang@localhost ~]$ 目录连接链接时，pwd -P 显示出实际路径，而非使用连接（link）路径；pwd显示的是连接路径 [wang@localhost ~]$ cd &#x2F;etc&#x2F;init.d [wang@localhost init.d]$ pwd &#x2F;etc&#x2F;init.d [wang@localhost init.d]$ pwd -P &#x2F;etc&#x2F;rc.d&#x2F;init.d","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"junit-assert","slug":"junit-assert","date":"2021-08-09T14:57:08.000Z","updated":"2021-08-28T09:19:13.808Z","comments":true,"path":"2021/08/09/junit-assert/","link":"","permalink":"https://qinglei1989.github.io/2021/08/09/junit-assert/","excerpt":"Junit为我们提供了一些辅助函数，他们用来帮助我们确定被测试的方法是否按照预期的效果正常工作。","text":"Junit为我们提供了一些辅助函数，他们用来帮助我们确定被测试的方法是否按照预期的效果正常工作。 单元测试 – Assert1、Assert.assertEquals(1423263017788772352L, queryUserResp.getUcid());}报错信息： Ambiguous method call: both ‘Assert.assertEquals(Object, Object)’ and ‘Assert.assertEquals(long, long)’ match 这是因为我们的queryUserResp.getUcid() 返回Long，而不是long。因此编译器很困惑：它应该将两个参数都转换为 Object，还是应该只将 Long 转换为 long？ 2、Json表达式验证器JsonPathResultMatchers jsonPath(String expression, Object ... args)&#x2F;ResultMatcher jsonPath(String expression, Matcher matcher) 3、对Map返回值的校验@Test public void insertSupplierBrandStrategyValid() throws Exception &#123; Map&lt;String, List&lt;String&gt;&gt; map &#x3D; new HashMap&lt;&gt;(); List&lt;String&gt; sessionList &#x3D; new ArrayList&lt;&gt;(2); String session1 &#x3D; UUID.randomUUID().toString(); String session2 &#x3D; UUID.randomUUID().toString(); sessionList.add(session1); sessionList.add(session2); map.put(&quot;1&quot;, sessionList); when(service.getUserSessions(1)).thenReturn(map); MockHttpServletRequestBuilder requestBuilder &#x3D; MockMvcRequestBuilders .get(&quot;&#x2F;manager&#x2F;user&#x2F;1&quot;) .accept(MediaType.APPLICATION_JSON) .contentType(MediaType.APPLICATION_JSON); MvcResult mvcResult &#x3D; mockMvc.perform(requestBuilder) .andDo(print()) &#x2F;&#x2F;打印输出发出请求的详细信息 .andExpect(status().isOk()) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data.length()&quot;).value(1)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data&quot;, Matchers.hasKey(&quot;1&quot;))) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data&quot;, Matchers.hasEntry(&quot;1&quot;,sessionList ))) .andReturn(); System.out.println(mvcResult.getResponse().getContentAsString()); &#125; 4、对List返回值的校验@Test public void testQueryCityAreaTree() throws Exception &#123; List&lt;CityAreaGroupNode&gt; cityAreaTreeList &#x3D; new ArrayList&lt;&gt;(); List&lt;CityAreaGroupNode&gt; cityAreaChildList &#x3D; new ArrayList&lt;&gt;(); CityAreaGroupNode cityAreaChild1 &#x3D; new CityAreaGroupNode(); cityAreaChild1.setId(1045); cityAreaChild1.setTitle(null); cityAreaChild1.setName(&quot;北京陈冲02&quot;); cityAreaChild1.setType(&quot;area&quot;); cityAreaChild1.setParent(&quot;北京&quot;); cityAreaChild1.setParentId(null); cityAreaChild1.setCity(&quot;北京&quot;); cityAreaChild1.setBusiness(&quot;个卖&quot;); cityAreaChild1.setChildren(null); CityAreaGroupNode cityAreaChild2 &#x3D; new CityAreaGroupNode(); cityAreaChild2.setId(1035); cityAreaChild2.setTitle(null); cityAreaChild2.setName(&quot;北京刘玉广01&quot;); cityAreaChild2.setType(&quot;area&quot;); cityAreaChild2.setParent(&quot;北京&quot;); cityAreaChild2.setParentId(null); cityAreaChild2.setCity(&quot;北京&quot;); cityAreaChild2.setBusiness(&quot;个卖&quot;); cityAreaChild2.setChildren(null); cityAreaChildList.add(cityAreaChild1); cityAreaChildList.add(cityAreaChild2); CityAreaGroupNode cityAreaGroupNode1 &#x3D; new CityAreaGroupNode(); cityAreaGroupNode1.setId(1); cityAreaGroupNode1.setTitle(null); cityAreaGroupNode1.setType(&quot;city&quot;); cityAreaGroupNode1.setParent(null); cityAreaGroupNode1.setName(&quot;北京&quot;); cityAreaGroupNode1.setParentId(null); cityAreaGroupNode1.setBusiness(null); cityAreaGroupNode1.setChildren(cityAreaChildList); cityAreaTreeList.add(cityAreaGroupNode1); Mockito.when(auctionParnerService.queryCityAreaTree()).thenReturn(cityAreaTreeList); MockHttpServletRequestBuilder requestBuilder &#x3D; MockMvcRequestBuilders .get(&quot;&#x2F;auction&#x2F;areas&#x2F;cityAreaTree&quot;) .param(&quot;aid&quot;, &quot;966926828067360769&quot;); mockMvc.perform(requestBuilder) .andDo(print()) &#x2F;&#x2F;打印输出发出请求的详细信息 .andExpect(status().isOk()) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data&quot;).isNotEmpty()) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data.length()&quot;).value(1)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].id&quot;).value(&quot;1&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].type&quot;).value(&quot;city&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].name&quot;).value(&quot;北京&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children.length()&quot;).value(2)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[0].id&quot;).value(1045)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[0].name&quot;).value(&quot;北京陈冲02&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[0].type&quot;).value(&quot;area&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[0].parent&quot;).value(&quot;北京&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[0].business&quot;).value(&quot;个卖&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[0].children&quot;).isEmpty()) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[1].id&quot;).value(1035)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[1].name&quot;).value(&quot;北京刘玉广01&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[1].type&quot;).value(&quot;area&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[1].parent&quot;).value(&quot;北京&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[1].business&quot;).value(&quot;个卖&quot;)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[1].title&quot;).isEmpty()) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data[0].children[1].parentId&quot;).isEmpty()) .andReturn(); &#125;","categories":[{"name":"单元测试","slug":"单元测试","permalink":"https://qinglei1989.github.io/categories/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"junit","slug":"junit","permalink":"https://qinglei1989.github.io/tags/junit/"}]},{"title":"tools-maven","slug":"tools-maven","date":"2021-08-09T11:27:53.000Z","updated":"2022-02-28T03:38:28.510Z","comments":true,"path":"2021/08/09/tools-maven/","link":"","permalink":"https://qinglei1989.github.io/2021/08/09/tools-maven/","excerpt":"Maven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。","text":"Maven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。 maven插件maven控制台中文乱码解决方式： 方式一：项目pom.xml中增加 &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;&#x2F;artifactId&gt; &lt;version&gt;2.12.4&lt;&#x2F;version&gt; &lt;configuration&gt; &lt;argLine&gt;-Dfile.encoding&#x3D;UTF-8&lt;&#x2F;argLine&gt; &lt;&#x2F;configuration&gt; &lt;&#x2F;plugin&gt; 方式二：在命令行中执行命令时添加mvn test -Dfile.encoding=UTF-8 pom.xml文件横线解决办法现象： 解决办法：","categories":[{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"实用工具","slug":"实用工具","permalink":"https://qinglei1989.github.io/tags/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"ls命令","slug":"linux-ls","date":"2021-08-08T14:32:20.000Z","updated":"2021-08-21T17:13:02.207Z","comments":true,"path":"2021/08/08/linux-ls/","link":"","permalink":"https://qinglei1989.github.io/2021/08/08/linux-ls/","excerpt":"ls（英文全拼：list files）命令用于显示指定工作目录下之内容（列出目前工作目录所含之文件及子目录)。","text":"ls（英文全拼：list files）命令用于显示指定工作目录下之内容（列出目前工作目录所含之文件及子目录)。 Linux ls 命令 语法 ls [-alrtAFR] [name...] 参数 : -a 显示所有文件及目录 (. 开头的隐藏文件也会列出) -l 除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出 -r 将文件以相反次序显示(原定依英文字母次序) -t 将文件依建立时间之先后次序列出 -A 同 -a ，但不列出 &quot;.&quot; (目前目录) 及 &quot;..&quot; (父目录) -F 在列出的文件名称后加一符号；例如可执行档则加 &quot;*&quot;, 目录则加 &quot;&#x2F;&quot; -R 若目录下有文件，则以下之文件亦皆依序列出 列出根目录()下的所有目录 [wang@localhost ~]$ ls &#x2F; bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var [wang@localhost ~]$ 列出目前工作目录下所有名称是 a 开头的文件，越新的排越后面 : [root@localhost bin]# ls -lR a* -rwxr-xr-x. 1 root root 107824 6月 18 2014 a2p -rwxr-xr-x. 1 root root 11232 6月 19 2014 abrt-action-analyze-backtrace -rwxr-xr-x. 1 root root 11208 6月 19 2014 abrt-action-analyze-c -rwxr-xr-x. 1 root root 1345 6月 19 2014 abrt-action-analyze-ccpp-local -rwxr-xr-x. 1 root root 6821 6月 19 2014 abrt-action-analyze-core -rwxr-xr-x. 1 root root 11208 6月 19 2014 abrt-action-analyze-oops -rwxr-xr-x. 1 root root 11216 6月 19 2014 abrt-action-analyze-python -rwxr-xr-x. 1 root root 2199 6月 19 2014 abrt-action-analyze-vmcore -rwxr-xr-x. 1 root root 1348 6月 19 2014 abrt-action-analyze-vulnerability -rwxr-xr-x. 1 root root 11248 6月 19 2014 abrt-action-analyze-xorg 将 /bin 目录以下所有目录及文件详细资料列出","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"linux-grep","slug":"linux-grep","date":"2021-08-03T15:04:27.000Z","updated":"2021-10-26T10:33:54.840Z","comments":true,"path":"2021/08/03/linux-grep/","link":"","permalink":"https://qinglei1989.github.io/2021/08/03/linux-grep/","excerpt":"grep用于分析一行信息，如果当中包含我们需要的信息，就会将该行拿出来。","text":"grep用于分析一行信息，如果当中包含我们需要的信息，就会将该行拿出来。 Linux grep 命令语法grep [-abcEFGhHilLnqrsvVwxy][-A&lt;显示行数&gt;][-B&lt;显示列数&gt;][-C&lt;显示列数&gt;][-d&lt;进行动作&gt;][-e&lt;范本样式&gt;][-f&lt;范本文件&gt;][--help][范本样式][文件或目录...] 原始文件 [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590650, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105710], sessionSetnull, time&#x3D;1628392590697, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[29987], sessionSetnull, time&#x3D;1628392590691, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590700, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [fcc01e59b3474decace4da79c85425fc] 2021-08-08 11:17:34 - [INFO] [MessageController:26 pushMessage] [推送服务gateway] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105371], sessionSetnull, time&#x3D;1628392643858, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - -c: 计算找到查找字符的次数 [wang@localhost ~]$ grep -c &quot;推送服务GATEWAY&quot; wang.txt 8 -i: 忽略大小写 推送服务GATEWAY 与 推送服务gateway [wang@localhost ~]$ grep -i &quot;推送服务GATEWAY&quot; wang.txt [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590650, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105710], sessionSetnull, time&#x3D;1628392590697, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[29987], sessionSetnull, time&#x3D;1628392590691, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590700, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [fcc01e59b3474decace4da79c85425fc] 2021-08-08 11:17:34 - [INFO] [MessageController:26 pushMessage] [推送服务gateway] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105371], sessionSetnull, time&#x3D;1628392643858, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] -n: 输出行号 [wang@localhost ~]$ grep -n &quot;1628392590691&quot; wang.txt 9:[e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[29987], sessionSetnull, time&#x3D;1628392590691, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] -v: 反向选择 [wang@localhost ~]$ grep -v &quot;推送服务GATEWAY]&quot; wang.txt [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [fcc01e59b3474decace4da79c85425fc] 2021-08-08 11:17:34 - [INFO] [MessageController:26 pushMessage] [推送服务gateway] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105371], sessionSetnull, time&#x3D;1628392643858, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - –color=auto: 将查找到的关键字部分加上颜色.CENTOS7中，默认的grep命令已经主动使用–color=auto [wang@localhost ~]$ grep --color &quot;推送服务GATEWAY]&quot; wang.txt [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590650, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105710], sessionSetnull, time&#x3D;1628392590697, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[29987], sessionSetnull, time&#x3D;1628392590691, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590700, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 -A: 除了显示符合范本样式的那一列之外，并显示该行之后的内容。 [wang@localhost ~]$ grep --color -A1 &quot;推送服务GATEWAY]&quot; wang.txt [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590650, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - -- [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105710], sessionSetnull, time&#x3D;1628392590697, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - -- [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[29987], sessionSetnull, time&#x3D;1628392590691, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - -- [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590700, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - -- [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [fcc01e59b3474decace4da79c85425fc] 2021-08-08 11:17:34 - [INFO] [MessageController:26 pushMessage] [推送服务gateway] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105371], sessionSetnull, time&#x3D;1628392643858, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] -B: 除了显示符合样式的那一行之外，并显示该行之前的内容 [wang@localhost ~]$ grep --color -B1 &quot;推送服务GATEWAY]&quot; wang.txt [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590650, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] -- [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105710], sessionSetnull, time&#x3D;1628392590697, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] -- [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[29987], sessionSetnull, time&#x3D;1628392590691, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] -- [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590700, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] -- [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 -C: 除了显示符合样式的那一行之外，并显示该行及其前后各n行 [wang@localhost ~]$ grep -C 3 &quot;fcc01e59b3474decace4da79c85425fc&quot; wang.txt [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [fcc01e59b3474decace4da79c85425fc] 2021-08-08 11:17:34 - [INFO] [MessageController:26 pushMessage] [推送服务gateway] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105371], sessionSetnull, time&#x3D;1628392643858, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - grep -E 同时匹配多个关键字–或关系 [wang@localhost ~]$ grep -E &quot;推送服务GATEWAY|e2f306c4e56947e3b2f7b92f77f96de7&quot; wang.txt [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590650, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[105710], sessionSetnull, time&#x3D;1628392590697, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[29987], sessionSetnull, time&#x3D;1628392590691, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [INFO] [MessageController:26 pushMessage] [推送服务GATEWAY] 请求参数 [message HttpInMessage [type&#x3D;publish, from&#x3D;cluefactory, to&#x3D;[106011], sessionSetnull, time&#x3D;1628392590700, content&#x3D;&#123;&#39;id&#39;:&#39;10208726&#39;,&#39;phone&#39;:&#39;19184312877&#39;&#125;]] [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - 同时匹配多个关键字–与关系 [wang@localhost ~]$ grep &quot;推送服务GATEWAY&quot; wang.txt | grep &quot;消息接收者Session为空&quot; [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 复杂场景：将/etc/passwd，将没有出现 root 和nologin的行取出来grep -v root /etc/passwd | grep -v nologin -F : 将样式视为固定字符串的列表 或者使用\\进行转义 [wang@localhost ~]$ grep &quot;\\[推送服务GATEWAY\\] 消息接收者Session为空&quot; wang.txt --color [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [wang@localhost ~]$ grep -F &quot;[推送服务GATEWAY] 消息接收者Session为空&quot; wang.txt --color [e2f306c4e56947e3b2f7b92f77f96de7] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [e991a256b22b4917811182ba1d1582c3] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [6cafbdfab9be4a18a97effbb529cb769] 2021-08-08 11:17:23 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [05377816635f4b8b81a0fe9af7da9891] 2021-08-08 11:17:24 - [ERROR] [MessageServiceImpl:92 redisChannelPush] [推送服务GATEWAY] 消息接收者Session为空 [wang@localhost ~]$ grep &quot;[推送服务GATEWAY] 消息接收者Session为空&quot; wang.txt --color [wang@localhost ~]$ 当查询的数据带有””时,使用grep ‘“createSource”:-1,”‘ usercenter_api.log –color [c1_UserCenter_API-00 usercenter_api]$ grep &#39;&quot;createSource&quot;:-1,&quot;&#39; usercenter_api.log --color [b068b442547d43d1b3c6f09fdda08fa0] 2021-08-24 00:00:00-[350679836] - [INFO] [FindUserBUCRouteService:91 findUserBUC][http-nio-0.0.0.0-8080-exec-8] findUserBUC weighted : 1,argsMapString&#x3D;&#123;&quot;ucid&quot;:&quot;1264820333857214464&quot;&#125;, dialout返回值：&#123;&quot;data&quot;:&#123;&quot;createSource&quot;:-1,&quot;nature&quot;:0,&quot;phone&quot;:&quot;D.Bd8e15f65d7fb6a9bf98a9cdd698052db.QTE1OTAzOTE2NDE0NzU5TmJhZ0VnNUpseVQrVFNNSkRHZXdRPT0&#x3D;&quot;,&quot;sourceType&quot;:-1,&quot;unencryptedPhone&quot;:&quot;15101612659&quot;,&quot;userTypes&quot;:1,&quot;isVip&quot;:0,&quot;status&quot;:1,&quot;ucid&quot;:1264820333857214464&#125;,&quot;errMsg&quot;:&quot;ok&quot;,&quot;version&quot;:0,&quot;errorMsg&quot;:&quot;ok&quot;,&quot;status&quot;:0,&quot;ts&quot;:1629734400164&#125;, elapsed:[1] 精确匹配 grep -w &quot;publis&quot; push_service_ws.log --color 正则表达式 查询相应时间大于3秒的数据 [nginx]$ grep -E &quot;elapsed&#x3D;\\[[3-9]&quot; access-2021-09-01.log --color request&#x3D;[POST &#x2F;facade&#x2F;v2&#x2F;user&#x2F;subordinate_relation_by_condition HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[102628] elapsed&#x3D;[3.111] refer&#x3D;[-] request&#x3D;[POST &#x2F;facade&#x2F;v2&#x2F;user&#x2F;subordinate_relation_by_condition HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[102628] elapsed&#x3D;[3.217] refer&#x3D;[-] request&#x3D;[POST &#x2F;facade&#x2F;v2&#x2F;user&#x2F;subordinate_relation_by_condition HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[102628] elapsed&#x3D;[3.098] refer&#x3D;[-] request&#x3D;[POST &#x2F;facade&#x2F;v2&#x2F;user&#x2F;subordinate_relation_by_condition HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[102628] elapsed&#x3D;[3.250] refer&#x3D;[-] request&#x3D;[POST &#x2F;facade&#x2F;v2&#x2F;user&#x2F;subordinate_relation_by_condition HTTP&#x2F;1.1] status&#x3D;[200] byte&#x3D;[102628] elapsed&#x3D;[3.041] refer&#x3D;[-] -r 指定要查找的是目录而非文件时，必须使用此参数 [[authority]$ grep -r &quot;info&quot; &#x2F;mnt&#x2F;logs&#x2F;authority&#x2F; &#x2F;mnt&#x2F;logs&#x2F;authority&#x2F;authority-api-info_2021-10-23.log:[7b40af7650074aeba22420fabbd919a9] 2021-10-23 00:02:47 - [INFO] [KaController:147 getKaOrPartnerInfoByUserId] Get ka or partner info by user_id : 42621 &#x2F;mnt&#x2F;logs&#x2F;authority&#x2F;authority-api-info_2021-10-23.log:[db79ba6c83604231bc34c66814ef4988] 2021-10-23 00:03:17 - [INFO] [KaController:147 getKaOrPartnerInfoByUserId] Get ka or partner info by user_id : 42621 ] 在多个文件中查找 [authority]$ grep &quot;78d869ab3b2d403a8903602c5a717953&quot; authority-api-info.log authority-api-info_2021-10-25.log authority-api-info.log:[78d869ab3b2d403a8903602c5a717953] 2021-10-26 18:15:42 - [INFO] [SlowLogAspect:67 logController] 请求开始 controller UserController.queryUserHierarchy [49089] authority-api-info.log:[78d869ab3b2d403a8903602c5a717953] 2021-10-26 18:15:42 - [INFO] [UserController:45 queryUserHierarchy] query user area group hierarchy and userId&#x3D;49089 authority-api-info.log:[78d869ab3b2d403a8903602c5a717953] 2021-10-26 18:15:42 - [INFO] [SlowLogAspect:73 logController] 请求结束，controller response &#123;&quot;data&quot;:&#123;&#125;, elapse[14ms] grep 与 head结合，返回符合条件前N个 [authority]$ grep &quot;info&quot; authority-api-info.log | head -n1 [69168ac54e4b434cbc756003bbe80fa6] 2021-10-26 00:01:26 - [INFO] [KaController:147 getKaOrPartnerInfoByUserId] Get ka or partner info by user_id : 64061 [authority]$ grep &quot;info&quot; authority-api-info.log | head -n2 [69168ac54e4b434cbc756003bbe80fa6] 2021-10-26 00:01:26 - [INFO] [KaController:147 getKaOrPartnerInfoByUserId] Get ka or partner info by user_id : 64061 [0c2acd74aff6416a942df7fb5793fe9b] 2021-10-26 00:02:11 - [INFO] [KaController:147 getKaOrPartnerInfoByUserId] Get ka or partner info by user_id : 67694 [authority]$ grep &quot;info&quot; authority-api-info.log | head -n3 [69168ac54e4b434cbc756003bbe80fa6] 2021-10-26 00:01:26 - [INFO] [KaController:147 getKaOrPartnerInfoByUserId] Get ka or partner info by user_id : 64061 [0c2acd74aff6416a942df7fb5793fe9b] 2021-10-26 00:02:11 - [INFO] [KaController:147 getKaOrPartnerInfoByUserId] Get ka or partner info by user_id : 67694 [51aba4fa356a4afdbe9c01a5f594e16d] 2021-10-26 00:02:21 - [INFO] [KaController:147 getKaOrPartnerInfoByUserId] Get ka or partner info by user_id : 43750","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"spring-boot-redis","slug":"spring-boot-redis","date":"2021-07-31T17:57:52.000Z","updated":"2022-10-03T09:40:44.158Z","comments":true,"path":"2021/08/01/spring-boot-redis/","link":"","permalink":"https://qinglei1989.github.io/2021/08/01/spring-boot-redis/","excerpt":"记录Springboot整合redis中遇到的问题。","text":"记录Springboot整合redis中遇到的问题。 Springboot整合redis相关配置POM文件 &lt;!--添加父工程依赖--> &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.5.0&lt;/version> &lt;relativePath/> &lt;/parent> &lt;!--添加redis相关依赖--> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.commons&lt;/groupId> &lt;artifactId>commons-pool2&lt;/artifactId> &lt;/dependency> application.yml # 测试环境 spring: #redis redis: database: 0 host: 127.0.0.1 port: 6379 password: foobared timeout: 5000 # 连接池设置 lettuce: pool: max-idle: 8 max-wait: -1 min-idle: 1 max-active: 8 shutdowntimeout: 100 RedisConfig相关代码 package com.rrc.config; import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; import com.rrc.listener.RedisReceiver; import lombok.extern.slf4j.Slf4j; import org.apache.commons.pool2.impl.GenericObjectPoolConfig; import org.springframework.beans.factory.annotation.Value; import org.springframework.cache.interceptor.KeyGenerator; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisPassword; import org.springframework.data.redis.connection.RedisStandaloneConfiguration; import org.springframework.data.redis.connection.lettuce.LettuceClientConfiguration; import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory; import org.springframework.data.redis.connection.lettuce.LettucePoolingClientConfiguration; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.listener.ChannelTopic; import org.springframework.data.redis.listener.RedisMessageListenerContainer; import org.springframework.data.redis.listener.adapter.MessageListenerAdapter; import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.RedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; import java.time.Duration; @Slf4j @Configuration public class RedisConfig &#123; @Value(&quot;$&#123;spring.redis.database&#125;&quot;) private int database; @Value(&quot;$&#123;spring.redis.host&#125;&quot;) private String host; @Value(&quot;$&#123;spring.redis.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.redis.port&#125;&quot;) private int port; @Value(&quot;$&#123;spring.redis.timeout&#125;&quot;) private long timeout; @Value(&quot;$&#123;spring.redis.lettuce.shutdown-timeout&#125;&quot;) private long shutDownTimeout; @Value(&quot;$&#123;spring.redis.lettuce.pool.max-idle&#125;&quot;) private int maxIdle; @Value(&quot;$&#123;spring.redis.lettuce.pool.min-idle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.redis.lettuce.pool.max-active&#125;&quot;) private int maxActive; @Value(&quot;$&#123;spring.redis.lettuce.pool.max-wait&#125;&quot;) private long maxWait; &#x2F;&#x2F;json序列化器 private Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer &#x3D; new Jackson2JsonRedisSerializer(Object.class); @Bean public LettuceConnectionFactory lettuceConnectionFactory() &#123; GenericObjectPoolConfig genericObjectPoolConfig &#x3D; new GenericObjectPoolConfig(); genericObjectPoolConfig.setMaxIdle(maxIdle); genericObjectPoolConfig.setMinIdle(minIdle); genericObjectPoolConfig.setMaxTotal(maxActive); genericObjectPoolConfig.setMaxWaitMillis(maxWait); genericObjectPoolConfig.setTimeBetweenEvictionRunsMillis(100); RedisStandaloneConfiguration redisStandaloneConfiguration &#x3D; new RedisStandaloneConfiguration(); redisStandaloneConfiguration.setDatabase(database); redisStandaloneConfiguration.setHostName(host); redisStandaloneConfiguration.setPort(port); redisStandaloneConfiguration.setPassword(RedisPassword.of(password)); LettuceClientConfiguration clientConfig &#x3D; LettucePoolingClientConfiguration.builder() .commandTimeout(Duration.ofMillis(timeout)) .shutdownTimeout(Duration.ofMillis(shutDownTimeout)) .poolConfig(genericObjectPoolConfig) .build(); LettuceConnectionFactory factory &#x3D; new LettuceConnectionFactory(redisStandaloneConfiguration, clientConfig); &#x2F;&#x2F; factory.setShareNativeConnection(true); &#x2F;&#x2F; factory.setValidateConnection(false); return factory; &#125; &#x2F;&#x2F;redisTemplate模板提供给其他类对redis数据库进行操作 @Bean(name &#x3D; &quot;redisTemplate&quot;) public RedisTemplate&lt;String, Object&gt; redisTemplate(LettuceConnectionFactory redisConnectionFactory) &#123; &#x2F;&#x2F;序列化配置 Jackson2JsonRedisSerializer&lt;Object&gt; objectJackson2JsonRedisSerializer &#x3D; new Jackson2JsonRedisSerializer&lt;Object&gt;(Object.class); ObjectMapper objectMapper &#x3D; new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); objectJackson2JsonRedisSerializer.setObjectMapper(objectMapper); RedisTemplate&lt;String, Object&gt; redisTemplate &#x3D; new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); redisTemplate.setKeySerializer(keySerializer()); redisTemplate.setHashKeySerializer(keySerializer()); redisTemplate.setValueSerializer(valueSerializer()); redisTemplate.setHashValueSerializer(valueSerializer()); log.debug(&quot;自定义RedisTemplate加载完成&quot;); return redisTemplate; &#125; &#x2F;&#x2F;redis键序列化使用StringRedisSerializer private RedisSerializer&lt;String&gt; keySerializer() &#123; return new StringRedisSerializer(); &#125; &#x2F;&#x2F;redis值序列化使用json序列化器 private RedisSerializer&lt;Object&gt; valueSerializer() &#123; return new GenericJackson2JsonRedisSerializer(); &#125; &#x2F;&#x2F;缓存键自动生成器 @Bean public KeyGenerator myKeyGenerator() &#123; return (target, method, params) -&gt; &#123; StringBuilder sb &#x3D; new StringBuilder(); sb.append(target.getClass().getName()); sb.append(method.getName()); for (Object obj : params) &#123; sb.append(obj.toString()); &#125; return sb.toString(); &#125;; &#125; &#x2F;** * redis消息监听器容器 * 点赞消息订阅处理器 * * @param collectListenerAdapter 关注消息订阅处理器 * @return *&#x2F; @Bean RedisMessageListenerContainer container(LettuceConnectionFactory redisConnectionFactory, MessageListenerAdapter collectListenerAdapter, MessageListenerAdapter commentListenerAdapter) &#123; RedisMessageListenerContainer container &#x3D; new RedisMessageListenerContainer(); container.setConnectionFactory(redisConnectionFactory); &#x2F;&#x2F; 以下为修改默认的序列化方式，网上大多数消息发布订阅都是String类型,但是实际中数据类型肯定不止String类型 Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer &#x3D; new Jackson2JsonRedisSerializer&lt;Object&gt;( Object.class); ObjectMapper objectMapper &#x3D; new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); &#x2F;&#x2F; 收藏主题并绑定消息订阅处理器 collectListenerAdapter.setSerializer(jackson2JsonRedisSerializer); container.addMessageListener(collectListenerAdapter, new ChannelTopic(&quot;TOPIC_COLLECT&quot;)); return container; &#125; &#x2F;** * 收藏消息订阅处理器,并指定处理方法 * * @param receiver * @return *&#x2F; @Bean MessageListenerAdapter commentListenerAdapter(RedisReceiver receiver) &#123; MessageListenerAdapter commentListenerAdapter &#x3D; new MessageListenerAdapter(receiver); &#x2F;&#x2F;消息的反序列化方式 commentListenerAdapter.setSerializer(jackson2JsonRedisSerializer); return commentListenerAdapter; &#125; &#125; 发布订阅消息发送 redisTemplate.convertAndSend(entry.getKey(), JSON.toJSONString(message)); Redis发布订阅频道信息获取 Redis原生命令获取发布订阅频道信息为：pubsub channels [pattern]。但是我在开发的时候使用的客户端是redisTemplate。不支持上述命令。最后使用曲线救国的方式。因为我连接池使用的是jedis，而jedis支持该命令，所以写了个工具类进行转换。 public class RedisChannelUtil &#123; private RedisChannelUtil() &#123; &#125; &#x2F;** * @Author Wangql * @Description 获取Redis中的发布订阅频道名称 redisTemplate不支持此命令 使用底层jedis来执行 * @Date 18:47 2021&#x2F;7&#x2F;1 * @Param [redisTemplate] * @return java.util.List&lt;java.lang.String&gt; **&#x2F; public static List&lt;String&gt; getPushRedisChannels(RedisTemplate redisTemplate) &#123; RedisConnectionFactory connection &#x3D; redisTemplate.getConnectionFactory(); Jedis jedis &#x3D; null; try &#123; jedis &#x3D; (Jedis) connection.getConnection().getNativeConnection(); &#x2F;&#x2F; 使用的带前缀的模糊匹配 return jedis.pubsubChannels(PushConstant.REDIS_SERVICE_CHANNEL + &quot;*&quot;); &#125; finally &#123; if (jedis !&#x3D; null) &#123; jedis.close(); &#125; &#125; &#125; &#125; 注意点： org.springframework.data.redis.listener.ChannelTopic：一个确定的字符串org.springframework.data.redis.listener.PatternTopic：基于模式匹配 在使用ChannelTopic时可以使用pubsub channels [pattern]获取到对应的频道，但是在使用PatternTopic时使用pubsub channels [pattern]就存在获取不到相应频道的情况。使用时一定要注意！！！ 踩坑记录&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;SpringBoot 服务启动完毕&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021-08-01 02:16:15.116 [main] INFO org.springframework.boot.availability.ApplicationAvailabilityBean 75 logStateChange - Application availability state ReadinessState changed to ACCEPTING_TRAFFIC 2021-08-01 02:16:15.813 [container-2] ERROR org.springframework.data.redis.listener.RedisMessageListenerContainer 651 handleSubscriptionException - Connection failure occurred. Restarting subscription task after 5000 ms 2021-08-01 02:16:20.823 [container-3] ERROR org.springframework.data.redis.listener.RedisMessageListenerContainer 651 handleSubscriptionException - Connection failure occurred. Restarting subscription task after 5000 ms 2021-08-01 02:16:25.847 [container-4] ERROR org.springframework.data.redis.listener.RedisMessageListenerContainer 651 handleSubscriptionException - Connection failure occurred. Restarting subscription task after 5000 ms 2021-08-01 02:16:30.860 [container-5] ERROR org.springframework.data.redis.listener.RedisMessageListenerContainer 651 handleSubscriptionException - Connection failure occurred. Restarting subscription task after 5000 ms 以上为报错信息看到handleSubscriptionException。刚开始以为自己的发布订阅模式配置有问题，最后发现为密码错误，但是启动Application一直会提示重连，不会有其他的提示信息。 但是写一个简单的单元测试后会发现提示密码错误ERR invalid password Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to 127.0.0.1:6379 at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:78) at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:56) at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:330) at io.lettuce.core.RedisClient.connect(RedisClient.java:216) Caused by: io.lettuce.core.RedisCommandExecutionException: ERR invalid password at io.lettuce.core.internal.ExceptionFactory.createExecutionException(ExceptionFactory.java:137) RedisTemplate 和 StringRedisTemplateRedisTemplate Springboot2后在Lettuce的redis客户端基础上进一步封装，于是就形成了RedisTemplate StringRedisTemplate StringRedisTemplate介绍 1、StringRedisTemplate继承RedisTemplate，是springboot中针对操作字符串类型数据推出的redis客户端工具 。 2、只能用于操作String类型。 3、StringRedisTemplate操作字符串数据结构的对象： ValueOperations = stringRedisTemplate.opsForValue() 。 4、使用String序列化策略。 RedisTemplate和StringRedisTemplate数据不互通的根本原因是两者的序列化方式不一致。 分布式锁： https://www.sevenyuan.cn/2020/04/04/redis/2020-04-04-annotation-redis-lock/#more redis客户端连接，最大连接数查询与设置info clients可以查看当前的redis连接数 Redis&gt;info clients &#123; &quot;client_recent_max_output_buffer&quot;: 0, &quot;blocked_clients&quot;: 0, &quot;connected_clients&quot;: 134, &#x2F;&#x2F;说明:客户端连接数 &quot;client_recent_max_input_buffer&quot;: 2 &#125; config get maxclients 可以查询redis允许的最大连接数 127.0.0.1:6379&gt; config get maxclients 1) &quot;maxclients&quot; 2) &quot;10000&quot; 127.0.0.1:6379&gt; 1. 在2.6之后版本，可以修改最大连接数配置，默认10000，可以在redis.conf配置文件中修改 # maxclients 10000 2.config set maxclients num 可以设置redis允许的最大连接数 127.0.0.1:6379&gt; CONFIG set maxclients 10 OK 127.0.0.1:6379&gt; 3.启动redis.service服务时加参数--maxclients 100000来设置最大连接数限制 redis-server --maxclients 100000 -f &#x2F;etc&#x2F;redis.conf 查看明细 127.0.0.1:6379&gt; client list id&#x3D;22 addr&#x3D;127.0.0.1:1311 fd&#x3D;12 name&#x3D; age&#x3D;56813 idle&#x3D;0 flags&#x3D;N db&#x3D;0 sub&#x3D;0 psub&#x3D;0 multi&#x3D;-1 qbuf&#x3D;26 qbuf-free&#x3D;32742 obl&#x3D;0 oll&#x3D;0 omem&#x3D;0 events&#x3D;r cmd&#x3D;client 每个字段含义：addr:客户端的地址和端口fd:套接字所使用的文件描述符idle:以秒计算的空闲时长flags:客户端 flagdb:该客户端正在使用的数据库 IDsub:已订阅频道的数量psub:已订阅模式的数量multi:在事务中被执行的命令数量qbuf:查询缓冲区的长度（字节为单位， 0 表示没有分配查询缓冲区）qbuf-free:查询缓冲区剩余空间的长度（字节为单位， 0 表示没有剩余空间）obl:输出缓冲区的长度（字节为单位， 0 表示没有分配输出缓冲区）oll:输出列表包含的对象数量（当输出缓冲区没有剩余空间时，命令回复会以字符串对象的形式被入队到这个队列里）omem:输出缓冲区和输出列表占用的内存总量events:文件描述符事件cmd:最近一次执行的命令","categories":[{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://qinglei1989.github.io/tags/spring-boot/"}]},{"title":"springEL","slug":"springEL","date":"2021-07-28T15:37:19.000Z","updated":"2021-07-29T16:44:24.316Z","comments":true,"path":"2021/07/28/springEL/","link":"","permalink":"https://qinglei1989.github.io/2021/07/28/springEL/","excerpt":"为了更加灵活,Spring 还提供了表达式语言Spring EL 。通过Spring EL 可以拥有更为强大的运算规则来更好地装配Bean。","text":"为了更加灵活,Spring 还提供了表达式语言Spring EL 。通过Spring EL 可以拥有更为强大的运算规则来更好地装配Bean。 SpringEL表达式Spring表达式语言（简称SpEL）是一个支持查询和操作运行时对象导航图功能的强大的表达式语言。不直接依赖于Spring,可独立使用。底层实现：接口ExpressionParser负责解析表达式字符串。 XML中使用相应的实体定义 package com.rrc.entity; import lombok.Data; @Data public class Customer &#123; private String name; private String telephone; &#125; package com.rrc.config; import com.rrc.entity.Customer; import lombok.Getter; import lombok.Setter; public class ConsumerComponent &#123; @Getter @Setter private Customer customer; @Getter @Setter private String custName; @Getter @Setter private String telephone; &#125; XML配置，在resources目录下新建spring-other.xml。 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"> &lt;bean id=\"customer\" class=\"com.rrc.entity.Customer\"> &lt;property name=\"name\" value=\"张三\"/> &lt;property name=\"telephone\" value=\"13666666666\"/> &lt;/bean> &lt;bean id=\"customerDao\" class=\"com.rrc.config.ConsumerComponent\"> &lt;property name=\"customer\" value=\"#&#123;customer&#125;\">&lt;/property> &lt;property name=\"custName\" value=\"#&#123;customer.name&#125;\">&lt;/property> &lt;property name=\"telephone\" value=\"#&#123;customer.telephone&#125;\">&lt;/property> &lt;/bean> &lt;/beans> 我们在Application中打印ConsumerComponent类下三个属性的值 package com.rrc; import com.rrc.config.ConsumerComponent; import lombok.extern.slf4j.Slf4j; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.ApplicationContext; import org.springframework.context.annotation.AnnotationConfigApplicationContext; import org.springframework.context.annotation.ImportResource; @Slf4j @SpringBootApplication @ImportResource(locations &#x3D; &quot;classpath:spring-other.xml&quot;) public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); ApplicationContext ctx &#x3D; new AnnotationConfigApplicationContext(Application.class); ConsumerComponent consumerComponent &#x3D; ctx.getBean(ConsumerComponent.class); log.info(&quot;consumerComponent custName &#123;&#125;&quot;, consumerComponent.getCustName()); log.info(&quot;consumerComponent telephone &#123;&#125;&quot;, consumerComponent.getTelephone()); log.info(&quot;consumerComponent customer &#123;&#125;&quot;, consumerComponent.getCustomer()); &#125; &#125; 2021-07-29 01:02:09.045 [main] INFO com.rrc.Application 21 main - consumerComponent custName 张三 2021-07-29 01:02:09.047 [main] INFO com.rrc.Application 22 main - consumerComponent telephone 13666666666 2021-07-29 01:02:09.047 [main] INFO com.rrc.Application 23 main - consumerComponent customer Customer(name&#x3D;张三, telephone&#x3D;13666666666) JAVA中使用我们把在XML中的customerDao的配置从XML移动到JAVA文件中，相应的修改如下。启动项目之后依旧可以打印出相关的信息。 package com.rrc.config; import com.rrc.entity.Customer; import lombok.Data; import lombok.Getter; import lombok.Setter; import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; @Component @Data public class ConsumerComponent &#123; @Value(&quot;#&#123;customer&#125;&quot;) private Customer customer; @Value(&quot;#&#123;customer.name&#125;&quot;) private String custName; @Value(&quot;#&#123;customer.telephone&#125;&quot;) private String telephone; &#125; EL使用场景 方法：EL可以调用另一个对象的方法或者属性 @Value(&quot;#&#123;originBean.getELvalue()&#125;&quot;) private String telephone; package com.rrc.config; import org.springframework.stereotype.Component; @Component public class OriginBean &#123; public String getELvalue() &#123; return &quot;EL METHOD&quot;; &#125; &#125; 构造：EL可以调用new关键字，实现构造方法调用，实例化出对象来 @Value(“#{new int[]{1,2,3}}”) @Value(“#{new 包名.类名()}”) package com.rrc.config; import com.rrc.entity.School; import lombok.Data; import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; @Component @Data public class ConsumerComponent &#123; @Value(&quot;#&#123;originBean.getELvalue()&#125;&quot;) private String telephone; @Value(&quot;#&#123;new int[]&#123;1, 2, 3&#125;&#125;&quot;) private int[] intArray; @Value(&quot;#&#123;new com.rrc.entity.School()&#125;&quot;) private School school; &#125; 操作符 EL支持大多数的算数运算符，@Value(&quot;#&#123;3+4&#125;&quot;) 关系运算符 @Value(&quot;#&#123;1^1&#125;&quot;) 逻辑运算符 @Value(&quot;#&#123;5&gt;3&#125;&quot;) 三元运算符 @Value(&quot;#&#123;1&gt; 2? 0:1&#125;&quot;) 引用： Spring框架——SpringEL","categories":[{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"}],"tags":[{"name":"springEL","slug":"springEL","permalink":"https://qinglei1989.github.io/tags/springEL/"}]},{"title":"Excel常用操作","slug":"tools-excel","date":"2021-07-19T16:05:27.000Z","updated":"2023-01-12T15:58:12.135Z","comments":true,"path":"2021/07/20/tools-excel/","link":"","permalink":"https://qinglei1989.github.io/2021/07/20/tools-excel/","excerpt":"分享常用的Excel常用操作，提高开发效率。因为老有业务人员让我帮忙导出数据，第一步就是拼SQL，批量操作文件。","text":"分享常用的Excel常用操作，提高开发效率。因为老有业务人员让我帮忙导出数据，第一步就是拼SQL，批量操作文件。 Excel常用操作快捷键EXCEL行列互转复制源数据–右键–选择性粘贴–勾“转置”，确定。 删除单元格内多余的空格和换行符假设数据在A列，在B列输入=TRIM(CLEAN(A1))，然后下拉公式即可 常用快捷键CTRL+SHIFT+↑ 快速定位到行首 CTRL+SHIFT+↓ 快速定位到行尾 SUBSTITUTE函数：指定字符串替换=substitute(text,old_text,new_text,[instance_num]) =SUBSTITUTE（需要替换的文本，旧文本，新文本，第N个旧文本） 参数Instance_num 可省略，这表示用 new_text（新文本）替换掉所有的old_text（旧文本） 快速填充 找出重复项并提取 多行堆叠成一行使用公式：=TEXTJOIN(“,”,TRUE,A1:A32) 交集=IF(COUNTIF(A:A,B1)&gt;0,B1,0) 函数的大致意思是：在A列中找B1的值，如果有至少一个，则把该单元格的值设定为B1，如果没有，则设置为0。 差集=IF(ISERROR(VLOOKUP(A1,B$3:B$24,1,0)),“不重复”,“重复”) 查找D3单元格在B3到B24中，是否存在。存在为0，用“重复”表示；不存在为1，用“不重复”表示；然后下面的单元格拖动加号往下拖即可动态赋值公式，计算差值。 ISERROR函数的含义是判断一个值或者公式是否错误，如果是错误的，则返回结果true，否则返回结果false VLOOKUP =VLOOKUP(D2,’C:\\Users\\wang\\Desktop[NB门店离职人员信息.xlsx]Sheet1’!$E:$H,4,FALSE) 第一个参数：你要用来匹配的值（A表） 第二个参数：匹配的范围（B表） 第三个参数：是匹配完成之后你想要返回的值在匹配范围的第几列 第四个参数：1/TRUE 或 0/FALSE 的近似或精确匹配项 TEXT=TEXT(H2,”yyyy-mm-dd”) 根据指定的数字格式来将数值转成文本","categories":[{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"实用工具","slug":"实用工具","permalink":"https://qinglei1989.github.io/tags/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"Hello World","slug":"hello-world","date":"2021-07-18T17:33:17.834Z","updated":"2021-05-15T13:50:23.921Z","comments":true,"path":"2021/07/19/hello-world/","link":"","permalink":"https://qinglei1989.github.io/2021/07/19/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"Google常用插件","slug":"tools-chrome","date":"2021-07-16T18:37:10.000Z","updated":"2021-07-17T03:29:49.517Z","comments":true,"path":"2021/07/17/tools-chrome/","link":"","permalink":"https://qinglei1989.github.io/2021/07/17/tools-chrome/","excerpt":"分享常用的Google插件，提高开发效率。","text":"分享常用的Google插件，提高开发效率。 Google常用插件 Momentum插件 一个精美而简单的起始页空间，有助于提升我们的工作效率的 每天一碗励志鸡汤 设定每日目标/重点/意图 待办事项列表跟踪任务 查看天气预报 标签页中显示书签栏 从应用商店查找插件，添加到浏览器 首次安装输入昵称 输入邮箱 输入密码 设置每日目标/重点/意图 现在我们就可以实用Momentum插件了，具体的设置都比较简单。 FeHelper前端插件 大家可以根据自己的实际情况添加相应的功能，上图中我只添加了JSON美化和网页截屏。网页截屏我是为了使用其中的滚动截屏工具。","categories":[{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"实用工具","slug":"实用工具","permalink":"https://qinglei1989.github.io/tags/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"Git(7) -- git restore","slug":"git6","date":"2021-07-11T16:32:02.000Z","updated":"2021-07-11T16:40:22.898Z","comments":true,"path":"2021/07/12/git6/","link":"","permalink":"https://qinglei1989.github.io/2021/07/12/git6/","excerpt":"","text":"https://blog.csdn.net/albertsh/article/details/104719370/","categories":[{"name":"版本控制","slug":"版本控制","permalink":"https://qinglei1989.github.io/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}],"tags":[{"name":"git","slug":"git","permalink":"https://qinglei1989.github.io/tags/git/"}]},{"title":"单元测试—Mockito设置方法返回值","slug":"junit5","date":"2021-07-10T09:33:00.000Z","updated":"2021-07-10T13:57:29.824Z","comments":true,"path":"2021/07/10/junit5/","link":"","permalink":"https://qinglei1989.github.io/2021/07/10/junit5/","excerpt":"Mockito 是一个模拟测试框架，主要功能是在单元测试中模拟类/对象的行为。","text":"Mockito 是一个模拟测试框架，主要功能是在单元测试中模拟类/对象的行为。 单元测试 – Mockito设置方法返回值1、thenReturn与doReturnthenReturn 用来指定特定函数和参数调用的返回值。 thenReturn 中可以指定多个返回值。在调用时返回值依次出现。若调用次数超过返回值的数量，再次调用时返回最后一个返回值。 doReturn 的作用和thenReturn相同，但使用方式不同(doReturn(1).when(random).nextInt();) @RunWith(MockitoJUnitRunner.class) public class Mocktio &#123; @Mock private ExampleService exampleService; @Test public void test_spy() &#123; MockitoAnnotations.openMocks(this); when(exampleService.add(anyInt(), anyInt())).thenReturn(1, 2, 3); Assert.assertEquals(1, exampleService.add(1, 2)); Assert.assertEquals(2, exampleService.add(9, 7)); Assert.assertEquals(3, exampleService.add(10, 12)); Assert.assertEquals(3, exampleService.add(11, 6)); Assert.assertEquals(3, exampleService.add(7, 3)); &#125; class ExampleService &#123; int add(int a, int b) &#123; System.out.println(&quot;方法调用被执行&quot;); return a+b; &#125; &#125; &#125; 2、thenThrow与doThrowthenThrow用来让函数调用抛出异常。thenThrow 中可以指定多个异常。在调用时异常依次出现。若调用次数超过异常的数量，再次调用时抛出最后一个异常。 对应返回类型是 void 的函数，thenThrow 是无效的，要使用doThrow。doThrow(new RuntimeException(“异常”)).when(exampleService).hello(); @RunWith(MockitoJUnitRunner.class) public class Mocktio &#123; @Mock private ExampleService exampleService; @Test public void test_spy() &#123; MockitoAnnotations.openMocks(this); when(exampleService.add(anyInt(),anyInt())).thenThrow(new RuntimeException(&quot;异常&quot;)); try &#123; exampleService.add(1, 2); Assert.fail(); &#x2F;&#x2F; 上面会抛出异常，所以不会走到这里 &#125; catch (Exception ex) &#123; Assert.assertTrue(ex instanceof RuntimeException); Assert.assertEquals(&quot;异常&quot;, ex.getMessage()); &#125; doThrow(new RuntimeException(&quot;异常&quot;)).when(exampleService).addPrint(1, 2); try &#123; exampleService.addPrint(1, 2); Assert.fail(); &#x2F;&#x2F; 上面会抛出异常，所以不会走到这里 &#125; catch (Exception ex) &#123; Assert.assertTrue(ex instanceof RuntimeException); Assert.assertEquals(&quot;异常&quot;, ex.getMessage()); &#125; &#125; class ExampleService &#123; int add(int a, int b) &#123; System.out.println(&quot;方法调用被执行&quot;); return a+b; &#125; void addPrint(int a, int b) &#123; System.out.println(&quot;方法调用被执行&quot;); &#125; &#125; &#125; 3、thenAnswerthen 和 thenAnswer 的效果是一样的。它们的参数是实现 Answer 接口的对象，在改对象中可以获取调用参数，自定义返回值。 4、引用Mockito 指南 教你使用Mock完成单元测试 springboot test","categories":[{"name":"单元测试","slug":"单元测试","permalink":"https://qinglei1989.github.io/categories/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"junit","slug":"junit","permalink":"https://qinglei1989.github.io/tags/junit/"}]},{"title":"单元测试—Mockito学习","slug":"junit4","date":"2021-07-07T17:19:03.000Z","updated":"2021-07-10T09:34:47.952Z","comments":true,"path":"2021/07/08/junit4/","link":"","permalink":"https://qinglei1989.github.io/2021/07/08/junit4/","excerpt":"Mockito 是一个模拟测试框架，主要功能是在单元测试中模拟类/对象的行为。","text":"Mockito 是一个模拟测试框架，主要功能是在单元测试中模拟类/对象的行为。 单元测试 – Mockito入门1、mock()方法org.mockito.Mockito 的 mock 方法可以模拟类和接口，以下代码演示直接在Test方法中对类和接口进行Mock @Test public void test() &#123; List mockList &#x3D; mock(List.class); &#x2F;&#x2F; mock对象的方法返回值默认都是返回类型的默认值。例如返回类型是int，默认返回值是0；类型是一个类，默认返回值是null。 Assert.assertEquals(0, mockList.size()); Assert.assertEquals(null, mockList.get(0)); &#x2F;&#x2F; 调用 mock 对象的写方法，是没有效果的 mockList.add(&quot;a&quot;); &#x2F;&#x2F; 没有指定 size() 方法返回值，这里结果是默认值 Assert.assertEquals(0, mockList.size()); &#x2F;&#x2F; 没有指定 get(0) 返回值，这里结果是默认值 Assert.assertEquals(null, mockList.get(0)); &#x2F;&#x2F; 指定 get(0)时返回 a when(mockList.get(0)).thenReturn(&quot;a&quot;); &#x2F;&#x2F; 没有指定 size() 方法返回值，这里结果是默认值 Assert.assertEquals(0, mockList.size()); &#x2F;&#x2F; 因为上面指定了 get(0) 返回 a，所以这里会返回 a Assert.assertEquals(&quot;a&quot;, mockList.get(0)); &#x2F;&#x2F; 没有指定 get(1) 返回值，这里结果是默认值 Assert.assertEquals(null, mockList.get(1)); &#x2F;&#x2F; 指定 size()返回123 when(mockList.size()).thenReturn(123); Assert.assertEquals(123, mockList.size()); &#125; 2、@Mock 注解@Mock 注解可以理解为对 mock 方法的一个替代。使用该注解时，要使用MockitoAnnotations.openMocks 方法，让注解生效。所以相对于1中的单测，会变成如下的形式。 import org.junit.Assert; import org.junit.Before; import org.junit.Test; import org.mockito.Mock; import org.mockito.MockitoAnnotations; import java.util.List; import static org.mockito.Mockito.when; public class Mocktio &#123; @Mock private List mockList; @Before public void setUp() &#123; MockitoAnnotations.openMocks(this); &#125; @Test public void test() &#123; &#x2F;&#x2F; mock 对象的方法的返回值默认都是返回类型的默认值。例如返回类型是一个类，默认返回值是 null。 Assert.assertEquals(0, mockList.size()); Assert.assertEquals(null, mockList.get(0)); &#x2F;&#x2F; 调用 mock 对象的写方法，是没有效果的 mockList.add(&quot;a&quot;); &#x2F;&#x2F; 没有指定 size() 方法返回值，这里结果是默认值 Assert.assertEquals(0, mockList.size()); &#x2F;&#x2F; 没有指定 get(0) 返回值，这里结果是默认值 Assert.assertEquals(null, mockList.get(0)); &#x2F;&#x2F; 指定 get(0)时返回 a when(mockList.get(0)).thenReturn(&quot;a&quot;); &#x2F;&#x2F; 没有指定 size() 方法返回值，这里结果是默认值 Assert.assertEquals(0, mockList.size()); &#x2F;&#x2F; 因为上面指定了 get(0) 返回 a，所以这里会返回 a Assert.assertEquals(&quot;a&quot;, mockList.get(0)); &#x2F;&#x2F; 没有指定 get(1) 返回值，这里结果是默认值 Assert.assertEquals(null, mockList.get(1)); &#x2F;&#x2F; 指定 size()返回123 when(mockList.size()).thenReturn(123); Assert.assertEquals(123, mockList.size()); &#125; &#125; 3、MockitoJUnitRunnerMockitoAnnotations.initMocks 的一个替代方案是使用 MockitoJUnitRunner ，具体的代码变形为 import org.junit.Assert; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.junit.MockitoJUnitRunner; import java.util.List; import static org.mockito.Mockito.when; @RunWith(MockitoJUnitRunner.class) public class Mocktio &#123; @Mock private List mockList; @Test public void test() &#123; &#x2F;&#x2F; mock 对象的方法的返回值默认都是返回类型的默认值。例如返回类型是一个类，默认返回值是 null。 Assert.assertEquals(0, mockList.size()); Assert.assertEquals(null, mockList.get(0)); &#x2F;&#x2F; 调用 mock 对象的写方法，是没有效果的 mockList.add(&quot;a&quot;); &#x2F;&#x2F; 没有指定 size() 方法返回值，这里结果是默认值 Assert.assertEquals(0, mockList.size()); &#x2F;&#x2F; 没有指定 get(0) 返回值，这里结果是默认值 Assert.assertEquals(null, mockList.get(0)); &#x2F;&#x2F; 指定 get(0)时返回 a when(mockList.get(0)).thenReturn(&quot;a&quot;); &#x2F;&#x2F; 没有指定 size() 方法返回值，这里结果是默认值 Assert.assertEquals(0, mockList.size()); &#x2F;&#x2F; 因为上面指定了 get(0) 返回 a，所以这里会返回 a Assert.assertEquals(&quot;a&quot;, mockList.get(0)); &#x2F;&#x2F; 没有指定 get(1) 返回值，这里结果是默认值 Assert.assertEquals(null, mockList.get(1)); &#x2F;&#x2F; 指定 size()返回123 when(mockList.size()).thenReturn(123); Assert.assertEquals(123, mockList.size()); &#125; &#125; 4、参数匹配&#x2F;&#x2F; 可以使用 Mockito.anyInt() 匹配所有类型为 int 的参数 when(mockList.get(anyInt())).thenReturn(&quot;a&quot;); Assert.assertEquals(&quot;a&quot;, mockList.get(0)); Assert.assertEquals(&quot;a&quot;, mockList.get(1)); mockito 有多种匹配函数，部分如下： 函数名 匹配类型 any() 所有对象类型 anyInt() 基本类型 int、非 null 的 Integer 类型 anyChar() 基本类型 char、非 null 的 Character 类型 anyShort() 基本类型 short、非 null 的 Short 类型 anyBoolean() 基本类型 boolean、非 null 的 Boolean 类型 anyDouble() 基本类型 double、非 null 的 Double 类型 anyFloat() 基本类型 float、非 null 的 Float 类型 anyLong() 基本类型 long、非 null 的 Long 类型 anyByte() 基本类型 byte、非 null 的 Byte 类型 anyString() String 类型(不能是 null) anyList() List&lt;T&gt; 类型(不能是 null) anyMap() Map&lt;K, V&gt;类型(不能是 null) anyCollection() Collection&lt;T&gt;类型(不能是 null) anySet() Set&lt;T&gt;类型(不能是 null) any(Class&lt;T&gt; type) type类型的对象(不能是 null) isNull() null notNull() 非 null 5、@Spy 注解spy 和 mock不同，不同点是： spy 的参数是对象示例，mock 的参数是 class。 被 spy修饰的对象，调用其方法时默认会走真实方法。mock 对象不会。 @RunWith(MockitoJUnitRunner.class) public class Mocktio &#123; @Mock private ExampleService spyExampleService; @Test public void test_spy() &#123; &#x2F;&#x2F;Assert.assertEquals(3, spyExampleService.add(1, 2)); when(spyExampleService.add(1, 2)).thenReturn(10); Assert.assertEquals(10, spyExampleService.add(1, 2)); &#125; class ExampleService &#123; int add(int a, int b) &#123; System.out.println(&quot;方法调用被执行&quot;); return a+b; &#125; &#125; &#125; &#x2F;&#x2F; Console打印为空 &#x2F;&#x2F;如果我们将@Mock注解替换为@Spy 去除单行注释&#x2F;&#x2F;Assert.assertEquals(3, spyExampleService.add(1, 2)); COnsole打印： 方法调用被执行 方法调用被执行","categories":[{"name":"单元测试","slug":"单元测试","permalink":"https://qinglei1989.github.io/categories/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"junit","slug":"junit","permalink":"https://qinglei1989.github.io/tags/junit/"}]},{"title":"单元测试—Mockito的使用","slug":"junit3","date":"2021-07-07T16:32:41.000Z","updated":"2023-03-03T16:10:53.841Z","comments":true,"path":"2021/07/08/junit3/","link":"","permalink":"https://qinglei1989.github.io/2021/07/08/junit3/","excerpt":"Mockito 是一个模拟测试框架，主要功能是在单元测试中模拟类/对象的行为。","text":"Mockito 是一个模拟测试框架，主要功能是在单元测试中模拟类/对象的行为。 单元测试 – Mockito的使用需要测试的方法如下： public void recallMessage(RecallMessageDTO recallMessageDTO) &#123; log.info(&quot;[融云][单条消息撤回]请求参数: [recallMessageDTO&#x3D;&#123;&#125;]&quot;, recallMessageDTO); RecallMessage recallMessage &#x3D; new RecallMessage() .setSenderId(recallMessageDTO.getFromUserId()) .setTargetId(recallMessageDTO.getTargetId()) .setuId(recallMessageDTO.getMessageUID()) .setSentTime(recallMessageDTO.getSentTime()) .setIsAdmin(recallMessageDTO.getIsAdmin()) .setIsDelete(recallMessageDTO.getIsDelete()) .setExtra(recallMessageDTO.getExtra()) .setDisablePush(recallMessageDTO.getDisablePush()); Result result &#x3D; null; try&#123; result &#x3D; rongCloud.message.msgPrivate.recall(recallMessage); log.info(&quot;[融云][单条消息撤回]请求结果: [result&#x3D;&#123;&#125;]&quot;, result); if (Objects.isNull(result)) &#123; throw new BusinessException(&quot;[融云][单条消息撤回]请求异常&quot;); &#125; if (!RongCloudCodeEnum.SUCCESS.getCode().equals(result.getCode())) &#123; throw new BusinessException(String.format(&quot;融云聊天室单条消息撤回失败: %s&quot;, result.getErrorMessage())); &#125; &#125; catch (Exception e) &#123; log.error(&quot;[融云][单条消息撤回]请求失败：[recallMessageDTO&#x3D;&#123;&#125;]&quot;, recallMessageDTO, e); throw new BusinessException(&quot;[融云][单条消息撤回]异常&quot;, e); &#125; &#125; 这个方法竟然是我写的，现在一看真是垃圾。try-catch这是干了啥抹杀了作案现场，含泪以他做一下单元测试吧。 在上边的方法中有以下情况需要考虑 result返回值为空的情况 result返回值不是success的情况 rongCloud调用异常的情况 方法正常执行 针对rongCloud的情况，我们需要Mock message和private并赋值给rongCloud。 相应的单元测试代码如下： public class RongCloudServiceTest &#123; @InjectMocks private RongCloudService rongCloudService; @Mock private RongCloud rongCloud; @Rule public ExpectedException thrown&#x3D; ExpectedException.none(); @Before public void setUp() &#123; MockitoAnnotations.initMocks(this); Private privateMsg &#x3D; Mockito.mock(Private.class); Message message &#x3D; Mockito.mock(Message.class); message.msgPrivate &#x3D; privateMsg; rongCloud.message &#x3D; message; &#125; @Test public void recallMessage() throws Exception &#123; Mockito.when(rongCloud.message.msgPrivate.recall(Mockito.any(RecallMessage.class))) .thenReturn(new ResponseResult(RongCloudCodeEnum.SUCCESS.getCode(), RongCloudCodeEnum.SUCCESS.getValue())); rongCloudService.recallMessage(new RecallMessageDTO()); &#125; @Test public void recallMessageNull() throws Exception &#123; thrown.expect(BusinessException.class); thrown.expectMessage(&quot;[融云][单条消息撤回]异常&quot;); Mockito.when(rongCloud.message.msgPrivate.recall(Mockito.any(RecallMessage.class))).thenReturn(null); rongCloudService.recallMessage(new RecallMessageDTO()); &#125; @Test public void recallMessageError() throws Exception &#123; thrown.expect(BusinessException.class); thrown.expectMessage(&quot;[融云][单条消息撤回]异常&quot;); Mockito.when(rongCloud.message.msgPrivate.recall(Mockito.any(RecallMessage.class))) .thenReturn(new ResponseResult(RongCloudCodeEnum.SERVER_ERROR.getCode(), RongCloudCodeEnum.SERVER_ERROR.getValue())); rongCloudService.recallMessage(new RecallMessageDTO()); &#125; @Test public void recallMessageException() throws Exception &#123; thrown.expect(BusinessException.class); thrown.expectMessage(&quot;[融云][单条消息撤回]异常&quot;); Mockito.when(rongCloud.message.msgPrivate.recall(Mockito.any(RecallMessage.class))).thenThrow(new ConnectException(&quot;连接超时&quot;)); rongCloudService.recallMessage(new RecallMessageDTO()); &#125; &#125; private方法如何做单元测试 需要测试的方法如下： private Map&lt;String, Set&lt;String&gt;&gt; getChannelSession(List&lt;Integer&gt; to) &#123; Map&lt;String, Set&lt;String&gt;&gt; channelSession &#x3D; new HashMap&lt;&gt;(4); to.stream().filter(Objects::nonNull).forEach(recevier -&gt; &#123; Set&lt;String&gt; sessionSet &#x3D; redisTemplate.opsForSet().members(PushConstant.REDIS_SERVICE_USERID + recevier); sessionSet.stream().filter(StringUtils::isNotEmpty).forEach(session -&gt; &#123; String channel &#x3D; (String) redisTemplate.opsForHash().get(REDIS_SERVICE_SESSSION + session, &quot;channel&quot;); if (StringUtils.isNotEmpty(channel)) &#123; if (channelSession.containsKey(channel)) &#123; Set&lt;String&gt; pushSessionSet &#x3D; channelSession.get(channel); pushSessionSet.add(session); &#125; else &#123; Set&lt;String&gt; pushSessionSet &#x3D; new HashSet&lt;&gt;(); pushSessionSet.add(session); channelSession.put(channel, pushSessionSet); &#125; &#125; &#125;); &#125;); return channelSession; &#125; 涉及到的Redis中的数据类型为： 我写的单元测试类如下： @RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest public class MessageServiceImplTest &#123; @InjectMocks private MessageServiceImpl messageService; @Mock private RedisTemplate redisTemplate; @Before public void setUp() &#123; MockitoAnnotations.initMocks(this); &#125; @Test public void testConvertPackageUsageNoData() &#123; Mockito.when(redisTemplate.opsForSet()).thenReturn(Mockito.mock(SetOperations.class)); Mockito.when(redisTemplate.opsForHash()).thenReturn(Mockito.mock(HashOperations.class)); Set&lt;String&gt; set1 &#x3D; new HashSet&lt;&gt;(); set1.add(&quot;4fd23740-4365-46d3-8ce7-f2dc9abd0a2b&quot;); set1.add(&quot;470bec5c-767f-4fde-aea7-4a43449353a4&quot;); Set&lt;String&gt; set2 &#x3D; new HashSet&lt;&gt;(); set2.add(&quot;1cefae25-29bc-4250-890b-a2eb7e36fd11&quot;); set2.add(&quot;a7174444-5327-4f6e-8205-8083c3030747&quot;); Mockito.when(redisTemplate.opsForSet().members(PushConstant.REDIS_SERVICE_USERID + 1)).thenReturn(set1); Mockito.when(redisTemplate.opsForSet().members(PushConstant.REDIS_SERVICE_USERID + 2)).thenReturn(set2); Mockito.when(redisTemplate.opsForHash().get(REDIS_SERVICE_SESSSION + &quot;4fd23740-4365-46d3-8ce7-f2dc9abd0a2b&quot;, &quot;channel&quot;)).thenReturn(&quot;122.168.0.130:30002&quot;); Mockito.when(redisTemplate.opsForHash().get(REDIS_SERVICE_SESSSION + &quot;470bec5c-767f-4fde-aea7-4a43449353a4&quot;, &quot;channel&quot;)).thenReturn(&quot;122.168.0.131:30002&quot;); Mockito.when(redisTemplate.opsForHash().get(REDIS_SERVICE_SESSSION + &quot;1cefae25-29bc-4250-890b-a2eb7e36fd11&quot;, &quot;channel&quot;)).thenReturn(&quot;122.168.0.130:30002&quot;); Mockito.when(redisTemplate.opsForHash().get(REDIS_SERVICE_SESSSION + &quot;a7174444-5327-4f6e-8205-8083c3030747&quot;, &quot;channel&quot;)).thenReturn(&quot;122.168.0.131:30002&quot;); List&lt;Integer&gt; toUser &#x3D; new ArrayList&lt;&gt;(2); toUser.add(1); toUser.add(2); Map&lt;String, Set&lt;String&gt;&gt; map &#x3D; ReflectionTestUtils.invokeMethod(messageService, &quot;getChannelSession&quot;, toUser); Assert.assertNotNull(map); Assert.assertTrue(!map.isEmpty()); Assert.assertEquals(2, map.size()); Assert.assertTrue(map.containsKey(&quot;122.168.0.130:30002&quot;)); Assert.assertTrue(map.containsKey(&quot;122.168.0.131:30002&quot;)); Assert.assertEquals(2, map.get(&quot;122.168.0.130:30002&quot;).size()); Assert.assertEquals(2, map.get(&quot;122.168.0.131:30002&quot;).size()); &#125; &#125; 这时候就存在一个问题，如果我们需要测试的方法很多，我们需要在所有的方法中写入以下代码： ​ Mockito.when(redisTemplate.opsForSet()).thenReturn(Mockito.mock(SetOperations.class));​ Mockito.when(redisTemplate.opsForHash()).thenReturn(Mockito.mock(HashOperations.class)); 而我们正确的方式应该时Mock整个RedisTemplate类 @Component public class RedisTemplateSpy implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (&quot;redisTemplate&quot;.equals(beanName)) &#123; RedisTemplate redisTemplate &#x3D; Mockito.mock(RedisTemplate.class); ValueOperations valueOperations &#x3D; Mockito.mock(ValueOperations.class); SetOperations setOperations &#x3D; Mockito.mock(SetOperations.class); HashOperations hashOperations &#x3D; Mockito.mock(HashOperations.class); ListOperations listOperations &#x3D; Mockito.mock(ListOperations.class); ZSetOperations zSetOperations &#x3D; Mockito.mock(ZSetOperations.class); Mockito.when(redisTemplate.opsForSet()).thenReturn(setOperations); Mockito.when(redisTemplate.opsForValue()).thenReturn(valueOperations); Mockito.when(redisTemplate.opsForHash()).thenReturn(hashOperations); Mockito.when(redisTemplate.opsForList()).thenReturn(listOperations); Mockito.when(redisTemplate.opsForZSet()).thenReturn(zSetOperations); RedisOperations redisOperations &#x3D; Mockito.mock(RedisOperations.class); RedisConnection redisConnection &#x3D; Mockito.mock(RedisConnection.class); RedisConnectionFactory redisConnectionFactory &#x3D; Mockito.mock(RedisConnectionFactory.class); Mockito.when(redisTemplate.getConnectionFactory()).thenReturn(redisConnectionFactory); Mockito.when(valueOperations.getOperations()).thenReturn(redisOperations); Mockito.when(redisTemplate.getConnectionFactory().getConnection()).thenReturn(redisConnection); return redisTemplate; &#125; return bean; &#125; &#125; 我们在需要使用RedisTemplate的地方直接引用即可，因为我们已经在上面的方法中实现了RedisTemplate的Mock。 @Autowired private RedisTemplate redisTemplate; 返回值校验 我们对接口http://localhost:8080/manager/user/55424进行单元测试 @RequestMapping(value &#x3D; &quot;&#x2F;user&#x2F;&#123;userId&#125;&quot;, method &#x3D; &#123; RequestMethod.GET &#125;) public Response&lt;Map&lt;String, List&lt;String&gt;&gt;&gt; getUser(@PathVariable Integer userId) &#123; log.info(&quot;[推送服务GATEWAY] 获取推送服务上单个WS用户 请求参数 [userId &#123;&#125;]&quot;, userId); Map&lt;String, List&lt;String&gt;&gt; sessionInfo &#x3D; managerService.getUserSessions(userId); return Response.ok(sessionInfo); &#125; 返回值为： &#123; &quot;version&quot;: 0, &quot;status&quot;: 0, &quot;errMsg&quot;: &quot;ok&quot;, &quot;errorMsg&quot;: &quot;ok&quot;, &quot;ts&quot;: 1626188639683, &quot;data&quot;: &#123; &quot;55424&quot;: [ &quot;7c921ff9-9a76-4ad8-92e4-02de140b40ad&quot; ] &#125; &#125; 相应的单元测试类为： @WebMvcTest(&#123; ManagerController.class&#125;) public class ManagerControllerTest &#123; private MockMvc mockMvc; @InjectMocks private ManagerController controller; @Mock private ManagerServiceImpl service; @Before public void before() &#123; MockitoAnnotations.initMocks(this); this.mockMvc &#x3D; MockMvcBuilders .standaloneSetup(controller) .build(); &#125; @Test public void insertSupplierBrandStrategyValid() throws Exception &#123; Map&lt;String, List&lt;String&gt;&gt; map &#x3D; new HashMap&lt;&gt;(); List&lt;String&gt; sessionList &#x3D; new ArrayList&lt;&gt;(2); String session1 &#x3D; UUID.randomUUID().toString(); String session2 &#x3D; UUID.randomUUID().toString(); sessionList.add(session1); sessionList.add(session2); map.put(&quot;1&quot;, sessionList); when(service.getUserSessions(1)).thenReturn(map); MockHttpServletRequestBuilder requestBuilder &#x3D; MockMvcRequestBuilders .get(&quot;&#x2F;manager&#x2F;user&#x2F;1&quot;) .accept(MediaType.APPLICATION_JSON) .contentType(MediaType.APPLICATION_JSON); MvcResult mvcResult &#x3D; mockMvc.perform(requestBuilder) .andDo(print()) &#x2F;&#x2F;打印输出发出请求的详细信息 .andExpect(status().isOk()) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data.length()&quot;).value(1)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data&quot;, Matchers.hasKey(&quot;1&quot;))) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.data&quot;, Matchers.hasEntry(&quot;1&quot;,sessionList ))) .andReturn(); System.out.println(mvcResult.getResponse().getContentAsString()); &#125; &#125; henReturn、doReturn 等函数支持链式调用，用来指定函数特定调用次数时的行为。 &#x2F;&#x2F; 让第1次调用返回 100，第2次调用返回 200 when(exampleService.add(1, 2)).thenReturn(100).thenReturn(200);","categories":[{"name":"单元测试","slug":"单元测试","permalink":"https://qinglei1989.github.io/categories/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"junit","slug":"junit","permalink":"https://qinglei1989.github.io/tags/junit/"}]},{"title":"单元测试—参数化测试","slug":"junit2","date":"2021-07-03T14:52:06.000Z","updated":"2021-07-13T15:52:27.093Z","comments":true,"path":"2021/07/03/junit2/","link":"","permalink":"https://qinglei1989.github.io/2021/07/03/junit2/","excerpt":"在写单元测试的时候经常会遇到一种情况，针对某个方法使用多组入参进行测试，这时可以每组入参写一个测试方法，但代码重复率高不优雅，而 junit 从 4.0 开始提供了一种叫做参数化测试的方式专门处理这样情况。","text":"在写单元测试的时候经常会遇到一种情况，针对某个方法使用多组入参进行测试，这时可以每组入参写一个测试方法，但代码重复率高不优雅，而 junit 从 4.0 开始提供了一种叫做参数化测试的方式专门处理这样情况。 单元测试 – 参数化测试普通的参数化测试package com.myz.util; import static org.junit.Assert.*; import java.util.Arrays; import java.util.Collection; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; @RunWith(Parameterized.class) public class JunitParameterTest &#123; &#x2F;** * 1.更改默认的运行器为@RunWith(Parameterized.class) * 2.声明变量来存放预期值和结果值 * 3.声明一个返回值为collection的公共静态方法，并使用@Parameters进行修饰 * 4.为测试类声明一个带参数的公共构造函数，并在其中为之声明变量赋值 *&#x2F; int expected&#x3D;0; int input1&#x3D;0; int input2&#x3D;0; @Parameters public static Collection&lt;Object[]&gt; t()&#123;&#x2F;&#x2F;保存参数 return Arrays.asList(new Object[][]&#123; &#123;3,1,2&#125;, &#123;4,2,2&#125; &#125;); &#125; public JunitParameterTest(int expected, int input1, int input2) &#123; this.expected &#x3D; expected; this.input1 &#x3D; input1; this.input2 &#x3D; input2; &#125; @Test public void testAdd()&#123;&#x2F;&#x2F;将参数传入，测试 assertEquals(expected,new Calculate().add(input1, input2)); &#125; &#125; Springboot中的参数化测试 注意 JUnit4 不支持多个 Runner，用了 @RunWith(Parameterized.class) 之后就没法再用 @RunWith(SpringRunner.class)，但是可以通过 @Before 中的 TestContextManager 来实现 SpringRunner 同样的效果 &#x2F;&#x2F; 我们需要测试的方法 @PostMapping(&quot;&#x2F;recall_message&quot;) public Response recallMessage(@RequestBody RecallMessageDTO recallMessageDTO) &#123; log.info(&quot;[聊天室][单条消息撤回]请求参数:[recallMessageDTO&#123;&#125;]&quot;, recallMessageDTO); recallMessageDTO.valid(); sendMessageService.recallMessage(recallMessageDTO); return Response.ok(); &#125; 在RecallMessageDTO中定义了一个valid方法 public void valid() &#123; if (StringUtils.isEmpty(fromUserId)) &#123; throw new BusinessException(&quot;消息发送人ID不能为空&quot;); &#125; if (StringUtils.isEmpty(targetId)) &#123; throw new BusinessException(&quot;消息接收人ID不能为空&quot;); &#125; ... 我们在测试valid()方法的时候，如果每种情况都写一个测试方法的话很不优雅，因为RecallMessageDTO中的valid()方法有很多的属性需要检验。这个时候我们就可以使用参数化测试了。 @RunWith(Parameterized.class) @SpringBootTest(classes &#x3D; Application .class) public class TimlineServiceTest &#123; @InjectMocks private SendMessageService sendMessageService; private TestContextManager testContextManager; private RecallMessageDTO recallMessageDTO; private String message; @Rule public ExpectedException thrown&#x3D; ExpectedException.none(); private ObjectMapper objectMapper; @InjectMocks private MessageController controller; private MockMvc mockMvc; &#x2F;&#x2F;参数数组，数组中每个元素将会被用来构造一个入参实例，每个入参实例对应一个测试用例， @Parameterized.Parameters public static Collection&lt;Object[]&gt; data() &#123; Object[][] objects &#x3D; &#123; &#123;&quot;&quot;, &quot;&quot;, &quot;消息发送人ID不能为空&quot;&#125;, &#123;&quot;fb_1904&quot;, &quot;&quot;, &quot;消息接收人ID不能为空&quot;&#125; &#125;; return Arrays.asList(objects); &#125; &#x2F;&#x2F;构造函数，使用上面的参数数组初始化入参 public TimlineServiceTest(String fromUserId, String targetId, String message) &#123; recallMessageDTO &#x3D; new RecallMessageDTO(); recallMessageDTO.setFromUserId(fromUserId); recallMessageDTO.setTargetId(targetId); this.message &#x3D; message; &#125; &#x2F;&#x2F;功能相当于 @RunWith(SpringRunner.class) ，否则无法注入bean，这里同时还可以给入参初始化一些固定值 @Before public void setUp() throws Exception &#123; &#x2F;&#x2F; equals to @RunWith(SpringRunner.class) in case that JUnit4 doesn’t accept multiple runners this.testContextManager &#x3D; new TestContextManager(getClass()); &#x2F;&#x2F;this.testContextManager.prepareTestInstance(this); MockitoAnnotations.initMocks(this); objectMapper &#x3D; new ObjectMapper(); objectMapper.setPropertyNamingStrategy(PropertyNamingStrategy.SNAKE_CASE); MappingJackson2HttpMessageConverter convert &#x3D; new MappingJackson2HttpMessageConverter(objectMapper); this.mockMvc &#x3D; MockMvcBuilders .standaloneSetup(controller) &#x2F;&#x2F;.setControllerAdvice(new GlobalExceptionResolver()) .setMessageConverters(convert) .build(); &#125; &#x2F;&#x2F;单元测试方法体 @Test public void tst() throws Exception &#123; thrown.expect(NestedServletException.class); thrown.expectMessage(message); MockHttpServletRequestBuilder requestBuilder &#x3D; MockMvcRequestBuilders .post(&quot;&#x2F;v1&#x2F;recall_message&quot;) .accept(MediaType.APPLICATION_JSON) .contentType(MediaType.APPLICATION_JSON) .content(objectMapper.writeValueAsString(recallMessageDTO)); MvcResult mvcResult &#x3D; mockMvc.perform(requestBuilder) .andDo(print()) &#x2F;&#x2F;打印输出发出请求的详细信息 .andExpect(status().isOk()) .andReturn(); &#125; &#125;","categories":[{"name":"单元测试","slug":"单元测试","permalink":"https://qinglei1989.github.io/categories/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"junit","slug":"junit","permalink":"https://qinglei1989.github.io/tags/junit/"}]},{"title":"单元测试—模拟方法异常执行","slug":"junit1","date":"2021-07-03T14:51:58.000Z","updated":"2021-07-03T15:19:13.349Z","comments":true,"path":"2021/07/03/junit1/","link":"","permalink":"https://qinglei1989.github.io/2021/07/03/junit1/","excerpt":"面向领导编程，公司开始使用SonarQube做代码检查了。又逼着自己学习新技能。","text":"面向领导编程，公司开始使用SonarQube做代码检查了。又逼着自己学习新技能。 单元测试 -- 模拟方法异常执行 使用@Test及其属性expected 只能校验异常类型，没法校验异常信息 @Test(expected &#x3D; NestedServletException.class) public void recallMessageError1() throws Exception &#123; RecallMessageDTO recallMessageDTO &#x3D; new RecallMessageDTO(); recallMessageDTO.setFromUserId(&quot;&quot;); recallMessageDTO.setTargetId(&quot;1131762050372997120&quot;); recallMessageDTO.setConversationType(ConversationTypeEnum.CONVERSATION_TYPE_1.getType()); recallMessageDTO.setSentTime(&quot;1624368676049&quot;); recallMessageDTO.setMessageUID(&quot;BQ6F-LFPK-87A7-G4SG&quot;); MockHttpServletRequestBuilder requestBuilder &#x3D; MockMvcRequestBuilders .post(&quot;&#x2F;v1&#x2F;recall_message&quot;) .accept(MediaType.APPLICATION_JSON) .contentType(MediaType.APPLICATION_JSON) .content(objectMapper.writeValueAsString(recallMessageDTO)); MvcResult result &#x3D; mockMvc.perform(requestBuilder) &#x2F;&#x2F;执行请求 .andExpect(status().isInternalServerError()) &#x2F;&#x2F;验证服务器内部错误 .andReturn(); &#125; 使用try-catch 可以在一个方法里使用try catch校验各种异常类型 @Test public void recallMessageError2() throws Exception &#123; RecallMessageDTO recallMessageDTO &#x3D; new RecallMessageDTO(); recallMessageDTO.setFromUserId(&quot;&quot;); recallMessageDTO.setTargetId(&quot;1131762050372997120&quot;); recallMessageDTO.setConversationType(ConversationTypeEnum.CONVERSATION_TYPE_1.getType()); recallMessageDTO.setSentTime(&quot;1624368676049&quot;); recallMessageDTO.setMessageUID(&quot;BQ6F-LFPK-87A7-G4SG&quot;); MockHttpServletRequestBuilder requestBuilder &#x3D; MockMvcRequestBuilders .post(&quot;&#x2F;v1&#x2F;recall_message&quot;) .accept(MediaType.APPLICATION_JSON) .contentType(MediaType.APPLICATION_JSON) .content(objectMapper.writeValueAsString(recallMessageDTO)); try&#123; &#x2F;&#x2F;异常处理 MvcResult result &#x3D; mockMvc.perform(requestBuilder) &#x2F;&#x2F;执行请求 .andExpect(status().isInternalServerError()) &#x2F;&#x2F;验证服务器内部错误 .andReturn(); &#125;catch (NestedServletException e) &#123; Assert.assertEquals(&quot;消息发送人ID不能为空&quot;, e.getCause().getMessage()); &#125; &#125; 使用@Rule和ExpectedException ExpectedException从4.7之后才有的，可以让你优雅的测试异常类型和异常信息 @Rule public ExpectedException thrown &#x3D; ExpectedException.none(); @Test public void recallMessageError() throws Exception &#123; &#x2F;&#x2F; 不填写发件人 RecallMessageDTO recallMessageDTO &#x3D; new RecallMessageDTO(); recallMessageDTO.setFromUserId(&quot;&quot;); recallMessageDTO.setTargetId(&quot;1131762050372997120&quot;); recallMessageDTO.setConversationType(ConversationTypeEnum.CONVERSATION_TYPE_1.getType()); recallMessageDTO.setSentTime(&quot;1624368676049&quot;); recallMessageDTO.setMessageUID(&quot;BQ6F-LFPK-87A7-G4SG&quot;); thrown.expect(NestedServletException.class); thrown.expectMessage(&quot;消息发送人ID不能为空&quot;); MockHttpServletRequestBuilder requestBuilder &#x3D; MockMvcRequestBuilders .post(&quot;&#x2F;v1&#x2F;recall_message&quot;) .accept(MediaType.APPLICATION_JSON) .contentType(MediaType.APPLICATION_JSON) .content(objectMapper.writeValueAsString(recallMessageDTO)); MvcResult mvcResult &#x3D; mockMvc.perform(requestBuilder) .andDo(print()) &#x2F;&#x2F;打印输出发出请求的详细信息 .andExpect(status().isOk()) .andReturn(); &#125;","categories":[{"name":"单元测试","slug":"单元测试","permalink":"https://qinglei1989.github.io/categories/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"junit","slug":"junit","permalink":"https://qinglei1989.github.io/tags/junit/"}]},{"title":"Git(6) -- diff文件差异","slug":"git5","date":"2021-07-01T16:01:27.000Z","updated":"2021-07-10T16:34:16.318Z","comments":true,"path":"2021/07/02/git5/","link":"","permalink":"https://qinglei1989.github.io/2021/07/02/git5/","excerpt":"git diff 命令用来显示已写入暂存区和已经被修改但尚未写入暂存区文件对区别。","text":"git diff 命令用来显示已写入暂存区和已经被修改但尚未写入暂存区文件对区别。 Git(6) -- diff文件差异 尚未缓存的改动 dit diff [file] 我们修改一个文件，不使用git add提交修改。 On branch dev Your branch is ahead of &#39;origin&#x2F;dev&#39; by 1 commit. (use &quot;git push&quot; to publish your local commits) Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) modified: phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) .idea&#x2F; no changes added to commit (use &quot;git add&quot; and&#x2F;or &quot;git commit -a&quot;) 此时我们使用git diff命令查看。 diff --git a&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java b&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java index 1ed1709..3d4e933 100644 --- a&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java +++ b&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java @@ -13,7 +13,7 @@ import java.sql.SQLException; &#x2F;** * @Author Wangql - * @Description 3 + * @Description 4 : 查看已缓存的改动： git diff –cached [file] 接上文，此时我们使用git diff --cached查看变更情况却发现没有任何改变。 D:\\IdeaProjects\\Springboot2&gt;git diff --cached D:\\IdeaProjects\\Springboot2&gt; 因为git diff –cached比较的是暂存区和上一次提交(commit)的差异。 我们使用git add将修改的文件加入到暂存区，然后再执行git diff --cached命令。 D:\\IdeaProjects\\Springboot2&gt;git status On branch dev Your branch is ahead of &#39;origin&#x2F;dev&#39; by 1 commit. (use &quot;git push&quot; to publish your local commits) Changes to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) modified: phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java D:\\IdeaProjects\\Springboot2&gt;git diff --cached diff --git a&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java b&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java index 1ed1709..3d4e933 100644 --- a&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java +++ b&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java @@ -13,7 +13,7 @@ import java.sql.SQLException; &#x2F;** * @Author Wangql - * @Description 3 + * @Description 4 : 查看已缓存的与未缓存的所有改动：git diff HEAD 比较的是工作区中的文件与版本库中文件的差异。HEAD指向的是版本库中的当前版本，而file指的是当前工作区中的文件 查看简单的diff结果，可以加上–stat参数 D:\\IdeaProjects\\Springboot2&gt;git diff HEAD --stat ...&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) 比较两个历史版本之间的差异git diff SHA1 SHA2 D:\\IdeaProjects\\Springboot2&gt;git diff 0a8bc8533b8be096431db85a45c24f4ffbc039be c92acaabf353d89bc19b74de2bab3e0bfc98e629 diff --git a&#x2F;phj-boot-common&#x2F;.gitignore b&#x2F;phj-boot-common&#x2F;.gitignore new file mode 100644 index 0000000..93ad232 --- &#x2F;dev&#x2F;null +++ b&#x2F;phj-boot-common&#x2F;.gitignore @@ -0,0 +1,93 @@ +&#x2F;target&#x2F; +!.mvn&#x2F;wrapper&#x2F;maven-wrapper.jar + +### STS ### D:\\IdeaProjects\\Springboot2&gt;git diff 0a8bc8533b8be096431db85a45c24f4ffbc039be 82df2f1053e01d4d094c267ced093c34c3d681b1 diff --git a&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java b&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java index 1ed1709..83cfa25 100644 --- a&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java +++ b&#x2F;phj-service-account&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;puhuijia&#x2F;config&#x2F;DruidDBConfig.java @@ -13,7 +13,7 @@ import java.sql.SQLException; &#x2F;** * @Author Wangql - * @Description 3 + * @Description 1 :","categories":[{"name":"版本控制","slug":"版本控制","permalink":"https://qinglei1989.github.io/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}],"tags":[{"name":"git","slug":"git","permalink":"https://qinglei1989.github.io/tags/git/"}]},{"title":"Git(5) -- commit提交管理","slug":"git4","date":"2021-06-29T15:02:18.000Z","updated":"2021-07-10T16:34:02.407Z","comments":true,"path":"2021/06/29/git4/","link":"","permalink":"https://qinglei1989.github.io/2021/06/29/git4/","excerpt":"Git 提交信息修改： 未push到远程仓库的代码使用以下方法。对于已经将代码push到远程仓库的情况，需要在最后多执行一条强制push到远程仓库：git push --force origin 分支名的命令。","text":"Git 提交信息修改： 未push到远程仓库的代码使用以下方法。对于已经将代码push到远程仓库的情况，需要在最后多执行一条强制push到远程仓库：git push --force origin 分支名的命令。 Git(5) -- commit提交修改 修改最新commit的message 本次操作在IntelliJ IDEA的Terminal命令窗口中完成 使用命令git commit –amend允许您打开编辑器，修改您更改最后一次提交消息。 &#x2F;&#x2F; 查看最近一次的提交记录 D:\\IdeaProjects\\spring-boot-study&gt;git log -n1 commit b73d13300ee6af0b84cb8ee6349a85b6bebf5255 (HEAD -&gt; master) Author: 王清雷 &lt;wang@rr.com&gt; Date: Mon Jun 28 01:26:48 2021 +0800 feat:默认分页起始页从1开始 修改最近的一次 commit message D:\\IdeaProjects\\spring-boot-study&gt;git commit --amend 输入git commit –amend后 按回车进入到 vim编辑器（熟悉LInux的同学已经知道如何编辑退出了） &quot;D:&#x2F;IdeaProjects&#x2F;spring-boot-study&#x2F;.git&#x2F;COMMIT_EDITMSG&quot; [unix] 15L, 535B written feat:默认分页起始页从1开始 修改最近的一次 commit message # Please enter the commit message for your changes. Lines starting # with &#39;#&#39; will be ignored, and an empty message aborts the commit. # # Date: Mon Jun 28 01:26:48 2021 +0800 # # On branch master # Your branch and &#39;origin&#x2F;master&#39; have diverged, # and have 1 and 1 different commits each, respectively. # (use &quot;git pull&quot; to merge the remote branch into yours) # # Changes to be committed: # modified: src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java 输入 **i ** 文档变成可编辑状态。在可编辑状态下便可以修改提交状态 **:wq ** 保存并退出 -- INSERT -- IntelliJ IDEA的Terminal命令在操作时发现了一些不方便的地方，导致自己以为命令输入有误 按Esc键之后光标定位到代码编辑器了，导致 :wq 输入到.java文件中了 保存退出后Terminal命令窗口的显示如下图，第一眼以为没退出呢。敲了好几个回车才反应过来，输入 **cls ** 清屏。不要怀疑，一切都是假象。 注意修改注释的时候可能使用的是中文输入法，在输入 :wq 的时候一定要切换到英文 修改老旧commit的message 使用命令git rebase –i commitID允许修改老旧commit的提交消息。 查看最近3次的代码提交 D:\\IdeaProjects\\spring-boot-study&gt;git log -3 commit 70e32372f96345f1447da020c95f5b1d8e40eaf3 (HEAD -&gt; master) Author: 王清雷 &lt;wang@rr.com&gt; Date: Mon Jun 28 01:26:48 2021 +0800 feat:默认分页起始页从1开始 修改最近的一次 commit message commit 0380f63f9c1d4df1309f53fad1728d1e763643f2 Author: 王清雷 &lt;wang@rr.com&gt; Date: Mon Jun 28 00:35:09 2021 +0800 feat:集成Redis commit fe056300b80f84a2caf9d92662d94e8e3fe218f1 Merge: a42c966 83f0da7 Author: 王清雷 &lt;wang@rr.com&gt; Date: Sun Jun 20 01:37:37 2021 +0800 Merge remote-tracking branch &#39;origin&#x2F;master&#39; # Conflicts: # src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java 我们选择修改倒数第二次的提交信息作变更，但是我们要选的基base应该为它的上一个commitID：fe056300b80f84a2caf9d92662d94e8e3fe218f1 我们执行命令git rebase –i fe056300b80f84a2caf9d92662d94e8e3fe218f1 pick 8f6f3e2 feat:集成Redis 实现修改历史commit message pick f1b7a7f feat:默认分页起始页从1开始 # Rebase fe05630..f1b7a7f onto fe05630 (2 commands) # # Commands: # p, pick &lt;commit&gt; &#x3D; use commit # r, reword &lt;commit&gt; &#x3D; use commit, but edit the commit message # e, edit &lt;commit&gt; &#x3D; use commit, but stop for amending # s, squash &lt;commit&gt; &#x3D; use commit, but meld into previous commit # f, fixup &lt;commit&gt; &#x3D; like &quot;squash&quot;, but discard this commit&#39;s log message # x, exec &lt;command&gt; &#x3D; run command (the rest of the line) using shell # b, break &#x3D; stop here (continue rebase later with &#39;git rebase --continue&#39;) # d, drop &lt;commit&gt; &#x3D; remove commit # l, label &lt;label&gt; &#x3D; label current HEAD with a name # t, reset &lt;label&gt; &#x3D; reset HEAD to a label # m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;] # . create a merge commit using the original merge commit&#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c &lt;commit&gt; to reword the commit message. # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # D:&#x2F;IdeaProjects&#x2F;spring-boot-study&#x2F;.git&#x2F;rebase-merge&#x2F;git-rebase-todo [unix] (00:52 30&#x2F;06&#x2F;2021) 1,1 Top -- INSERT -- 我们将pick 8f6f3e2 feat:集成Redis 实现修改历史commit message中的pick修改为r。**:wq**保存退出。注释# r, reword &lt;commit&gt; = use commit, but edit the commit message即只修改commit message。 feat:集成Redis 实现修改历史commit message # Please enter the commit message for your changes. Lines starting # with &#39;#&#39; will be ignored, and an empty message aborts the commit. # # Date: Mon Jun 28 00:35:09 2021 +0800 # # interactive rebase in progress; onto fe05630 # Last command done (1 command done): # reword 8f6f3e2 feat:集成Redis 实现修改历史commit message # Next command to do (1 remaining command): # pick f1b7a7f feat:默认分页起始页从1开始 # You are currently editing a commit while rebasing branch &#39;master&#39; on &#39;fe05630&#39;. # # Changes to be committed: # new file: src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;aspect&#x2F;RequestParameterAop.java # modified: src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;config&#x2F;RedisConfig.java # modified: src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;RedisConstant.java # modified: src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;listener&#x2F;RedisReceiver.java # modified: src&#x2F;test&#x2F;java&#x2F;Test_1.java # ~ D:&#x2F;IdeaProjects&#x2F;spring-boot-study&#x2F;.git&#x2F;COMMIT_EDITMSG [unix] (00:58 30&#x2F;06&#x2F;2021) 1,1 All -- INSERT -- 以上提示为Please enter the commit message for your changes。我们将feat:集成Redis 实现修改历史commit message修改为feat:集成Redis。**:wq**保存退出。 再次使用git log -3查看commit提交信息，发现除了第二次的commit message改变，相应的commitID也发生了改变。 D:\\IdeaProjects\\spring-boot-study&gt;git log -3 commit b995b18c781edde9df53df82d8312644c25b6f7d (HEAD -&gt; master) Author: 王清雷 &lt;wang@rr.com&gt; Date: Mon Jun 28 01:26:48 2021 +0800 feat:默认分页起始页从1开始 commit e2d0ac8803245313e46389a72dc620a9cbd7eced Author: 王清雷 &lt;wang@rr.com&gt; Date: Mon Jun 28 00:35:09 2021 +0800 feat:集成Redis commit fe056300b80f84a2caf9d92662d94e8e3fe218f1 Merge: a42c966 83f0da7 Author: 王清雷 &lt;wang@rr.com&gt; Date: Sun Jun 20 01:37:37 2021 +0800 Merge remote-tracking branch &#39;origin&#x2F;master&#39; # Conflicts: # src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java 连续多个commit整理成1个 使用命令git rebase –i commitID允许将连续多个commit整理成1个commit。 查看最近3次的代码提交 D:\\IdeaProjects\\spring-boot-study&gt;git log -3 commit b995b18c781edde9df53df82d8312644c25b6f7d (HEAD -&gt; master) Author: 王清雷 &lt;wang@rr.com&gt; Date: Mon Jun 28 01:26:48 2021 +0800 feat:默认分页起始页从1开始 commit e2d0ac8803245313e46389a72dc620a9cbd7eced Author: 王清雷 &lt;wang@rr.com&gt; Date: Mon Jun 28 00:35:09 2021 +0800 feat:集成Redis commit fe056300b80f84a2caf9d92662d94e8e3fe218f1 Merge: a42c966 83f0da7 Author: 王清雷 &lt;wang@rr.com&gt; Date: Sun Jun 20 01:37:37 2021 +0800 Merge remote-tracking branch &#39;origin&#x2F;master&#39; # Conflicts: # src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java D:\\IdeaProjects\\spring-boot-study&gt;git rebase -i fe056300b80f84a2caf9d92662d94e8e3fe218f1 我们选择将前两个的提交信息进行合并，但是我们要选的基base应该为它的上一个commitID：fe056300b80f84a2caf9d92662d94e8e3fe218f1 我们执行命令git rebase –i fe056300b80f84a2caf9d92662d94e8e3fe218f1 pick e2d0ac8 feat:集成Redis pick b995b18 feat:默认分页起始页从1开始 # Rebase fe05630..b995b18 onto fe05630 (2 commands) # # Commands: # p, pick &lt;commit&gt; &#x3D; use commit # r, reword &lt;commit&gt; &#x3D; use commit, but edit the commit message # e, edit &lt;commit&gt; &#x3D; use commit, but stop for amending # s, squash &lt;commit&gt; &#x3D; use commit, but meld into previous commit # f, fixup &lt;commit&gt; &#x3D; like &quot;squash&quot;, but discard this commit&#39;s log message # x, exec &lt;command&gt; &#x3D; run command (the rest of the line) using shell # b, break &#x3D; stop here (continue rebase later with &#39;git rebase --continue&#39;) # d, drop &lt;commit&gt; &#x3D; remove commit # l, label &lt;label&gt; &#x3D; label current HEAD with a name # t, reset &lt;label&gt; &#x3D; reset HEAD to a label # m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;] # . create a merge commit using the original merge commit&#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c &lt;commit&gt; to reword the commit message. # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # # However, if you remove everything, the rebase will be aborted. # D:&#x2F;IdeaProjects&#x2F;spring-boot-study&#x2F;.git&#x2F;rebase-merge&#x2F;git-rebase-todo [unix] (22:33 30&#x2F;06&#x2F;2021) 1,1 All -- INSERT -- 我们将pick b995b18 feat:默认分页起始页从1开始中的pick修改为s。**:wq**保存退出。注释# s, squash &lt;commit&gt; = use commit, but meld into previous commit。 pick 表示使用本次提交squash,表示将本次提交合并到上一次pick的提交 pick e2d0ac8 feat:集成Redis s b995b18 feat:默认分页起始页从1开始 :wq! [detached HEAD 0dd5958] 合并两次请求 Date: Mon Jun 28 00:35:09 2021 +0800 6 files changed, 145 insertions(+), 7 deletions(-) create mode 100644 src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;aspect&#x2F;RequestParameterAop.java Successfully rebased and updated refs&#x2F;heads&#x2F;master. 再次使用git log -3查看commit提交信息，发现已经合并。 D:\\IdeaProjects\\spring-boot-study&gt;git log -3 commit 0dd595879b8c093992250b6845c1df8fdc8a4f2e (HEAD -&gt; master) Author: 王清雷 &lt;wang@rr.com&gt; Date: Mon Jun 28 00:35:09 2021 +0800 合并两次请求 feat:集成Redis feat:默认分页起始页从1开始 commit fe056300b80f84a2caf9d92662d94e8e3fe218f1 Merge: a42c966 83f0da7 Author: 王清雷 &lt;wang@rr.com&gt; Date: Sun Jun 20 01:37:37 2021 +0800 Merge remote-tracking branch &#39;origin&#x2F;master&#39; # Conflicts: # src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java commit a42c966e039d7db874673a55f3dad62c07b3f216 Author: 王清雷 &lt;wang@rr.com&gt; Date: Sun Jun 20 01:36:27 2021 +0800 feat:Redis发布订阅学习","categories":[{"name":"版本控制","slug":"版本控制","permalink":"https://qinglei1989.github.io/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}],"tags":[{"name":"git","slug":"git","permalink":"https://qinglei1989.github.io/tags/git/"}]},{"title":"Git(4) -- branch分支管理","slug":"git3","date":"2021-06-28T16:28:08.000Z","updated":"2021-07-11T16:08:05.485Z","comments":true,"path":"2021/06/29/git3/","link":"","permalink":"https://qinglei1989.github.io/2021/06/29/git3/","excerpt":"每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。","text":"每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。 Git(4) – branch分支管理列出所有分支git branch 没有参数时，git branch 会列出你在本地的分支。 加上-a参数可以查看全部分支(包含本地分支和远程分支)，远程分支会用红色表示出来（如果你开了颜色支持的话） 加上-r参数可以查看远程分支 其中带*号标注的是当前所在的分支 D:\\che\\im-api&gt;git branch 20210421_add_get_user_reward 20210520_manage_chatroom_entry_wangql 20210604_user_reward_chatroom_entry * 20210622_feat_message_recall_wangql 20210622_fix_extra_content_decode_wangql develop master D:\\che\\im-api&gt;git branch -a 20210421_add_get_user_reward 20210520_manage_chatroom_entry_wangql 20210604_user_reward_chatroom_entry * 20210622_feat_message_recall_wangql 20210622_fix_extra_content_decode_wangql develop master remotes&#x2F;origin&#x2F;20210324_init_develop_env remotes&#x2F;origin&#x2F;20210421_add_get_user_reward remotes&#x2F;origin&#x2F;20210520_manage_chatroom_entry_wangql remotes&#x2F;origin&#x2F;20210604_user_reward_chatroom_entry remotes&#x2F;origin&#x2F;20210622_feat_message_recall_wangql remotes&#x2F;origin&#x2F;20210622_fix_extra_content_decode_wangql remotes&#x2F;origin&#x2F;HEAD -&gt; origin&#x2F;develop remotes&#x2F;origin&#x2F;develop remotes&#x2F;origin&#x2F;master D:\\renrenche\\im-api&gt;git branch -r origin&#x2F;20210324_init_develop_env origin&#x2F;20210421_add_get_user_reward origin&#x2F;20210520_manage_chatroom_entry_wangql origin&#x2F;20210604_user_reward_chatroom_entry origin&#x2F;20210622_feat_message_recall_wangql origin&#x2F;20210622_fix_extra_content_decode_wangql origin&#x2F;HEAD -&gt; origin&#x2F;develop origin&#x2F;develop origin&#x2F;master 切换分支git checkout (branchname) 当你切换分支的时候，Git 会用该分支的最后提交的快照替换你的工作目录的内容。 根据指定版本号创建分支: git checkout -b branchName commitId D:\\renrenche\\im-api&gt;git checkout 20210324_init_develop_env Switched to a new branch &#39;20210324_init_develop_env&#39; Branch &#39;20210324_init_develop_env&#39; set up to track remote branch &#39;20210324_init_develop_env&#39; from &#39;origin&#39;. D:\\renrenche\\im-api&gt;git branch * 20210324_init_develop_env 20210421_add_get_user_reward 20210520_manage_chatroom_entry_wangql 20210604_user_reward_chatroom_entry 20210622_feat_message_recall_wangql 20210622_fix_extra_content_decode_wangql develop master 删除分支git branch -d (branchname)用来删除本地分支 git push origin --delete [branchname]用来删除远端分支，在删除远程分支时，同名的本地分支并不会被删除，所以还需要单独删除本地同名分支 清理本地无效分支(远程已删除本地没删除的分支): git fetch -p D:\\IdeaProjects\\spring-boot-study&gt;git branch master * test test_new D:\\IdeaProjects\\spring-boot-study&gt;git branch -d test_new Deleted branch test_new (was 4914823). D:\\IdeaProjects\\spring-boot-study&gt;git push origin -d test_new remote: Powered by GITEE.COM [GNK-5.0] To https:&#x2F;&#x2F;gitee.com&#x2F;ShanXiXiaoMoTou&#x2F;spring-boot-study.git - [deleted] test_new 常见错误：error: Cannot delete branch ‘XXX’ checked out at ‘XXXXXX’ 在删除分支时，当前分支为在要删除的分支上，则会报以上错误。解决办法就是切换到其他任意分支，再去删除目标分支。 D:\\IdeaProjects\\spring-boot-study&gt;git branch master * test_new D:\\IdeaProjects\\spring-boot-study&gt;git branch -d test_new error: Cannot delete branch &#39;test_new&#39; checked out at &#39;D:&#x2F;IdeaProjects&#x2F;spring-boot-study&#39;","categories":[{"name":"版本控制","slug":"版本控制","permalink":"https://qinglei1989.github.io/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}],"tags":[{"name":"git","slug":"git","permalink":"https://qinglei1989.github.io/tags/git/"}]},{"title":"Git(3) -- 查看提交历史","slug":"git2","date":"2021-06-15T16:28:08.000Z","updated":"2021-06-28T02:44:30.585Z","comments":true,"path":"2021/06/16/git2/","link":"","permalink":"https://qinglei1989.github.io/2021/06/16/git2/","excerpt":"Git 提交历史一般常用两个命令： git log - 查看历史提交记录。 git blame - 以列表形式查看指定文件的历史修改记录。","text":"Git 提交历史一般常用两个命令： git log - 查看历史提交记录。 git blame - 以列表形式查看指定文件的历史修改记录。 Git(3) -- 查看提交历史 git log在使用 Git 提交了若干更新之后，又或者克隆了某个项目，想回顾下提交历史，我们可以使用 git log 命令查看。 git log 默认查看当前分支的提交历史 通过以下可以看到当前为master分支 通过：处上下键可以查看更早的提交历史。 在：处输入q退出历史版本查看 wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git log commit 0380f63f9c1d4df1309f53fad1728d1e763643f2 (HEAD -&gt; master, origin&#x2F;master) Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; Date: Mon Jun 28 00:35:09 2021 +0800 feat:集成Redis commit fe056300b80f84a2caf9d92662d94e8e3fe218f1 Merge: a42c966 83f0da7 Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; Date: Sun Jun 20 01:37:37 2021 +0800 Merge remote-tracking branch &#39;origin&#x2F;master&#39; # Conflicts: # src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java commit a42c966e039d7db874673a55f3dad62c07b3f216 Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; Date: Sun Jun 20 01:36:27 2021 +0800 feat:Redis发布订阅学习 commit aa2a13e24a001e25b84921adaa02914837459053 : 我们可以通过–oneline 选项来查看历史记录的简洁的版本。 wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git log --oneline 0380f63 (HEAD -&gt; master, origin&#x2F;master) feat:集成Redis fe05630 Merge remote-tracking branch &#39;origin&#x2F;master&#39; a42c966 feat:Redis发布订阅学习 aa2a13e feat:commit提交回滚 : 我们可以通过–n[number] 选项来查看最近的几个历史记录版本。 查看最近的两条提交记录 git log -n2 git log -n2 –oneline wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git log -n2 commit 0380f63f9c1d4df1309f53fad1728d1e763643f2 (HEAD -&gt; master, origin&#x2F;master) Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; Date: Mon Jun 28 00:35:09 2021 +0800 feat:集成Redis commit fe056300b80f84a2caf9d92662d94e8e3fe218f1 Merge: a42c966 83f0da7 Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; Date: Sun Jun 20 01:37:37 2021 +0800 Merge remote-tracking branch &#39;origin&#x2F;master&#39; # Conflicts: # src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git log -n2 --oneline 0380f63 (HEAD -&gt; master, origin&#x2F;master) feat:集成Redis fe05630 Merge remote-tracking branch &#39;origin&#x2F;master&#39; 我们可以通过–all 选项查看所有分支的版本演进历史 wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (2528c1e) $ git log --all commit 943411f8b99e8ab60bf39f03b2e513bf40e66337 (HEAD -&gt; 2528c1e, origin&#x2F;2528c1e) Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; Date: Mon Jun 28 01:02:51 2021 +0800 feat:默认分页常量增加 commit 0380f63f9c1d4df1309f53fad1728d1e763643f2 (origin&#x2F;master, master) Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; Date: Mon Jun 28 00:35:09 2021 +0800 feat:集成Redis commit fe056300b80f84a2caf9d92662d94e8e3fe218f1 Merge: a42c966 83f0da7 Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; Date: Sun Jun 20 01:37:37 2021 +0800 Merge remote-tracking branch &#39;origin&#x2F;master&#39; # Conflicts: # src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java : 我们可以通过–graph 选项以图形化的形式来查看版本演进历史 wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (2528c1e) $ git log --all --graph * commit 943411f8b99e8ab60bf39f03b2e513bf40e66337 (HEAD -&gt; 2528c1e, origin&#x2F;2528c1e) | Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; | Date: Mon Jun 28 01:02:51 2021 +0800 | | feat:默认分页常量增加 | * commit 0380f63f9c1d4df1309f53fad1728d1e763643f2 (origin&#x2F;master, master) | Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; | Date: Mon Jun 28 00:35:09 2021 +0800 | | feat:集成Redis | * commit fe056300b80f84a2caf9d92662d94e8e3fe218f1 |\\ Merge: a42c966 83f0da7 | | Author: 王清雷 &lt;wangqinglei01@renrenche.com&gt; | | Date: Sun Jun 20 01:37:37 2021 +0800 | | | | Merge remote-tracking branch &#39;origin&#x2F;master&#39; | | | | # Conflicts: | | # src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java | | : 以后补IDEA相关操作 git blamegit blame 命令是以列表形式显示修改记录，如下实例： D:\\IdeaProjects\\spring-boot-study&gt;git blame src\\main\\java\\com\\rrc\\controller\\school\\SchoolController.java ^d504062 (qinglei1989 2021-05-23 11:24:30 +0800 1) package com.rrc.controller.school; ^d504062 (qinglei1989 2021-05-23 11:24:30 +0800 2) 91fbfe36 (王清雷 2021-06-06 16:19:40 +0800 3) import com.baomidou.mybatisplus.extension.plugins.pagination.Page; d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 4) import com.rrc.dto.base.ResultDto; 6c77b894 (qinglei1989 2021-05-25 13:53:52 +0800 5) import com.rrc.service.ISchoolService; d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 6) import com.rrc.util.AppUtil; d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 7) import com.rrc.vo.SchoolVo; ^d504062 (qinglei1989 2021-05-23 11:24:30 +0800 8) import lombok.extern.slf4j.Slf4j; 6c77b894 (qinglei1989 2021-05-25 13:53:52 +0800 9) import org.springframework.beans.factory.annotation.Autowired; 2f195422 (王清雷 2021-06-06 22:38:21 +0800 10) import org.springframework.validation.annotation.Validated; d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 11) import org.springframework.web.bind.annotation.*; d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 12) d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 13) import javax.validation.Valid; d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 14) import javax.validation.constraints.NotBlank; ^d504062 (qinglei1989 2021-05-23 11:24:30 +0800 15) ^d504062 (qinglei1989 2021-05-23 11:24:30 +0800 16) @RestController d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 17) @RequestMapping(&quot;v1&quot;) ^d504062 (qinglei1989 2021-05-23 11:24:30 +0800 18) @Slf4j ^d504062 (qinglei1989 2021-05-23 11:24:30 +0800 19) public class SchoolController &#123; d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 20) 6c77b894 (qinglei1989 2021-05-25 13:53:52 +0800 21) @Autowired 6c77b894 (qinglei1989 2021-05-25 13:53:52 +0800 22) private ISchoolService schoolService; 6c77b894 (qinglei1989 2021-05-25 13:53:52 +0800 23) d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 24) @GetMapping(&quot;&#x2F;school&#x2F;&#123;schoolId&#125;&quot;) a5ee4be0 (qinglei1989 2021-05-26 19:45:31 +0800 25) public ResultDto querySchool(@NotBlank(message &#x3D; &quot;schoolId不能为空&quot;) @PathVariable(&quot;schoolId&quot;) Long schoolId) &#123; d684dcf9 (qinglei1989 2021-05-24 14:05:50 +0800 26) :","categories":[{"name":"版本控制","slug":"版本控制","permalink":"https://qinglei1989.github.io/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}],"tags":[{"name":"git","slug":"git","permalink":"https://qinglei1989.github.io/tags/git/"}]},{"title":"Git(2) -- git操作技巧","slug":"git1","date":"2021-06-15T16:10:41.000Z","updated":"2021-07-11T17:06:01.471Z","comments":true,"path":"2021/06/16/git1/","link":"","permalink":"https://qinglei1989.github.io/2021/06/16/git1/","excerpt":"分享git常用操作技巧。","text":"分享git常用操作技巧。 Git(2) -- 操作技巧 1、文件重命名 &#x2F;&#x2F; 演示将CommonConst.java 重命名为 CommonConstant.java wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ cd src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F; wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant (master) $ git mv CommonConst.java CommonConstant.java wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant (master) $ git status On branch master Your branch and &#39;origin&#x2F;master&#39; have diverged, and have 1 and 1 different commits each, respectively. (use &quot;git pull&quot; to merge the remote branch into yours) Changes to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) renamed: CommonConst.java -&gt; CommonConstant.java 2、git reset –hard HEAD^后显示more D:\\IdeaProjects\\spring-boot-study&gt;git reset --HEAD^ More? More? error: unknown option &#96;HEAD 我们可以选择直接打开一个cmd窗口，在里边输入一个^,发现也弹出了More。通过下边的dir命令大概大家已经发现了^符号的含义—用来连接两端命令的。每当^符号出现的时候，系统会认为后面还会有命令，所以会提示两次more? 来询问用户输入下一步的命令。另外，在cmd环境中^也以转义字符的身份出现。^符号也会用在一些特定字符前面用来输出，例如您想让命令输出&gt;号，输出的命令必须为Echo ^&gt; C:\\Users\\wang\\Pictures&gt;^ More? More? C:\\Users\\wang\\Pictures&gt;di^ More? r 驱动器 C 中的卷是 Windows 卷的序列号是 0265-6A69 C:\\Users\\wang\\Pictures 的目录 2021&#x2F;04&#x2F;17 10:13 &lt;DIR&gt; . 2021&#x2F;04&#x2F;17 10:13 &lt;DIR&gt; .. 2020&#x2F;06&#x2F;21 18:46 &lt;DIR&gt; Camera Roll 2021&#x2F;01&#x2F;14 16:18 &lt;DIR&gt; Feedback 2020&#x2F;06&#x2F;21 18:46 &lt;DIR&gt; Saved Pictures 0 个文件 0 字节 5 个目录 21,613,289,472 可用字节 C:\\Users\\wang\\Pictures&gt;dir 驱动器 C 中的卷是 Windows 卷的序列号是 0265-6A69 C:\\Users\\wang\\Pictures 的目录 2021&#x2F;04&#x2F;17 10:13 &lt;DIR&gt; . 2021&#x2F;04&#x2F;17 10:13 &lt;DIR&gt; .. 2020&#x2F;06&#x2F;21 18:46 &lt;DIR&gt; Camera Roll 2021&#x2F;01&#x2F;14 16:18 &lt;DIR&gt; Feedback 2020&#x2F;06&#x2F;21 18:46 &lt;DIR&gt; Saved Pictures 0 个文件 0 字节 5 个目录 21,613,158,400 可用字节 ^作为转义字符的作用 C:\\Users\\wang\\Pictures&gt;echo &gt; 命令语法不正确。 C:\\Users\\wang\\Pictures&gt;echo ^&gt; &gt; 所以对应于我们标题的问题，我们可以有两种写法 加引号：git reset –hard “HEAD^” 加一个转义^：git reset –hard HEAD^^ 当然对于git reset命令，我们可以使用git reset --hard HEAD~ 或者 git reset --hard HEAD~1来代替HEAD^ 3、删除文件","categories":[{"name":"版本控制","slug":"版本控制","permalink":"https://qinglei1989.github.io/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}],"tags":[{"name":"git","slug":"git","permalink":"https://qinglei1989.github.io/tags/git/"}]},{"title":"Git(1) -- 入门知识","slug":"git","date":"2021-06-13T16:09:29.000Z","updated":"2021-07-14T17:12:28.876Z","comments":true,"path":"2021/06/14/git/","link":"","permalink":"https://qinglei1989.github.io/2021/06/14/git/","excerpt":"Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。","text":"Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。 Git(1)—基础知识 1、git仓库 git init 命令用于在目录中创建Git仓库。在目录中执行 git init 后你可以看到在你的项目中生成了 .git 这个子目录，这就是你的 Git 仓库了，所有有关你的此项目的快照数据都存放在这里。 git init your_project 新建项目直接用GIT管理，会在当前路径下创建和your_project同名的文件夹 **.git默认是隐藏的，可以用 ls -a 命令查看 ** $ git init Initialized empty Git repository in D:&#x2F;git学习&#x2F;.git&#x2F; git clone [url]克隆远程仓库 $ git clone https:&#x2F;&#x2F;gitee.com&#x2F;ShanXiXiaoMoTou&#x2F;spring-boot-study.git Cloning into &#39;spring-boot-study&#39;... remote: Enumerating objects: 75, done. remote: Counting objects: 100% (75&#x2F;75), done. remote: Compressing objects: 100% (59&#x2F;59), done. remote: Total 75 (delta 1), reused 0 (delta 0), pack-reused 0 Receiving objects: 100% (75&#x2F;75), 27.85 KiB | 1.99 MiB&#x2F;s, done. Resolving deltas: 100% (1&#x2F;1), done. 2、设置用户信息 设置全局用户信息(对当前用户的所有仓库有效) git config --global user.name your_username git config --global user.email your_email 设置局部仓库用户信息(只对某个仓库有效) git config --local user.name your_username git config --local user.email your_email 3、Git 工作区、暂存区和版本库 Workspace： 工作区，就是你平时存放项目代码的地方 Index / Stage： 暂存区，用于临时存放你的改动，事实上它只是一个文件，保存即将提交到文件列表信息 Repository： 本地仓库，这里面有你提交到所有版本的数据。其中HEAD指向最新放入仓库的版本 Remote： 远程仓库，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换 4、 Git工作流程 git的工作流程一般是这样的： １、在工作目录中添加、修改文件； ２、将需要进行版本管理的文件放入暂存区域； ３、将暂存区域的文件提交到git仓库。 因此，git管理的文件有三种状态：已修改（modified）,已暂存（staged）,已提交(committed) 5、文件的四种状态 Untracked: 未跟踪, 此文件在文件夹中, 但并没有加入到git库, 不参与版本控制。通过git add 状态变为Staged。 Unmodify: 文件已入库未修改。 如果被修改会变为Modified。如果使用git rm移出版本库,成为Untracked文件。 Modified: 文件已修改。通过git add可进入暂存staged状态, 使用git checkout覆盖当前修改返回到unmodify状态。 Staged: 暂存状态。 执行git commit提交变为Unmodify状态。执行git reset HEAD filename取消暂存变为Modified。 6、Git提交与修改 git add 将该文件添加到暂存区 命令 作用 git add [file1] [file2] … 添加一个或多个文件到暂存区 git add [dir] 添加指定目录到暂存区，包括子目录 git add . 添加当前目录下的所有文件到暂存区 wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git status -s ?? src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F; wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git add . warning: LF will be replaced by CRLF in src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java. The file will have its original line endings in your working directory wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git status On branch master Your branch is up to date with &#39;origin&#x2F;master&#39;. Changes to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) new file: src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java git commit 提交暂存区到本地仓库 命令 作用 git commit -m [message] 提交暂存区到本地仓库中: git commit [file1] [file2] … -m [message] 提交暂存区的指定文件到仓库区 git commit -a -a 参数设置修改文件后不需要执行 git add 命令，直接来提交 注：此时提交代码使用的用户信息就是我们在开始钱设置的用户信息（用户名和邮箱） wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git commit -m &quot;feat:删除标志位代码增加&quot; [master 761e5f6] feat:删除标志位代码增加 1 file changed, 20 insertions(+) create mode 100644 src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git reset --soft HEAD^ wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git status On branch master Your branch is up to date with &#39;origin&#x2F;master&#39;. Changes to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) new file: src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F;CommonConst.java git reset 回退版本，可以指定退回某一次提交的版本 git reset [–soft | –mixed | –hard] [HEAD] 撤销git commit操作 git reset –soft HEAD^ HEAD^的意思是上一个版本，也可以写成HEAD~1。如果你进行了2次commit，想都撤回，可以使用HEAD~2 –mixed（默认参数） git reset –mixed HEAD^ 和 git reset HEAD^ 效果是一样的。 不删除工作空间改动代码，撤销commit，并且撤销git add . 操作 –soft不删除工作空间改动代码，撤销commit，不撤销git add . –hard删除工作空间改动代码，撤销commit，撤销git add .注意完成这个操作后，就恢复到了上一次的commit状态。 $ git status On branch master Your branch is ahead of &#39;origin&#x2F;master&#39; by 1 commit. (use &quot;git push&quot; to publish your local commits) nothing to commit, working tree clean wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git reset head^ wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git status On branch master Your branch is up to date with &#39;origin&#x2F;master&#39;. Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F; nothing added to commit but untracked files present (use &quot;git add&quot; to track) 取消之前 git add 添加，但不希望包含在下一提交快照中的缓存 git reset HEAD 如果后面什么都不跟的话 就是上一次add 里面的全部撤销了 git reset HEAD 文件名 就是对某个文件进行撤销了 wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git reset Head wang@LAPTOP-4HQAPUSB MINGW64 &#x2F;d&#x2F;IdeaProjects&#x2F;spring-boot-study (master) $ git status On branch master Your branch is up to date with &#39;origin&#x2F;master&#39;. Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) src&#x2F;main&#x2F;java&#x2F;com&#x2F;rrc&#x2F;constant&#x2F; nothing added to commit but untracked files present (use &quot;git add&quot; to track) 撤销对远程仓库的push操作 获取需要回退的版本号 执行 git reset –-soft &lt;版本号&gt; ，重置至指定版本的提交，达到撤销提交的目的 执行 git push origin 分支名 –-force ，强制提交当前版本号，完成push撤销 D:\\IdeaProjects\\spring-boot-study&gt;git log commit 6c8685349e4fb3fefbb1d4cf2be351e4e2a61a70 (HEAD -&gt; master, origin&#x2F;master) Author: 王清雷 &lt;wangqing@ren.com&gt; Date: Wed Jun 23 00:06:29 2021 +0800 feat:测试回滚操作 commit fe056300b80f84a2caf9d92662d94e8e3fe218f1 Merge: a42c966 83f0da7 Author: 王清雷 &lt;wangqing@ren.com&gt; Date: Sun Jun 20 01:37:37 2021 +0800 Merge remote-tracking branch &#39;origin&#x2F;master&#39; D:\\IdeaProjects\\spring-boot-study&gt;git reset --soft fe056300b80f84a2caf9d92662d94e8e3fe218f1 D:\\IdeaProjects\\spring-boot-study&gt;git push origin master --force Total 0 (delta 0), reused 0 (delta 0), pack-reused 0 To https:&#x2F;&#x2F;github.com&#x2F;qinglei1989&#x2F;spring-boot-study.git + 6c86853...fe05630 master -&gt; master (forced update)","categories":[{"name":"版本控制","slug":"版本控制","permalink":"https://qinglei1989.github.io/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}],"tags":[{"name":"git","slug":"git","permalink":"https://qinglei1989.github.io/tags/git/"}]},{"title":"VirtualBox上安装CentOS7","slug":"linux0","date":"2021-06-13T16:09:29.000Z","updated":"2021-06-27T15:14:31.675Z","comments":true,"path":"2021/06/14/linux0/","link":"","permalink":"https://qinglei1989.github.io/2021/06/14/linux0/","excerpt":"最近打算学习一下Linux知识，所以准备装个Linux虚拟机玩玩。而VirtualBox是一款免费、开源、高性能的虚拟机软件，可以跨平台运行，支持Windows、Mac、Linux等操作系统。所以我选择使用VirtualBox来安装CentOS7。","text":"最近打算学习一下Linux知识，所以准备装个Linux虚拟机玩玩。而VirtualBox是一款免费、开源、高性能的虚拟机软件，可以跨平台运行，支持Windows、Mac、Linux等操作系统。所以我选择使用VirtualBox来安装CentOS7。 Linux学习1—VirtualBox上安装CentOS7 1、安装VirtualBox 基础环境：宿主机是64位 Windows10操作系统，通过无线网访问网络。 VirtualBox的安装比较简单，此处不做说明。VirtualBox最新版下载地址：Downloads – Oracle VM VirtualBox 本次安装教程使用VirtualBox6.1版来完成 2、下载CentOS7 CentOS7下载地址：Downloads – CentOS7 我没有选择Minimal ISO（最小化安装包），因为自己比较菜，直接下载了CentOS-7.0-1406-x86_64-DVD.iso版本，4个多G。买了一本经典的LINUX课本《鸟哥的LINUX私房菜》，尽量与课本保持一致。 3、初始化虚拟机 点击新建虚拟机，依次输入名称、选择安装目录、选择虚拟机操作系统类型与具体的版本。点击下一步 根据自己的电脑配置选择合适的内存及硬盘大小依次点击下一步 选择存放位置 设置虚拟机能够使用的最大硬盘空间 点击创建就完成了初始化的操作 4、安装虚拟机 启动虚拟机，选择我们开始下载的CentOS7安装包，点击启动 时区选择上海 双击软件选择，在弹出界面中选择GNOME桌面，对于初学者比较友好。 网络选择:选择打开以太网，减少后期对网络的配置，点击完成 备注：必须完成带有黄色感叹号的内容，才能进行下一步，我们点击安装位置后直接点击确定 设置ROOT用户密码 创建一个普通用户 初始化完成进入登录页面，输入密码，即可进入CentOS桌面 注意：进入系统显示的帮助说明不是在浏览器中显示的，顶部不是地址栏 5、注意事项 刚刚安装的虚拟机显示很小，可以打开自动缩放模式，快捷键为Host+C。Host键对应于键盘右边的那个CTRL键 宿主机wifi时的虚拟机网络设置 此时虚拟机可以ping通外网，但是外网访问不到虚拟机。 网卡1连接方式为网络地址转换(nat)，用于访问外网 我们设置网卡2连接方式为仅主机(Host-Only)网络，界面名称选择virtualBox安装后自动生成的以太网卡适配器，用于与宿主机通信 此时重启CentOS虚拟机 使用**MobaXterm**连接虚拟机，输入IP地址、用户名、端口，点击OK，在打开的敞口中输入密码即完成MobaXterm连接VirtualBox 虚拟机中的 CentOS 7 至此，VirtualBox上安装CentOS7大功告成，开始学习。。。 引用文章 知乎—VirtualBox上安装CentOS7 博客园—VirtualBox下安装CentOS7系统","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"}]},{"title":"MyBatis-Plus学习(2)","slug":"MybatisPlus1","date":"2021-06-09T15:04:35.000Z","updated":"2021-06-10T16:23:12.675Z","comments":true,"path":"2021/06/09/MybatisPlus1/","link":"","permalink":"https://qinglei1989.github.io/2021/06/09/MybatisPlus1/","excerpt":"MybatisPlus常用操作的熟悉了解。快速迭代开发技巧熟悉，相关知识点总结记录。后续加入复杂查询及分页等。","text":"MybatisPlus常用操作的熟悉了解。快速迭代开发技巧熟悉，相关知识点总结记录。后续加入复杂查询及分页等。 MyBatis-Plus常用操作 1、主键查询返回实体类 School school &#x3D; schoolMapper.selectById(schoolId); &#x2F;&#x2F; 相应的控制台打印 Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@52ebdf07] was not registered for synchronization because synchronization is not active JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@4ecf9] will not be managed by Spring &#x3D;&#x3D;&gt; Preparing: SELECT id,school_name,school_address,school_icon,school_establish,create_date,create_user,update_date,update_user,is_delete FROM sys_school WHERE id&#x3D;? AND is_delete&#x3D;1 &#x3D;&#x3D;&gt; Parameters: 1(Long) &lt;&#x3D;&#x3D; Total: 0 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@52ebdf07] 2、非主键查询默认返回List QueryWrapper&lt;School&gt; queryWrapper &#x3D; new QueryWrapper&lt;&gt;(); queryWrapper.eq(&quot;school_address&quot;, &quot;44&quot;); List&lt;School&gt; schoolList &#x3D; schoolMapper.selectList(queryWrapper); &#x2F;&#x2F; 相应的控制台打印 Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@506c3bdd] was not registered for synchronization because synchronization is not active JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@6ab856dd] will not be managed by Spring &#x3D;&#x3D;&gt; Preparing: SELECT id,school_name,school_address,school_icon,school_establish,create_date,create_user,update_date,update_user,is_delete FROM sys_school WHERE is_delete&#x3D;1 AND (school_address &#x3D; ?) &#x3D;&#x3D;&gt; Parameters: 44(String) &lt;&#x3D;&#x3D; Columns: id, school_name, school_address, school_icon, school_establish, create_date, create_user, update_date, update_user, is_delete &lt;&#x3D;&#x3D; Row: 4, 44, 44, 55, 2020-09-08 03:11:11, 2021-05-26 11:43:11, 1, 2021-05-26 11:43:11, 1, 1 &lt;&#x3D;&#x3D; Row: 6, 55555, 44, 55, 2021-05-28 11:35:56, 2021-05-28 03:35:57, 1, 2021-05-28 03:35:57, 1, 1 &lt;&#x3D;&#x3D; Row: 7, 8888889, 44, 55, 2021-05-28 15:34:01, 2021-05-28 07:34:01, 1, 2021-05-28 07:34:01, 1, 1 &lt;&#x3D;&#x3D; Total: 3 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@506c3bdd] 3、非主键唯一查询 QueryWrapper&lt;School&gt; queryWrapper &#x3D; new QueryWrapper&lt;&gt;(); queryWrapper.eq(&quot;school_address&quot;, &quot;44&quot;); School schoolList &#x3D; schoolMapper.selectOne(queryWrapper); &#x2F;&#x2F;当根据查询条件返回多个结果时,系统会报异常 org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.TooManyResultsException: Expected one result (or null) to be returned by selectOne(), but found: 3 &#x2F;&#x2F;如果我们想要根据查询结果取一条的话相应的QueryWrapper拼接如下： QueryWrapper&lt;School&gt; queryWrapper &#x3D; new QueryWrapper&lt;&gt;(); queryWrapper.eq(&quot;school_address&quot;, &quot;44&quot;).last(&quot; limit 1&quot;); School schoolList &#x3D; schoolMapper.selectOne(queryWrapper); &#x2F;&#x2F; 相应的控制台打印 SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@25ba7e55] was not registered for synchronization because synchronization is not active JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@7cb406f8] will not be managed by Spring &#x3D;&#x3D;&gt; Preparing: SELECT id,school_name,school_address,school_icon,school_establish,create_date,create_user,update_date,update_user,is_delete FROM sys_school WHERE is_delete&#x3D;1 AND (school_address &#x3D; ?) limit 1 &#x3D;&#x3D;&gt; Parameters: 44(String) &lt;&#x3D;&#x3D; Columns: id, school_name, school_address, school_icon, school_establish, create_date, create_user, update_date, update_user, is_delete &lt;&#x3D;&#x3D; Row: 4, 44, 44, 55, 2020-09-08 03:11:11, 2021-05-26 11:43:11, 1, 2021-05-26 11:43:11, 1, 1 &lt;&#x3D;&#x3D; Total: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@25ba7e55] 4、查询结果返回指定列 QueryWrapper&lt;School&gt; queryWrapper &#x3D; new QueryWrapper&lt;&gt;(); queryWrapper.s elect(&quot;id, school_name, school_address&quot;).eq(&quot;school_address&quot;, &quot;44&quot;).last(&quot; limit 1&quot;); School schoolList &#x3D; schoolMapper.selectOne(queryWrapper); SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@7526927e] was not registered for synchronization because synchronization is not active JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@1afc5a20] will not be managed by Spring &#x3D;&#x3D;&gt; Preparing: SELECT id, school_name, school_address FROM sys_school WHERE is_delete&#x3D;1 AND (school_address &#x3D; ?) limit 1 &#x3D;&#x3D;&gt; Parameters: 44(String) &lt;&#x3D;&#x3D; Columns: id, school_name, school_address &lt;&#x3D;&#x3D; Row: 4, 44, 44 &lt;&#x3D;&#x3D; Total: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@7526927e] 5、查询返回自定义实体 &#x2F;&#x2F; List查询结果使用convert函数进行转换 Page&lt;School&gt; listPage &#x3D; schoolMapper.selectPage(page, queryWrapper); return listPage.convert(obj -&gt; SchoolDto.builder() .id(obj.getId()) .schoolName(obj.getSchoolName()) .schoolAddress(obj.getSchoolAddress()) .schoolIcon(obj.getSchoolIcon()) .schoolEstablish(obj.getSchoolEstablish()) .build()); &#x2F;&#x2F; 使用自定义SQL来返回自定义实体 @Select(&quot;select * from sys_school $&#123;ew.customSqlSegment&#125;&quot;) SchoolDto selectCustomById(@Param(Constants.WRAPPER) Wrapper wrapper); 6、Query封装 &#x2F;&#x2F; lamdaQuery QueryWrapper&lt;School&gt; queryWrapper &#x3D; new QueryWrapper&lt;School&gt;(); if (Optional.ofNullable(schoolVo).isPresent()) &#123; queryWrapper.lambda() .eq(StringUtils.isNotBlank(schoolVo.getSchoolName()), School::getSchoolName, schoolVo.getSchoolName()) .eq(StringUtils.isNotBlank(schoolVo.getSchoolAddress()), School::getSchoolAddress, schoolVo.getSchoolAddress()) .eq(StringUtils.isNotBlank(schoolVo.getSchoolIcon()), School::getSchoolIcon, schoolVo.getSchoolIcon()) .eq(Objects.nonNull(schoolVo.getSchoolEstablish()), School::getSchoolEstablish, schoolVo.getSchoolEstablish()); &#125; &#x2F;&#x2F; query有以下两种写法 QueryWrapper&lt;School&gt; queryWrapper &#x3D; new QueryWrapper&lt;School&gt;(); queryWrapper.eq(StringUtils.isNotBlank(schoolVo.getSchoolName()), &quot;school_name&quot;, schoolVo.getSchoolName()); if (StringUtils.isNotBlank(schoolVo.getSchoolName())) &#123; queryWrapper.eq(&quot;school_name&quot;, schoolVo.getSchoolName()); &#125;","categories":[{"name":"持久层","slug":"持久层","permalink":"https://qinglei1989.github.io/categories/%E6%8C%81%E4%B9%85%E5%B1%82/"}],"tags":[{"name":"MyBatis-Plus","slug":"MyBatis-Plus","permalink":"https://qinglei1989.github.io/tags/MyBatis-Plus/"}]},{"title":"Notepad++数据批量处理技巧","slug":"tools-notepad","date":"2021-06-04T15:14:54.000Z","updated":"2023-01-28T17:05:33.291Z","comments":true,"path":"2021/06/04/tools-notepad/","link":"","permalink":"https://qinglei1989.github.io/2021/06/04/tools-notepad/","excerpt":"Notepad++是Windows下一款很好用的文本编辑器。对于大量文本内容的查找和批量处理很高效。","text":"Notepad++是Windows下一款很好用的文本编辑器。对于大量文本内容的查找和批量处理很高效。 Notepad++实用技巧 查找操作技巧在软件开发过程中，如果我们的代码出现异常，有时候我们需要从日志中提取相应的信息，进行异常补偿。此时我们就可以使用NodePad++的批量操作来快速定位相应的关键信息（比如数据ID等)。 如下例使用Nodepad++打开日志文件，我们在日志文件中使用Ctrl+F查找关键字”axb录音发送延迟队列成功”，然后点击在当前文件中查找按钮进行快速查找。 相应的搜索结果及匹配次数就会显示在Notepad++下方的搜索结果里，如果我们需要进一步的根据搜索结果拿到全部匹配日志中的uniqueId列，我们需要将搜索结果中的记录集复制到一个新文档中继续批量操作 在新文档中，由于日志基本上都是按固定格式排列的，此时我们就可以通过批量操作快速找到我们需要使用的数据。我们依然通过快速获取全部的uniqueId列来进行举例。 批量操作技巧首先我们将光标定位在uniqueId列等号后，此时将文档下拉到尾部，在最后一行的uniqueId列等号后，按住Alt+Shift，再次点击鼠标，此时会有一条闪烁的直线在所有的uniqueId列等号后（说明操作块行选择完成），此时依然按住Alt+Shift，再次将光标定位到uniqueId列，前边完成块的选择，此时文档块为灰色选中状态。 再次按下Ctrl+C复制当前的选中块，在文档中进行黏贴，就完成了全部uniqueId的统计了。 有的时候我们需要根据这些ID来进行SQL的拼接，Nodepad++比较适合少量简单数据的SQL拼接工作，十分方便。我们将光标定位在第一行行首。在最后一行行首按住Alt+Shift，再次点击鼠标。此时会有一条闪烁的直线在所有行行首，我们直接输入语句（INSERT INTO TABLE VALUES (），它会填充到每个行。 至此Nodepad++批量操作的技巧就介绍完毕了。 切记： 先定位行，再定义列，就完成了块的选择操作 先定位行就可以完成批量插入操作 去除不必要的换行和空格有时候我们需要将多行数据转换到一行，可以通过如下操作来实现，如下，我们要将这个SQL转成一行，在Navicat中可以通过简化SQL来实现，在Notepad++中，则通过移除非必需的空白和EOL来实现。 SELECT temp.city as &#39;城市&#39;, users.&#96;name&#96; AS &#39;子账号姓名&#39;, users.mobile as &#39;子账号联系方式&#39;, users.created_at as &#39;账号创建时间&#39;, CASE when users.user_status &#x3D; 2 then &#39;禁用&#39; when users.user_status &#x3D; 3 then &#39;离职&#39; when users.user_status &#x3D; 0 then &#39;正常&#39; when users.user_status &#x3D; 1 then &#39;未激活&#39; end as &#39;账号状态&#39;, temp.group_leader_name AS &#39;主账号姓名&#39;, temp.mobile AS &#39;主账号联系方式&#39; FROM users JOIN ( SELECT gu.user_id, uc.group_leader_id, group_leader_name, uc.city, u.mobile FROM group_user gu JOIN user_city_area_group uc ON gu.group_id &#x3D; uc.id join users u on uc.group_leader_id &#x3D; u.id AND uc.city IN (&#39;长沙&#39;, &#39;广州&#39;) ) temp ON users.user_id &#x3D; temp.user_id SELECT temp.city as &#39;城市&#39;, users.&#96;name&#96; AS &#39;子账号姓名&#39;, users.mobile as &#39;子账号联系方式&#39;, users.created_at as &#39;账号创建时间&#39;, CASE when users.user_status &#x3D; 2 then &#39;禁用&#39; when users.user_status &#x3D; 3 then &#39;离职&#39; when users.user_status &#x3D; 0 then &#39;正常&#39; when users.user_status &#x3D; 1 then &#39;未激活&#39; end as &#39;账号状态&#39;, temp.group_leader_name AS &#39;主账号姓名&#39;, temp.mobile AS &#39;主账号联系方式&#39; FROM users JOIN ( SELECT gu.user_id, uc.group_leader_id, group_leader_name, uc.city, u.mobile FROM group_user gu JOIN user_city_area_group uc ON gu.group_id &#x3D; uc.id join users u on uc.group_leader_id &#x3D; u.id AND uc.city IN (&#39;长沙&#39;, &#39;广州&#39;) ) temp ON users.user_id &#x3D; temp.user_id 行列转换 行转列 Ctrl + F 选择替换 查找目标：填写指定的内容 替换为：\\r\\n 查找模式：正则表达式 单击替换或全部替换按钮 列转行 Ctrl + F 选择替换 查找目标：\\r\\n 替换为：不填写或填写指定的内容 查找模式：正则表达式 单击替换或全部替换按钮 去除多余的空行","categories":[{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"实用工具","slug":"实用工具","permalink":"https://qinglei1989.github.io/tags/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"MyBatis-Plus学习(1)","slug":"MybatisPlus0","date":"2021-06-04T12:46:25.000Z","updated":"2021-08-21T18:23:43.959Z","comments":true,"path":"2021/06/04/MybatisPlus0/","link":"","permalink":"https://qinglei1989.github.io/2021/06/04/MybatisPlus0/","excerpt":"一个Mybatis的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。","text":"一个Mybatis的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。 MyBatis-Plus了解 MyBatis-Plus特点 无侵入：只做增强不做改变，引入它不会对现有工程产生影响 损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作 强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错 支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题 支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作 支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ） 内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 代码，支持模板引擎，自定义配置 内置分页插件：基于 MyBatis 物理分页 内置性能分析插件：可输出 Sql 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询 内置全局拦截插件：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作 官方文档地址 Mybatis-Plus与Springboot整合 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;&#x2F;artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;&#x2F;artifactId&gt; &lt;&#x2F;exclusion&gt; &lt;&#x2F;exclusions&gt; &lt;&#x2F;dependency&gt; &lt;!-- druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;druid.version&#125;&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;mybatis-plus.version&#125;&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;scope&gt;compile&lt;&#x2F;scope&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;&#x2F;artifactId&gt; &lt;scope&gt;test&lt;&#x2F;scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;&#x2F;groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;&#x2F;artifactId&gt; &lt;&#x2F;exclusion&gt; &lt;&#x2F;exclusions&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;&#x2F;groupId&gt; &lt;artifactId&gt;lombok&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;&#x2F;version&gt; &lt;scope&gt;provided&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;!-- 字符串 集合类校验 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;&#x2F;groupId&gt; &lt;artifactId&gt;commons-lang3&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;commons-lang3.version&#125;&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;!-- 参数校验框架学习 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-validation&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;!-- mybatis-plus-generator --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;&#x2F;artifactId&gt; &lt;version&gt;3.3.2&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;!-- freemarker模板 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;&#x2F;groupId&gt; &lt;artifactId&gt;freemarker&lt;&#x2F;artifactId&gt; &lt;version&gt;2.3.30&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt;","categories":[{"name":"持久层","slug":"持久层","permalink":"https://qinglei1989.github.io/categories/%E6%8C%81%E4%B9%85%E5%B1%82/"}],"tags":[{"name":"MyBatis-Plus","slug":"MyBatis-Plus","permalink":"https://qinglei1989.github.io/tags/MyBatis-Plus/"}]}],"categories":[{"name":"容器","slug":"容器","permalink":"https://qinglei1989.github.io/categories/%E5%AE%B9%E5%99%A8/"},{"name":"持久层","slug":"持久层","permalink":"https://qinglei1989.github.io/categories/%E6%8C%81%E4%B9%85%E5%B1%82/"},{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"工作总结","slug":"工作总结","permalink":"https://qinglei1989.github.io/categories/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"},{"name":"开发技巧","slug":"开发技巧","permalink":"https://qinglei1989.github.io/categories/%E5%BC%80%E5%8F%91%E6%8A%80%E5%B7%A7/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://qinglei1989.github.io/categories/rabbitmq/"},{"name":"Spring","slug":"Spring","permalink":"https://qinglei1989.github.io/categories/Spring/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/categories/spring-cloud/"},{"name":"spring-cloud-alibaba","slug":"spring-cloud-alibaba","permalink":"https://qinglei1989.github.io/categories/spring-cloud-alibaba/"},{"name":"服务器","slug":"服务器","permalink":"https://qinglei1989.github.io/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"JAVA","slug":"JAVA","permalink":"https://qinglei1989.github.io/categories/JAVA/"},{"name":"数据库","slug":"数据库","permalink":"https://qinglei1989.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"操作系统","slug":"操作系统","permalink":"https://qinglei1989.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"单元测试","slug":"单元测试","permalink":"https://qinglei1989.github.io/categories/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"name":"版本控制","slug":"版本控制","permalink":"https://qinglei1989.github.io/categories/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinglei1989.github.io/tags/Docker/"},{"name":"MyBatis-Plus","slug":"MyBatis-Plus","permalink":"https://qinglei1989.github.io/tags/MyBatis-Plus/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://qinglei1989.github.io/tags/Elasticsearch/"},{"name":"工作总结","slug":"工作总结","permalink":"https://qinglei1989.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"},{"name":"Sublime Text","slug":"Sublime-Text","permalink":"https://qinglei1989.github.io/tags/Sublime-Text/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://qinglei1989.github.io/tags/MyBatis/"},{"name":"中间件","slug":"中间件","permalink":"https://qinglei1989.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"spring-boot","slug":"spring-boot","permalink":"https://qinglei1989.github.io/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qinglei1989.github.io/tags/spring-cloud/"},{"name":"nginx","slug":"nginx","permalink":"https://qinglei1989.github.io/tags/nginx/"},{"name":"JVM","slug":"JVM","permalink":"https://qinglei1989.github.io/tags/JVM/"},{"name":"Thread","slug":"Thread","permalink":"https://qinglei1989.github.io/tags/Thread/"},{"name":"mysql","slug":"mysql","permalink":"https://qinglei1989.github.io/tags/mysql/"},{"name":"jwt","slug":"jwt","permalink":"https://qinglei1989.github.io/tags/jwt/"},{"name":"Linux","slug":"Linux","permalink":"https://qinglei1989.github.io/tags/Linux/"},{"name":"postman","slug":"postman","permalink":"https://qinglei1989.github.io/tags/postman/"},{"name":"junit","slug":"junit","permalink":"https://qinglei1989.github.io/tags/junit/"},{"name":"实用工具","slug":"实用工具","permalink":"https://qinglei1989.github.io/tags/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"name":"springEL","slug":"springEL","permalink":"https://qinglei1989.github.io/tags/springEL/"},{"name":"git","slug":"git","permalink":"https://qinglei1989.github.io/tags/git/"}]}